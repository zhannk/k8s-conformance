Conformance test: not doing test setup.
I1214 08:24:23.764792    6274 e2e.go:116] Starting e2e run "9ae8086e-b003-4dc8-a6f0-714e56cd5c18" on Ginkgo node 1
Dec 14 08:24:23.776: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /go/src/k8s.io/kubernetes/platforms/linux/amd64
=====================================================================================
Random Seed: 1671006263 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Dec 14 08:24:23.869: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:24:23.870: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 14 08:24:24.000: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Dec 14 08:24:24.140: INFO: 37 / 37 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 14 08:24:24.140: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Dec 14 08:24:24.140: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'cloud-node-manager' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node-disk' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node-file' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'egress-filter-applier' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-1-v1.25.4' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-host' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-pod' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec 14 08:24:24.175: INFO: e2e test version: v1.25.4
Dec 14 08:24:24.199: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Dec 14 08:24:24.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:24:24.226: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.357 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec 14 08:24:23.869: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:24:23.870: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Dec 14 08:24:24.000: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
    Dec 14 08:24:24.140: INFO: 37 / 37 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Dec 14 08:24:24.140: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
    Dec 14 08:24:24.140: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'cloud-node-manager' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node-disk' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node-file' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'egress-filter-applier' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-1-v1.25.4' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-host' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-pod' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
    Dec 14 08:24:24.175: INFO: e2e test version: v1.25.4
    Dec 14 08:24:24.199: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec 14 08:24:24.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:24:24.226: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:24:24.254
Dec 14 08:24:24.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:24:24.255
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:24.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:24.384
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4190 12/14/22 08:24:24.435
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 08:24:24.472
STEP: creating service externalsvc in namespace services-4190 12/14/22 08:24:24.472
STEP: creating replication controller externalsvc in namespace services-4190 12/14/22 08:24:24.509
I1214 08:24:24.536799    6274 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4190, replica count: 2
I1214 08:24:27.589264    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 08:24:30.589800    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 08:24:33.591001    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 12/14/22 08:24:33.617
Dec 14 08:24:33.679: INFO: Creating new exec pod
Dec 14 08:24:33.735: INFO: Waiting up to 5m0s for pod "execpodmznht" in namespace "services-4190" to be "running"
Dec 14 08:24:33.761: INFO: Pod "execpodmznht": Phase="Pending", Reason="", readiness=false. Elapsed: 25.789876ms
Dec 14 08:24:35.788: INFO: Pod "execpodmznht": Phase="Running", Reason="", readiness=true. Elapsed: 2.053662843s
Dec 14 08:24:35.788: INFO: Pod "execpodmznht" satisfied condition "running"
Dec 14 08:24:35.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4190 exec execpodmznht -- /bin/sh -x -c nslookup clusterip-service.services-4190.svc.cluster.local'
Dec 14 08:24:36.760: INFO: stderr: "+ nslookup clusterip-service.services-4190.svc.cluster.local\n"
Dec 14 08:24:36.761: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-4190.svc.cluster.local\tcanonical name = externalsvc.services-4190.svc.cluster.local.\nName:\texternalsvc.services-4190.svc.cluster.local\nAddress: 100.110.195.20\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4190, will wait for the garbage collector to delete the pods 12/14/22 08:24:36.761
Dec 14 08:24:36.865: INFO: Deleting ReplicationController externalsvc took: 27.768948ms
Dec 14 08:24:36.967: INFO: Terminating ReplicationController externalsvc pods took: 101.090311ms
Dec 14 08:24:40.907: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:24:40.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4190" for this suite. 12/14/22 08:24:40.987
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":1,"skipped":1,"failed":0}
------------------------------
• [16.761 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:24:24.254
    Dec 14 08:24:24.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:24:24.255
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:24.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:24.384
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4190 12/14/22 08:24:24.435
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 08:24:24.472
    STEP: creating service externalsvc in namespace services-4190 12/14/22 08:24:24.472
    STEP: creating replication controller externalsvc in namespace services-4190 12/14/22 08:24:24.509
    I1214 08:24:24.536799    6274 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4190, replica count: 2
    I1214 08:24:27.589264    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 08:24:30.589800    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 08:24:33.591001    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 12/14/22 08:24:33.617
    Dec 14 08:24:33.679: INFO: Creating new exec pod
    Dec 14 08:24:33.735: INFO: Waiting up to 5m0s for pod "execpodmznht" in namespace "services-4190" to be "running"
    Dec 14 08:24:33.761: INFO: Pod "execpodmznht": Phase="Pending", Reason="", readiness=false. Elapsed: 25.789876ms
    Dec 14 08:24:35.788: INFO: Pod "execpodmznht": Phase="Running", Reason="", readiness=true. Elapsed: 2.053662843s
    Dec 14 08:24:35.788: INFO: Pod "execpodmznht" satisfied condition "running"
    Dec 14 08:24:35.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4190 exec execpodmznht -- /bin/sh -x -c nslookup clusterip-service.services-4190.svc.cluster.local'
    Dec 14 08:24:36.760: INFO: stderr: "+ nslookup clusterip-service.services-4190.svc.cluster.local\n"
    Dec 14 08:24:36.761: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-4190.svc.cluster.local\tcanonical name = externalsvc.services-4190.svc.cluster.local.\nName:\texternalsvc.services-4190.svc.cluster.local\nAddress: 100.110.195.20\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4190, will wait for the garbage collector to delete the pods 12/14/22 08:24:36.761
    Dec 14 08:24:36.865: INFO: Deleting ReplicationController externalsvc took: 27.768948ms
    Dec 14 08:24:36.967: INFO: Terminating ReplicationController externalsvc pods took: 101.090311ms
    Dec 14 08:24:40.907: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:24:40.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4190" for this suite. 12/14/22 08:24:40.987
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:24:41.016
Dec 14 08:24:41.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:24:41.017
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:41.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:41.146
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Dec 14 08:24:41.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:24:41.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-47" for this suite. 12/14/22 08:24:41.876
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":2,"skipped":9,"failed":0}
------------------------------
• [0.887 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:24:41.016
    Dec 14 08:24:41.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:24:41.017
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:41.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:41.146
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Dec 14 08:24:41.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:24:41.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-47" for this suite. 12/14/22 08:24:41.876
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:24:41.904
Dec 14 08:24:41.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 08:24:41.904
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:41.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:42.034
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 in namespace container-probe-4330 12/14/22 08:24:42.083
Dec 14 08:24:42.126: INFO: Waiting up to 5m0s for pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267" in namespace "container-probe-4330" to be "not pending"
Dec 14 08:24:42.151: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267": Phase="Pending", Reason="", readiness=false. Elapsed: 25.606409ms
Dec 14 08:24:44.178: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267": Phase="Running", Reason="", readiness=true. Elapsed: 2.052194899s
Dec 14 08:24:44.178: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267" satisfied condition "not pending"
Dec 14 08:24:44.178: INFO: Started pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 in namespace container-probe-4330
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:24:44.178
Dec 14 08:24:44.204: INFO: Initial restart count of pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 is 0
STEP: deleting the pod 12/14/22 08:28:45.461
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 08:28:45.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4330" for this suite. 12/14/22 08:28:45.546
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":3,"skipped":10,"failed":0}
------------------------------
• [243.671 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:24:41.904
    Dec 14 08:24:41.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 08:24:41.904
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:24:41.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:24:42.034
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 in namespace container-probe-4330 12/14/22 08:24:42.083
    Dec 14 08:24:42.126: INFO: Waiting up to 5m0s for pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267" in namespace "container-probe-4330" to be "not pending"
    Dec 14 08:24:42.151: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267": Phase="Pending", Reason="", readiness=false. Elapsed: 25.606409ms
    Dec 14 08:24:44.178: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267": Phase="Running", Reason="", readiness=true. Elapsed: 2.052194899s
    Dec 14 08:24:44.178: INFO: Pod "liveness-c9132817-d8fc-466d-9aaf-f861bdb77267" satisfied condition "not pending"
    Dec 14 08:24:44.178: INFO: Started pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 in namespace container-probe-4330
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:24:44.178
    Dec 14 08:24:44.204: INFO: Initial restart count of pod liveness-c9132817-d8fc-466d-9aaf-f861bdb77267 is 0
    STEP: deleting the pod 12/14/22 08:28:45.461
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 08:28:45.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4330" for this suite. 12/14/22 08:28:45.546
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:28:45.578
Dec 14 08:28:45.578: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 08:28:45.579
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:28:45.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:28:45.704
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 in namespace container-probe-126 12/14/22 08:28:45.756
Dec 14 08:28:45.807: INFO: Waiting up to 5m0s for pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150" in namespace "container-probe-126" to be "not pending"
Dec 14 08:28:45.832: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Pending", Reason="", readiness=false. Elapsed: 25.587437ms
Dec 14 08:28:47.862: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054904253s
Dec 14 08:28:49.864: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Running", Reason="", readiness=true. Elapsed: 4.056704988s
Dec 14 08:28:49.864: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150" satisfied condition "not pending"
Dec 14 08:28:49.864: INFO: Started pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 in namespace container-probe-126
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:28:49.864
Dec 14 08:28:49.893: INFO: Initial restart count of pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 is 0
STEP: deleting the pod 12/14/22 08:32:51.147
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 08:32:51.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-126" for this suite. 12/14/22 08:32:51.23
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":4,"skipped":68,"failed":0}
------------------------------
• [245.679 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:28:45.578
    Dec 14 08:28:45.578: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 08:28:45.579
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:28:45.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:28:45.704
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 in namespace container-probe-126 12/14/22 08:28:45.756
    Dec 14 08:28:45.807: INFO: Waiting up to 5m0s for pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150" in namespace "container-probe-126" to be "not pending"
    Dec 14 08:28:45.832: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Pending", Reason="", readiness=false. Elapsed: 25.587437ms
    Dec 14 08:28:47.862: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054904253s
    Dec 14 08:28:49.864: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150": Phase="Running", Reason="", readiness=true. Elapsed: 4.056704988s
    Dec 14 08:28:49.864: INFO: Pod "busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150" satisfied condition "not pending"
    Dec 14 08:28:49.864: INFO: Started pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 in namespace container-probe-126
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:28:49.864
    Dec 14 08:28:49.893: INFO: Initial restart count of pod busybox-5fbac05e-8e9a-4c1a-8a6b-f26e8b46f150 is 0
    STEP: deleting the pod 12/14/22 08:32:51.147
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 08:32:51.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-126" for this suite. 12/14/22 08:32:51.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:32:51.258
Dec 14 08:32:51.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:32:51.259
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:32:51.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:32:51.395
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 12/14/22 08:32:51.443
Dec 14 08:32:51.489: INFO: Waiting up to 5m0s for pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64" in namespace "downward-api-3154" to be "running and ready"
Dec 14 08:32:51.515: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64": Phase="Pending", Reason="", readiness=false. Elapsed: 25.6928ms
Dec 14 08:32:51.515: INFO: The phase of Pod labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:32:53.541: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64": Phase="Running", Reason="", readiness=true. Elapsed: 2.051953308s
Dec 14 08:32:53.541: INFO: The phase of Pod labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64 is Running (Ready = true)
Dec 14 08:32:53.541: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64" satisfied condition "running and ready"
Dec 14 08:32:54.199: INFO: Successfully updated pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 08:32:58.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3154" for this suite. 12/14/22 08:32:58.347
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":5,"skipped":79,"failed":0}
------------------------------
• [7.117 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:32:51.258
    Dec 14 08:32:51.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:32:51.259
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:32:51.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:32:51.395
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 12/14/22 08:32:51.443
    Dec 14 08:32:51.489: INFO: Waiting up to 5m0s for pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64" in namespace "downward-api-3154" to be "running and ready"
    Dec 14 08:32:51.515: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64": Phase="Pending", Reason="", readiness=false. Elapsed: 25.6928ms
    Dec 14 08:32:51.515: INFO: The phase of Pod labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:32:53.541: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64": Phase="Running", Reason="", readiness=true. Elapsed: 2.051953308s
    Dec 14 08:32:53.541: INFO: The phase of Pod labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64 is Running (Ready = true)
    Dec 14 08:32:53.541: INFO: Pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64" satisfied condition "running and ready"
    Dec 14 08:32:54.199: INFO: Successfully updated pod "labelsupdate1376b5d5-4943-49d8-adf9-1943d5383c64"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 08:32:58.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3154" for this suite. 12/14/22 08:32:58.347
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:32:58.375
Dec 14 08:32:58.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:32:58.376
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:32:58.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:32:58.499
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:32:58.547
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-lq4c 12/14/22 08:32:58.598
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:32:58.598
Dec 14 08:32:58.638: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lq4c" in namespace "subpath-9944" to be "Succeeded or Failed"
Dec 14 08:32:58.663: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.264054ms
Dec 14 08:33:00.690: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.051834775s
Dec 14 08:33:02.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.053022539s
Dec 14 08:33:04.689: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.051067728s
Dec 14 08:33:06.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 8.053109366s
Dec 14 08:33:08.721: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 10.082771779s
Dec 14 08:33:10.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 12.053148122s
Dec 14 08:33:12.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 14.05332724s
Dec 14 08:33:14.690: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 16.051787049s
Dec 14 08:33:16.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.052890907s
Dec 14 08:33:18.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 20.052747089s
Dec 14 08:33:20.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=false. Elapsed: 22.05286769s
Dec 14 08:33:22.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053289336s
STEP: Saw pod success 12/14/22 08:33:22.692
Dec 14 08:33:22.692: INFO: Pod "pod-subpath-test-configmap-lq4c" satisfied condition "Succeeded or Failed"
Dec 14 08:33:22.718: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-configmap-lq4c container test-container-subpath-configmap-lq4c: <nil>
STEP: delete the pod 12/14/22 08:33:22.756
Dec 14 08:33:22.794: INFO: Waiting for pod pod-subpath-test-configmap-lq4c to disappear
Dec 14 08:33:22.820: INFO: Pod pod-subpath-test-configmap-lq4c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lq4c 12/14/22 08:33:22.82
Dec 14 08:33:22.820: INFO: Deleting pod "pod-subpath-test-configmap-lq4c" in namespace "subpath-9944"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:33:22.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9944" for this suite. 12/14/22 08:33:22.894
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":6,"skipped":82,"failed":0}
------------------------------
• [24.547 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:32:58.375
    Dec 14 08:32:58.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:32:58.376
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:32:58.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:32:58.499
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:32:58.547
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-lq4c 12/14/22 08:32:58.598
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:32:58.598
    Dec 14 08:32:58.638: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lq4c" in namespace "subpath-9944" to be "Succeeded or Failed"
    Dec 14 08:32:58.663: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.264054ms
    Dec 14 08:33:00.690: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.051834775s
    Dec 14 08:33:02.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.053022539s
    Dec 14 08:33:04.689: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.051067728s
    Dec 14 08:33:06.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 8.053109366s
    Dec 14 08:33:08.721: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 10.082771779s
    Dec 14 08:33:10.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 12.053148122s
    Dec 14 08:33:12.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 14.05332724s
    Dec 14 08:33:14.690: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 16.051787049s
    Dec 14 08:33:16.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.052890907s
    Dec 14 08:33:18.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=true. Elapsed: 20.052747089s
    Dec 14 08:33:20.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Running", Reason="", readiness=false. Elapsed: 22.05286769s
    Dec 14 08:33:22.691: INFO: Pod "pod-subpath-test-configmap-lq4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053289336s
    STEP: Saw pod success 12/14/22 08:33:22.692
    Dec 14 08:33:22.692: INFO: Pod "pod-subpath-test-configmap-lq4c" satisfied condition "Succeeded or Failed"
    Dec 14 08:33:22.718: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-configmap-lq4c container test-container-subpath-configmap-lq4c: <nil>
    STEP: delete the pod 12/14/22 08:33:22.756
    Dec 14 08:33:22.794: INFO: Waiting for pod pod-subpath-test-configmap-lq4c to disappear
    Dec 14 08:33:22.820: INFO: Pod pod-subpath-test-configmap-lq4c no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-lq4c 12/14/22 08:33:22.82
    Dec 14 08:33:22.820: INFO: Deleting pod "pod-subpath-test-configmap-lq4c" in namespace "subpath-9944"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:33:22.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9944" for this suite. 12/14/22 08:33:22.894
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:33:22.923
Dec 14 08:33:22.923: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 08:33:22.924
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:23.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:23.051
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-86a90322-3f18-4d1a-a387-65b9b7e540fa 12/14/22 08:33:23.128
STEP: Creating secret with name s-test-opt-upd-908dfe59-4dd1-4588-a1ca-241f82c068fa 12/14/22 08:33:23.154
STEP: Creating the pod 12/14/22 08:33:23.182
Dec 14 08:33:23.217: INFO: Waiting up to 5m0s for pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c" in namespace "secrets-6066" to be "running and ready"
Dec 14 08:33:23.242: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.20948ms
Dec 14 08:33:23.243: INFO: The phase of Pod pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:33:25.269: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c": Phase="Running", Reason="", readiness=true. Elapsed: 2.051922336s
Dec 14 08:33:25.269: INFO: The phase of Pod pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c is Running (Ready = true)
Dec 14 08:33:25.269: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-86a90322-3f18-4d1a-a387-65b9b7e540fa 12/14/22 08:33:25.505
STEP: Updating secret s-test-opt-upd-908dfe59-4dd1-4588-a1ca-241f82c068fa 12/14/22 08:33:25.532
STEP: Creating secret with name s-test-opt-create-d10d16b7-dfe0-4d07-aa25-6d0468db9180 12/14/22 08:33:25.565
STEP: waiting to observe update in volume 12/14/22 08:33:25.591
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 08:33:29.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6066" for this suite. 12/14/22 08:33:29.929
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":7,"skipped":100,"failed":0}
------------------------------
• [7.033 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:33:22.923
    Dec 14 08:33:22.923: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 08:33:22.924
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:23.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:23.051
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-86a90322-3f18-4d1a-a387-65b9b7e540fa 12/14/22 08:33:23.128
    STEP: Creating secret with name s-test-opt-upd-908dfe59-4dd1-4588-a1ca-241f82c068fa 12/14/22 08:33:23.154
    STEP: Creating the pod 12/14/22 08:33:23.182
    Dec 14 08:33:23.217: INFO: Waiting up to 5m0s for pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c" in namespace "secrets-6066" to be "running and ready"
    Dec 14 08:33:23.242: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.20948ms
    Dec 14 08:33:23.243: INFO: The phase of Pod pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:33:25.269: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c": Phase="Running", Reason="", readiness=true. Elapsed: 2.051922336s
    Dec 14 08:33:25.269: INFO: The phase of Pod pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c is Running (Ready = true)
    Dec 14 08:33:25.269: INFO: Pod "pod-secrets-4f384048-b9ba-4bb6-9994-c423acd1f80c" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-86a90322-3f18-4d1a-a387-65b9b7e540fa 12/14/22 08:33:25.505
    STEP: Updating secret s-test-opt-upd-908dfe59-4dd1-4588-a1ca-241f82c068fa 12/14/22 08:33:25.532
    STEP: Creating secret with name s-test-opt-create-d10d16b7-dfe0-4d07-aa25-6d0468db9180 12/14/22 08:33:25.565
    STEP: waiting to observe update in volume 12/14/22 08:33:25.591
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 08:33:29.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6066" for this suite. 12/14/22 08:33:29.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:33:29.957
Dec 14 08:33:29.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 08:33:29.959
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:30.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:30.084
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-4158 12/14/22 08:33:30.133
STEP: creating a selector 12/14/22 08:33:30.133
STEP: Creating the service pods in kubernetes 12/14/22 08:33:30.133
Dec 14 08:33:30.133: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 08:33:30.250: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4158" to be "running and ready"
Dec 14 08:33:30.276: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.328915ms
Dec 14 08:33:30.276: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:33:32.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.052298524s
Dec 14 08:33:32.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:34.305: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.054149929s
Dec 14 08:33:34.305: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:36.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.052386388s
Dec 14 08:33:36.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:38.307: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.056775596s
Dec 14 08:33:38.307: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:40.305: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.054923686s
Dec 14 08:33:40.305: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:42.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.052583375s
Dec 14 08:33:42.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:44.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.052411352s
Dec 14 08:33:44.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:46.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.052223525s
Dec 14 08:33:46.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:48.304: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.053624219s
Dec 14 08:33:48.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:50.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.051690088s
Dec 14 08:33:50.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 08:33:52.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.052392958s
Dec 14 08:33:52.303: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 08:33:52.303: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 08:33:52.328: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4158" to be "running and ready"
Dec 14 08:33:52.354: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.434977ms
Dec 14 08:33:52.354: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 08:33:52.354: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 08:33:52.379
Dec 14 08:33:52.413: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4158" to be "running"
Dec 14 08:33:52.438: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.687872ms
Dec 14 08:33:54.467: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.054603658s
Dec 14 08:33:54.467: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 08:33:54.494: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 08:33:54.494: INFO: Breadth first check of 100.64.0.17 on host 10.250.0.5...
Dec 14 08:33:54.519: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.18:9080/dial?request=hostname&protocol=udp&host=100.64.0.17&port=8081&tries=1'] Namespace:pod-network-test-4158 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:33:54.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:33:54.520: INFO: ExecWithOptions: Clientset creation
Dec 14 08:33:54.520: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-4158/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.18%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.64.0.17%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 08:33:55.034: INFO: Waiting for responses: map[]
Dec 14 08:33:55.035: INFO: reached 100.64.0.17 after 0/1 tries
Dec 14 08:33:55.035: INFO: Breadth first check of 100.64.1.16 on host 10.250.0.4...
Dec 14 08:33:55.060: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.18:9080/dial?request=hostname&protocol=udp&host=100.64.1.16&port=8081&tries=1'] Namespace:pod-network-test-4158 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:33:55.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:33:55.060: INFO: ExecWithOptions: Clientset creation
Dec 14 08:33:55.060: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-4158/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.18%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.64.1.16%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 08:33:55.511: INFO: Waiting for responses: map[]
Dec 14 08:33:55.511: INFO: reached 100.64.1.16 after 0/1 tries
Dec 14 08:33:55.511: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 08:33:55.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4158" for this suite. 12/14/22 08:33:55.561
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":8,"skipped":116,"failed":0}
------------------------------
• [25.631 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:33:29.957
    Dec 14 08:33:29.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 08:33:29.959
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:30.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:30.084
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-4158 12/14/22 08:33:30.133
    STEP: creating a selector 12/14/22 08:33:30.133
    STEP: Creating the service pods in kubernetes 12/14/22 08:33:30.133
    Dec 14 08:33:30.133: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 08:33:30.250: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4158" to be "running and ready"
    Dec 14 08:33:30.276: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.328915ms
    Dec 14 08:33:30.276: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:33:32.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.052298524s
    Dec 14 08:33:32.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:34.305: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.054149929s
    Dec 14 08:33:34.305: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:36.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.052386388s
    Dec 14 08:33:36.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:38.307: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.056775596s
    Dec 14 08:33:38.307: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:40.305: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.054923686s
    Dec 14 08:33:40.305: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:42.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.052583375s
    Dec 14 08:33:42.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:44.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.052411352s
    Dec 14 08:33:44.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:46.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.052223525s
    Dec 14 08:33:46.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:48.304: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.053624219s
    Dec 14 08:33:48.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:50.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.051690088s
    Dec 14 08:33:50.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 08:33:52.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.052392958s
    Dec 14 08:33:52.303: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 08:33:52.303: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 08:33:52.328: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4158" to be "running and ready"
    Dec 14 08:33:52.354: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.434977ms
    Dec 14 08:33:52.354: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 08:33:52.354: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 08:33:52.379
    Dec 14 08:33:52.413: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4158" to be "running"
    Dec 14 08:33:52.438: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.687872ms
    Dec 14 08:33:54.467: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.054603658s
    Dec 14 08:33:54.467: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 08:33:54.494: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 08:33:54.494: INFO: Breadth first check of 100.64.0.17 on host 10.250.0.5...
    Dec 14 08:33:54.519: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.18:9080/dial?request=hostname&protocol=udp&host=100.64.0.17&port=8081&tries=1'] Namespace:pod-network-test-4158 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:33:54.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:33:54.520: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:33:54.520: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-4158/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.18%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.64.0.17%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 08:33:55.034: INFO: Waiting for responses: map[]
    Dec 14 08:33:55.035: INFO: reached 100.64.0.17 after 0/1 tries
    Dec 14 08:33:55.035: INFO: Breadth first check of 100.64.1.16 on host 10.250.0.4...
    Dec 14 08:33:55.060: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.18:9080/dial?request=hostname&protocol=udp&host=100.64.1.16&port=8081&tries=1'] Namespace:pod-network-test-4158 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:33:55.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:33:55.060: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:33:55.060: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-4158/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.18%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.64.1.16%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 08:33:55.511: INFO: Waiting for responses: map[]
    Dec 14 08:33:55.511: INFO: reached 100.64.1.16 after 0/1 tries
    Dec 14 08:33:55.511: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 08:33:55.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4158" for this suite. 12/14/22 08:33:55.561
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:33:55.589
Dec 14 08:33:55.589: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename controllerrevisions 12/14/22 08:33:55.59
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:55.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:55.714
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-hfxvl-daemon-set" 12/14/22 08:33:55.877
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:33:55.908
Dec 14 08:33:55.960: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:33:55.960: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:33:57.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:33:57.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:33:58.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:33:58.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:33:59.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:33:59.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:00.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:00.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:01.043: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:01.043: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:02.040: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:02.040: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:03.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:03.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:04.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:04.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:05.035: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:05.035: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:34:06.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 1
Dec 14 08:34:06.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:34:07.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 2
Dec 14 08:34:07.036: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-hfxvl-daemon-set
STEP: Confirm DaemonSet "e2e-hfxvl-daemon-set" successfully created with "daemonset-name=e2e-hfxvl-daemon-set" label 12/14/22 08:34:07.062
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-hfxvl-daemon-set" 12/14/22 08:34:07.116
Dec 14 08:34:07.142: INFO: Located ControllerRevision: "e2e-hfxvl-daemon-set-89b49bf4c"
STEP: Patching ControllerRevision "e2e-hfxvl-daemon-set-89b49bf4c" 12/14/22 08:34:07.17
Dec 14 08:34:07.197: INFO: e2e-hfxvl-daemon-set-89b49bf4c has been patched
STEP: Create a new ControllerRevision 12/14/22 08:34:07.197
Dec 14 08:34:07.224: INFO: Created ControllerRevision: e2e-hfxvl-daemon-set-5cfcdc9f8c
STEP: Confirm that there are two ControllerRevisions 12/14/22 08:34:07.224
Dec 14 08:34:07.224: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 08:34:07.250: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-hfxvl-daemon-set-89b49bf4c" 12/14/22 08:34:07.25
STEP: Confirm that there is only one ControllerRevision 12/14/22 08:34:07.277
Dec 14 08:34:07.277: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 08:34:07.302: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-hfxvl-daemon-set-5cfcdc9f8c" 12/14/22 08:34:07.327
Dec 14 08:34:07.379: INFO: e2e-hfxvl-daemon-set-5cfcdc9f8c has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 12/14/22 08:34:07.379
W1214 08:34:07.409822    6274 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 12/14/22 08:34:07.409
Dec 14 08:34:07.410: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 08:34:07.438: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-hfxvl-daemon-set-5cfcdc9f8c=updated" 12/14/22 08:34:07.438
STEP: Confirm that there is only one ControllerRevision 12/14/22 08:34:07.466
Dec 14 08:34:07.466: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 08:34:07.491: INFO: Found 1 ControllerRevisions
Dec 14 08:34:07.516: INFO: ControllerRevision "e2e-hfxvl-daemon-set-848665d97d" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-hfxvl-daemon-set" 12/14/22 08:34:07.542
STEP: deleting DaemonSet.extensions e2e-hfxvl-daemon-set in namespace controllerrevisions-9085, will wait for the garbage collector to delete the pods 12/14/22 08:34:07.542
Dec 14 08:34:07.646: INFO: Deleting DaemonSet.extensions e2e-hfxvl-daemon-set took: 27.224743ms
Dec 14 08:34:07.747: INFO: Terminating DaemonSet.extensions e2e-hfxvl-daemon-set pods took: 101.127058ms
Dec 14 08:34:11.373: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
Dec 14 08:34:11.373: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-hfxvl-daemon-set
Dec 14 08:34:11.403: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11601"},"items":null}

Dec 14 08:34:11.428: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11601"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:34:11.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-9085" for this suite. 12/14/22 08:34:11.534
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":9,"skipped":118,"failed":0}
------------------------------
• [15.976 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:33:55.589
    Dec 14 08:33:55.589: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename controllerrevisions 12/14/22 08:33:55.59
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:33:55.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:33:55.714
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-hfxvl-daemon-set" 12/14/22 08:33:55.877
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:33:55.908
    Dec 14 08:33:55.960: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:33:55.960: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:33:57.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:33:57.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:33:58.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:33:58.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:33:59.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:33:59.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:00.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:00.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:01.043: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:01.043: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:02.040: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:02.040: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:03.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:03.036: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:04.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:04.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:05.035: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:05.035: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:34:06.037: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 1
    Dec 14 08:34:06.037: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:34:07.036: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 2
    Dec 14 08:34:07.036: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-hfxvl-daemon-set
    STEP: Confirm DaemonSet "e2e-hfxvl-daemon-set" successfully created with "daemonset-name=e2e-hfxvl-daemon-set" label 12/14/22 08:34:07.062
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-hfxvl-daemon-set" 12/14/22 08:34:07.116
    Dec 14 08:34:07.142: INFO: Located ControllerRevision: "e2e-hfxvl-daemon-set-89b49bf4c"
    STEP: Patching ControllerRevision "e2e-hfxvl-daemon-set-89b49bf4c" 12/14/22 08:34:07.17
    Dec 14 08:34:07.197: INFO: e2e-hfxvl-daemon-set-89b49bf4c has been patched
    STEP: Create a new ControllerRevision 12/14/22 08:34:07.197
    Dec 14 08:34:07.224: INFO: Created ControllerRevision: e2e-hfxvl-daemon-set-5cfcdc9f8c
    STEP: Confirm that there are two ControllerRevisions 12/14/22 08:34:07.224
    Dec 14 08:34:07.224: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 08:34:07.250: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-hfxvl-daemon-set-89b49bf4c" 12/14/22 08:34:07.25
    STEP: Confirm that there is only one ControllerRevision 12/14/22 08:34:07.277
    Dec 14 08:34:07.277: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 08:34:07.302: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-hfxvl-daemon-set-5cfcdc9f8c" 12/14/22 08:34:07.327
    Dec 14 08:34:07.379: INFO: e2e-hfxvl-daemon-set-5cfcdc9f8c has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 12/14/22 08:34:07.379
    W1214 08:34:07.409822    6274 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 12/14/22 08:34:07.409
    Dec 14 08:34:07.410: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 08:34:07.438: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-hfxvl-daemon-set-5cfcdc9f8c=updated" 12/14/22 08:34:07.438
    STEP: Confirm that there is only one ControllerRevision 12/14/22 08:34:07.466
    Dec 14 08:34:07.466: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 08:34:07.491: INFO: Found 1 ControllerRevisions
    Dec 14 08:34:07.516: INFO: ControllerRevision "e2e-hfxvl-daemon-set-848665d97d" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-hfxvl-daemon-set" 12/14/22 08:34:07.542
    STEP: deleting DaemonSet.extensions e2e-hfxvl-daemon-set in namespace controllerrevisions-9085, will wait for the garbage collector to delete the pods 12/14/22 08:34:07.542
    Dec 14 08:34:07.646: INFO: Deleting DaemonSet.extensions e2e-hfxvl-daemon-set took: 27.224743ms
    Dec 14 08:34:07.747: INFO: Terminating DaemonSet.extensions e2e-hfxvl-daemon-set pods took: 101.127058ms
    Dec 14 08:34:11.373: INFO: Number of nodes with available pods controlled by daemonset e2e-hfxvl-daemon-set: 0
    Dec 14 08:34:11.373: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-hfxvl-daemon-set
    Dec 14 08:34:11.403: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11601"},"items":null}

    Dec 14 08:34:11.428: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11601"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:34:11.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-9085" for this suite. 12/14/22 08:34:11.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:11.565
Dec 14 08:34:11.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 08:34:11.566
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:11.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:11.69
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 12/14/22 08:34:11.738
STEP: patching the Namespace 12/14/22 08:34:11.815
STEP: get the Namespace and ensuring it has the label 12/14/22 08:34:11.845
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:34:11.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2110" for this suite. 12/14/22 08:34:11.897
STEP: Destroying namespace "nspatchtest-c1104db5-c1e2-4555-bcf0-96fb1664d408-8257" for this suite. 12/14/22 08:34:11.924
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":10,"skipped":126,"failed":0}
------------------------------
• [0.386 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:11.565
    Dec 14 08:34:11.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 08:34:11.566
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:11.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:11.69
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 12/14/22 08:34:11.738
    STEP: patching the Namespace 12/14/22 08:34:11.815
    STEP: get the Namespace and ensuring it has the label 12/14/22 08:34:11.845
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:34:11.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2110" for this suite. 12/14/22 08:34:11.897
    STEP: Destroying namespace "nspatchtest-c1104db5-c1e2-4555-bcf0-96fb1664d408-8257" for this suite. 12/14/22 08:34:11.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:11.951
Dec 14 08:34:11.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 08:34:11.952
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:12.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:12.078
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Dec 14 08:34:12.126: INFO: Creating pod...
Dec 14 08:34:12.161: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7357" to be "running"
Dec 14 08:34:12.187: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 25.912016ms
Dec 14 08:34:14.214: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053010312s
Dec 14 08:34:14.214: INFO: Pod "agnhost" satisfied condition "running"
Dec 14 08:34:14.214: INFO: Creating service...
Dec 14 08:34:14.255: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=DELETE
Dec 14 08:34:14.385: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 08:34:14.386: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=OPTIONS
Dec 14 08:34:14.430: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 08:34:14.430: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=PATCH
Dec 14 08:34:14.460: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 08:34:14.460: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=POST
Dec 14 08:34:14.490: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 08:34:14.490: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=PUT
Dec 14 08:34:14.524: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 08:34:14.524: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=DELETE
Dec 14 08:34:14.560: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 08:34:14.560: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=OPTIONS
Dec 14 08:34:14.591: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 08:34:14.591: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=PATCH
Dec 14 08:34:14.621: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 08:34:14.621: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=POST
Dec 14 08:34:14.654: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 08:34:14.654: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=PUT
Dec 14 08:34:14.684: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 08:34:14.684: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=GET
Dec 14 08:34:14.710: INFO: http.Client request:GET StatusCode:301
Dec 14 08:34:14.710: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=GET
Dec 14 08:34:14.746: INFO: http.Client request:GET StatusCode:301
Dec 14 08:34:14.746: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=HEAD
Dec 14 08:34:14.771: INFO: http.Client request:HEAD StatusCode:301
Dec 14 08:34:14.771: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=HEAD
Dec 14 08:34:14.798: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 08:34:14.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7357" for this suite. 12/14/22 08:34:14.849
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":11,"skipped":133,"failed":0}
------------------------------
• [2.928 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:11.951
    Dec 14 08:34:11.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 08:34:11.952
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:12.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:12.078
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Dec 14 08:34:12.126: INFO: Creating pod...
    Dec 14 08:34:12.161: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7357" to be "running"
    Dec 14 08:34:12.187: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 25.912016ms
    Dec 14 08:34:14.214: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053010312s
    Dec 14 08:34:14.214: INFO: Pod "agnhost" satisfied condition "running"
    Dec 14 08:34:14.214: INFO: Creating service...
    Dec 14 08:34:14.255: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=DELETE
    Dec 14 08:34:14.385: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 08:34:14.386: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=OPTIONS
    Dec 14 08:34:14.430: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 08:34:14.430: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=PATCH
    Dec 14 08:34:14.460: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 08:34:14.460: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=POST
    Dec 14 08:34:14.490: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 08:34:14.490: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=PUT
    Dec 14 08:34:14.524: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 08:34:14.524: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=DELETE
    Dec 14 08:34:14.560: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 08:34:14.560: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Dec 14 08:34:14.591: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 08:34:14.591: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=PATCH
    Dec 14 08:34:14.621: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 08:34:14.621: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=POST
    Dec 14 08:34:14.654: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 08:34:14.654: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=PUT
    Dec 14 08:34:14.684: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 08:34:14.684: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=GET
    Dec 14 08:34:14.710: INFO: http.Client request:GET StatusCode:301
    Dec 14 08:34:14.710: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=GET
    Dec 14 08:34:14.746: INFO: http.Client request:GET StatusCode:301
    Dec 14 08:34:14.746: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/pods/agnhost/proxy?method=HEAD
    Dec 14 08:34:14.771: INFO: http.Client request:HEAD StatusCode:301
    Dec 14 08:34:14.771: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-7357/services/e2e-proxy-test-service/proxy?method=HEAD
    Dec 14 08:34:14.798: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 08:34:14.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7357" for this suite. 12/14/22 08:34:14.849
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:14.88
Dec 14 08:34:14.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:34:14.881
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:14.959
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:15.013
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 08:34:15.061
Dec 14 08:34:15.097: INFO: Waiting up to 5m0s for pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440" in namespace "emptydir-6332" to be "Succeeded or Failed"
Dec 14 08:34:15.123: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Pending", Reason="", readiness=false. Elapsed: 26.685773ms
Dec 14 08:34:17.152: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Running", Reason="", readiness=true. Elapsed: 2.055475125s
Dec 14 08:34:19.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Running", Reason="", readiness=false. Elapsed: 4.05379241s
Dec 14 08:34:21.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054094073s
STEP: Saw pod success 12/14/22 08:34:21.151
Dec 14 08:34:21.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440" satisfied condition "Succeeded or Failed"
Dec 14 08:34:21.176: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 container test-container: <nil>
STEP: delete the pod 12/14/22 08:34:21.208
Dec 14 08:34:21.242: INFO: Waiting for pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 to disappear
Dec 14 08:34:21.268: INFO: Pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:34:21.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6332" for this suite. 12/14/22 08:34:21.317
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":12,"skipped":154,"failed":0}
------------------------------
• [6.464 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:14.88
    Dec 14 08:34:14.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:34:14.881
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:14.959
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:15.013
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 08:34:15.061
    Dec 14 08:34:15.097: INFO: Waiting up to 5m0s for pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440" in namespace "emptydir-6332" to be "Succeeded or Failed"
    Dec 14 08:34:15.123: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Pending", Reason="", readiness=false. Elapsed: 26.685773ms
    Dec 14 08:34:17.152: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Running", Reason="", readiness=true. Elapsed: 2.055475125s
    Dec 14 08:34:19.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Running", Reason="", readiness=false. Elapsed: 4.05379241s
    Dec 14 08:34:21.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054094073s
    STEP: Saw pod success 12/14/22 08:34:21.151
    Dec 14 08:34:21.151: INFO: Pod "pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440" satisfied condition "Succeeded or Failed"
    Dec 14 08:34:21.176: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 container test-container: <nil>
    STEP: delete the pod 12/14/22 08:34:21.208
    Dec 14 08:34:21.242: INFO: Waiting for pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 to disappear
    Dec 14 08:34:21.268: INFO: Pod pod-36b0108f-ad89-4ad8-aa10-ee27de1dd440 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:34:21.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6332" for this suite. 12/14/22 08:34:21.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:21.345
Dec 14 08:34:21.345: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:34:21.346
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:21.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:21.469
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 08:34:21.523
Dec 14 08:34:21.555: INFO: Waiting up to 5m0s for pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e" in namespace "emptydir-8659" to be "Succeeded or Failed"
Dec 14 08:34:21.581: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.224237ms
Dec 14 08:34:23.607: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051436834s
Dec 14 08:34:25.608: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052288179s
STEP: Saw pod success 12/14/22 08:34:25.608
Dec 14 08:34:25.608: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e" satisfied condition "Succeeded or Failed"
Dec 14 08:34:25.634: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-ef822a8c-e60e-4724-8dca-60df0881157e container test-container: <nil>
STEP: delete the pod 12/14/22 08:34:25.668
Dec 14 08:34:25.702: INFO: Waiting for pod pod-ef822a8c-e60e-4724-8dca-60df0881157e to disappear
Dec 14 08:34:25.727: INFO: Pod pod-ef822a8c-e60e-4724-8dca-60df0881157e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:34:25.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8659" for this suite. 12/14/22 08:34:25.775
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":13,"skipped":161,"failed":0}
------------------------------
• [4.457 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:21.345
    Dec 14 08:34:21.345: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:34:21.346
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:21.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:21.469
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 08:34:21.523
    Dec 14 08:34:21.555: INFO: Waiting up to 5m0s for pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e" in namespace "emptydir-8659" to be "Succeeded or Failed"
    Dec 14 08:34:21.581: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.224237ms
    Dec 14 08:34:23.607: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051436834s
    Dec 14 08:34:25.608: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052288179s
    STEP: Saw pod success 12/14/22 08:34:25.608
    Dec 14 08:34:25.608: INFO: Pod "pod-ef822a8c-e60e-4724-8dca-60df0881157e" satisfied condition "Succeeded or Failed"
    Dec 14 08:34:25.634: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-ef822a8c-e60e-4724-8dca-60df0881157e container test-container: <nil>
    STEP: delete the pod 12/14/22 08:34:25.668
    Dec 14 08:34:25.702: INFO: Waiting for pod pod-ef822a8c-e60e-4724-8dca-60df0881157e to disappear
    Dec 14 08:34:25.727: INFO: Pod pod-ef822a8c-e60e-4724-8dca-60df0881157e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:34:25.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8659" for this suite. 12/14/22 08:34:25.775
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:25.803
Dec 14 08:34:25.804: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context 12/14/22 08:34:25.804
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:25.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:25.928
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 08:34:25.976
Dec 14 08:34:26.008: INFO: Waiting up to 5m0s for pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223" in namespace "security-context-9585" to be "Succeeded or Failed"
Dec 14 08:34:26.035: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Pending", Reason="", readiness=false. Elapsed: 27.087782ms
Dec 14 08:34:28.062: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05327269s
Dec 14 08:34:30.062: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054031012s
STEP: Saw pod success 12/14/22 08:34:30.062
Dec 14 08:34:30.063: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223" satisfied condition "Succeeded or Failed"
Dec 14 08:34:30.090: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 container test-container: <nil>
STEP: delete the pod 12/14/22 08:34:30.121
Dec 14 08:34:30.153: INFO: Waiting for pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 to disappear
Dec 14 08:34:30.179: INFO: Pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:34:30.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-9585" for this suite. 12/14/22 08:34:30.228
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":14,"skipped":186,"failed":0}
------------------------------
• [4.451 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:25.803
    Dec 14 08:34:25.804: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context 12/14/22 08:34:25.804
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:25.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:25.928
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 08:34:25.976
    Dec 14 08:34:26.008: INFO: Waiting up to 5m0s for pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223" in namespace "security-context-9585" to be "Succeeded or Failed"
    Dec 14 08:34:26.035: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Pending", Reason="", readiness=false. Elapsed: 27.087782ms
    Dec 14 08:34:28.062: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05327269s
    Dec 14 08:34:30.062: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054031012s
    STEP: Saw pod success 12/14/22 08:34:30.062
    Dec 14 08:34:30.063: INFO: Pod "security-context-5b662ab8-3c10-483d-b639-9bc57d391223" satisfied condition "Succeeded or Failed"
    Dec 14 08:34:30.090: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 container test-container: <nil>
    STEP: delete the pod 12/14/22 08:34:30.121
    Dec 14 08:34:30.153: INFO: Waiting for pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 to disappear
    Dec 14 08:34:30.179: INFO: Pod security-context-5b662ab8-3c10-483d-b639-9bc57d391223 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:34:30.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-9585" for this suite. 12/14/22 08:34:30.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:30.256
Dec 14 08:34:30.256: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 08:34:30.257
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:30.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:30.381
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Dec 14 08:34:30.514: INFO: created pod pod-service-account-defaultsa
Dec 14 08:34:30.514: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 14 08:34:30.548: INFO: created pod pod-service-account-mountsa
Dec 14 08:34:30.548: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 14 08:34:30.577: INFO: created pod pod-service-account-nomountsa
Dec 14 08:34:30.577: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 14 08:34:30.606: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 14 08:34:30.606: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 14 08:34:30.636: INFO: created pod pod-service-account-mountsa-mountspec
Dec 14 08:34:30.636: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 14 08:34:30.665: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 14 08:34:30.665: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 14 08:34:30.694: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 14 08:34:30.694: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 14 08:34:30.722: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 14 08:34:30.722: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 14 08:34:30.751: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 14 08:34:30.751: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 08:34:30.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4316" for this suite. 12/14/22 08:34:30.782
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":15,"skipped":214,"failed":0}
------------------------------
• [0.552 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:30.256
    Dec 14 08:34:30.256: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 08:34:30.257
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:30.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:30.381
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Dec 14 08:34:30.514: INFO: created pod pod-service-account-defaultsa
    Dec 14 08:34:30.514: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Dec 14 08:34:30.548: INFO: created pod pod-service-account-mountsa
    Dec 14 08:34:30.548: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Dec 14 08:34:30.577: INFO: created pod pod-service-account-nomountsa
    Dec 14 08:34:30.577: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Dec 14 08:34:30.606: INFO: created pod pod-service-account-defaultsa-mountspec
    Dec 14 08:34:30.606: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Dec 14 08:34:30.636: INFO: created pod pod-service-account-mountsa-mountspec
    Dec 14 08:34:30.636: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Dec 14 08:34:30.665: INFO: created pod pod-service-account-nomountsa-mountspec
    Dec 14 08:34:30.665: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Dec 14 08:34:30.694: INFO: created pod pod-service-account-defaultsa-nomountspec
    Dec 14 08:34:30.694: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Dec 14 08:34:30.722: INFO: created pod pod-service-account-mountsa-nomountspec
    Dec 14 08:34:30.722: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Dec 14 08:34:30.751: INFO: created pod pod-service-account-nomountsa-nomountspec
    Dec 14 08:34:30.751: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 08:34:30.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4316" for this suite. 12/14/22 08:34:30.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:30.809
Dec 14 08:34:30.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 08:34:30.809
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:30.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:30.934
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Dec 14 08:34:31.016: INFO: Waiting up to 2m0s for pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" in namespace "var-expansion-3212" to be "container 0 failed with reason CreateContainerConfigError"
Dec 14 08:34:31.041: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.05521ms
Dec 14 08:34:33.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051542961s
Dec 14 08:34:35.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051482151s
Dec 14 08:34:35.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec 14 08:34:35.067: INFO: Deleting pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" in namespace "var-expansion-3212"
Dec 14 08:34:35.096: INFO: Wait up to 5m0s for pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 08:34:37.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3212" for this suite. 12/14/22 08:34:37.201
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":16,"skipped":225,"failed":0}
------------------------------
• [6.420 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:30.809
    Dec 14 08:34:30.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 08:34:30.809
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:30.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:30.934
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Dec 14 08:34:31.016: INFO: Waiting up to 2m0s for pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" in namespace "var-expansion-3212" to be "container 0 failed with reason CreateContainerConfigError"
    Dec 14 08:34:31.041: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.05521ms
    Dec 14 08:34:33.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051542961s
    Dec 14 08:34:35.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051482151s
    Dec 14 08:34:35.067: INFO: Pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec 14 08:34:35.067: INFO: Deleting pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" in namespace "var-expansion-3212"
    Dec 14 08:34:35.096: INFO: Wait up to 5m0s for pod "var-expansion-02e8c698-8c50-401e-9e92-e7b86c05f3b3" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 08:34:37.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3212" for this suite. 12/14/22 08:34:37.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:37.23
Dec 14 08:34:37.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 08:34:37.231
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:37.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:37.362
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Dec 14 08:34:37.445: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa" in namespace "security-context-test-1441" to be "Succeeded or Failed"
Dec 14 08:34:37.471: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 25.6632ms
Dec 14 08:34:39.498: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052263113s
Dec 14 08:34:41.499: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053463102s
Dec 14 08:34:41.499: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:34:41.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1441" for this suite. 12/14/22 08:34:41.553
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":17,"skipped":243,"failed":0}
------------------------------
• [4.351 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:37.23
    Dec 14 08:34:37.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 08:34:37.231
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:37.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:37.362
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Dec 14 08:34:37.445: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa" in namespace "security-context-test-1441" to be "Succeeded or Failed"
    Dec 14 08:34:37.471: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 25.6632ms
    Dec 14 08:34:39.498: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052263113s
    Dec 14 08:34:41.499: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053463102s
    Dec 14 08:34:41.499: INFO: Pod "busybox-readonly-false-47159adf-c662-470f-a427-e3a7acb4e6fa" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:34:41.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1441" for this suite. 12/14/22 08:34:41.553
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:41.581
Dec 14 08:34:41.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 08:34:41.582
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:41.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:41.711
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Dec 14 08:34:41.793: INFO: Waiting up to 5m0s for pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963" in namespace "pods-4443" to be "running and ready"
Dec 14 08:34:41.823: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963": Phase="Pending", Reason="", readiness=false. Elapsed: 30.18177ms
Dec 14 08:34:41.823: INFO: The phase of Pod server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:34:43.853: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963": Phase="Running", Reason="", readiness=true. Elapsed: 2.060440547s
Dec 14 08:34:43.853: INFO: The phase of Pod server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963 is Running (Ready = true)
Dec 14 08:34:43.853: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963" satisfied condition "running and ready"
Dec 14 08:34:43.945: INFO: Waiting up to 5m0s for pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f" in namespace "pods-4443" to be "Succeeded or Failed"
Dec 14 08:34:43.970: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.079643ms
Dec 14 08:34:45.997: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05173987s
Dec 14 08:34:47.999: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053345841s
STEP: Saw pod success 12/14/22 08:34:47.999
Dec 14 08:34:47.999: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f" satisfied condition "Succeeded or Failed"
Dec 14 08:34:48.024: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f container env3cont: <nil>
STEP: delete the pod 12/14/22 08:34:48.058
Dec 14 08:34:48.090: INFO: Waiting for pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f to disappear
Dec 14 08:34:48.116: INFO: Pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 08:34:48.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4443" for this suite. 12/14/22 08:34:48.165
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":18,"skipped":251,"failed":0}
------------------------------
• [6.611 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:41.581
    Dec 14 08:34:41.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 08:34:41.582
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:41.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:41.711
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Dec 14 08:34:41.793: INFO: Waiting up to 5m0s for pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963" in namespace "pods-4443" to be "running and ready"
    Dec 14 08:34:41.823: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963": Phase="Pending", Reason="", readiness=false. Elapsed: 30.18177ms
    Dec 14 08:34:41.823: INFO: The phase of Pod server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:34:43.853: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963": Phase="Running", Reason="", readiness=true. Elapsed: 2.060440547s
    Dec 14 08:34:43.853: INFO: The phase of Pod server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963 is Running (Ready = true)
    Dec 14 08:34:43.853: INFO: Pod "server-envvars-8a8797b0-f59b-4a2b-9d6a-5d4f22390963" satisfied condition "running and ready"
    Dec 14 08:34:43.945: INFO: Waiting up to 5m0s for pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f" in namespace "pods-4443" to be "Succeeded or Failed"
    Dec 14 08:34:43.970: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.079643ms
    Dec 14 08:34:45.997: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05173987s
    Dec 14 08:34:47.999: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053345841s
    STEP: Saw pod success 12/14/22 08:34:47.999
    Dec 14 08:34:47.999: INFO: Pod "client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f" satisfied condition "Succeeded or Failed"
    Dec 14 08:34:48.024: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f container env3cont: <nil>
    STEP: delete the pod 12/14/22 08:34:48.058
    Dec 14 08:34:48.090: INFO: Waiting for pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f to disappear
    Dec 14 08:34:48.116: INFO: Pod client-envvars-6be366c3-26f0-4a19-8496-68a91e9ee70f no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 08:34:48.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4443" for this suite. 12/14/22 08:34:48.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:48.193
Dec 14 08:34:48.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:34:48.194
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:48.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:48.318
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:34:48.366
Dec 14 08:34:48.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82" in namespace "downward-api-492" to be "Succeeded or Failed"
Dec 14 08:34:48.434: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Pending", Reason="", readiness=false. Elapsed: 30.745299ms
Dec 14 08:34:50.461: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Running", Reason="", readiness=false. Elapsed: 2.057742274s
Dec 14 08:34:52.460: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057488217s
STEP: Saw pod success 12/14/22 08:34:52.46
Dec 14 08:34:52.460: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82" satisfied condition "Succeeded or Failed"
Dec 14 08:34:52.486: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 container client-container: <nil>
STEP: delete the pod 12/14/22 08:34:52.518
Dec 14 08:34:52.556: INFO: Waiting for pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 to disappear
Dec 14 08:34:52.582: INFO: Pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 08:34:52.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-492" for this suite. 12/14/22 08:34:52.631
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":19,"skipped":273,"failed":0}
------------------------------
• [4.469 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:48.193
    Dec 14 08:34:48.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:34:48.194
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:48.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:48.318
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:34:48.366
    Dec 14 08:34:48.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82" in namespace "downward-api-492" to be "Succeeded or Failed"
    Dec 14 08:34:48.434: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Pending", Reason="", readiness=false. Elapsed: 30.745299ms
    Dec 14 08:34:50.461: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Running", Reason="", readiness=false. Elapsed: 2.057742274s
    Dec 14 08:34:52.460: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057488217s
    STEP: Saw pod success 12/14/22 08:34:52.46
    Dec 14 08:34:52.460: INFO: Pod "downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82" satisfied condition "Succeeded or Failed"
    Dec 14 08:34:52.486: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:34:52.518
    Dec 14 08:34:52.556: INFO: Waiting for pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 to disappear
    Dec 14 08:34:52.582: INFO: Pod downwardapi-volume-4c8bed61-4e65-435b-860f-283e6ed60b82 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 08:34:52.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-492" for this suite. 12/14/22 08:34:52.631
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:52.662
Dec 14 08:34:52.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sysctl 12/14/22 08:34:52.663
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:52.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:52.798
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/14/22 08:34:52.852
STEP: Watching for error events or started pod 12/14/22 08:34:52.884
STEP: Waiting for pod completion 12/14/22 08:34:54.912
Dec 14 08:34:54.912: INFO: Waiting up to 3m0s for pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c" in namespace "sysctl-5910" to be "completed"
Dec 14 08:34:54.938: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.628821ms
Dec 14 08:34:56.965: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052632907s
Dec 14 08:34:56.965: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c" satisfied condition "completed"
STEP: Checking that the pod succeeded 12/14/22 08:34:56.992
STEP: Getting logs from the pod 12/14/22 08:34:56.992
STEP: Checking that the sysctl is actually updated 12/14/22 08:34:57.078
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:34:57.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5910" for this suite. 12/14/22 08:34:57.127
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":20,"skipped":286,"failed":0}
------------------------------
• [4.492 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:52.662
    Dec 14 08:34:52.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sysctl 12/14/22 08:34:52.663
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:52.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:52.798
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/14/22 08:34:52.852
    STEP: Watching for error events or started pod 12/14/22 08:34:52.884
    STEP: Waiting for pod completion 12/14/22 08:34:54.912
    Dec 14 08:34:54.912: INFO: Waiting up to 3m0s for pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c" in namespace "sysctl-5910" to be "completed"
    Dec 14 08:34:54.938: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.628821ms
    Dec 14 08:34:56.965: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052632907s
    Dec 14 08:34:56.965: INFO: Pod "sysctl-00c7f72f-ce8d-45df-8104-4d6136a3f25c" satisfied condition "completed"
    STEP: Checking that the pod succeeded 12/14/22 08:34:56.992
    STEP: Getting logs from the pod 12/14/22 08:34:56.992
    STEP: Checking that the sysctl is actually updated 12/14/22 08:34:57.078
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:34:57.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5910" for this suite. 12/14/22 08:34:57.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:34:57.155
Dec 14 08:34:57.155: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 08:34:57.156
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:57.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:57.282
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 12/14/22 08:34:57.331
STEP: wait for the container to reach Succeeded 12/14/22 08:34:57.363
STEP: get the container status 12/14/22 08:35:01.512
STEP: the container should be terminated 12/14/22 08:35:01.538
STEP: the termination message should be set 12/14/22 08:35:01.539
Dec 14 08:35:01.539: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 12/14/22 08:35:01.539
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 08:35:01.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2299" for this suite. 12/14/22 08:35:01.644
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":21,"skipped":294,"failed":0}
------------------------------
• [4.517 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:34:57.155
    Dec 14 08:34:57.155: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 08:34:57.156
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:34:57.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:34:57.282
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 12/14/22 08:34:57.331
    STEP: wait for the container to reach Succeeded 12/14/22 08:34:57.363
    STEP: get the container status 12/14/22 08:35:01.512
    STEP: the container should be terminated 12/14/22 08:35:01.538
    STEP: the termination message should be set 12/14/22 08:35:01.539
    Dec 14 08:35:01.539: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 12/14/22 08:35:01.539
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 08:35:01.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-2299" for this suite. 12/14/22 08:35:01.644
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:01.673
Dec 14 08:35:01.673: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:35:01.674
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:01.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:01.799
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 08:35:01.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2058" for this suite. 12/14/22 08:35:01.937
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":22,"skipped":296,"failed":0}
------------------------------
• [0.304 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:01.673
    Dec 14 08:35:01.673: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:35:01.674
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:01.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:01.799
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 08:35:01.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2058" for this suite. 12/14/22 08:35:01.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:01.978
Dec 14 08:35:01.978: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:35:01.979
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:02.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:02.102
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 12/14/22 08:35:02.151
Dec 14 08:35:02.151: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 create -f -'
Dec 14 08:35:03.168: INFO: stderr: ""
Dec 14 08:35:03.168: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 12/14/22 08:35:03.168
Dec 14 08:35:03.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 diff -f -'
Dec 14 08:35:03.509: INFO: rc: 1
Dec 14 08:35:03.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 delete -f -'
Dec 14 08:35:03.687: INFO: stderr: ""
Dec 14 08:35:03.687: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:35:03.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4512" for this suite. 12/14/22 08:35:03.736
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":23,"skipped":322,"failed":0}
------------------------------
• [1.785 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:01.978
    Dec 14 08:35:01.978: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:35:01.979
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:02.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:02.102
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 12/14/22 08:35:02.151
    Dec 14 08:35:02.151: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 create -f -'
    Dec 14 08:35:03.168: INFO: stderr: ""
    Dec 14 08:35:03.168: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 12/14/22 08:35:03.168
    Dec 14 08:35:03.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 diff -f -'
    Dec 14 08:35:03.509: INFO: rc: 1
    Dec 14 08:35:03.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4512 delete -f -'
    Dec 14 08:35:03.687: INFO: stderr: ""
    Dec 14 08:35:03.687: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:35:03.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4512" for this suite. 12/14/22 08:35:03.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:03.764
Dec 14 08:35:03.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:35:03.764
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:03.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:03.896
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 12/14/22 08:35:03.944
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/14/22 08:35:03.968
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 08:35:03.968
STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/14/22 08:35:03.968
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/14/22 08:35:03.992
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:35:03.992
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:35:04.016
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:35:04.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8783" for this suite. 12/14/22 08:35:04.045
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":24,"skipped":327,"failed":0}
------------------------------
• [0.307 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:03.764
    Dec 14 08:35:03.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:35:03.764
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:03.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:03.896
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 12/14/22 08:35:03.944
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/14/22 08:35:03.968
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 08:35:03.968
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/14/22 08:35:03.968
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/14/22 08:35:03.992
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:35:03.992
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:35:04.016
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:35:04.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8783" for this suite. 12/14/22 08:35:04.045
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:04.073
Dec 14 08:35:04.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:35:04.074
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:04.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:04.198
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-f402314d-5a51-4c99-9104-d90b25794a3f 12/14/22 08:35:04.273
STEP: Creating the pod 12/14/22 08:35:04.299
Dec 14 08:35:04.334: INFO: Waiting up to 5m0s for pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3" in namespace "configmap-7064" to be "running"
Dec 14 08:35:04.359: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.490495ms
Dec 14 08:35:06.387: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3": Phase="Running", Reason="", readiness=false. Elapsed: 2.052877555s
Dec 14 08:35:06.387: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3" satisfied condition "running"
STEP: Waiting for pod with text data 12/14/22 08:35:06.387
STEP: Waiting for pod with binary data 12/14/22 08:35:06.424
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:35:06.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7064" for this suite. 12/14/22 08:35:06.56
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":25,"skipped":372,"failed":0}
------------------------------
• [2.514 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:04.073
    Dec 14 08:35:04.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:35:04.074
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:04.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:04.198
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-f402314d-5a51-4c99-9104-d90b25794a3f 12/14/22 08:35:04.273
    STEP: Creating the pod 12/14/22 08:35:04.299
    Dec 14 08:35:04.334: INFO: Waiting up to 5m0s for pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3" in namespace "configmap-7064" to be "running"
    Dec 14 08:35:04.359: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.490495ms
    Dec 14 08:35:06.387: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3": Phase="Running", Reason="", readiness=false. Elapsed: 2.052877555s
    Dec 14 08:35:06.387: INFO: Pod "pod-configmaps-730e38cd-9d16-454e-899d-d3b011d393e3" satisfied condition "running"
    STEP: Waiting for pod with text data 12/14/22 08:35:06.387
    STEP: Waiting for pod with binary data 12/14/22 08:35:06.424
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:35:06.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7064" for this suite. 12/14/22 08:35:06.56
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:06.588
Dec 14 08:35:06.588: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 08:35:06.589
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:06.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:06.722
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 12/14/22 08:35:06.77
STEP: waiting for pod running 12/14/22 08:35:06.805
Dec 14 08:35:06.805: INFO: Waiting up to 2m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105" to be "running"
Dec 14 08:35:06.832: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.973212ms
Dec 14 08:35:08.859: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.053565129s
Dec 14 08:35:08.859: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" satisfied condition "running"
STEP: creating a file in subpath 12/14/22 08:35:08.859
Dec 14 08:35:08.885: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2105 PodName:var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:35:08.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:35:08.885: INFO: ExecWithOptions: Clientset creation
Dec 14 08:35:08.885: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-2105/pods/var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 12/14/22 08:35:09.294
Dec 14 08:35:09.321: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2105 PodName:var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:35:09.321: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:35:09.322: INFO: ExecWithOptions: Clientset creation
Dec 14 08:35:09.322: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-2105/pods/var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 12/14/22 08:35:09.719
Dec 14 08:35:10.276: INFO: Successfully updated pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e"
STEP: waiting for annotated pod running 12/14/22 08:35:10.276
Dec 14 08:35:10.277: INFO: Waiting up to 2m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105" to be "running"
Dec 14 08:35:10.303: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Running", Reason="", readiness=true. Elapsed: 26.192896ms
Dec 14 08:35:10.303: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 08:35:10.303
Dec 14 08:35:10.303: INFO: Deleting pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105"
Dec 14 08:35:10.330: INFO: Wait up to 5m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 08:35:44.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2105" for this suite. 12/14/22 08:35:44.439
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":26,"skipped":395,"failed":0}
------------------------------
• [37.881 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:06.588
    Dec 14 08:35:06.588: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 08:35:06.589
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:06.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:06.722
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 12/14/22 08:35:06.77
    STEP: waiting for pod running 12/14/22 08:35:06.805
    Dec 14 08:35:06.805: INFO: Waiting up to 2m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105" to be "running"
    Dec 14 08:35:06.832: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.973212ms
    Dec 14 08:35:08.859: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.053565129s
    Dec 14 08:35:08.859: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" satisfied condition "running"
    STEP: creating a file in subpath 12/14/22 08:35:08.859
    Dec 14 08:35:08.885: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2105 PodName:var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:35:08.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:35:08.885: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:35:08.885: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-2105/pods/var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 12/14/22 08:35:09.294
    Dec 14 08:35:09.321: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2105 PodName:var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:35:09.321: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:35:09.322: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:35:09.322: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-2105/pods/var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 12/14/22 08:35:09.719
    Dec 14 08:35:10.276: INFO: Successfully updated pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e"
    STEP: waiting for annotated pod running 12/14/22 08:35:10.276
    Dec 14 08:35:10.277: INFO: Waiting up to 2m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105" to be "running"
    Dec 14 08:35:10.303: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e": Phase="Running", Reason="", readiness=true. Elapsed: 26.192896ms
    Dec 14 08:35:10.303: INFO: Pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 08:35:10.303
    Dec 14 08:35:10.303: INFO: Deleting pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" in namespace "var-expansion-2105"
    Dec 14 08:35:10.330: INFO: Wait up to 5m0s for pod "var-expansion-3a955e1e-d164-446b-ab1c-3ae87408ba6e" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 08:35:44.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2105" for this suite. 12/14/22 08:35:44.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:44.469
Dec 14 08:35:44.470: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop 12/14/22 08:35:44.471
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:44.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:44.606
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-2929 12/14/22 08:35:44.656
STEP: Waiting for pods to come up. 12/14/22 08:35:44.692
Dec 14 08:35:44.762: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2929" to be "running"
Dec 14 08:35:44.790: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 27.547337ms
Dec 14 08:35:46.818: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.056182859s
Dec 14 08:35:46.818: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-2929 12/14/22 08:35:46.845
Dec 14 08:35:46.881: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2929" to be "running"
Dec 14 08:35:46.909: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 27.683871ms
Dec 14 08:35:48.941: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.059495801s
Dec 14 08:35:48.941: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 12/14/22 08:35:48.941
Dec 14 08:35:54.106: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 12/14/22 08:35:54.106
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Dec 14 08:35:54.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2929" for this suite. 12/14/22 08:35:54.192
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":27,"skipped":410,"failed":0}
------------------------------
• [9.753 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:44.469
    Dec 14 08:35:44.470: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename prestop 12/14/22 08:35:44.471
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:44.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:44.606
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-2929 12/14/22 08:35:44.656
    STEP: Waiting for pods to come up. 12/14/22 08:35:44.692
    Dec 14 08:35:44.762: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2929" to be "running"
    Dec 14 08:35:44.790: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 27.547337ms
    Dec 14 08:35:46.818: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.056182859s
    Dec 14 08:35:46.818: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-2929 12/14/22 08:35:46.845
    Dec 14 08:35:46.881: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2929" to be "running"
    Dec 14 08:35:46.909: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 27.683871ms
    Dec 14 08:35:48.941: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.059495801s
    Dec 14 08:35:48.941: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 12/14/22 08:35:48.941
    Dec 14 08:35:54.106: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 12/14/22 08:35:54.106
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Dec 14 08:35:54.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-2929" for this suite. 12/14/22 08:35:54.192
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:54.223
Dec 14 08:35:54.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:35:54.224
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:54.306
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:54.365
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-0bc5062c-750c-40e0-9625-5292ab8bfeb9 12/14/22 08:35:54.417
STEP: Creating a pod to test consume configMaps 12/14/22 08:35:54.444
Dec 14 08:35:54.479: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4" in namespace "configmap-3989" to be "Succeeded or Failed"
Dec 14 08:35:54.510: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.223171ms
Dec 14 08:35:56.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059769037s
Dec 14 08:35:58.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059564141s
STEP: Saw pod success 12/14/22 08:35:58.539
Dec 14 08:35:58.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4" satisfied condition "Succeeded or Failed"
Dec 14 08:35:58.567: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:35:58.604
Dec 14 08:35:58.637: INFO: Waiting for pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 to disappear
Dec 14 08:35:58.666: INFO: Pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:35:58.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3989" for this suite. 12/14/22 08:35:58.719
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":28,"skipped":417,"failed":0}
------------------------------
• [4.526 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:54.223
    Dec 14 08:35:54.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:35:54.224
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:54.306
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:54.365
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-0bc5062c-750c-40e0-9625-5292ab8bfeb9 12/14/22 08:35:54.417
    STEP: Creating a pod to test consume configMaps 12/14/22 08:35:54.444
    Dec 14 08:35:54.479: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4" in namespace "configmap-3989" to be "Succeeded or Failed"
    Dec 14 08:35:54.510: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.223171ms
    Dec 14 08:35:56.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059769037s
    Dec 14 08:35:58.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059564141s
    STEP: Saw pod success 12/14/22 08:35:58.539
    Dec 14 08:35:58.539: INFO: Pod "pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4" satisfied condition "Succeeded or Failed"
    Dec 14 08:35:58.567: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:35:58.604
    Dec 14 08:35:58.637: INFO: Waiting for pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 to disappear
    Dec 14 08:35:58.666: INFO: Pod pod-configmaps-b4550d0a-770c-480f-9536-1ecce60b80b4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:35:58.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3989" for this suite. 12/14/22 08:35:58.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:35:58.75
Dec 14 08:35:58.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:35:58.75
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:58.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:58.887
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 12/14/22 08:35:58.938
STEP: Counting existing ResourceQuota 12/14/22 08:36:03.965
STEP: Creating a ResourceQuota 12/14/22 08:36:08.995
STEP: Ensuring resource quota status is calculated 12/14/22 08:36:09.025
STEP: Creating a Secret 12/14/22 08:36:11.054
STEP: Ensuring resource quota status captures secret creation 12/14/22 08:36:11.093
STEP: Deleting a secret 12/14/22 08:36:13.123
STEP: Ensuring resource quota status released usage 12/14/22 08:36:13.152
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:36:15.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9029" for this suite. 12/14/22 08:36:15.233
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":29,"skipped":437,"failed":0}
------------------------------
• [16.512 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:35:58.75
    Dec 14 08:35:58.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:35:58.75
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:35:58.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:35:58.887
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 12/14/22 08:35:58.938
    STEP: Counting existing ResourceQuota 12/14/22 08:36:03.965
    STEP: Creating a ResourceQuota 12/14/22 08:36:08.995
    STEP: Ensuring resource quota status is calculated 12/14/22 08:36:09.025
    STEP: Creating a Secret 12/14/22 08:36:11.054
    STEP: Ensuring resource quota status captures secret creation 12/14/22 08:36:11.093
    STEP: Deleting a secret 12/14/22 08:36:13.123
    STEP: Ensuring resource quota status released usage 12/14/22 08:36:13.152
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:36:15.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9029" for this suite. 12/14/22 08:36:15.233
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:15.262
Dec 14 08:36:15.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:36:15.263
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:15.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:15.397
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Dec 14 08:36:15.448: INFO: Creating deployment "test-recreate-deployment"
Dec 14 08:36:15.476: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 14 08:36:15.530: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 14 08:36:15.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 08:36:17.589: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 14 08:36:17.645: INFO: Updating deployment test-recreate-deployment
Dec 14 08:36:17.646: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:36:17.730: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5912  77b417ca-7444-41ff-8922-46e4b7aaab43 12924 2 2022-12-14 08:36:15 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00088b9e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 08:36:17 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-14 08:36:17 +0000 UTC,LastTransitionTime:2022-12-14 08:36:15 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 14 08:36:17.758: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5912  c1d96752-20da-487d-9458-fd05b33a1fa9 12923 1 2022-12-14 08:36:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 77b417ca-7444-41ff-8922-46e4b7aaab43 0xc0006a9c80 0xc0006a9c81}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b417ca-7444-41ff-8922-46e4b7aaab43\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000235638 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:36:17.758: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 14 08:36:17.758: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5912  8184315e-bf79-4982-8cc7-be6eb219547b 12916 2 2022-12-14 08:36:15 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 77b417ca-7444-41ff-8922-46e4b7aaab43 0xc00058d5d7 0xc00058d5d8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b417ca-7444-41ff-8922-46e4b7aaab43\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0006a90e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:36:17.788: INFO: Pod "test-recreate-deployment-9d58999df-ksmvs" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-ksmvs test-recreate-deployment-9d58999df- deployment-5912  a1daa980-5184-4658-aedf-ebbb111c9ca7 12925 0 2022-12-14 08:36:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df c1d96752-20da-487d-9458-fd05b33a1fa9 0xc0016e20f0 0xc0016e20f1}] [] [{kube-controller-manager Update v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c1d96752-20da-487d-9458-fd05b33a1fa9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nhgb8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nhgb8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 08:36:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:36:17.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5912" for this suite. 12/14/22 08:36:17.844
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":30,"skipped":439,"failed":0}
------------------------------
• [2.610 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:15.262
    Dec 14 08:36:15.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:36:15.263
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:15.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:15.397
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Dec 14 08:36:15.448: INFO: Creating deployment "test-recreate-deployment"
    Dec 14 08:36:15.476: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Dec 14 08:36:15.530: INFO: Waiting deployment "test-recreate-deployment" to complete
    Dec 14 08:36:15.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 36, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 08:36:17.589: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Dec 14 08:36:17.645: INFO: Updating deployment test-recreate-deployment
    Dec 14 08:36:17.646: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:36:17.730: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-5912  77b417ca-7444-41ff-8922-46e4b7aaab43 12924 2 2022-12-14 08:36:15 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00088b9e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 08:36:17 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-14 08:36:17 +0000 UTC,LastTransitionTime:2022-12-14 08:36:15 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Dec 14 08:36:17.758: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5912  c1d96752-20da-487d-9458-fd05b33a1fa9 12923 1 2022-12-14 08:36:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 77b417ca-7444-41ff-8922-46e4b7aaab43 0xc0006a9c80 0xc0006a9c81}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b417ca-7444-41ff-8922-46e4b7aaab43\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000235638 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:36:17.758: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Dec 14 08:36:17.758: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5912  8184315e-bf79-4982-8cc7-be6eb219547b 12916 2 2022-12-14 08:36:15 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 77b417ca-7444-41ff-8922-46e4b7aaab43 0xc00058d5d7 0xc00058d5d8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b417ca-7444-41ff-8922-46e4b7aaab43\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0006a90e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:36:17.788: INFO: Pod "test-recreate-deployment-9d58999df-ksmvs" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-ksmvs test-recreate-deployment-9d58999df- deployment-5912  a1daa980-5184-4658-aedf-ebbb111c9ca7 12925 0 2022-12-14 08:36:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df c1d96752-20da-487d-9458-fd05b33a1fa9 0xc0016e20f0 0xc0016e20f1}] [] [{kube-controller-manager Update v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c1d96752-20da-487d-9458-fd05b33a1fa9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:36:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nhgb8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nhgb8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:36:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 08:36:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:36:17.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5912" for this suite. 12/14/22 08:36:17.844
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:17.874
Dec 14 08:36:17.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:36:17.875
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:17.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:18.009
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 12/14/22 08:36:18.061
Dec 14 08:36:18.061: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2223 proxy --unix-socket=/tmp/kubectl-proxy-unix1421830179/test'
STEP: retrieving proxy /api/ output 12/14/22 08:36:18.136
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:36:18.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2223" for this suite. 12/14/22 08:36:18.168
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":31,"skipped":450,"failed":0}
------------------------------
• [0.331 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:17.874
    Dec 14 08:36:17.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:36:17.875
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:17.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:18.009
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 12/14/22 08:36:18.061
    Dec 14 08:36:18.061: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2223 proxy --unix-socket=/tmp/kubectl-proxy-unix1421830179/test'
    STEP: retrieving proxy /api/ output 12/14/22 08:36:18.136
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:36:18.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2223" for this suite. 12/14/22 08:36:18.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:18.207
Dec 14 08:36:18.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:36:18.208
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:18.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:18.345
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-173.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-173.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 12/14/22 08:36:18.397
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-173.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-173.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 12/14/22 08:36:18.397
STEP: creating a pod to probe /etc/hosts 12/14/22 08:36:18.397
STEP: submitting the pod to kubernetes 12/14/22 08:36:18.397
Dec 14 08:36:18.433: INFO: Waiting up to 15m0s for pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248" in namespace "dns-173" to be "running"
Dec 14 08:36:18.461: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 27.370454ms
Dec 14 08:36:20.493: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059875242s
Dec 14 08:36:22.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056069238s
Dec 14 08:36:24.488: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055147755s
Dec 14 08:36:26.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 8.056049719s
Dec 14 08:36:28.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Running", Reason="", readiness=true. Elapsed: 10.056230801s
Dec 14 08:36:28.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:36:28.489
STEP: looking for the results for each expected name from probers 12/14/22 08:36:28.517
Dec 14 08:36:28.758: INFO: DNS probes using dns-173/dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248 succeeded

STEP: deleting the pod 12/14/22 08:36:28.758
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:36:28.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-173" for this suite. 12/14/22 08:36:28.847
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":32,"skipped":490,"failed":0}
------------------------------
• [10.667 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:18.207
    Dec 14 08:36:18.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:36:18.208
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:18.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:18.345
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-173.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-173.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     12/14/22 08:36:18.397
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-173.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-173.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     12/14/22 08:36:18.397
    STEP: creating a pod to probe /etc/hosts 12/14/22 08:36:18.397
    STEP: submitting the pod to kubernetes 12/14/22 08:36:18.397
    Dec 14 08:36:18.433: INFO: Waiting up to 15m0s for pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248" in namespace "dns-173" to be "running"
    Dec 14 08:36:18.461: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 27.370454ms
    Dec 14 08:36:20.493: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059875242s
    Dec 14 08:36:22.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056069238s
    Dec 14 08:36:24.488: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055147755s
    Dec 14 08:36:26.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Pending", Reason="", readiness=false. Elapsed: 8.056049719s
    Dec 14 08:36:28.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248": Phase="Running", Reason="", readiness=true. Elapsed: 10.056230801s
    Dec 14 08:36:28.489: INFO: Pod "dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:36:28.489
    STEP: looking for the results for each expected name from probers 12/14/22 08:36:28.517
    Dec 14 08:36:28.758: INFO: DNS probes using dns-173/dns-test-553a92ed-cd9e-4543-b0be-19eaf0da9248 succeeded

    STEP: deleting the pod 12/14/22 08:36:28.758
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:36:28.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-173" for this suite. 12/14/22 08:36:28.847
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:28.875
Dec 14 08:36:28.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename conformance-tests 12/14/22 08:36:28.876
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:28.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:29.013
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 12/14/22 08:36:29.065
Dec 14 08:36:29.065: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Dec 14 08:36:29.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1966" for this suite. 12/14/22 08:36:29.162
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":33,"skipped":495,"failed":0}
------------------------------
• [0.314 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:28.875
    Dec 14 08:36:28.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename conformance-tests 12/14/22 08:36:28.876
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:28.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:29.013
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 12/14/22 08:36:29.065
    Dec 14 08:36:29.065: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Dec 14 08:36:29.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1966" for this suite. 12/14/22 08:36:29.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:29.191
Dec 14 08:36:29.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:36:29.192
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:29.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:29.326
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 12/14/22 08:36:29.383
Dec 14 08:36:29.418: INFO: Waiting up to 5m0s for pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d" in namespace "emptydir-5578" to be "Succeeded or Failed"
Dec 14 08:36:29.447: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.885941ms
Dec 14 08:36:31.475: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056929532s
Dec 14 08:36:33.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057637383s
Dec 14 08:36:35.477: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058456276s
Dec 14 08:36:37.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.057501424s
Dec 14 08:36:39.475: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056245368s
Dec 14 08:36:41.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.057905912s
STEP: Saw pod success 12/14/22 08:36:41.476
Dec 14 08:36:41.477: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d" satisfied condition "Succeeded or Failed"
Dec 14 08:36:41.504: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-c0d5e520-e294-43ff-82f7-107e1642786d container test-container: <nil>
STEP: delete the pod 12/14/22 08:36:41.538
Dec 14 08:36:41.574: INFO: Waiting for pod pod-c0d5e520-e294-43ff-82f7-107e1642786d to disappear
Dec 14 08:36:41.601: INFO: Pod pod-c0d5e520-e294-43ff-82f7-107e1642786d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:36:41.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5578" for this suite. 12/14/22 08:36:41.656
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":34,"skipped":519,"failed":0}
------------------------------
• [12.601 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:29.191
    Dec 14 08:36:29.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:36:29.192
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:29.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:29.326
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 12/14/22 08:36:29.383
    Dec 14 08:36:29.418: INFO: Waiting up to 5m0s for pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d" in namespace "emptydir-5578" to be "Succeeded or Failed"
    Dec 14 08:36:29.447: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.885941ms
    Dec 14 08:36:31.475: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056929532s
    Dec 14 08:36:33.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057637383s
    Dec 14 08:36:35.477: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058456276s
    Dec 14 08:36:37.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.057501424s
    Dec 14 08:36:39.475: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056245368s
    Dec 14 08:36:41.476: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.057905912s
    STEP: Saw pod success 12/14/22 08:36:41.476
    Dec 14 08:36:41.477: INFO: Pod "pod-c0d5e520-e294-43ff-82f7-107e1642786d" satisfied condition "Succeeded or Failed"
    Dec 14 08:36:41.504: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-c0d5e520-e294-43ff-82f7-107e1642786d container test-container: <nil>
    STEP: delete the pod 12/14/22 08:36:41.538
    Dec 14 08:36:41.574: INFO: Waiting for pod pod-c0d5e520-e294-43ff-82f7-107e1642786d to disappear
    Dec 14 08:36:41.601: INFO: Pod pod-c0d5e520-e294-43ff-82f7-107e1642786d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:36:41.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5578" for this suite. 12/14/22 08:36:41.656
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:41.793
Dec 14 08:36:41.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange 12/14/22 08:36:41.793
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:41.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:41.927
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 12/14/22 08:36:41.979
STEP: Setting up watch 12/14/22 08:36:41.98
STEP: Submitting a LimitRange 12/14/22 08:36:42.107
STEP: Verifying LimitRange creation was observed 12/14/22 08:36:42.14
STEP: Fetching the LimitRange to ensure it has proper values 12/14/22 08:36:42.14
Dec 14 08:36:42.167: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 14 08:36:42.167: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 12/14/22 08:36:42.167
STEP: Ensuring Pod has resource requirements applied from LimitRange 12/14/22 08:36:42.2
Dec 14 08:36:42.228: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 14 08:36:42.228: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 12/14/22 08:36:42.228
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/14/22 08:36:42.261
Dec 14 08:36:42.290: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec 14 08:36:42.290: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 12/14/22 08:36:42.29
STEP: Failing to create a Pod with more than max resources 12/14/22 08:36:42.321
STEP: Updating a LimitRange 12/14/22 08:36:42.352
STEP: Verifying LimitRange updating is effective 12/14/22 08:36:42.383
STEP: Creating a Pod with less than former min resources 12/14/22 08:36:44.41
STEP: Failing to create a Pod with more than max resources 12/14/22 08:36:44.443
STEP: Deleting a LimitRange 12/14/22 08:36:44.474
STEP: Verifying the LimitRange was deleted 12/14/22 08:36:44.503
Dec 14 08:36:49.531: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 12/14/22 08:36:49.531
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Dec 14 08:36:49.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-9577" for this suite. 12/14/22 08:36:49.619
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":35,"skipped":534,"failed":0}
------------------------------
• [7.854 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:41.793
    Dec 14 08:36:41.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename limitrange 12/14/22 08:36:41.793
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:41.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:41.927
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 12/14/22 08:36:41.979
    STEP: Setting up watch 12/14/22 08:36:41.98
    STEP: Submitting a LimitRange 12/14/22 08:36:42.107
    STEP: Verifying LimitRange creation was observed 12/14/22 08:36:42.14
    STEP: Fetching the LimitRange to ensure it has proper values 12/14/22 08:36:42.14
    Dec 14 08:36:42.167: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec 14 08:36:42.167: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 12/14/22 08:36:42.167
    STEP: Ensuring Pod has resource requirements applied from LimitRange 12/14/22 08:36:42.2
    Dec 14 08:36:42.228: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec 14 08:36:42.228: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 12/14/22 08:36:42.228
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/14/22 08:36:42.261
    Dec 14 08:36:42.290: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Dec 14 08:36:42.290: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 12/14/22 08:36:42.29
    STEP: Failing to create a Pod with more than max resources 12/14/22 08:36:42.321
    STEP: Updating a LimitRange 12/14/22 08:36:42.352
    STEP: Verifying LimitRange updating is effective 12/14/22 08:36:42.383
    STEP: Creating a Pod with less than former min resources 12/14/22 08:36:44.41
    STEP: Failing to create a Pod with more than max resources 12/14/22 08:36:44.443
    STEP: Deleting a LimitRange 12/14/22 08:36:44.474
    STEP: Verifying the LimitRange was deleted 12/14/22 08:36:44.503
    Dec 14 08:36:49.531: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 12/14/22 08:36:49.531
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Dec 14 08:36:49.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-9577" for this suite. 12/14/22 08:36:49.619
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:36:49.648
Dec 14 08:36:49.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:36:49.649
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:49.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:49.782
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:36:49.835
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-l8mh 12/14/22 08:36:49.891
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:36:49.891
Dec 14 08:36:49.930: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l8mh" in namespace "subpath-6594" to be "Succeeded or Failed"
Dec 14 08:36:49.961: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Pending", Reason="", readiness=false. Elapsed: 31.493533ms
Dec 14 08:36:51.996: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 2.066423072s
Dec 14 08:36:53.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 4.061502624s
Dec 14 08:36:55.993: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 6.063131938s
Dec 14 08:36:57.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 8.059748686s
Dec 14 08:36:59.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 10.060318683s
Dec 14 08:37:01.993: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 12.062988548s
Dec 14 08:37:03.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 14.059931106s
Dec 14 08:37:05.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 16.060373915s
Dec 14 08:37:07.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 18.061808565s
Dec 14 08:37:09.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 20.059446884s
Dec 14 08:37:11.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=false. Elapsed: 22.061450108s
Dec 14 08:37:13.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.059445682s
STEP: Saw pod success 12/14/22 08:37:13.989
Dec 14 08:37:13.989: INFO: Pod "pod-subpath-test-secret-l8mh" satisfied condition "Succeeded or Failed"
Dec 14 08:37:14.019: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-secret-l8mh container test-container-subpath-secret-l8mh: <nil>
STEP: delete the pod 12/14/22 08:37:14.055
Dec 14 08:37:14.097: INFO: Waiting for pod pod-subpath-test-secret-l8mh to disappear
Dec 14 08:37:14.125: INFO: Pod pod-subpath-test-secret-l8mh no longer exists
STEP: Deleting pod pod-subpath-test-secret-l8mh 12/14/22 08:37:14.125
Dec 14 08:37:14.125: INFO: Deleting pod "pod-subpath-test-secret-l8mh" in namespace "subpath-6594"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:37:14.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6594" for this suite. 12/14/22 08:37:14.237
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":36,"skipped":554,"failed":0}
------------------------------
• [24.618 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:36:49.648
    Dec 14 08:36:49.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:36:49.649
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:36:49.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:36:49.782
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:36:49.835
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-l8mh 12/14/22 08:36:49.891
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:36:49.891
    Dec 14 08:36:49.930: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l8mh" in namespace "subpath-6594" to be "Succeeded or Failed"
    Dec 14 08:36:49.961: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Pending", Reason="", readiness=false. Elapsed: 31.493533ms
    Dec 14 08:36:51.996: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 2.066423072s
    Dec 14 08:36:53.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 4.061502624s
    Dec 14 08:36:55.993: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 6.063131938s
    Dec 14 08:36:57.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 8.059748686s
    Dec 14 08:36:59.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 10.060318683s
    Dec 14 08:37:01.993: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 12.062988548s
    Dec 14 08:37:03.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 14.059931106s
    Dec 14 08:37:05.990: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 16.060373915s
    Dec 14 08:37:07.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 18.061808565s
    Dec 14 08:37:09.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=true. Elapsed: 20.059446884s
    Dec 14 08:37:11.991: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Running", Reason="", readiness=false. Elapsed: 22.061450108s
    Dec 14 08:37:13.989: INFO: Pod "pod-subpath-test-secret-l8mh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.059445682s
    STEP: Saw pod success 12/14/22 08:37:13.989
    Dec 14 08:37:13.989: INFO: Pod "pod-subpath-test-secret-l8mh" satisfied condition "Succeeded or Failed"
    Dec 14 08:37:14.019: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-secret-l8mh container test-container-subpath-secret-l8mh: <nil>
    STEP: delete the pod 12/14/22 08:37:14.055
    Dec 14 08:37:14.097: INFO: Waiting for pod pod-subpath-test-secret-l8mh to disappear
    Dec 14 08:37:14.125: INFO: Pod pod-subpath-test-secret-l8mh no longer exists
    STEP: Deleting pod pod-subpath-test-secret-l8mh 12/14/22 08:37:14.125
    Dec 14 08:37:14.125: INFO: Deleting pod "pod-subpath-test-secret-l8mh" in namespace "subpath-6594"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:37:14.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6594" for this suite. 12/14/22 08:37:14.237
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:37:14.267
Dec 14 08:37:14.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 08:37:14.268
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:14.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:14.402
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/14/22 08:37:14.456
Dec 14 08:37:14.490: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2060" to be "running and ready"
Dec 14 08:37:14.518: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 27.67374ms
Dec 14 08:37:14.532: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:37:16.560: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.06978667s
Dec 14 08:37:16.560: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Dec 14 08:37:16.560: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 12/14/22 08:37:16.588
STEP: Then the orphan pod is adopted 12/14/22 08:37:16.616
STEP: When the matched label of one of its pods change 12/14/22 08:37:16.646
Dec 14 08:37:16.673: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 12/14/22 08:37:16.731
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 08:37:16.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2060" for this suite. 12/14/22 08:37:16.814
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":37,"skipped":575,"failed":0}
------------------------------
• [2.576 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:37:14.267
    Dec 14 08:37:14.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 08:37:14.268
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:14.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:14.402
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/14/22 08:37:14.456
    Dec 14 08:37:14.490: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2060" to be "running and ready"
    Dec 14 08:37:14.518: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 27.67374ms
    Dec 14 08:37:14.532: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:37:16.560: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.06978667s
    Dec 14 08:37:16.560: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Dec 14 08:37:16.560: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 12/14/22 08:37:16.588
    STEP: Then the orphan pod is adopted 12/14/22 08:37:16.616
    STEP: When the matched label of one of its pods change 12/14/22 08:37:16.646
    Dec 14 08:37:16.673: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/14/22 08:37:16.731
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 08:37:16.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2060" for this suite. 12/14/22 08:37:16.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:37:16.844
Dec 14 08:37:16.844: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:37:16.845
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:16.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:16.978
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:37:17.034
Dec 14 08:37:17.034: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 14 08:37:17.262: INFO: stderr: ""
Dec 14 08:37:17.263: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 12/14/22 08:37:17.263
Dec 14 08:37:17.263: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Dec 14 08:37:17.728: INFO: stderr: ""
Dec 14 08:37:17.728: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:37:17.728
Dec 14 08:37:17.761: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 delete pods e2e-test-httpd-pod'
Dec 14 08:37:19.686: INFO: stderr: ""
Dec 14 08:37:19.686: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:37:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1456" for this suite. 12/14/22 08:37:19.738
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":38,"skipped":592,"failed":0}
------------------------------
• [2.924 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:37:16.844
    Dec 14 08:37:16.844: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:37:16.845
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:16.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:16.978
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:37:17.034
    Dec 14 08:37:17.034: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec 14 08:37:17.262: INFO: stderr: ""
    Dec 14 08:37:17.263: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 12/14/22 08:37:17.263
    Dec 14 08:37:17.263: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Dec 14 08:37:17.728: INFO: stderr: ""
    Dec 14 08:37:17.728: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:37:17.728
    Dec 14 08:37:17.761: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1456 delete pods e2e-test-httpd-pod'
    Dec 14 08:37:19.686: INFO: stderr: ""
    Dec 14 08:37:19.686: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:37:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1456" for this suite. 12/14/22 08:37:19.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:37:19.768
Dec 14 08:37:19.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 08:37:19.769
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:19.851
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:19.904
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 12/14/22 08:37:19.985
STEP: delete the rc 12/14/22 08:37:25.043
STEP: wait for the rc to be deleted 12/14/22 08:37:25.078
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/14/22 08:37:30.108
STEP: Gathering metrics 12/14/22 08:38:00.177
W1214 08:38:00.239474    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 08:38:00.239: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 14 08:38:00.239: INFO: Deleting pod "simpletest.rc-2fzrf" in namespace "gc-3590"
Dec 14 08:38:00.274: INFO: Deleting pod "simpletest.rc-2j7fn" in namespace "gc-3590"
Dec 14 08:38:00.310: INFO: Deleting pod "simpletest.rc-2p5d5" in namespace "gc-3590"
Dec 14 08:38:00.343: INFO: Deleting pod "simpletest.rc-47vm4" in namespace "gc-3590"
Dec 14 08:38:00.379: INFO: Deleting pod "simpletest.rc-4gmj7" in namespace "gc-3590"
Dec 14 08:38:00.413: INFO: Deleting pod "simpletest.rc-4lk7t" in namespace "gc-3590"
Dec 14 08:38:00.444: INFO: Deleting pod "simpletest.rc-4wqnm" in namespace "gc-3590"
Dec 14 08:38:00.478: INFO: Deleting pod "simpletest.rc-4zbt9" in namespace "gc-3590"
Dec 14 08:38:00.509: INFO: Deleting pod "simpletest.rc-5hhm2" in namespace "gc-3590"
Dec 14 08:38:00.545: INFO: Deleting pod "simpletest.rc-5pp99" in namespace "gc-3590"
Dec 14 08:38:00.581: INFO: Deleting pod "simpletest.rc-5s6cm" in namespace "gc-3590"
Dec 14 08:38:00.618: INFO: Deleting pod "simpletest.rc-6nlw9" in namespace "gc-3590"
Dec 14 08:38:00.651: INFO: Deleting pod "simpletest.rc-74mq9" in namespace "gc-3590"
Dec 14 08:38:00.687: INFO: Deleting pod "simpletest.rc-7624s" in namespace "gc-3590"
Dec 14 08:38:00.724: INFO: Deleting pod "simpletest.rc-76cbj" in namespace "gc-3590"
Dec 14 08:38:00.765: INFO: Deleting pod "simpletest.rc-86lp8" in namespace "gc-3590"
Dec 14 08:38:00.801: INFO: Deleting pod "simpletest.rc-8rngw" in namespace "gc-3590"
Dec 14 08:38:00.836: INFO: Deleting pod "simpletest.rc-9bcwj" in namespace "gc-3590"
Dec 14 08:38:00.868: INFO: Deleting pod "simpletest.rc-9s7gx" in namespace "gc-3590"
Dec 14 08:38:00.900: INFO: Deleting pod "simpletest.rc-9v57s" in namespace "gc-3590"
Dec 14 08:38:00.936: INFO: Deleting pod "simpletest.rc-b2d2f" in namespace "gc-3590"
Dec 14 08:38:00.971: INFO: Deleting pod "simpletest.rc-b4k44" in namespace "gc-3590"
Dec 14 08:38:01.007: INFO: Deleting pod "simpletest.rc-b5pd9" in namespace "gc-3590"
Dec 14 08:38:01.042: INFO: Deleting pod "simpletest.rc-b789x" in namespace "gc-3590"
Dec 14 08:38:01.079: INFO: Deleting pod "simpletest.rc-bgcgs" in namespace "gc-3590"
Dec 14 08:38:01.113: INFO: Deleting pod "simpletest.rc-cr4rw" in namespace "gc-3590"
Dec 14 08:38:01.146: INFO: Deleting pod "simpletest.rc-cs98f" in namespace "gc-3590"
Dec 14 08:38:01.179: INFO: Deleting pod "simpletest.rc-csjm9" in namespace "gc-3590"
Dec 14 08:38:01.219: INFO: Deleting pod "simpletest.rc-d7krd" in namespace "gc-3590"
Dec 14 08:38:01.254: INFO: Deleting pod "simpletest.rc-d86bd" in namespace "gc-3590"
Dec 14 08:38:01.297: INFO: Deleting pod "simpletest.rc-d9jh4" in namespace "gc-3590"
Dec 14 08:38:01.332: INFO: Deleting pod "simpletest.rc-dlrz2" in namespace "gc-3590"
Dec 14 08:38:01.368: INFO: Deleting pod "simpletest.rc-f4ftx" in namespace "gc-3590"
Dec 14 08:38:01.402: INFO: Deleting pod "simpletest.rc-f6hds" in namespace "gc-3590"
Dec 14 08:38:01.437: INFO: Deleting pod "simpletest.rc-f9x2h" in namespace "gc-3590"
Dec 14 08:38:01.475: INFO: Deleting pod "simpletest.rc-fmnht" in namespace "gc-3590"
Dec 14 08:38:01.508: INFO: Deleting pod "simpletest.rc-fz96q" in namespace "gc-3590"
Dec 14 08:38:01.544: INFO: Deleting pod "simpletest.rc-fzqtb" in namespace "gc-3590"
Dec 14 08:38:01.581: INFO: Deleting pod "simpletest.rc-gdm9r" in namespace "gc-3590"
Dec 14 08:38:01.615: INFO: Deleting pod "simpletest.rc-gmsd4" in namespace "gc-3590"
Dec 14 08:38:01.650: INFO: Deleting pod "simpletest.rc-gptvx" in namespace "gc-3590"
Dec 14 08:38:01.683: INFO: Deleting pod "simpletest.rc-gs8t7" in namespace "gc-3590"
Dec 14 08:38:01.717: INFO: Deleting pod "simpletest.rc-gsdfp" in namespace "gc-3590"
Dec 14 08:38:01.752: INFO: Deleting pod "simpletest.rc-gt67c" in namespace "gc-3590"
Dec 14 08:38:01.785: INFO: Deleting pod "simpletest.rc-h658f" in namespace "gc-3590"
Dec 14 08:38:01.819: INFO: Deleting pod "simpletest.rc-hhcfb" in namespace "gc-3590"
Dec 14 08:38:01.856: INFO: Deleting pod "simpletest.rc-hlqd4" in namespace "gc-3590"
Dec 14 08:38:01.892: INFO: Deleting pod "simpletest.rc-hs2tn" in namespace "gc-3590"
Dec 14 08:38:01.928: INFO: Deleting pod "simpletest.rc-j82k8" in namespace "gc-3590"
Dec 14 08:38:01.968: INFO: Deleting pod "simpletest.rc-jpfcc" in namespace "gc-3590"
Dec 14 08:38:02.003: INFO: Deleting pod "simpletest.rc-jqgmv" in namespace "gc-3590"
Dec 14 08:38:02.042: INFO: Deleting pod "simpletest.rc-jvffp" in namespace "gc-3590"
Dec 14 08:38:02.083: INFO: Deleting pod "simpletest.rc-jwjvb" in namespace "gc-3590"
Dec 14 08:38:02.116: INFO: Deleting pod "simpletest.rc-k2nrk" in namespace "gc-3590"
Dec 14 08:38:02.151: INFO: Deleting pod "simpletest.rc-kgjm7" in namespace "gc-3590"
Dec 14 08:38:02.190: INFO: Deleting pod "simpletest.rc-km2qw" in namespace "gc-3590"
Dec 14 08:38:02.228: INFO: Deleting pod "simpletest.rc-kvbzq" in namespace "gc-3590"
Dec 14 08:38:02.266: INFO: Deleting pod "simpletest.rc-kx8kk" in namespace "gc-3590"
Dec 14 08:38:02.304: INFO: Deleting pod "simpletest.rc-lhlpn" in namespace "gc-3590"
Dec 14 08:38:02.338: INFO: Deleting pod "simpletest.rc-lxwlg" in namespace "gc-3590"
Dec 14 08:38:02.374: INFO: Deleting pod "simpletest.rc-m5rnh" in namespace "gc-3590"
Dec 14 08:38:02.413: INFO: Deleting pod "simpletest.rc-m7gmc" in namespace "gc-3590"
Dec 14 08:38:02.457: INFO: Deleting pod "simpletest.rc-mhbjg" in namespace "gc-3590"
Dec 14 08:38:02.490: INFO: Deleting pod "simpletest.rc-p9n5q" in namespace "gc-3590"
Dec 14 08:38:02.524: INFO: Deleting pod "simpletest.rc-pfl9k" in namespace "gc-3590"
Dec 14 08:38:02.557: INFO: Deleting pod "simpletest.rc-pj2f4" in namespace "gc-3590"
Dec 14 08:38:02.591: INFO: Deleting pod "simpletest.rc-pjtt5" in namespace "gc-3590"
Dec 14 08:38:02.625: INFO: Deleting pod "simpletest.rc-pp52h" in namespace "gc-3590"
Dec 14 08:38:02.662: INFO: Deleting pod "simpletest.rc-pql5z" in namespace "gc-3590"
Dec 14 08:38:02.698: INFO: Deleting pod "simpletest.rc-pr7jr" in namespace "gc-3590"
Dec 14 08:38:02.732: INFO: Deleting pod "simpletest.rc-q8htv" in namespace "gc-3590"
Dec 14 08:38:02.769: INFO: Deleting pod "simpletest.rc-qh65c" in namespace "gc-3590"
Dec 14 08:38:02.800: INFO: Deleting pod "simpletest.rc-qmlqm" in namespace "gc-3590"
Dec 14 08:38:02.835: INFO: Deleting pod "simpletest.rc-qnbrs" in namespace "gc-3590"
Dec 14 08:38:02.871: INFO: Deleting pod "simpletest.rc-r4hkk" in namespace "gc-3590"
Dec 14 08:38:02.907: INFO: Deleting pod "simpletest.rc-r7f4j" in namespace "gc-3590"
Dec 14 08:38:02.945: INFO: Deleting pod "simpletest.rc-r8w54" in namespace "gc-3590"
Dec 14 08:38:02.979: INFO: Deleting pod "simpletest.rc-rk2ch" in namespace "gc-3590"
Dec 14 08:38:03.014: INFO: Deleting pod "simpletest.rc-rrbjr" in namespace "gc-3590"
Dec 14 08:38:03.055: INFO: Deleting pod "simpletest.rc-rx57g" in namespace "gc-3590"
Dec 14 08:38:03.090: INFO: Deleting pod "simpletest.rc-rxk4x" in namespace "gc-3590"
Dec 14 08:38:03.127: INFO: Deleting pod "simpletest.rc-rzp2v" in namespace "gc-3590"
Dec 14 08:38:03.166: INFO: Deleting pod "simpletest.rc-smxcc" in namespace "gc-3590"
Dec 14 08:38:03.204: INFO: Deleting pod "simpletest.rc-srhjj" in namespace "gc-3590"
Dec 14 08:38:03.241: INFO: Deleting pod "simpletest.rc-sscxf" in namespace "gc-3590"
Dec 14 08:38:03.273: INFO: Deleting pod "simpletest.rc-t2flz" in namespace "gc-3590"
Dec 14 08:38:03.308: INFO: Deleting pod "simpletest.rc-tfccp" in namespace "gc-3590"
Dec 14 08:38:03.339: INFO: Deleting pod "simpletest.rc-ttzmm" in namespace "gc-3590"
Dec 14 08:38:03.377: INFO: Deleting pod "simpletest.rc-v2zld" in namespace "gc-3590"
Dec 14 08:38:03.413: INFO: Deleting pod "simpletest.rc-vnlvp" in namespace "gc-3590"
Dec 14 08:38:03.450: INFO: Deleting pod "simpletest.rc-vprwk" in namespace "gc-3590"
Dec 14 08:38:03.493: INFO: Deleting pod "simpletest.rc-vrjjc" in namespace "gc-3590"
Dec 14 08:38:03.526: INFO: Deleting pod "simpletest.rc-vwdl2" in namespace "gc-3590"
Dec 14 08:38:03.561: INFO: Deleting pod "simpletest.rc-w7qsw" in namespace "gc-3590"
Dec 14 08:38:03.600: INFO: Deleting pod "simpletest.rc-w9wz9" in namespace "gc-3590"
Dec 14 08:38:03.635: INFO: Deleting pod "simpletest.rc-x9qbv" in namespace "gc-3590"
Dec 14 08:38:03.671: INFO: Deleting pod "simpletest.rc-xslpt" in namespace "gc-3590"
Dec 14 08:38:03.708: INFO: Deleting pod "simpletest.rc-z9cbb" in namespace "gc-3590"
Dec 14 08:38:03.745: INFO: Deleting pod "simpletest.rc-zltz9" in namespace "gc-3590"
Dec 14 08:38:03.782: INFO: Deleting pod "simpletest.rc-znbht" in namespace "gc-3590"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 08:38:03.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3590" for this suite. 12/14/22 08:38:03.848
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":39,"skipped":601,"failed":0}
------------------------------
• [44.108 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:37:19.768
    Dec 14 08:37:19.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 08:37:19.769
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:37:19.851
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:37:19.904
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 12/14/22 08:37:19.985
    STEP: delete the rc 12/14/22 08:37:25.043
    STEP: wait for the rc to be deleted 12/14/22 08:37:25.078
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/14/22 08:37:30.108
    STEP: Gathering metrics 12/14/22 08:38:00.177
    W1214 08:38:00.239474    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 08:38:00.239: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec 14 08:38:00.239: INFO: Deleting pod "simpletest.rc-2fzrf" in namespace "gc-3590"
    Dec 14 08:38:00.274: INFO: Deleting pod "simpletest.rc-2j7fn" in namespace "gc-3590"
    Dec 14 08:38:00.310: INFO: Deleting pod "simpletest.rc-2p5d5" in namespace "gc-3590"
    Dec 14 08:38:00.343: INFO: Deleting pod "simpletest.rc-47vm4" in namespace "gc-3590"
    Dec 14 08:38:00.379: INFO: Deleting pod "simpletest.rc-4gmj7" in namespace "gc-3590"
    Dec 14 08:38:00.413: INFO: Deleting pod "simpletest.rc-4lk7t" in namespace "gc-3590"
    Dec 14 08:38:00.444: INFO: Deleting pod "simpletest.rc-4wqnm" in namespace "gc-3590"
    Dec 14 08:38:00.478: INFO: Deleting pod "simpletest.rc-4zbt9" in namespace "gc-3590"
    Dec 14 08:38:00.509: INFO: Deleting pod "simpletest.rc-5hhm2" in namespace "gc-3590"
    Dec 14 08:38:00.545: INFO: Deleting pod "simpletest.rc-5pp99" in namespace "gc-3590"
    Dec 14 08:38:00.581: INFO: Deleting pod "simpletest.rc-5s6cm" in namespace "gc-3590"
    Dec 14 08:38:00.618: INFO: Deleting pod "simpletest.rc-6nlw9" in namespace "gc-3590"
    Dec 14 08:38:00.651: INFO: Deleting pod "simpletest.rc-74mq9" in namespace "gc-3590"
    Dec 14 08:38:00.687: INFO: Deleting pod "simpletest.rc-7624s" in namespace "gc-3590"
    Dec 14 08:38:00.724: INFO: Deleting pod "simpletest.rc-76cbj" in namespace "gc-3590"
    Dec 14 08:38:00.765: INFO: Deleting pod "simpletest.rc-86lp8" in namespace "gc-3590"
    Dec 14 08:38:00.801: INFO: Deleting pod "simpletest.rc-8rngw" in namespace "gc-3590"
    Dec 14 08:38:00.836: INFO: Deleting pod "simpletest.rc-9bcwj" in namespace "gc-3590"
    Dec 14 08:38:00.868: INFO: Deleting pod "simpletest.rc-9s7gx" in namespace "gc-3590"
    Dec 14 08:38:00.900: INFO: Deleting pod "simpletest.rc-9v57s" in namespace "gc-3590"
    Dec 14 08:38:00.936: INFO: Deleting pod "simpletest.rc-b2d2f" in namespace "gc-3590"
    Dec 14 08:38:00.971: INFO: Deleting pod "simpletest.rc-b4k44" in namespace "gc-3590"
    Dec 14 08:38:01.007: INFO: Deleting pod "simpletest.rc-b5pd9" in namespace "gc-3590"
    Dec 14 08:38:01.042: INFO: Deleting pod "simpletest.rc-b789x" in namespace "gc-3590"
    Dec 14 08:38:01.079: INFO: Deleting pod "simpletest.rc-bgcgs" in namespace "gc-3590"
    Dec 14 08:38:01.113: INFO: Deleting pod "simpletest.rc-cr4rw" in namespace "gc-3590"
    Dec 14 08:38:01.146: INFO: Deleting pod "simpletest.rc-cs98f" in namespace "gc-3590"
    Dec 14 08:38:01.179: INFO: Deleting pod "simpletest.rc-csjm9" in namespace "gc-3590"
    Dec 14 08:38:01.219: INFO: Deleting pod "simpletest.rc-d7krd" in namespace "gc-3590"
    Dec 14 08:38:01.254: INFO: Deleting pod "simpletest.rc-d86bd" in namespace "gc-3590"
    Dec 14 08:38:01.297: INFO: Deleting pod "simpletest.rc-d9jh4" in namespace "gc-3590"
    Dec 14 08:38:01.332: INFO: Deleting pod "simpletest.rc-dlrz2" in namespace "gc-3590"
    Dec 14 08:38:01.368: INFO: Deleting pod "simpletest.rc-f4ftx" in namespace "gc-3590"
    Dec 14 08:38:01.402: INFO: Deleting pod "simpletest.rc-f6hds" in namespace "gc-3590"
    Dec 14 08:38:01.437: INFO: Deleting pod "simpletest.rc-f9x2h" in namespace "gc-3590"
    Dec 14 08:38:01.475: INFO: Deleting pod "simpletest.rc-fmnht" in namespace "gc-3590"
    Dec 14 08:38:01.508: INFO: Deleting pod "simpletest.rc-fz96q" in namespace "gc-3590"
    Dec 14 08:38:01.544: INFO: Deleting pod "simpletest.rc-fzqtb" in namespace "gc-3590"
    Dec 14 08:38:01.581: INFO: Deleting pod "simpletest.rc-gdm9r" in namespace "gc-3590"
    Dec 14 08:38:01.615: INFO: Deleting pod "simpletest.rc-gmsd4" in namespace "gc-3590"
    Dec 14 08:38:01.650: INFO: Deleting pod "simpletest.rc-gptvx" in namespace "gc-3590"
    Dec 14 08:38:01.683: INFO: Deleting pod "simpletest.rc-gs8t7" in namespace "gc-3590"
    Dec 14 08:38:01.717: INFO: Deleting pod "simpletest.rc-gsdfp" in namespace "gc-3590"
    Dec 14 08:38:01.752: INFO: Deleting pod "simpletest.rc-gt67c" in namespace "gc-3590"
    Dec 14 08:38:01.785: INFO: Deleting pod "simpletest.rc-h658f" in namespace "gc-3590"
    Dec 14 08:38:01.819: INFO: Deleting pod "simpletest.rc-hhcfb" in namespace "gc-3590"
    Dec 14 08:38:01.856: INFO: Deleting pod "simpletest.rc-hlqd4" in namespace "gc-3590"
    Dec 14 08:38:01.892: INFO: Deleting pod "simpletest.rc-hs2tn" in namespace "gc-3590"
    Dec 14 08:38:01.928: INFO: Deleting pod "simpletest.rc-j82k8" in namespace "gc-3590"
    Dec 14 08:38:01.968: INFO: Deleting pod "simpletest.rc-jpfcc" in namespace "gc-3590"
    Dec 14 08:38:02.003: INFO: Deleting pod "simpletest.rc-jqgmv" in namespace "gc-3590"
    Dec 14 08:38:02.042: INFO: Deleting pod "simpletest.rc-jvffp" in namespace "gc-3590"
    Dec 14 08:38:02.083: INFO: Deleting pod "simpletest.rc-jwjvb" in namespace "gc-3590"
    Dec 14 08:38:02.116: INFO: Deleting pod "simpletest.rc-k2nrk" in namespace "gc-3590"
    Dec 14 08:38:02.151: INFO: Deleting pod "simpletest.rc-kgjm7" in namespace "gc-3590"
    Dec 14 08:38:02.190: INFO: Deleting pod "simpletest.rc-km2qw" in namespace "gc-3590"
    Dec 14 08:38:02.228: INFO: Deleting pod "simpletest.rc-kvbzq" in namespace "gc-3590"
    Dec 14 08:38:02.266: INFO: Deleting pod "simpletest.rc-kx8kk" in namespace "gc-3590"
    Dec 14 08:38:02.304: INFO: Deleting pod "simpletest.rc-lhlpn" in namespace "gc-3590"
    Dec 14 08:38:02.338: INFO: Deleting pod "simpletest.rc-lxwlg" in namespace "gc-3590"
    Dec 14 08:38:02.374: INFO: Deleting pod "simpletest.rc-m5rnh" in namespace "gc-3590"
    Dec 14 08:38:02.413: INFO: Deleting pod "simpletest.rc-m7gmc" in namespace "gc-3590"
    Dec 14 08:38:02.457: INFO: Deleting pod "simpletest.rc-mhbjg" in namespace "gc-3590"
    Dec 14 08:38:02.490: INFO: Deleting pod "simpletest.rc-p9n5q" in namespace "gc-3590"
    Dec 14 08:38:02.524: INFO: Deleting pod "simpletest.rc-pfl9k" in namespace "gc-3590"
    Dec 14 08:38:02.557: INFO: Deleting pod "simpletest.rc-pj2f4" in namespace "gc-3590"
    Dec 14 08:38:02.591: INFO: Deleting pod "simpletest.rc-pjtt5" in namespace "gc-3590"
    Dec 14 08:38:02.625: INFO: Deleting pod "simpletest.rc-pp52h" in namespace "gc-3590"
    Dec 14 08:38:02.662: INFO: Deleting pod "simpletest.rc-pql5z" in namespace "gc-3590"
    Dec 14 08:38:02.698: INFO: Deleting pod "simpletest.rc-pr7jr" in namespace "gc-3590"
    Dec 14 08:38:02.732: INFO: Deleting pod "simpletest.rc-q8htv" in namespace "gc-3590"
    Dec 14 08:38:02.769: INFO: Deleting pod "simpletest.rc-qh65c" in namespace "gc-3590"
    Dec 14 08:38:02.800: INFO: Deleting pod "simpletest.rc-qmlqm" in namespace "gc-3590"
    Dec 14 08:38:02.835: INFO: Deleting pod "simpletest.rc-qnbrs" in namespace "gc-3590"
    Dec 14 08:38:02.871: INFO: Deleting pod "simpletest.rc-r4hkk" in namespace "gc-3590"
    Dec 14 08:38:02.907: INFO: Deleting pod "simpletest.rc-r7f4j" in namespace "gc-3590"
    Dec 14 08:38:02.945: INFO: Deleting pod "simpletest.rc-r8w54" in namespace "gc-3590"
    Dec 14 08:38:02.979: INFO: Deleting pod "simpletest.rc-rk2ch" in namespace "gc-3590"
    Dec 14 08:38:03.014: INFO: Deleting pod "simpletest.rc-rrbjr" in namespace "gc-3590"
    Dec 14 08:38:03.055: INFO: Deleting pod "simpletest.rc-rx57g" in namespace "gc-3590"
    Dec 14 08:38:03.090: INFO: Deleting pod "simpletest.rc-rxk4x" in namespace "gc-3590"
    Dec 14 08:38:03.127: INFO: Deleting pod "simpletest.rc-rzp2v" in namespace "gc-3590"
    Dec 14 08:38:03.166: INFO: Deleting pod "simpletest.rc-smxcc" in namespace "gc-3590"
    Dec 14 08:38:03.204: INFO: Deleting pod "simpletest.rc-srhjj" in namespace "gc-3590"
    Dec 14 08:38:03.241: INFO: Deleting pod "simpletest.rc-sscxf" in namespace "gc-3590"
    Dec 14 08:38:03.273: INFO: Deleting pod "simpletest.rc-t2flz" in namespace "gc-3590"
    Dec 14 08:38:03.308: INFO: Deleting pod "simpletest.rc-tfccp" in namespace "gc-3590"
    Dec 14 08:38:03.339: INFO: Deleting pod "simpletest.rc-ttzmm" in namespace "gc-3590"
    Dec 14 08:38:03.377: INFO: Deleting pod "simpletest.rc-v2zld" in namespace "gc-3590"
    Dec 14 08:38:03.413: INFO: Deleting pod "simpletest.rc-vnlvp" in namespace "gc-3590"
    Dec 14 08:38:03.450: INFO: Deleting pod "simpletest.rc-vprwk" in namespace "gc-3590"
    Dec 14 08:38:03.493: INFO: Deleting pod "simpletest.rc-vrjjc" in namespace "gc-3590"
    Dec 14 08:38:03.526: INFO: Deleting pod "simpletest.rc-vwdl2" in namespace "gc-3590"
    Dec 14 08:38:03.561: INFO: Deleting pod "simpletest.rc-w7qsw" in namespace "gc-3590"
    Dec 14 08:38:03.600: INFO: Deleting pod "simpletest.rc-w9wz9" in namespace "gc-3590"
    Dec 14 08:38:03.635: INFO: Deleting pod "simpletest.rc-x9qbv" in namespace "gc-3590"
    Dec 14 08:38:03.671: INFO: Deleting pod "simpletest.rc-xslpt" in namespace "gc-3590"
    Dec 14 08:38:03.708: INFO: Deleting pod "simpletest.rc-z9cbb" in namespace "gc-3590"
    Dec 14 08:38:03.745: INFO: Deleting pod "simpletest.rc-zltz9" in namespace "gc-3590"
    Dec 14 08:38:03.782: INFO: Deleting pod "simpletest.rc-znbht" in namespace "gc-3590"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 08:38:03.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3590" for this suite. 12/14/22 08:38:03.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:03.878
Dec 14 08:38:03.878: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:38:03.879
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:03.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:04.013
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:38:04.066
Dec 14 08:38:04.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52" in namespace "projected-6285" to be "Succeeded or Failed"
Dec 14 08:38:04.135: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 34.692996ms
Dec 14 08:38:06.165: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064169542s
Dec 14 08:38:08.164: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063618136s
Dec 14 08:38:10.163: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063009494s
STEP: Saw pod success 12/14/22 08:38:10.163
Dec 14 08:38:10.164: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52" satisfied condition "Succeeded or Failed"
Dec 14 08:38:10.191: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 container client-container: <nil>
STEP: delete the pod 12/14/22 08:38:10.265
Dec 14 08:38:10.301: INFO: Waiting for pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 to disappear
Dec 14 08:38:10.328: INFO: Pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:38:10.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6285" for this suite. 12/14/22 08:38:10.382
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":40,"skipped":627,"failed":0}
------------------------------
• [6.532 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:03.878
    Dec 14 08:38:03.878: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:38:03.879
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:03.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:04.013
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:38:04.066
    Dec 14 08:38:04.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52" in namespace "projected-6285" to be "Succeeded or Failed"
    Dec 14 08:38:04.135: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 34.692996ms
    Dec 14 08:38:06.165: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064169542s
    Dec 14 08:38:08.164: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063618136s
    Dec 14 08:38:10.163: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063009494s
    STEP: Saw pod success 12/14/22 08:38:10.163
    Dec 14 08:38:10.164: INFO: Pod "downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52" satisfied condition "Succeeded or Failed"
    Dec 14 08:38:10.191: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:38:10.265
    Dec 14 08:38:10.301: INFO: Waiting for pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 to disappear
    Dec 14 08:38:10.328: INFO: Pod downwardapi-volume-a2037d05-a5b6-4ad8-86b9-c72672c4fe52 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:38:10.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6285" for this suite. 12/14/22 08:38:10.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:10.411
Dec 14 08:38:10.411: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:38:10.412
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:10.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:10.55
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 08:38:10.602
Dec 14 08:38:10.638: INFO: Waiting up to 5m0s for pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb" in namespace "emptydir-3564" to be "Succeeded or Failed"
Dec 14 08:38:10.665: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Pending", Reason="", readiness=false. Elapsed: 27.22349ms
Dec 14 08:38:12.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056652555s
Dec 14 08:38:14.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056827685s
STEP: Saw pod success 12/14/22 08:38:14.695
Dec 14 08:38:14.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb" satisfied condition "Succeeded or Failed"
Dec 14 08:38:14.723: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb container test-container: <nil>
STEP: delete the pod 12/14/22 08:38:14.758
Dec 14 08:38:14.798: INFO: Waiting for pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb to disappear
Dec 14 08:38:14.825: INFO: Pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:38:14.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3564" for this suite. 12/14/22 08:38:14.885
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":41,"skipped":632,"failed":0}
------------------------------
• [4.504 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:10.411
    Dec 14 08:38:10.411: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:38:10.412
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:10.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:10.55
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 08:38:10.602
    Dec 14 08:38:10.638: INFO: Waiting up to 5m0s for pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb" in namespace "emptydir-3564" to be "Succeeded or Failed"
    Dec 14 08:38:10.665: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Pending", Reason="", readiness=false. Elapsed: 27.22349ms
    Dec 14 08:38:12.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056652555s
    Dec 14 08:38:14.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056827685s
    STEP: Saw pod success 12/14/22 08:38:14.695
    Dec 14 08:38:14.695: INFO: Pod "pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb" satisfied condition "Succeeded or Failed"
    Dec 14 08:38:14.723: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb container test-container: <nil>
    STEP: delete the pod 12/14/22 08:38:14.758
    Dec 14 08:38:14.798: INFO: Waiting for pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb to disappear
    Dec 14 08:38:14.825: INFO: Pod pod-940d3668-dc7d-43a1-8b5a-9ccc59fdfcbb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:38:14.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3564" for this suite. 12/14/22 08:38:14.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:14.915
Dec 14 08:38:14.915: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:38:14.916
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:14.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:15.05
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:38:15.102
Dec 14 08:38:15.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd" in namespace "projected-4912" to be "Succeeded or Failed"
Dec 14 08:38:15.166: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Pending", Reason="", readiness=false. Elapsed: 27.736263ms
Dec 14 08:38:17.195: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056842721s
Dec 14 08:38:19.194: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055910168s
STEP: Saw pod success 12/14/22 08:38:19.194
Dec 14 08:38:19.194: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd" satisfied condition "Succeeded or Failed"
Dec 14 08:38:19.232: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd container client-container: <nil>
STEP: delete the pod 12/14/22 08:38:19.268
Dec 14 08:38:19.304: INFO: Waiting for pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd to disappear
Dec 14 08:38:19.332: INFO: Pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:38:19.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4912" for this suite. 12/14/22 08:38:19.384
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":42,"skipped":649,"failed":0}
------------------------------
• [4.498 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:14.915
    Dec 14 08:38:14.915: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:38:14.916
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:14.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:15.05
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:38:15.102
    Dec 14 08:38:15.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd" in namespace "projected-4912" to be "Succeeded or Failed"
    Dec 14 08:38:15.166: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Pending", Reason="", readiness=false. Elapsed: 27.736263ms
    Dec 14 08:38:17.195: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056842721s
    Dec 14 08:38:19.194: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055910168s
    STEP: Saw pod success 12/14/22 08:38:19.194
    Dec 14 08:38:19.194: INFO: Pod "downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd" satisfied condition "Succeeded or Failed"
    Dec 14 08:38:19.232: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd container client-container: <nil>
    STEP: delete the pod 12/14/22 08:38:19.268
    Dec 14 08:38:19.304: INFO: Waiting for pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd to disappear
    Dec 14 08:38:19.332: INFO: Pod downwardapi-volume-81516359-36a3-41a2-a9bc-4a99525b48bd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:38:19.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4912" for this suite. 12/14/22 08:38:19.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:19.415
Dec 14 08:38:19.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:38:19.415
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:19.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:19.57
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 12/14/22 08:38:19.658
Dec 14 08:38:19.658: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb" in namespace "kubelet-test-352" to be "completed"
Dec 14 08:38:19.685: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Pending", Reason="", readiness=false. Elapsed: 27.480384ms
Dec 14 08:38:21.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05711545s
Dec 14 08:38:23.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056875525s
Dec 14 08:38:23.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 08:38:23.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-352" for this suite. 12/14/22 08:38:23.803
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":43,"skipped":677,"failed":0}
------------------------------
• [4.417 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:19.415
    Dec 14 08:38:19.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:38:19.415
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:19.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:19.57
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 12/14/22 08:38:19.658
    Dec 14 08:38:19.658: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb" in namespace "kubelet-test-352" to be "completed"
    Dec 14 08:38:19.685: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Pending", Reason="", readiness=false. Elapsed: 27.480384ms
    Dec 14 08:38:21.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05711545s
    Dec 14 08:38:23.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056875525s
    Dec 14 08:38:23.715: INFO: Pod "agnhost-host-aliases5b3ebf92-2326-4d6c-b899-0663db9738fb" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 08:38:23.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-352" for this suite. 12/14/22 08:38:23.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:23.832
Dec 14 08:38:23.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 08:38:23.833
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:23.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:23.974
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 12/14/22 08:38:24.061
STEP: Updating PodDisruptionBudget status 12/14/22 08:38:24.088
STEP: Waiting for all pods to be running 12/14/22 08:38:24.127
Dec 14 08:38:24.157: INFO: running pods: 0 < 1
Dec 14 08:38:26.186: INFO: running pods: 0 < 1
STEP: locating a running pod 12/14/22 08:38:28.185
STEP: Waiting for the pdb to be processed 12/14/22 08:38:28.27
STEP: Patching PodDisruptionBudget status 12/14/22 08:38:28.325
STEP: Waiting for the pdb to be processed 12/14/22 08:38:28.382
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 08:38:28.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1243" for this suite. 12/14/22 08:38:28.463
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":44,"skipped":684,"failed":0}
------------------------------
• [4.659 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:23.832
    Dec 14 08:38:23.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 08:38:23.833
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:23.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:23.974
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 12/14/22 08:38:24.061
    STEP: Updating PodDisruptionBudget status 12/14/22 08:38:24.088
    STEP: Waiting for all pods to be running 12/14/22 08:38:24.127
    Dec 14 08:38:24.157: INFO: running pods: 0 < 1
    Dec 14 08:38:26.186: INFO: running pods: 0 < 1
    STEP: locating a running pod 12/14/22 08:38:28.185
    STEP: Waiting for the pdb to be processed 12/14/22 08:38:28.27
    STEP: Patching PodDisruptionBudget status 12/14/22 08:38:28.325
    STEP: Waiting for the pdb to be processed 12/14/22 08:38:28.382
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 08:38:28.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1243" for this suite. 12/14/22 08:38:28.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:28.496
Dec 14 08:38:28.496: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sysctl 12/14/22 08:38:28.497
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:28.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:28.63
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 12/14/22 08:38:28.682
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:38:28.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-2380" for this suite. 12/14/22 08:38:28.743
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":45,"skipped":735,"failed":0}
------------------------------
• [0.278 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:28.496
    Dec 14 08:38:28.496: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sysctl 12/14/22 08:38:28.497
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:28.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:28.63
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 12/14/22 08:38:28.682
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:38:28.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-2380" for this suite. 12/14/22 08:38:28.743
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:28.774
Dec 14 08:38:28.774: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename csistoragecapacity 12/14/22 08:38:28.775
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:28.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:28.913
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 12/14/22 08:38:28.965
STEP: getting /apis/storage.k8s.io 12/14/22 08:38:29.016
STEP: getting /apis/storage.k8s.io/v1 12/14/22 08:38:29.041
STEP: creating 12/14/22 08:38:29.068
STEP: watching 12/14/22 08:38:29.161
Dec 14 08:38:29.161: INFO: starting watch
STEP: getting 12/14/22 08:38:29.241
STEP: listing in namespace 12/14/22 08:38:29.268
STEP: listing across namespaces 12/14/22 08:38:29.296
STEP: patching 12/14/22 08:38:29.324
STEP: updating 12/14/22 08:38:29.353
Dec 14 08:38:29.381: INFO: waiting for watch events with expected annotations in namespace
Dec 14 08:38:29.381: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 12/14/22 08:38:29.381
STEP: deleting a collection 12/14/22 08:38:29.465
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Dec 14 08:38:29.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-1034" for this suite. 12/14/22 08:38:29.562
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":46,"skipped":743,"failed":0}
------------------------------
• [0.818 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:28.774
    Dec 14 08:38:28.774: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename csistoragecapacity 12/14/22 08:38:28.775
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:28.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:28.913
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 12/14/22 08:38:28.965
    STEP: getting /apis/storage.k8s.io 12/14/22 08:38:29.016
    STEP: getting /apis/storage.k8s.io/v1 12/14/22 08:38:29.041
    STEP: creating 12/14/22 08:38:29.068
    STEP: watching 12/14/22 08:38:29.161
    Dec 14 08:38:29.161: INFO: starting watch
    STEP: getting 12/14/22 08:38:29.241
    STEP: listing in namespace 12/14/22 08:38:29.268
    STEP: listing across namespaces 12/14/22 08:38:29.296
    STEP: patching 12/14/22 08:38:29.324
    STEP: updating 12/14/22 08:38:29.353
    Dec 14 08:38:29.381: INFO: waiting for watch events with expected annotations in namespace
    Dec 14 08:38:29.381: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 12/14/22 08:38:29.381
    STEP: deleting a collection 12/14/22 08:38:29.465
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Dec 14 08:38:29.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-1034" for this suite. 12/14/22 08:38:29.562
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:29.593
Dec 14 08:38:29.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:38:29.595
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:29.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:29.729
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 12/14/22 08:38:29.78
STEP: Creating a ResourceQuota 12/14/22 08:38:34.812
STEP: Ensuring resource quota status is calculated 12/14/22 08:38:34.843
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:38:36.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7302" for this suite. 12/14/22 08:38:36.935
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":47,"skipped":771,"failed":0}
------------------------------
• [7.371 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:29.593
    Dec 14 08:38:29.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:38:29.595
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:29.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:29.729
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 12/14/22 08:38:29.78
    STEP: Creating a ResourceQuota 12/14/22 08:38:34.812
    STEP: Ensuring resource quota status is calculated 12/14/22 08:38:34.843
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:38:36.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7302" for this suite. 12/14/22 08:38:36.935
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:36.965
Dec 14 08:38:36.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:38:36.966
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:37.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:37.101
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 12/14/22 08:38:37.182
Dec 14 08:38:37.182: INFO: Creating simple deployment test-deployment-cmpjz
Dec 14 08:38:37.318: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-cmpjz-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 12/14/22 08:38:39.377
Dec 14 08:38:39.406: INFO: Deployment test-deployment-cmpjz has Conditions: [{Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 12/14/22 08:38:39.406
Dec 14 08:38:39.463: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-cmpjz-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 12/14/22 08:38:39.463
Dec 14 08:38:39.490: INFO: Observed &Deployment event: ADDED
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-cmpjz-777898ffcc" is progressing.}
Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
Dec 14 08:38:39.490: INFO: Found Deployment test-deployment-cmpjz in namespace deployment-2633 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 08:38:39.490: INFO: Deployment test-deployment-cmpjz has an updated status
STEP: patching the Statefulset Status 12/14/22 08:38:39.49
Dec 14 08:38:39.490: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 08:38:39.527: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 12/14/22 08:38:39.527
Dec 14 08:38:39.595: INFO: Observed &Deployment event: ADDED
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-cmpjz-777898ffcc" is progressing.}
Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
Dec 14 08:38:39.596: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 08:38:39.596: INFO: Observed &Deployment event: MODIFIED
Dec 14 08:38:39.596: INFO: Found deployment test-deployment-cmpjz in namespace deployment-2633 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Dec 14 08:38:39.596: INFO: Deployment test-deployment-cmpjz has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:38:39.623: INFO: Deployment "test-deployment-cmpjz":
&Deployment{ObjectMeta:{test-deployment-cmpjz  deployment-2633  d139b7e0-8857-407f-a328-f1d72590abd3 14985 1 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-14 08:38:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-14 08:38:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c0ad38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:38:39 +0000 UTC,LastTransitionTime:2022-12-14 08:38:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.,LastUpdateTime:2022-12-14 08:38:39 +0000 UTC,LastTransitionTime:2022-12-14 08:38:39 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 08:38:39.651: INFO: New ReplicaSet "test-deployment-cmpjz-777898ffcc" of Deployment "test-deployment-cmpjz":
&ReplicaSet{ObjectMeta:{test-deployment-cmpjz-777898ffcc  deployment-2633  e60ed870-b04b-4ad0-962e-e8900b5ada94 14975 1 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-cmpjz d139b7e0-8857-407f-a328-f1d72590abd3 0xc00391e810 0xc00391e811}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d139b7e0-8857-407f-a328-f1d72590abd3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:38:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00391e8b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:38:39.678: INFO: Pod "test-deployment-cmpjz-777898ffcc-vkrx6" is available:
&Pod{ObjectMeta:{test-deployment-cmpjz-777898ffcc-vkrx6 test-deployment-cmpjz-777898ffcc- deployment-2633  ea6a20dd-bd9f-4d06-88f6-f050722a6f7e 14974 0 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:641092c21f98d0b815cd55ba67beedd5cce277d7e24576c901f08c57fa729a1e cni.projectcalico.org/podIP:100.64.0.104/32 cni.projectcalico.org/podIPs:100.64.0.104/32] [{apps/v1 ReplicaSet test-deployment-cmpjz-777898ffcc e60ed870-b04b-4ad0-962e-e8900b5ada94 0xc003c0b160 0xc003c0b161}] [] [{Go-http-client Update v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e60ed870-b04b-4ad0-962e-e8900b5ada94\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:38:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kgh7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kgh7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.104,StartTime:2022-12-14 08:38:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:38:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b34f8fb3ee313433f77f821e4851742d942b3c8ae9e828507a09a78f67793a8f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:38:39.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2633" for this suite. 12/14/22 08:38:39.708
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":48,"skipped":773,"failed":0}
------------------------------
• [2.771 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:36.965
    Dec 14 08:38:36.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:38:36.966
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:37.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:37.101
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 12/14/22 08:38:37.182
    Dec 14 08:38:37.182: INFO: Creating simple deployment test-deployment-cmpjz
    Dec 14 08:38:37.318: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-cmpjz-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 12/14/22 08:38:39.377
    Dec 14 08:38:39.406: INFO: Deployment test-deployment-cmpjz has Conditions: [{Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 12/14/22 08:38:39.406
    Dec 14 08:38:39.463: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 37, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-cmpjz-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 12/14/22 08:38:39.463
    Dec 14 08:38:39.490: INFO: Observed &Deployment event: ADDED
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
    Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-cmpjz-777898ffcc" is progressing.}
    Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
    Dec 14 08:38:39.490: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 08:38:39.490: INFO: Observed Deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
    Dec 14 08:38:39.490: INFO: Found Deployment test-deployment-cmpjz in namespace deployment-2633 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 08:38:39.490: INFO: Deployment test-deployment-cmpjz has an updated status
    STEP: patching the Statefulset Status 12/14/22 08:38:39.49
    Dec 14 08:38:39.490: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 08:38:39.527: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 12/14/22 08:38:39.527
    Dec 14 08:38:39.595: INFO: Observed &Deployment event: ADDED
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
    Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-cmpjz-777898ffcc"}
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:37 +0000 UTC 2022-12-14 08:38:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-cmpjz-777898ffcc" is progressing.}
    Dec 14 08:38:39.595: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 08:38:39.595: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
    Dec 14 08:38:39.596: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 08:38:38 +0000 UTC 2022-12-14 08:38:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.}
    Dec 14 08:38:39.596: INFO: Observed deployment test-deployment-cmpjz in namespace deployment-2633 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 08:38:39.596: INFO: Observed &Deployment event: MODIFIED
    Dec 14 08:38:39.596: INFO: Found deployment test-deployment-cmpjz in namespace deployment-2633 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Dec 14 08:38:39.596: INFO: Deployment test-deployment-cmpjz has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:38:39.623: INFO: Deployment "test-deployment-cmpjz":
    &Deployment{ObjectMeta:{test-deployment-cmpjz  deployment-2633  d139b7e0-8857-407f-a328-f1d72590abd3 14985 1 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-14 08:38:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-14 08:38:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c0ad38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:38:39 +0000 UTC,LastTransitionTime:2022-12-14 08:38:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-cmpjz-777898ffcc" has successfully progressed.,LastUpdateTime:2022-12-14 08:38:39 +0000 UTC,LastTransitionTime:2022-12-14 08:38:39 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 08:38:39.651: INFO: New ReplicaSet "test-deployment-cmpjz-777898ffcc" of Deployment "test-deployment-cmpjz":
    &ReplicaSet{ObjectMeta:{test-deployment-cmpjz-777898ffcc  deployment-2633  e60ed870-b04b-4ad0-962e-e8900b5ada94 14975 1 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-cmpjz d139b7e0-8857-407f-a328-f1d72590abd3 0xc00391e810 0xc00391e811}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d139b7e0-8857-407f-a328-f1d72590abd3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:38:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00391e8b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:38:39.678: INFO: Pod "test-deployment-cmpjz-777898ffcc-vkrx6" is available:
    &Pod{ObjectMeta:{test-deployment-cmpjz-777898ffcc-vkrx6 test-deployment-cmpjz-777898ffcc- deployment-2633  ea6a20dd-bd9f-4d06-88f6-f050722a6f7e 14974 0 2022-12-14 08:38:37 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:641092c21f98d0b815cd55ba67beedd5cce277d7e24576c901f08c57fa729a1e cni.projectcalico.org/podIP:100.64.0.104/32 cni.projectcalico.org/podIPs:100.64.0.104/32] [{apps/v1 ReplicaSet test-deployment-cmpjz-777898ffcc e60ed870-b04b-4ad0-962e-e8900b5ada94 0xc003c0b160 0xc003c0b161}] [] [{Go-http-client Update v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:38:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e60ed870-b04b-4ad0-962e-e8900b5ada94\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:38:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kgh7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kgh7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:38:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.104,StartTime:2022-12-14 08:38:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:38:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b34f8fb3ee313433f77f821e4851742d942b3c8ae9e828507a09a78f67793a8f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:38:39.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2633" for this suite. 12/14/22 08:38:39.708
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:39.738
Dec 14 08:38:39.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:38:39.739
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:39.824
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:39.876
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:38:39.985
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:38:40.373
STEP: Deploying the webhook pod 12/14/22 08:38:40.402
STEP: Wait for the deployment to be ready 12/14/22 08:38:40.461
Dec 14 08:38:40.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:38:42.575
STEP: Verifying the service has paired with the endpoint 12/14/22 08:38:42.613
Dec 14 08:38:43.613: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 12/14/22 08:38:43.935
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:38:44.097
STEP: Deleting the collection of validation webhooks 12/14/22 08:38:44.217
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:38:44.28
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:38:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9095" for this suite. 12/14/22 08:38:44.37
STEP: Destroying namespace "webhook-9095-markers" for this suite. 12/14/22 08:38:44.399
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":49,"skipped":793,"failed":0}
------------------------------
• [4.840 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:39.738
    Dec 14 08:38:39.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:38:39.739
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:39.824
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:39.876
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:38:39.985
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:38:40.373
    STEP: Deploying the webhook pod 12/14/22 08:38:40.402
    STEP: Wait for the deployment to be ready 12/14/22 08:38:40.461
    Dec 14 08:38:40.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:38:42.575
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:38:42.613
    Dec 14 08:38:43.613: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 12/14/22 08:38:43.935
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:38:44.097
    STEP: Deleting the collection of validation webhooks 12/14/22 08:38:44.217
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:38:44.28
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:38:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9095" for this suite. 12/14/22 08:38:44.37
    STEP: Destroying namespace "webhook-9095-markers" for this suite. 12/14/22 08:38:44.399
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:44.581
Dec 14 08:38:44.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:38:44.582
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:44.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:44.731
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 12/14/22 08:38:44.784
STEP: Creating a ResourceQuota 12/14/22 08:38:49.813
STEP: Ensuring resource quota status is calculated 12/14/22 08:38:49.841
STEP: Creating a Service 12/14/22 08:38:51.87
STEP: Creating a NodePort Service 12/14/22 08:38:51.915
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/14/22 08:38:51.965
STEP: Ensuring resource quota status captures service creation 12/14/22 08:38:52.018
STEP: Deleting Services 12/14/22 08:38:54.046
STEP: Ensuring resource quota status released usage 12/14/22 08:38:54.143
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:38:56.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4113" for this suite. 12/14/22 08:38:56.23
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":50,"skipped":845,"failed":0}
------------------------------
• [11.677 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:44.581
    Dec 14 08:38:44.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:38:44.582
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:44.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:44.731
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 12/14/22 08:38:44.784
    STEP: Creating a ResourceQuota 12/14/22 08:38:49.813
    STEP: Ensuring resource quota status is calculated 12/14/22 08:38:49.841
    STEP: Creating a Service 12/14/22 08:38:51.87
    STEP: Creating a NodePort Service 12/14/22 08:38:51.915
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/14/22 08:38:51.965
    STEP: Ensuring resource quota status captures service creation 12/14/22 08:38:52.018
    STEP: Deleting Services 12/14/22 08:38:54.046
    STEP: Ensuring resource quota status released usage 12/14/22 08:38:54.143
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:38:56.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4113" for this suite. 12/14/22 08:38:56.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:38:56.259
Dec 14 08:38:56.259: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:38:56.26
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:56.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:56.394
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:38:56.511
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:38:56.781
STEP: Deploying the webhook pod 12/14/22 08:38:56.809
STEP: Wait for the deployment to be ready 12/14/22 08:38:56.866
Dec 14 08:38:56.958: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:38:58.989
STEP: Verifying the service has paired with the endpoint 12/14/22 08:38:59.033
Dec 14 08:39:00.034: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 12/14/22 08:39:00.062
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.23
STEP: Updating a validating webhook configuration's rules to not include the create operation 12/14/22 08:39:00.365
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.423
STEP: Patching a validating webhook configuration's rules to include the create operation 12/14/22 08:39:00.492
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.521
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:39:00.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9652" for this suite. 12/14/22 08:39:00.634
STEP: Destroying namespace "webhook-9652-markers" for this suite. 12/14/22 08:39:00.663
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":51,"skipped":855,"failed":0}
------------------------------
• [4.595 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:38:56.259
    Dec 14 08:38:56.259: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:38:56.26
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:38:56.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:38:56.394
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:38:56.511
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:38:56.781
    STEP: Deploying the webhook pod 12/14/22 08:38:56.809
    STEP: Wait for the deployment to be ready 12/14/22 08:38:56.866
    Dec 14 08:38:56.958: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 38, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:38:58.989
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:38:59.033
    Dec 14 08:39:00.034: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 12/14/22 08:39:00.062
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.23
    STEP: Updating a validating webhook configuration's rules to not include the create operation 12/14/22 08:39:00.365
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.423
    STEP: Patching a validating webhook configuration's rules to include the create operation 12/14/22 08:39:00.492
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 08:39:00.521
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:39:00.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9652" for this suite. 12/14/22 08:39:00.634
    STEP: Destroying namespace "webhook-9652-markers" for this suite. 12/14/22 08:39:00.663
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:00.855
Dec 14 08:39:00.855: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 08:39:00.856
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:00.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:00.994
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 12/14/22 08:39:01.046
STEP: creating a new configmap 12/14/22 08:39:01.071
STEP: modifying the configmap once 12/14/22 08:39:01.099
STEP: closing the watch once it receives two notifications 12/14/22 08:39:01.156
Dec 14 08:39:01.156: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15274 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 08:39:01.156: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15275 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 12/14/22 08:39:01.156
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/14/22 08:39:01.217
STEP: deleting the configmap 12/14/22 08:39:01.243
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/14/22 08:39:01.271
Dec 14 08:39:01.271: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15276 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 08:39:01.272: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15277 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 08:39:01.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1142" for this suite. 12/14/22 08:39:01.3
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":52,"skipped":870,"failed":0}
------------------------------
• [0.474 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:00.855
    Dec 14 08:39:00.855: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 08:39:00.856
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:00.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:00.994
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 12/14/22 08:39:01.046
    STEP: creating a new configmap 12/14/22 08:39:01.071
    STEP: modifying the configmap once 12/14/22 08:39:01.099
    STEP: closing the watch once it receives two notifications 12/14/22 08:39:01.156
    Dec 14 08:39:01.156: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15274 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 08:39:01.156: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15275 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 12/14/22 08:39:01.156
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/14/22 08:39:01.217
    STEP: deleting the configmap 12/14/22 08:39:01.243
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/14/22 08:39:01.271
    Dec 14 08:39:01.271: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15276 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 08:39:01.272: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1142  dba83d7a-8c7b-4110-ae83-ca52d35f7f81 15277 0 2022-12-14 08:39:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 08:39:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 08:39:01.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1142" for this suite. 12/14/22 08:39:01.3
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:01.329
Dec 14 08:39:01.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:39:01.33
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:01.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:01.463
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 12/14/22 08:39:01.514
Dec 14 08:39:01.514: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 create -f -'
Dec 14 08:39:01.869: INFO: stderr: ""
Dec 14 08:39:01.870: INFO: stdout: "pod/pause created\n"
Dec 14 08:39:01.870: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 14 08:39:01.870: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7595" to be "running and ready"
Dec 14 08:39:01.897: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 27.555925ms
Dec 14 08:39:01.897: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'shoot--it--tm0ct-io0-worker-1-6f755-hwmlx' to be 'Running' but was 'Pending'
Dec 14 08:39:03.926: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.05624258s
Dec 14 08:39:03.926: INFO: Pod "pause" satisfied condition "running and ready"
Dec 14 08:39:03.926: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 12/14/22 08:39:03.926
Dec 14 08:39:03.926: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 label pods pause testing-label=testing-label-value'
Dec 14 08:39:04.111: INFO: stderr: ""
Dec 14 08:39:04.111: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 12/14/22 08:39:04.111
Dec 14 08:39:04.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pod pause -L testing-label'
Dec 14 08:39:04.272: INFO: stderr: ""
Dec 14 08:39:04.272: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod 12/14/22 08:39:04.272
Dec 14 08:39:04.272: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 label pods pause testing-label-'
Dec 14 08:39:04.458: INFO: stderr: ""
Dec 14 08:39:04.458: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 12/14/22 08:39:04.458
Dec 14 08:39:04.458: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pod pause -L testing-label'
Dec 14 08:39:04.620: INFO: stderr: ""
Dec 14 08:39:04.620: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 12/14/22 08:39:04.62
Dec 14 08:39:04.620: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 delete --grace-period=0 --force -f -'
Dec 14 08:39:04.821: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:39:04.821: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 14 08:39:04.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get rc,svc -l name=pause --no-headers'
Dec 14 08:39:05.025: INFO: stderr: "No resources found in kubectl-7595 namespace.\n"
Dec 14 08:39:05.025: INFO: stdout: ""
Dec 14 08:39:05.025: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 08:39:05.197: INFO: stderr: ""
Dec 14 08:39:05.197: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:39:05.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7595" for this suite. 12/14/22 08:39:05.25
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":53,"skipped":874,"failed":0}
------------------------------
• [3.950 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:01.329
    Dec 14 08:39:01.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:39:01.33
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:01.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:01.463
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 12/14/22 08:39:01.514
    Dec 14 08:39:01.514: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 create -f -'
    Dec 14 08:39:01.869: INFO: stderr: ""
    Dec 14 08:39:01.870: INFO: stdout: "pod/pause created\n"
    Dec 14 08:39:01.870: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Dec 14 08:39:01.870: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7595" to be "running and ready"
    Dec 14 08:39:01.897: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 27.555925ms
    Dec 14 08:39:01.897: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'shoot--it--tm0ct-io0-worker-1-6f755-hwmlx' to be 'Running' but was 'Pending'
    Dec 14 08:39:03.926: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.05624258s
    Dec 14 08:39:03.926: INFO: Pod "pause" satisfied condition "running and ready"
    Dec 14 08:39:03.926: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 12/14/22 08:39:03.926
    Dec 14 08:39:03.926: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 label pods pause testing-label=testing-label-value'
    Dec 14 08:39:04.111: INFO: stderr: ""
    Dec 14 08:39:04.111: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 12/14/22 08:39:04.111
    Dec 14 08:39:04.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pod pause -L testing-label'
    Dec 14 08:39:04.272: INFO: stderr: ""
    Dec 14 08:39:04.272: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 12/14/22 08:39:04.272
    Dec 14 08:39:04.272: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 label pods pause testing-label-'
    Dec 14 08:39:04.458: INFO: stderr: ""
    Dec 14 08:39:04.458: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 12/14/22 08:39:04.458
    Dec 14 08:39:04.458: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pod pause -L testing-label'
    Dec 14 08:39:04.620: INFO: stderr: ""
    Dec 14 08:39:04.620: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 12/14/22 08:39:04.62
    Dec 14 08:39:04.620: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 delete --grace-period=0 --force -f -'
    Dec 14 08:39:04.821: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:39:04.821: INFO: stdout: "pod \"pause\" force deleted\n"
    Dec 14 08:39:04.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get rc,svc -l name=pause --no-headers'
    Dec 14 08:39:05.025: INFO: stderr: "No resources found in kubectl-7595 namespace.\n"
    Dec 14 08:39:05.025: INFO: stdout: ""
    Dec 14 08:39:05.025: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7595 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 08:39:05.197: INFO: stderr: ""
    Dec 14 08:39:05.197: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:39:05.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7595" for this suite. 12/14/22 08:39:05.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:05.281
Dec 14 08:39:05.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:39:05.282
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:05.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:05.419
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:39:05.471
Dec 14 08:39:05.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3457 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Dec 14 08:39:05.630: INFO: stderr: ""
Dec 14 08:39:05.630: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 08:39:05.63
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Dec 14 08:39:05.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3457 delete pods e2e-test-httpd-pod'
Dec 14 08:39:08.114: INFO: stderr: ""
Dec 14 08:39:08.114: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:39:08.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3457" for this suite. 12/14/22 08:39:08.167
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":54,"skipped":913,"failed":0}
------------------------------
• [2.914 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:05.281
    Dec 14 08:39:05.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:39:05.282
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:05.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:05.419
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 08:39:05.471
    Dec 14 08:39:05.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3457 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Dec 14 08:39:05.630: INFO: stderr: ""
    Dec 14 08:39:05.630: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 08:39:05.63
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Dec 14 08:39:05.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3457 delete pods e2e-test-httpd-pod'
    Dec 14 08:39:08.114: INFO: stderr: ""
    Dec 14 08:39:08.114: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:39:08.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3457" for this suite. 12/14/22 08:39:08.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:08.196
Dec 14 08:39:08.196: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 08:39:08.197
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:08.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:08.33
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 12/14/22 08:39:08.385
STEP: Waiting for the pdb to be processed 12/14/22 08:39:08.413
STEP: First trying to evict a pod which shouldn't be evictable 12/14/22 08:39:08.469
STEP: Waiting for all pods to be running 12/14/22 08:39:08.469
Dec 14 08:39:08.498: INFO: running pods: 0 < 3
Dec 14 08:39:10.527: INFO: running pods: 2 < 3
STEP: locating a running pod 12/14/22 08:39:12.528
STEP: Updating the pdb to allow a pod to be evicted 12/14/22 08:39:12.587
STEP: Waiting for the pdb to be processed 12/14/22 08:39:12.646
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 08:39:12.673
STEP: Waiting for all pods to be running 12/14/22 08:39:12.673
STEP: Waiting for the pdb to observed all healthy pods 12/14/22 08:39:12.701
STEP: Patching the pdb to disallow a pod to be evicted 12/14/22 08:39:12.768
STEP: Waiting for the pdb to be processed 12/14/22 08:39:12.832
STEP: Waiting for all pods to be running 12/14/22 08:39:12.859
Dec 14 08:39:12.888: INFO: running pods: 2 < 3
STEP: locating a running pod 12/14/22 08:39:14.917
STEP: Deleting the pdb to allow a pod to be evicted 12/14/22 08:39:14.978
STEP: Waiting for the pdb to be deleted 12/14/22 08:39:15.007
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 08:39:15.034
STEP: Waiting for all pods to be running 12/14/22 08:39:15.034
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 08:39:15.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8984" for this suite. 12/14/22 08:39:15.149
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":55,"skipped":927,"failed":0}
------------------------------
• [6.986 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:08.196
    Dec 14 08:39:08.196: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 08:39:08.197
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:08.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:08.33
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 12/14/22 08:39:08.385
    STEP: Waiting for the pdb to be processed 12/14/22 08:39:08.413
    STEP: First trying to evict a pod which shouldn't be evictable 12/14/22 08:39:08.469
    STEP: Waiting for all pods to be running 12/14/22 08:39:08.469
    Dec 14 08:39:08.498: INFO: running pods: 0 < 3
    Dec 14 08:39:10.527: INFO: running pods: 2 < 3
    STEP: locating a running pod 12/14/22 08:39:12.528
    STEP: Updating the pdb to allow a pod to be evicted 12/14/22 08:39:12.587
    STEP: Waiting for the pdb to be processed 12/14/22 08:39:12.646
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 08:39:12.673
    STEP: Waiting for all pods to be running 12/14/22 08:39:12.673
    STEP: Waiting for the pdb to observed all healthy pods 12/14/22 08:39:12.701
    STEP: Patching the pdb to disallow a pod to be evicted 12/14/22 08:39:12.768
    STEP: Waiting for the pdb to be processed 12/14/22 08:39:12.832
    STEP: Waiting for all pods to be running 12/14/22 08:39:12.859
    Dec 14 08:39:12.888: INFO: running pods: 2 < 3
    STEP: locating a running pod 12/14/22 08:39:14.917
    STEP: Deleting the pdb to allow a pod to be evicted 12/14/22 08:39:14.978
    STEP: Waiting for the pdb to be deleted 12/14/22 08:39:15.007
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 08:39:15.034
    STEP: Waiting for all pods to be running 12/14/22 08:39:15.034
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 08:39:15.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8984" for this suite. 12/14/22 08:39:15.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:15.184
Dec 14 08:39:15.184: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:39:15.184
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:15.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:15.32
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:39:15.371
Dec 14 08:39:15.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d" in namespace "projected-2298" to be "Succeeded or Failed"
Dec 14 08:39:15.435: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.443291ms
Dec 14 08:39:17.464: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056918123s
Dec 14 08:39:19.462: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055716057s
STEP: Saw pod success 12/14/22 08:39:19.462
Dec 14 08:39:19.463: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d" satisfied condition "Succeeded or Failed"
Dec 14 08:39:19.490: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d container client-container: <nil>
STEP: delete the pod 12/14/22 08:39:19.565
Dec 14 08:39:19.607: INFO: Waiting for pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d to disappear
Dec 14 08:39:19.635: INFO: Pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:39:19.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2298" for this suite. 12/14/22 08:39:19.689
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":56,"skipped":954,"failed":0}
------------------------------
• [4.534 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:15.184
    Dec 14 08:39:15.184: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:39:15.184
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:15.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:15.32
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:39:15.371
    Dec 14 08:39:15.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d" in namespace "projected-2298" to be "Succeeded or Failed"
    Dec 14 08:39:15.435: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.443291ms
    Dec 14 08:39:17.464: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056918123s
    Dec 14 08:39:19.462: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055716057s
    STEP: Saw pod success 12/14/22 08:39:19.462
    Dec 14 08:39:19.463: INFO: Pod "downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d" satisfied condition "Succeeded or Failed"
    Dec 14 08:39:19.490: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d container client-container: <nil>
    STEP: delete the pod 12/14/22 08:39:19.565
    Dec 14 08:39:19.607: INFO: Waiting for pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d to disappear
    Dec 14 08:39:19.635: INFO: Pod downwardapi-volume-2ae40a8e-6408-4d1a-b438-2ca1e5d60a8d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:39:19.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2298" for this suite. 12/14/22 08:39:19.689
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:19.718
Dec 14 08:39:19.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ingressclass 12/14/22 08:39:19.719
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:19.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:19.853
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 12/14/22 08:39:19.905
STEP: getting /apis/networking.k8s.io 12/14/22 08:39:19.957
STEP: getting /apis/networking.k8s.iov1 12/14/22 08:39:19.982
STEP: creating 12/14/22 08:39:20.009
STEP: getting 12/14/22 08:39:20.092
STEP: listing 12/14/22 08:39:20.12
STEP: watching 12/14/22 08:39:20.148
Dec 14 08:39:20.148: INFO: starting watch
STEP: patching 12/14/22 08:39:20.174
STEP: updating 12/14/22 08:39:20.203
Dec 14 08:39:20.232: INFO: waiting for watch events with expected annotations
Dec 14 08:39:20.232: INFO: saw patched and updated annotations
STEP: deleting 12/14/22 08:39:20.232
STEP: deleting a collection 12/14/22 08:39:20.316
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Dec 14 08:39:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-4863" for this suite. 12/14/22 08:39:20.409
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":57,"skipped":955,"failed":0}
------------------------------
• [0.723 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:19.718
    Dec 14 08:39:19.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ingressclass 12/14/22 08:39:19.719
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:19.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:19.853
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 12/14/22 08:39:19.905
    STEP: getting /apis/networking.k8s.io 12/14/22 08:39:19.957
    STEP: getting /apis/networking.k8s.iov1 12/14/22 08:39:19.982
    STEP: creating 12/14/22 08:39:20.009
    STEP: getting 12/14/22 08:39:20.092
    STEP: listing 12/14/22 08:39:20.12
    STEP: watching 12/14/22 08:39:20.148
    Dec 14 08:39:20.148: INFO: starting watch
    STEP: patching 12/14/22 08:39:20.174
    STEP: updating 12/14/22 08:39:20.203
    Dec 14 08:39:20.232: INFO: waiting for watch events with expected annotations
    Dec 14 08:39:20.232: INFO: saw patched and updated annotations
    STEP: deleting 12/14/22 08:39:20.232
    STEP: deleting a collection 12/14/22 08:39:20.316
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Dec 14 08:39:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-4863" for this suite. 12/14/22 08:39:20.409
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:20.442
Dec 14 08:39:20.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:39:20.443
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:20.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:20.576
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:39:20.629
Dec 14 08:39:20.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0" in namespace "projected-2127" to be "Succeeded or Failed"
Dec 14 08:39:20.692: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Pending", Reason="", readiness=false. Elapsed: 27.987399ms
Dec 14 08:39:22.722: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057094999s
Dec 14 08:39:24.721: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0569984s
STEP: Saw pod success 12/14/22 08:39:24.721
Dec 14 08:39:24.722: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0" satisfied condition "Succeeded or Failed"
Dec 14 08:39:24.753: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 container client-container: <nil>
STEP: delete the pod 12/14/22 08:39:24.788
Dec 14 08:39:24.825: INFO: Waiting for pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 to disappear
Dec 14 08:39:24.852: INFO: Pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:39:24.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2127" for this suite. 12/14/22 08:39:24.906
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":58,"skipped":961,"failed":0}
------------------------------
• [4.493 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:20.442
    Dec 14 08:39:20.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:39:20.443
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:20.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:20.576
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:39:20.629
    Dec 14 08:39:20.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0" in namespace "projected-2127" to be "Succeeded or Failed"
    Dec 14 08:39:20.692: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Pending", Reason="", readiness=false. Elapsed: 27.987399ms
    Dec 14 08:39:22.722: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057094999s
    Dec 14 08:39:24.721: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0569984s
    STEP: Saw pod success 12/14/22 08:39:24.721
    Dec 14 08:39:24.722: INFO: Pod "downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0" satisfied condition "Succeeded or Failed"
    Dec 14 08:39:24.753: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:39:24.788
    Dec 14 08:39:24.825: INFO: Waiting for pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 to disappear
    Dec 14 08:39:24.852: INFO: Pod downwardapi-volume-89890417-71ae-47a3-af95-97fcd466ffd0 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:39:24.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2127" for this suite. 12/14/22 08:39:24.906
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:24.935
Dec 14 08:39:24.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:39:24.936
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:25.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:25.07
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 08:39:25.122
Dec 14 08:39:25.157: INFO: Waiting up to 5m0s for pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40" in namespace "emptydir-2901" to be "Succeeded or Failed"
Dec 14 08:39:25.184: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Pending", Reason="", readiness=false. Elapsed: 26.682268ms
Dec 14 08:39:27.213: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055350687s
Dec 14 08:39:29.212: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054931188s
STEP: Saw pod success 12/14/22 08:39:29.212
Dec 14 08:39:29.212: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40" satisfied condition "Succeeded or Failed"
Dec 14 08:39:29.239: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 container test-container: <nil>
STEP: delete the pod 12/14/22 08:39:29.273
Dec 14 08:39:29.309: INFO: Waiting for pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 to disappear
Dec 14 08:39:29.344: INFO: Pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:39:29.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2901" for this suite. 12/14/22 08:39:29.396
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":976,"failed":0}
------------------------------
• [4.491 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:24.935
    Dec 14 08:39:24.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:39:24.936
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:25.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:25.07
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 08:39:25.122
    Dec 14 08:39:25.157: INFO: Waiting up to 5m0s for pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40" in namespace "emptydir-2901" to be "Succeeded or Failed"
    Dec 14 08:39:25.184: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Pending", Reason="", readiness=false. Elapsed: 26.682268ms
    Dec 14 08:39:27.213: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055350687s
    Dec 14 08:39:29.212: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054931188s
    STEP: Saw pod success 12/14/22 08:39:29.212
    Dec 14 08:39:29.212: INFO: Pod "pod-5e0d226f-2437-4d88-a405-0428b7fd8f40" satisfied condition "Succeeded or Failed"
    Dec 14 08:39:29.239: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 container test-container: <nil>
    STEP: delete the pod 12/14/22 08:39:29.273
    Dec 14 08:39:29.309: INFO: Waiting for pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 to disappear
    Dec 14 08:39:29.344: INFO: Pod pod-5e0d226f-2437-4d88-a405-0428b7fd8f40 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:39:29.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2901" for this suite. 12/14/22 08:39:29.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:29.427
Dec 14 08:39:29.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 08:39:29.427
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:29.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:29.56
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1894 12/14/22 08:39:29.612
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1894 12/14/22 08:39:29.64
Dec 14 08:39:29.696: INFO: Found 0 stateful pods, waiting for 1
Dec 14 08:39:39.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 12/14/22 08:39:39.782
STEP: updating a scale subresource 12/14/22 08:39:39.809
STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 08:39:39.843
STEP: Patch a scale subresource 12/14/22 08:39:39.87
STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 08:39:39.899
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 08:39:39.927: INFO: Deleting all statefulset in ns statefulset-1894
Dec 14 08:39:39.953: INFO: Scaling statefulset ss to 0
Dec 14 08:39:50.068: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 08:39:50.096: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 08:39:50.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1894" for this suite. 12/14/22 08:39:50.235
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":60,"skipped":996,"failed":0}
------------------------------
• [20.844 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:29.427
    Dec 14 08:39:29.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 08:39:29.427
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:29.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:29.56
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1894 12/14/22 08:39:29.612
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1894 12/14/22 08:39:29.64
    Dec 14 08:39:29.696: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 08:39:39.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 12/14/22 08:39:39.782
    STEP: updating a scale subresource 12/14/22 08:39:39.809
    STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 08:39:39.843
    STEP: Patch a scale subresource 12/14/22 08:39:39.87
    STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 08:39:39.899
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 08:39:39.927: INFO: Deleting all statefulset in ns statefulset-1894
    Dec 14 08:39:39.953: INFO: Scaling statefulset ss to 0
    Dec 14 08:39:50.068: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 08:39:50.096: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 08:39:50.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1894" for this suite. 12/14/22 08:39:50.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:39:50.271
Dec 14 08:39:50.272: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 08:39:50.273
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:50.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:50.408
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 12/14/22 08:39:55.717
STEP: referencing matching pods with named port 12/14/22 08:40:00.773
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/14/22 08:40:05.829
STEP: recreating EndpointSlices after they've been deleted 12/14/22 08:40:10.885
Dec 14 08:40:10.998: INFO: EndpointSlice for Service endpointslice-6962/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 08:40:21.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6962" for this suite. 12/14/22 08:40:21.112
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":61,"skipped":1005,"failed":0}
------------------------------
• [30.870 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:39:50.271
    Dec 14 08:39:50.272: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 08:39:50.273
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:39:50.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:39:50.408
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 12/14/22 08:39:55.717
    STEP: referencing matching pods with named port 12/14/22 08:40:00.773
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/14/22 08:40:05.829
    STEP: recreating EndpointSlices after they've been deleted 12/14/22 08:40:10.885
    Dec 14 08:40:10.998: INFO: EndpointSlice for Service endpointslice-6962/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 08:40:21.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6962" for this suite. 12/14/22 08:40:21.112
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:21.144
Dec 14 08:40:21.144: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 08:40:21.145
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:21.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:21.281
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 12/14/22 08:40:21.332
STEP: delete the rc 12/14/22 08:40:26.389
STEP: wait for all pods to be garbage collected 12/14/22 08:40:26.42
STEP: Gathering metrics 12/14/22 08:40:31.477
W1214 08:40:31.565354    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 08:40:31.565: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 08:40:31.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7139" for this suite. 12/14/22 08:40:31.594
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":62,"skipped":1053,"failed":0}
------------------------------
• [10.480 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:21.144
    Dec 14 08:40:21.144: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 08:40:21.145
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:21.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:21.281
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 12/14/22 08:40:21.332
    STEP: delete the rc 12/14/22 08:40:26.389
    STEP: wait for all pods to be garbage collected 12/14/22 08:40:26.42
    STEP: Gathering metrics 12/14/22 08:40:31.477
    W1214 08:40:31.565354    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 08:40:31.565: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 08:40:31.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7139" for this suite. 12/14/22 08:40:31.594
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:31.625
Dec 14 08:40:31.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:40:31.626
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:31.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:31.761
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-2e3d1a0c-fc11-46b9-9960-6a3e5de22808 12/14/22 08:40:31.813
STEP: Creating a pod to test consume configMaps 12/14/22 08:40:31.841
Dec 14 08:40:31.876: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718" in namespace "projected-4495" to be "Succeeded or Failed"
Dec 14 08:40:31.903: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Pending", Reason="", readiness=false. Elapsed: 26.907029ms
Dec 14 08:40:33.931: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055322739s
Dec 14 08:40:35.932: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0556149s
STEP: Saw pod success 12/14/22 08:40:35.932
Dec 14 08:40:35.932: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718" satisfied condition "Succeeded or Failed"
Dec 14 08:40:35.959: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:40:36.06
Dec 14 08:40:36.098: INFO: Waiting for pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 to disappear
Dec 14 08:40:36.125: INFO: Pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:40:36.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4495" for this suite. 12/14/22 08:40:36.178
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":63,"skipped":1078,"failed":0}
------------------------------
• [4.582 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:31.625
    Dec 14 08:40:31.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:40:31.626
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:31.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:31.761
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-2e3d1a0c-fc11-46b9-9960-6a3e5de22808 12/14/22 08:40:31.813
    STEP: Creating a pod to test consume configMaps 12/14/22 08:40:31.841
    Dec 14 08:40:31.876: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718" in namespace "projected-4495" to be "Succeeded or Failed"
    Dec 14 08:40:31.903: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Pending", Reason="", readiness=false. Elapsed: 26.907029ms
    Dec 14 08:40:33.931: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055322739s
    Dec 14 08:40:35.932: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0556149s
    STEP: Saw pod success 12/14/22 08:40:35.932
    Dec 14 08:40:35.932: INFO: Pod "pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718" satisfied condition "Succeeded or Failed"
    Dec 14 08:40:35.959: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:40:36.06
    Dec 14 08:40:36.098: INFO: Waiting for pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 to disappear
    Dec 14 08:40:36.125: INFO: Pod pod-projected-configmaps-b3105963-aa3d-4d4c-89b5-9c5624402718 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:40:36.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4495" for this suite. 12/14/22 08:40:36.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:36.208
Dec 14 08:40:36.208: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:40:36.208
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:36.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:36.343
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:40:36.453
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:40:36.994
STEP: Deploying the webhook pod 12/14/22 08:40:37.022
STEP: Wait for the deployment to be ready 12/14/22 08:40:37.079
Dec 14 08:40:37.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:40:39.196
STEP: Verifying the service has paired with the endpoint 12/14/22 08:40:39.236
Dec 14 08:40:40.237: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 12/14/22 08:40:40.559
STEP: Creating a configMap that should be mutated 12/14/22 08:40:40.798
STEP: Deleting the collection of validation webhooks 12/14/22 08:40:41.352
STEP: Creating a configMap that should not be mutated 12/14/22 08:40:41.474
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:40:41.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-682" for this suite. 12/14/22 08:40:41.561
STEP: Destroying namespace "webhook-682-markers" for this suite. 12/14/22 08:40:41.59
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":64,"skipped":1084,"failed":0}
------------------------------
• [5.538 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:36.208
    Dec 14 08:40:36.208: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:40:36.208
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:36.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:36.343
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:40:36.453
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:40:36.994
    STEP: Deploying the webhook pod 12/14/22 08:40:37.022
    STEP: Wait for the deployment to be ready 12/14/22 08:40:37.079
    Dec 14 08:40:37.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 40, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:40:39.196
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:40:39.236
    Dec 14 08:40:40.237: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 12/14/22 08:40:40.559
    STEP: Creating a configMap that should be mutated 12/14/22 08:40:40.798
    STEP: Deleting the collection of validation webhooks 12/14/22 08:40:41.352
    STEP: Creating a configMap that should not be mutated 12/14/22 08:40:41.474
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:40:41.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-682" for this suite. 12/14/22 08:40:41.561
    STEP: Destroying namespace "webhook-682-markers" for this suite. 12/14/22 08:40:41.59
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:41.747
Dec 14 08:40:41.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 08:40:41.748
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:41.829
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:41.881
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 08:40:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1024" for this suite. 12/14/22 08:40:42.218
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":65,"skipped":1136,"failed":0}
------------------------------
• [0.501 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:41.747
    Dec 14 08:40:41.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 08:40:41.748
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:41.829
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:41.881
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 08:40:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1024" for this suite. 12/14/22 08:40:42.218
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:42.248
Dec 14 08:40:42.248: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:40:42.249
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:42.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:42.387
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-4d0e092d-1cc2-46b4-b3d9-6347dfeb2464 12/14/22 08:40:42.473
STEP: Creating configMap with name cm-test-opt-upd-c1f4a823-e30b-4285-8051-7d3b6321926c 12/14/22 08:40:42.5
STEP: Creating the pod 12/14/22 08:40:42.528
Dec 14 08:40:42.566: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3" in namespace "projected-9995" to be "running and ready"
Dec 14 08:40:42.595: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 28.517911ms
Dec 14 08:40:42.595: INFO: The phase of Pod pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:40:44.624: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.057638379s
Dec 14 08:40:44.624: INFO: The phase of Pod pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3 is Running (Ready = true)
Dec 14 08:40:44.624: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-4d0e092d-1cc2-46b4-b3d9-6347dfeb2464 12/14/22 08:40:44.868
STEP: Updating configmap cm-test-opt-upd-c1f4a823-e30b-4285-8051-7d3b6321926c 12/14/22 08:40:44.899
STEP: Creating configMap with name cm-test-opt-create-43617dfc-c6cd-48a0-9071-f093cc135a92 12/14/22 08:40:44.926
STEP: waiting to observe update in volume 12/14/22 08:40:44.954
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:40:49.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9995" for this suite. 12/14/22 08:40:49.29
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":66,"skipped":1136,"failed":0}
------------------------------
• [7.071 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:42.248
    Dec 14 08:40:42.248: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:40:42.249
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:42.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:42.387
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-4d0e092d-1cc2-46b4-b3d9-6347dfeb2464 12/14/22 08:40:42.473
    STEP: Creating configMap with name cm-test-opt-upd-c1f4a823-e30b-4285-8051-7d3b6321926c 12/14/22 08:40:42.5
    STEP: Creating the pod 12/14/22 08:40:42.528
    Dec 14 08:40:42.566: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3" in namespace "projected-9995" to be "running and ready"
    Dec 14 08:40:42.595: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 28.517911ms
    Dec 14 08:40:42.595: INFO: The phase of Pod pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:40:44.624: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.057638379s
    Dec 14 08:40:44.624: INFO: The phase of Pod pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3 is Running (Ready = true)
    Dec 14 08:40:44.624: INFO: Pod "pod-projected-configmaps-d706f614-ddf2-4aca-9d50-8e1689e7b2c3" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-4d0e092d-1cc2-46b4-b3d9-6347dfeb2464 12/14/22 08:40:44.868
    STEP: Updating configmap cm-test-opt-upd-c1f4a823-e30b-4285-8051-7d3b6321926c 12/14/22 08:40:44.899
    STEP: Creating configMap with name cm-test-opt-create-43617dfc-c6cd-48a0-9071-f093cc135a92 12/14/22 08:40:44.926
    STEP: waiting to observe update in volume 12/14/22 08:40:44.954
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:40:49.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9995" for this suite. 12/14/22 08:40:49.29
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:49.32
Dec 14 08:40:49.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:40:49.32
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:49.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:49.454
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-6132 12/14/22 08:40:49.506
STEP: creating service affinity-nodeport in namespace services-6132 12/14/22 08:40:49.506
STEP: creating replication controller affinity-nodeport in namespace services-6132 12/14/22 08:40:49.546
I1214 08:40:49.575616    6274 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6132, replica count: 3
I1214 08:40:52.627306    6274 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 08:40:52.737: INFO: Creating new exec pod
Dec 14 08:40:52.772: INFO: Waiting up to 5m0s for pod "execpod-affinityhlppd" in namespace "services-6132" to be "running"
Dec 14 08:40:52.799: INFO: Pod "execpod-affinityhlppd": Phase="Pending", Reason="", readiness=false. Elapsed: 27.205093ms
Dec 14 08:40:54.827: INFO: Pod "execpod-affinityhlppd": Phase="Running", Reason="", readiness=true. Elapsed: 2.055207259s
Dec 14 08:40:54.827: INFO: Pod "execpod-affinityhlppd" satisfied condition "running"
Dec 14 08:40:55.880: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Dec 14 08:40:56.471: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Dec 14 08:40:56.471: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:40:56.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.201.175 80'
Dec 14 08:40:57.024: INFO: stderr: "+ nc -v -t -w 2 100.111.201.175 80\n+ echo hostName\nConnection to 100.111.201.175 80 port [tcp/http] succeeded!\n"
Dec 14 08:40:57.024: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:40:57.024: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32406'
Dec 14 08:40:57.699: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 10.250.0.5 32406\nConnection to 10.250.0.5 32406 port [tcp/*] succeeded!\n"
Dec 14 08:40:57.699: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:40:57.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32406'
Dec 14 08:40:58.226: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32406\nConnection to 10.250.0.4 32406 port [tcp/*] succeeded!\n"
Dec 14 08:40:58.226: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:40:58.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:32406/ ; done'
Dec 14 08:40:58.997: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n"
Dec 14 08:40:58.997: INFO: stdout: "\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr"
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
Dec 14 08:40:58.997: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-6132, will wait for the garbage collector to delete the pods 12/14/22 08:40:59.033
Dec 14 08:40:59.147: INFO: Deleting ReplicationController affinity-nodeport took: 31.074881ms
Dec 14 08:40:59.247: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.316022ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:41:01.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6132" for this suite. 12/14/22 08:41:01.731
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":67,"skipped":1164,"failed":0}
------------------------------
• [12.441 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:49.32
    Dec 14 08:40:49.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:40:49.32
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:49.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:49.454
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-6132 12/14/22 08:40:49.506
    STEP: creating service affinity-nodeport in namespace services-6132 12/14/22 08:40:49.506
    STEP: creating replication controller affinity-nodeport in namespace services-6132 12/14/22 08:40:49.546
    I1214 08:40:49.575616    6274 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6132, replica count: 3
    I1214 08:40:52.627306    6274 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 08:40:52.737: INFO: Creating new exec pod
    Dec 14 08:40:52.772: INFO: Waiting up to 5m0s for pod "execpod-affinityhlppd" in namespace "services-6132" to be "running"
    Dec 14 08:40:52.799: INFO: Pod "execpod-affinityhlppd": Phase="Pending", Reason="", readiness=false. Elapsed: 27.205093ms
    Dec 14 08:40:54.827: INFO: Pod "execpod-affinityhlppd": Phase="Running", Reason="", readiness=true. Elapsed: 2.055207259s
    Dec 14 08:40:54.827: INFO: Pod "execpod-affinityhlppd" satisfied condition "running"
    Dec 14 08:40:55.880: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Dec 14 08:40:56.471: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Dec 14 08:40:56.471: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:40:56.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.201.175 80'
    Dec 14 08:40:57.024: INFO: stderr: "+ nc -v -t -w 2 100.111.201.175 80\n+ echo hostName\nConnection to 100.111.201.175 80 port [tcp/http] succeeded!\n"
    Dec 14 08:40:57.024: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:40:57.024: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32406'
    Dec 14 08:40:57.699: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 10.250.0.5 32406\nConnection to 10.250.0.5 32406 port [tcp/*] succeeded!\n"
    Dec 14 08:40:57.699: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:40:57.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32406'
    Dec 14 08:40:58.226: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32406\nConnection to 10.250.0.4 32406 port [tcp/*] succeeded!\n"
    Dec 14 08:40:58.226: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:40:58.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6132 exec execpod-affinityhlppd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:32406/ ; done'
    Dec 14 08:40:58.997: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32406/\n"
    Dec 14 08:40:58.997: INFO: stdout: "\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr\naffinity-nodeport-fgvxr"
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Received response from host: affinity-nodeport-fgvxr
    Dec 14 08:40:58.997: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-6132, will wait for the garbage collector to delete the pods 12/14/22 08:40:59.033
    Dec 14 08:40:59.147: INFO: Deleting ReplicationController affinity-nodeport took: 31.074881ms
    Dec 14 08:40:59.247: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.316022ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:41:01.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6132" for this suite. 12/14/22 08:41:01.731
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:01.762
Dec 14 08:41:01.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:41:01.763
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:01.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:01.899
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:41:01.951
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-trt4 12/14/22 08:41:02.006
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:41:02.006
Dec 14 08:41:02.041: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-trt4" in namespace "subpath-6953" to be "Succeeded or Failed"
Dec 14 08:41:02.068: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.017203ms
Dec 14 08:41:04.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 2.053545908s
Dec 14 08:41:06.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 4.054504823s
Dec 14 08:41:08.105: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 6.063633033s
Dec 14 08:41:10.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 8.053757742s
Dec 14 08:41:12.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 10.053888333s
Dec 14 08:41:14.094: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 12.052992298s
Dec 14 08:41:16.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 14.05436244s
Dec 14 08:41:18.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 16.053575129s
Dec 14 08:41:20.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 18.054459948s
Dec 14 08:41:22.094: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 20.053100168s
Dec 14 08:41:24.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=false. Elapsed: 22.053335966s
Dec 14 08:41:26.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05420374s
STEP: Saw pod success 12/14/22 08:41:26.096
Dec 14 08:41:26.097: INFO: Pod "pod-subpath-test-projected-trt4" satisfied condition "Succeeded or Failed"
Dec 14 08:41:26.124: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-projected-trt4 container test-container-subpath-projected-trt4: <nil>
STEP: delete the pod 12/14/22 08:41:26.157
Dec 14 08:41:26.194: INFO: Waiting for pod pod-subpath-test-projected-trt4 to disappear
Dec 14 08:41:26.219: INFO: Pod pod-subpath-test-projected-trt4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-trt4 12/14/22 08:41:26.219
Dec 14 08:41:26.219: INFO: Deleting pod "pod-subpath-test-projected-trt4" in namespace "subpath-6953"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:41:26.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6953" for this suite. 12/14/22 08:41:26.294
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":68,"skipped":1217,"failed":0}
------------------------------
• [24.560 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:01.762
    Dec 14 08:41:01.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:41:01.763
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:01.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:01.899
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:41:01.951
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-trt4 12/14/22 08:41:02.006
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:41:02.006
    Dec 14 08:41:02.041: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-trt4" in namespace "subpath-6953" to be "Succeeded or Failed"
    Dec 14 08:41:02.068: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.017203ms
    Dec 14 08:41:04.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 2.053545908s
    Dec 14 08:41:06.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 4.054504823s
    Dec 14 08:41:08.105: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 6.063633033s
    Dec 14 08:41:10.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 8.053757742s
    Dec 14 08:41:12.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 10.053888333s
    Dec 14 08:41:14.094: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 12.052992298s
    Dec 14 08:41:16.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 14.05436244s
    Dec 14 08:41:18.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 16.053575129s
    Dec 14 08:41:20.096: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 18.054459948s
    Dec 14 08:41:22.094: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=true. Elapsed: 20.053100168s
    Dec 14 08:41:24.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Running", Reason="", readiness=false. Elapsed: 22.053335966s
    Dec 14 08:41:26.095: INFO: Pod "pod-subpath-test-projected-trt4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05420374s
    STEP: Saw pod success 12/14/22 08:41:26.096
    Dec 14 08:41:26.097: INFO: Pod "pod-subpath-test-projected-trt4" satisfied condition "Succeeded or Failed"
    Dec 14 08:41:26.124: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-projected-trt4 container test-container-subpath-projected-trt4: <nil>
    STEP: delete the pod 12/14/22 08:41:26.157
    Dec 14 08:41:26.194: INFO: Waiting for pod pod-subpath-test-projected-trt4 to disappear
    Dec 14 08:41:26.219: INFO: Pod pod-subpath-test-projected-trt4 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-trt4 12/14/22 08:41:26.219
    Dec 14 08:41:26.219: INFO: Deleting pod "pod-subpath-test-projected-trt4" in namespace "subpath-6953"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:41:26.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6953" for this suite. 12/14/22 08:41:26.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:26.324
Dec 14 08:41:26.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 08:41:26.325
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:26.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:26.452
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 12/14/22 08:41:26.501
STEP: listing secrets in all namespaces to ensure that there are more than zero 12/14/22 08:41:26.527
STEP: patching the secret 12/14/22 08:41:26.559
STEP: deleting the secret using a LabelSelector 12/14/22 08:41:26.614
STEP: listing secrets in all namespaces, searching for label name and value in patch 12/14/22 08:41:26.642
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 08:41:26.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2744" for this suite. 12/14/22 08:41:26.7
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":69,"skipped":1248,"failed":0}
------------------------------
• [0.411 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:26.324
    Dec 14 08:41:26.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 08:41:26.325
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:26.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:26.452
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 12/14/22 08:41:26.501
    STEP: listing secrets in all namespaces to ensure that there are more than zero 12/14/22 08:41:26.527
    STEP: patching the secret 12/14/22 08:41:26.559
    STEP: deleting the secret using a LabelSelector 12/14/22 08:41:26.614
    STEP: listing secrets in all namespaces, searching for label name and value in patch 12/14/22 08:41:26.642
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 08:41:26.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2744" for this suite. 12/14/22 08:41:26.7
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:26.735
Dec 14 08:41:26.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:41:26.736
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:26.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:26.867
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-6055 12/14/22 08:41:26.916
STEP: creating service affinity-clusterip-transition in namespace services-6055 12/14/22 08:41:26.916
STEP: creating replication controller affinity-clusterip-transition in namespace services-6055 12/14/22 08:41:26.956
I1214 08:41:26.985586    6274 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6055, replica count: 3
I1214 08:41:30.087285    6274 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 08:41:30.139: INFO: Creating new exec pod
Dec 14 08:41:30.173: INFO: Waiting up to 5m0s for pod "execpod-affinitys5h8c" in namespace "services-6055" to be "running"
Dec 14 08:41:30.198: INFO: Pod "execpod-affinitys5h8c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.183924ms
Dec 14 08:41:32.226: INFO: Pod "execpod-affinitys5h8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.05290137s
Dec 14 08:41:32.226: INFO: Pod "execpod-affinitys5h8c" satisfied condition "running"
Dec 14 08:41:33.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Dec 14 08:41:33.901: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Dec 14 08:41:33.901: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:41:33.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.104.97.3 80'
Dec 14 08:41:34.459: INFO: stderr: "+ nc -v -t -w 2 100.104.97.3 80\nConnection to 100.104.97.3 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 14 08:41:34.459: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:41:34.516: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.104.97.3:80/ ; done'
Dec 14 08:41:35.177: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n"
Dec 14 08:41:35.177: INFO: stdout: "\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj"
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
Dec 14 08:41:35.229: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.104.97.3:80/ ; done'
Dec 14 08:41:35.907: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n"
Dec 14 08:41:35.907: INFO: stdout: "\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm"
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
Dec 14 08:41:35.907: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6055, will wait for the garbage collector to delete the pods 12/14/22 08:41:35.945
Dec 14 08:41:36.059: INFO: Deleting ReplicationController affinity-clusterip-transition took: 35.770548ms
Dec 14 08:41:36.159: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.376114ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:41:38.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6055" for this suite. 12/14/22 08:41:38.726
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":70,"skipped":1248,"failed":0}
------------------------------
• [12.018 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:26.735
    Dec 14 08:41:26.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:41:26.736
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:26.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:26.867
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-6055 12/14/22 08:41:26.916
    STEP: creating service affinity-clusterip-transition in namespace services-6055 12/14/22 08:41:26.916
    STEP: creating replication controller affinity-clusterip-transition in namespace services-6055 12/14/22 08:41:26.956
    I1214 08:41:26.985586    6274 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6055, replica count: 3
    I1214 08:41:30.087285    6274 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 08:41:30.139: INFO: Creating new exec pod
    Dec 14 08:41:30.173: INFO: Waiting up to 5m0s for pod "execpod-affinitys5h8c" in namespace "services-6055" to be "running"
    Dec 14 08:41:30.198: INFO: Pod "execpod-affinitys5h8c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.183924ms
    Dec 14 08:41:32.226: INFO: Pod "execpod-affinitys5h8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.05290137s
    Dec 14 08:41:32.226: INFO: Pod "execpod-affinitys5h8c" satisfied condition "running"
    Dec 14 08:41:33.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Dec 14 08:41:33.901: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Dec 14 08:41:33.901: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:41:33.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.104.97.3 80'
    Dec 14 08:41:34.459: INFO: stderr: "+ nc -v -t -w 2 100.104.97.3 80\nConnection to 100.104.97.3 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Dec 14 08:41:34.459: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:41:34.516: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.104.97.3:80/ ; done'
    Dec 14 08:41:35.177: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n"
    Dec 14 08:41:35.177: INFO: stdout: "\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-wbgqj\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-xqg8c\naffinity-clusterip-transition-wbgqj"
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-xqg8c
    Dec 14 08:41:35.177: INFO: Received response from host: affinity-clusterip-transition-wbgqj
    Dec 14 08:41:35.229: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6055 exec execpod-affinitys5h8c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.104.97.3:80/ ; done'
    Dec 14 08:41:35.907: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.104.97.3:80/\n"
    Dec 14 08:41:35.907: INFO: stdout: "\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm\naffinity-clusterip-transition-w8wgm"
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Received response from host: affinity-clusterip-transition-w8wgm
    Dec 14 08:41:35.907: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6055, will wait for the garbage collector to delete the pods 12/14/22 08:41:35.945
    Dec 14 08:41:36.059: INFO: Deleting ReplicationController affinity-clusterip-transition took: 35.770548ms
    Dec 14 08:41:36.159: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.376114ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:41:38.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6055" for this suite. 12/14/22 08:41:38.726
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:38.754
Dec 14 08:41:38.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods 12/14/22 08:41:38.755
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:38.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:38.878
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Dec 14 08:41:38.926: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 08:42:39.157: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Dec 14 08:42:39.182: INFO: Starting informer...
STEP: Starting pods... 12/14/22 08:42:39.182
Dec 14 08:42:39.267: INFO: Pod1 is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
Dec 14 08:42:39.322: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8058" to be "running"
Dec 14 08:42:39.347: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 25.288367ms
Dec 14 08:42:41.373: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051278508s
Dec 14 08:42:41.373: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Dec 14 08:42:41.373: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8058" to be "running"
Dec 14 08:42:41.398: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 25.28097ms
Dec 14 08:42:41.398: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Dec 14 08:42:41.398: INFO: Pod2 is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
STEP: Trying to apply a taint on the Node 12/14/22 08:42:41.398
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 08:42:41.481
STEP: Waiting for Pod1 and Pod2 to be deleted 12/14/22 08:42:41.506
Dec 14 08:42:47.658: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 14 08:43:07.703: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 08:43:07.766
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:43:07.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8058" for this suite. 12/14/22 08:43:07.821
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":71,"skipped":1271,"failed":0}
------------------------------
• [89.109 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:38.754
    Dec 14 08:41:38.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename taint-multiple-pods 12/14/22 08:41:38.755
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:38.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:38.878
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Dec 14 08:41:38.926: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 08:42:39.157: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Dec 14 08:42:39.182: INFO: Starting informer...
    STEP: Starting pods... 12/14/22 08:42:39.182
    Dec 14 08:42:39.267: INFO: Pod1 is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
    Dec 14 08:42:39.322: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8058" to be "running"
    Dec 14 08:42:39.347: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 25.288367ms
    Dec 14 08:42:41.373: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051278508s
    Dec 14 08:42:41.373: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Dec 14 08:42:41.373: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8058" to be "running"
    Dec 14 08:42:41.398: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 25.28097ms
    Dec 14 08:42:41.398: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Dec 14 08:42:41.398: INFO: Pod2 is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
    STEP: Trying to apply a taint on the Node 12/14/22 08:42:41.398
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 08:42:41.481
    STEP: Waiting for Pod1 and Pod2 to be deleted 12/14/22 08:42:41.506
    Dec 14 08:42:47.658: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Dec 14 08:43:07.703: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 08:43:07.766
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:43:07.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-8058" for this suite. 12/14/22 08:43:07.821
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:07.864
Dec 14 08:43:07.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:43:07.865
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:07.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:08
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-6e89238c-28e2-4961-8020-2a266fac1f21 12/14/22 08:43:08.051
STEP: Creating a pod to test consume secrets 12/14/22 08:43:08.079
Dec 14 08:43:08.113: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af" in namespace "projected-3935" to be "Succeeded or Failed"
Dec 14 08:43:08.141: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Pending", Reason="", readiness=false. Elapsed: 27.751681ms
Dec 14 08:43:10.170: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056510981s
Dec 14 08:43:12.171: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0576339s
STEP: Saw pod success 12/14/22 08:43:12.171
Dec 14 08:43:12.171: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af" satisfied condition "Succeeded or Failed"
Dec 14 08:43:12.198: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 08:43:12.382
Dec 14 08:43:12.418: INFO: Waiting for pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af to disappear
Dec 14 08:43:12.445: INFO: Pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 08:43:12.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3935" for this suite. 12/14/22 08:43:12.497
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":72,"skipped":1296,"failed":0}
------------------------------
• [4.662 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:07.864
    Dec 14 08:43:07.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:43:07.865
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:07.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:08
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-6e89238c-28e2-4961-8020-2a266fac1f21 12/14/22 08:43:08.051
    STEP: Creating a pod to test consume secrets 12/14/22 08:43:08.079
    Dec 14 08:43:08.113: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af" in namespace "projected-3935" to be "Succeeded or Failed"
    Dec 14 08:43:08.141: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Pending", Reason="", readiness=false. Elapsed: 27.751681ms
    Dec 14 08:43:10.170: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056510981s
    Dec 14 08:43:12.171: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0576339s
    STEP: Saw pod success 12/14/22 08:43:12.171
    Dec 14 08:43:12.171: INFO: Pod "pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af" satisfied condition "Succeeded or Failed"
    Dec 14 08:43:12.198: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:43:12.382
    Dec 14 08:43:12.418: INFO: Waiting for pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af to disappear
    Dec 14 08:43:12.445: INFO: Pod pod-projected-secrets-a0117a06-a701-4d91-a879-f156aedb30af no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 08:43:12.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3935" for this suite. 12/14/22 08:43:12.497
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:12.526
Dec 14 08:43:12.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename discovery 12/14/22 08:43:12.527
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:12.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:12.662
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 12/14/22 08:43:12.74
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Dec 14 08:43:13.558: INFO: Checking APIGroup: apiregistration.k8s.io
Dec 14 08:43:13.583: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Dec 14 08:43:13.583: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Dec 14 08:43:13.583: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Dec 14 08:43:13.583: INFO: Checking APIGroup: apps
Dec 14 08:43:13.609: INFO: PreferredVersion.GroupVersion: apps/v1
Dec 14 08:43:13.609: INFO: Versions found [{apps/v1 v1}]
Dec 14 08:43:13.609: INFO: apps/v1 matches apps/v1
Dec 14 08:43:13.609: INFO: Checking APIGroup: events.k8s.io
Dec 14 08:43:13.635: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Dec 14 08:43:13.635: INFO: Versions found [{events.k8s.io/v1 v1}]
Dec 14 08:43:13.635: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Dec 14 08:43:13.635: INFO: Checking APIGroup: authentication.k8s.io
Dec 14 08:43:13.661: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Dec 14 08:43:13.661: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Dec 14 08:43:13.661: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Dec 14 08:43:13.661: INFO: Checking APIGroup: authorization.k8s.io
Dec 14 08:43:13.686: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Dec 14 08:43:13.687: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Dec 14 08:43:13.687: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Dec 14 08:43:13.687: INFO: Checking APIGroup: autoscaling
Dec 14 08:43:13.712: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Dec 14 08:43:13.712: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Dec 14 08:43:13.712: INFO: autoscaling/v2 matches autoscaling/v2
Dec 14 08:43:13.712: INFO: Checking APIGroup: batch
Dec 14 08:43:13.738: INFO: PreferredVersion.GroupVersion: batch/v1
Dec 14 08:43:13.738: INFO: Versions found [{batch/v1 v1}]
Dec 14 08:43:13.738: INFO: batch/v1 matches batch/v1
Dec 14 08:43:13.738: INFO: Checking APIGroup: certificates.k8s.io
Dec 14 08:43:13.764: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Dec 14 08:43:13.764: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Dec 14 08:43:13.764: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Dec 14 08:43:13.764: INFO: Checking APIGroup: networking.k8s.io
Dec 14 08:43:13.789: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Dec 14 08:43:13.789: INFO: Versions found [{networking.k8s.io/v1 v1}]
Dec 14 08:43:13.790: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Dec 14 08:43:13.790: INFO: Checking APIGroup: policy
Dec 14 08:43:13.815: INFO: PreferredVersion.GroupVersion: policy/v1
Dec 14 08:43:13.815: INFO: Versions found [{policy/v1 v1}]
Dec 14 08:43:13.815: INFO: policy/v1 matches policy/v1
Dec 14 08:43:13.815: INFO: Checking APIGroup: rbac.authorization.k8s.io
Dec 14 08:43:13.840: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Dec 14 08:43:13.840: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Dec 14 08:43:13.840: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Dec 14 08:43:13.840: INFO: Checking APIGroup: storage.k8s.io
Dec 14 08:43:13.866: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Dec 14 08:43:13.866: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Dec 14 08:43:13.866: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Dec 14 08:43:13.866: INFO: Checking APIGroup: admissionregistration.k8s.io
Dec 14 08:43:13.892: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Dec 14 08:43:13.892: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Dec 14 08:43:13.892: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Dec 14 08:43:13.892: INFO: Checking APIGroup: apiextensions.k8s.io
Dec 14 08:43:13.917: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Dec 14 08:43:13.917: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Dec 14 08:43:13.917: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Dec 14 08:43:13.917: INFO: Checking APIGroup: scheduling.k8s.io
Dec 14 08:43:13.942: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Dec 14 08:43:13.943: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Dec 14 08:43:13.943: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Dec 14 08:43:13.943: INFO: Checking APIGroup: coordination.k8s.io
Dec 14 08:43:13.968: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Dec 14 08:43:13.968: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Dec 14 08:43:13.968: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Dec 14 08:43:13.968: INFO: Checking APIGroup: node.k8s.io
Dec 14 08:43:13.993: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Dec 14 08:43:13.993: INFO: Versions found [{node.k8s.io/v1 v1}]
Dec 14 08:43:13.993: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Dec 14 08:43:13.993: INFO: Checking APIGroup: discovery.k8s.io
Dec 14 08:43:14.051: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Dec 14 08:43:14.051: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Dec 14 08:43:14.051: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Dec 14 08:43:14.051: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Dec 14 08:43:14.078: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Dec 14 08:43:14.078: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Dec 14 08:43:14.078: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Dec 14 08:43:14.078: INFO: Checking APIGroup: autoscaling.k8s.io
Dec 14 08:43:14.103: INFO: PreferredVersion.GroupVersion: autoscaling.k8s.io/v1
Dec 14 08:43:14.103: INFO: Versions found [{autoscaling.k8s.io/v1 v1} {autoscaling.k8s.io/v1beta2 v1beta2}]
Dec 14 08:43:14.103: INFO: autoscaling.k8s.io/v1 matches autoscaling.k8s.io/v1
Dec 14 08:43:14.103: INFO: Checking APIGroup: crd.projectcalico.org
Dec 14 08:43:14.129: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Dec 14 08:43:14.129: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Dec 14 08:43:14.129: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Dec 14 08:43:14.129: INFO: Checking APIGroup: snapshot.storage.k8s.io
Dec 14 08:43:14.155: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Dec 14 08:43:14.155: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
Dec 14 08:43:14.155: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Dec 14 08:43:14.155: INFO: Checking APIGroup: cert.gardener.cloud
Dec 14 08:43:14.181: INFO: PreferredVersion.GroupVersion: cert.gardener.cloud/v1alpha1
Dec 14 08:43:14.181: INFO: Versions found [{cert.gardener.cloud/v1alpha1 v1alpha1}]
Dec 14 08:43:14.181: INFO: cert.gardener.cloud/v1alpha1 matches cert.gardener.cloud/v1alpha1
Dec 14 08:43:14.181: INFO: Checking APIGroup: dns.gardener.cloud
Dec 14 08:43:14.207: INFO: PreferredVersion.GroupVersion: dns.gardener.cloud/v1alpha1
Dec 14 08:43:14.207: INFO: Versions found [{dns.gardener.cloud/v1alpha1 v1alpha1}]
Dec 14 08:43:14.207: INFO: dns.gardener.cloud/v1alpha1 matches dns.gardener.cloud/v1alpha1
Dec 14 08:43:14.207: INFO: Checking APIGroup: metrics.k8s.io
Dec 14 08:43:14.233: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Dec 14 08:43:14.233: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Dec 14 08:43:14.233: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Dec 14 08:43:14.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-4054" for this suite. 12/14/22 08:43:14.285
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":73,"skipped":1298,"failed":0}
------------------------------
• [1.788 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:12.526
    Dec 14 08:43:12.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename discovery 12/14/22 08:43:12.527
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:12.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:12.662
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 12/14/22 08:43:12.74
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Dec 14 08:43:13.558: INFO: Checking APIGroup: apiregistration.k8s.io
    Dec 14 08:43:13.583: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Dec 14 08:43:13.583: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Dec 14 08:43:13.583: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Dec 14 08:43:13.583: INFO: Checking APIGroup: apps
    Dec 14 08:43:13.609: INFO: PreferredVersion.GroupVersion: apps/v1
    Dec 14 08:43:13.609: INFO: Versions found [{apps/v1 v1}]
    Dec 14 08:43:13.609: INFO: apps/v1 matches apps/v1
    Dec 14 08:43:13.609: INFO: Checking APIGroup: events.k8s.io
    Dec 14 08:43:13.635: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Dec 14 08:43:13.635: INFO: Versions found [{events.k8s.io/v1 v1}]
    Dec 14 08:43:13.635: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Dec 14 08:43:13.635: INFO: Checking APIGroup: authentication.k8s.io
    Dec 14 08:43:13.661: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Dec 14 08:43:13.661: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Dec 14 08:43:13.661: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Dec 14 08:43:13.661: INFO: Checking APIGroup: authorization.k8s.io
    Dec 14 08:43:13.686: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Dec 14 08:43:13.687: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Dec 14 08:43:13.687: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Dec 14 08:43:13.687: INFO: Checking APIGroup: autoscaling
    Dec 14 08:43:13.712: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Dec 14 08:43:13.712: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Dec 14 08:43:13.712: INFO: autoscaling/v2 matches autoscaling/v2
    Dec 14 08:43:13.712: INFO: Checking APIGroup: batch
    Dec 14 08:43:13.738: INFO: PreferredVersion.GroupVersion: batch/v1
    Dec 14 08:43:13.738: INFO: Versions found [{batch/v1 v1}]
    Dec 14 08:43:13.738: INFO: batch/v1 matches batch/v1
    Dec 14 08:43:13.738: INFO: Checking APIGroup: certificates.k8s.io
    Dec 14 08:43:13.764: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Dec 14 08:43:13.764: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Dec 14 08:43:13.764: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Dec 14 08:43:13.764: INFO: Checking APIGroup: networking.k8s.io
    Dec 14 08:43:13.789: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Dec 14 08:43:13.789: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Dec 14 08:43:13.790: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Dec 14 08:43:13.790: INFO: Checking APIGroup: policy
    Dec 14 08:43:13.815: INFO: PreferredVersion.GroupVersion: policy/v1
    Dec 14 08:43:13.815: INFO: Versions found [{policy/v1 v1}]
    Dec 14 08:43:13.815: INFO: policy/v1 matches policy/v1
    Dec 14 08:43:13.815: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Dec 14 08:43:13.840: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Dec 14 08:43:13.840: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Dec 14 08:43:13.840: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Dec 14 08:43:13.840: INFO: Checking APIGroup: storage.k8s.io
    Dec 14 08:43:13.866: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Dec 14 08:43:13.866: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Dec 14 08:43:13.866: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Dec 14 08:43:13.866: INFO: Checking APIGroup: admissionregistration.k8s.io
    Dec 14 08:43:13.892: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Dec 14 08:43:13.892: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Dec 14 08:43:13.892: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Dec 14 08:43:13.892: INFO: Checking APIGroup: apiextensions.k8s.io
    Dec 14 08:43:13.917: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Dec 14 08:43:13.917: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Dec 14 08:43:13.917: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Dec 14 08:43:13.917: INFO: Checking APIGroup: scheduling.k8s.io
    Dec 14 08:43:13.942: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Dec 14 08:43:13.943: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Dec 14 08:43:13.943: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Dec 14 08:43:13.943: INFO: Checking APIGroup: coordination.k8s.io
    Dec 14 08:43:13.968: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Dec 14 08:43:13.968: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Dec 14 08:43:13.968: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Dec 14 08:43:13.968: INFO: Checking APIGroup: node.k8s.io
    Dec 14 08:43:13.993: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Dec 14 08:43:13.993: INFO: Versions found [{node.k8s.io/v1 v1}]
    Dec 14 08:43:13.993: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Dec 14 08:43:13.993: INFO: Checking APIGroup: discovery.k8s.io
    Dec 14 08:43:14.051: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Dec 14 08:43:14.051: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Dec 14 08:43:14.051: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Dec 14 08:43:14.051: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Dec 14 08:43:14.078: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Dec 14 08:43:14.078: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Dec 14 08:43:14.078: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Dec 14 08:43:14.078: INFO: Checking APIGroup: autoscaling.k8s.io
    Dec 14 08:43:14.103: INFO: PreferredVersion.GroupVersion: autoscaling.k8s.io/v1
    Dec 14 08:43:14.103: INFO: Versions found [{autoscaling.k8s.io/v1 v1} {autoscaling.k8s.io/v1beta2 v1beta2}]
    Dec 14 08:43:14.103: INFO: autoscaling.k8s.io/v1 matches autoscaling.k8s.io/v1
    Dec 14 08:43:14.103: INFO: Checking APIGroup: crd.projectcalico.org
    Dec 14 08:43:14.129: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Dec 14 08:43:14.129: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Dec 14 08:43:14.129: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Dec 14 08:43:14.129: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Dec 14 08:43:14.155: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Dec 14 08:43:14.155: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
    Dec 14 08:43:14.155: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Dec 14 08:43:14.155: INFO: Checking APIGroup: cert.gardener.cloud
    Dec 14 08:43:14.181: INFO: PreferredVersion.GroupVersion: cert.gardener.cloud/v1alpha1
    Dec 14 08:43:14.181: INFO: Versions found [{cert.gardener.cloud/v1alpha1 v1alpha1}]
    Dec 14 08:43:14.181: INFO: cert.gardener.cloud/v1alpha1 matches cert.gardener.cloud/v1alpha1
    Dec 14 08:43:14.181: INFO: Checking APIGroup: dns.gardener.cloud
    Dec 14 08:43:14.207: INFO: PreferredVersion.GroupVersion: dns.gardener.cloud/v1alpha1
    Dec 14 08:43:14.207: INFO: Versions found [{dns.gardener.cloud/v1alpha1 v1alpha1}]
    Dec 14 08:43:14.207: INFO: dns.gardener.cloud/v1alpha1 matches dns.gardener.cloud/v1alpha1
    Dec 14 08:43:14.207: INFO: Checking APIGroup: metrics.k8s.io
    Dec 14 08:43:14.233: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Dec 14 08:43:14.233: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Dec 14 08:43:14.233: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Dec 14 08:43:14.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-4054" for this suite. 12/14/22 08:43:14.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:14.315
Dec 14 08:43:14.315: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 08:43:14.316
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:14.398
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:14.449
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 12/14/22 08:43:14.501
STEP: Replace a pod template 12/14/22 08:43:14.53
Dec 14 08:43:14.585: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 08:43:14.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-736" for this suite. 12/14/22 08:43:14.614
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":74,"skipped":1313,"failed":0}
------------------------------
• [0.330 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:14.315
    Dec 14 08:43:14.315: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 08:43:14.316
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:14.398
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:14.449
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 12/14/22 08:43:14.501
    STEP: Replace a pod template 12/14/22 08:43:14.53
    Dec 14 08:43:14.585: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 08:43:14.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-736" for this suite. 12/14/22 08:43:14.614
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:14.645
Dec 14 08:43:14.645: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:43:14.646
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:14.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:14.786
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 12/14/22 08:43:14.838
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:14.865
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:14.866
STEP: creating a pod to probe DNS 12/14/22 08:43:14.866
STEP: submitting the pod to kubernetes 12/14/22 08:43:14.866
Dec 14 08:43:14.904: INFO: Waiting up to 15m0s for pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034" in namespace "dns-3574" to be "running"
Dec 14 08:43:14.931: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034": Phase="Pending", Reason="", readiness=false. Elapsed: 27.289445ms
Dec 14 08:43:16.962: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034": Phase="Running", Reason="", readiness=true. Elapsed: 2.058330225s
Dec 14 08:43:16.962: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:43:16.962
STEP: looking for the results for each expected name from probers 12/14/22 08:43:16.99
Dec 14 08:43:17.144: INFO: DNS probes using dns-test-c18c096b-1d06-4721-a2ae-43dd16804034 succeeded

STEP: deleting the pod 12/14/22 08:43:17.144
STEP: changing the externalName to bar.example.com 12/14/22 08:43:17.18
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:17.234
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:17.234
STEP: creating a second pod to probe DNS 12/14/22 08:43:17.234
STEP: submitting the pod to kubernetes 12/14/22 08:43:17.234
Dec 14 08:43:17.267: INFO: Waiting up to 15m0s for pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c" in namespace "dns-3574" to be "running"
Dec 14 08:43:17.294: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.751106ms
Dec 14 08:43:19.323: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c": Phase="Running", Reason="", readiness=true. Elapsed: 2.055706273s
Dec 14 08:43:19.323: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:43:19.323
STEP: looking for the results for each expected name from probers 12/14/22 08:43:19.351
Dec 14 08:43:19.428: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:19.475: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:19.475: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:24.508: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:24.555: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:24.555: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:29.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:29.551: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:29.551: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:34.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:34.556: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:34.556: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:39.510: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:39.555: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:39.555: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:44.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:44.559: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:43:44.559: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

Dec 14 08:43:49.555: INFO: DNS probes using dns-test-45320854-6f15-4b99-a451-558a24f4673c succeeded

STEP: deleting the pod 12/14/22 08:43:49.555
STEP: changing the service to type=ClusterIP 12/14/22 08:43:49.593
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:49.665
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
 12/14/22 08:43:49.665
STEP: creating a third pod to probe DNS 12/14/22 08:43:49.665
STEP: submitting the pod to kubernetes 12/14/22 08:43:49.691
Dec 14 08:43:49.730: INFO: Waiting up to 15m0s for pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2" in namespace "dns-3574" to be "running"
Dec 14 08:43:49.760: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.569346ms
Dec 14 08:43:51.789: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059103775s
Dec 14 08:43:53.792: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Running", Reason="", readiness=true. Elapsed: 4.062226409s
Dec 14 08:43:53.792: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:43:53.792
STEP: looking for the results for each expected name from probers 12/14/22 08:43:53.82
Dec 14 08:43:53.997: INFO: DNS probes using dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2 succeeded

STEP: deleting the pod 12/14/22 08:43:53.997
STEP: deleting the test externalName service 12/14/22 08:43:54.033
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:43:54.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3574" for this suite. 12/14/22 08:43:54.124
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":75,"skipped":1315,"failed":0}
------------------------------
• [39.508 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:14.645
    Dec 14 08:43:14.645: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:43:14.646
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:14.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:14.786
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 12/14/22 08:43:14.838
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:14.865
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:14.866
    STEP: creating a pod to probe DNS 12/14/22 08:43:14.866
    STEP: submitting the pod to kubernetes 12/14/22 08:43:14.866
    Dec 14 08:43:14.904: INFO: Waiting up to 15m0s for pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034" in namespace "dns-3574" to be "running"
    Dec 14 08:43:14.931: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034": Phase="Pending", Reason="", readiness=false. Elapsed: 27.289445ms
    Dec 14 08:43:16.962: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034": Phase="Running", Reason="", readiness=true. Elapsed: 2.058330225s
    Dec 14 08:43:16.962: INFO: Pod "dns-test-c18c096b-1d06-4721-a2ae-43dd16804034" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:43:16.962
    STEP: looking for the results for each expected name from probers 12/14/22 08:43:16.99
    Dec 14 08:43:17.144: INFO: DNS probes using dns-test-c18c096b-1d06-4721-a2ae-43dd16804034 succeeded

    STEP: deleting the pod 12/14/22 08:43:17.144
    STEP: changing the externalName to bar.example.com 12/14/22 08:43:17.18
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:17.234
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:17.234
    STEP: creating a second pod to probe DNS 12/14/22 08:43:17.234
    STEP: submitting the pod to kubernetes 12/14/22 08:43:17.234
    Dec 14 08:43:17.267: INFO: Waiting up to 15m0s for pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c" in namespace "dns-3574" to be "running"
    Dec 14 08:43:17.294: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.751106ms
    Dec 14 08:43:19.323: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c": Phase="Running", Reason="", readiness=true. Elapsed: 2.055706273s
    Dec 14 08:43:19.323: INFO: Pod "dns-test-45320854-6f15-4b99-a451-558a24f4673c" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:43:19.323
    STEP: looking for the results for each expected name from probers 12/14/22 08:43:19.351
    Dec 14 08:43:19.428: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:19.475: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:19.475: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:24.508: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:24.555: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:24.555: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:29.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:29.551: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:29.551: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:34.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:34.556: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:34.556: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:39.510: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:39.555: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:39.555: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:44.507: INFO: File wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:44.559: INFO: File jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local from pod  dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:43:44.559: INFO: Lookups using dns-3574/dns-test-45320854-6f15-4b99-a451-558a24f4673c failed for: [wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local]

    Dec 14 08:43:49.555: INFO: DNS probes using dns-test-45320854-6f15-4b99-a451-558a24f4673c succeeded

    STEP: deleting the pod 12/14/22 08:43:49.555
    STEP: changing the service to type=ClusterIP 12/14/22 08:43:49.593
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:49.665
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3574.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3574.svc.cluster.local; sleep 1; done
     12/14/22 08:43:49.665
    STEP: creating a third pod to probe DNS 12/14/22 08:43:49.665
    STEP: submitting the pod to kubernetes 12/14/22 08:43:49.691
    Dec 14 08:43:49.730: INFO: Waiting up to 15m0s for pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2" in namespace "dns-3574" to be "running"
    Dec 14 08:43:49.760: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.569346ms
    Dec 14 08:43:51.789: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059103775s
    Dec 14 08:43:53.792: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2": Phase="Running", Reason="", readiness=true. Elapsed: 4.062226409s
    Dec 14 08:43:53.792: INFO: Pod "dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:43:53.792
    STEP: looking for the results for each expected name from probers 12/14/22 08:43:53.82
    Dec 14 08:43:53.997: INFO: DNS probes using dns-test-dd6cc28b-647d-4cf3-a265-89ec89f511e2 succeeded

    STEP: deleting the pod 12/14/22 08:43:53.997
    STEP: deleting the test externalName service 12/14/22 08:43:54.033
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:43:54.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3574" for this suite. 12/14/22 08:43:54.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:54.158
Dec 14 08:43:54.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:43:54.159
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:54.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:54.296
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:43:54.406
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:43:55.309
STEP: Deploying the webhook pod 12/14/22 08:43:55.339
STEP: Wait for the deployment to be ready 12/14/22 08:43:55.397
Dec 14 08:43:55.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:43:57.512
STEP: Verifying the service has paired with the endpoint 12/14/22 08:43:57.55
Dec 14 08:43:58.551: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Dec 14 08:43:58.584: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/14/22 08:43:58.709
STEP: Creating a custom resource that should be denied by the webhook 12/14/22 08:43:58.93
STEP: Creating a custom resource whose deletion would be denied by the webhook 12/14/22 08:44:01.13
STEP: Updating the custom resource with disallowed data should be denied 12/14/22 08:44:01.209
STEP: Deleting the custom resource should be denied 12/14/22 08:44:01.272
STEP: Remove the offending key and value from the custom resource data 12/14/22 08:44:01.311
STEP: Deleting the updated custom resource should be successful 12/14/22 08:44:01.417
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:44:01.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-287" for this suite. 12/14/22 08:44:01.639
STEP: Destroying namespace "webhook-287-markers" for this suite. 12/14/22 08:44:01.668
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":76,"skipped":1416,"failed":0}
------------------------------
• [7.677 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:54.158
    Dec 14 08:43:54.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:43:54.159
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:54.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:54.296
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:43:54.406
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:43:55.309
    STEP: Deploying the webhook pod 12/14/22 08:43:55.339
    STEP: Wait for the deployment to be ready 12/14/22 08:43:55.397
    Dec 14 08:43:55.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 43, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:43:57.512
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:43:57.55
    Dec 14 08:43:58.551: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Dec 14 08:43:58.584: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/14/22 08:43:58.709
    STEP: Creating a custom resource that should be denied by the webhook 12/14/22 08:43:58.93
    STEP: Creating a custom resource whose deletion would be denied by the webhook 12/14/22 08:44:01.13
    STEP: Updating the custom resource with disallowed data should be denied 12/14/22 08:44:01.209
    STEP: Deleting the custom resource should be denied 12/14/22 08:44:01.272
    STEP: Remove the offending key and value from the custom resource data 12/14/22 08:44:01.311
    STEP: Deleting the updated custom resource should be successful 12/14/22 08:44:01.417
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:44:01.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-287" for this suite. 12/14/22 08:44:01.639
    STEP: Destroying namespace "webhook-287-markers" for this suite. 12/14/22 08:44:01.668
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:44:01.837
Dec 14 08:44:01.837: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:44:01.838
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:01.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:01.974
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 08:44:02.111: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 08:45:02.378: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:02.405
Dec 14 08:45:02.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 08:45:02.406
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:02.489
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:02.54
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Dec 14 08:45:02.677: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Dec 14 08:45:02.705: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Dec 14 08:45:02.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1707" for this suite. 12/14/22 08:45:02.874
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:45:02.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7352" for this suite. 12/14/22 08:45:02.966
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":77,"skipped":1451,"failed":0}
------------------------------
• [61.326 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:44:01.837
    Dec 14 08:44:01.837: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:44:01.838
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:01.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:01.974
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 08:44:02.111: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 08:45:02.378: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:02.405
    Dec 14 08:45:02.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 08:45:02.406
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:02.489
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:02.54
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Dec 14 08:45:02.677: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Dec 14 08:45:02.705: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Dec 14 08:45:02.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1707" for this suite. 12/14/22 08:45:02.874
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:45:02.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7352" for this suite. 12/14/22 08:45:02.966
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:03.163
Dec 14 08:45:03.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 08:45:03.165
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.301
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 12/14/22 08:45:03.353
Dec 14 08:45:03.380: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 12/14/22 08:45:03.38
Dec 14 08:45:03.409: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 12/14/22 08:45:03.409
Dec 14 08:45:03.464: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:45:03.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9101" for this suite. 12/14/22 08:45:03.492
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":78,"skipped":1471,"failed":0}
------------------------------
• [0.362 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:03.163
    Dec 14 08:45:03.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 08:45:03.165
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.301
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 12/14/22 08:45:03.353
    Dec 14 08:45:03.380: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 12/14/22 08:45:03.38
    Dec 14 08:45:03.409: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 12/14/22 08:45:03.409
    Dec 14 08:45:03.464: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:45:03.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9101" for this suite. 12/14/22 08:45:03.492
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:03.526
Dec 14 08:45:03.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:45:03.527
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.661
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-d73ba516-60f0-49d8-9fa7-4e80acc3fab8 12/14/22 08:45:03.744
STEP: Creating secret with name s-test-opt-upd-8d1560ed-da7b-4fc1-a52d-4743e5839cc8 12/14/22 08:45:03.771
STEP: Creating the pod 12/14/22 08:45:03.799
Dec 14 08:45:03.835: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259" in namespace "projected-2115" to be "running and ready"
Dec 14 08:45:03.863: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Pending", Reason="", readiness=false. Elapsed: 28.141363ms
Dec 14 08:45:03.863: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:45:05.892: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056750169s
Dec 14 08:45:05.892: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:45:07.893: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Running", Reason="", readiness=true. Elapsed: 4.057697767s
Dec 14 08:45:07.893: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Running (Ready = true)
Dec 14 08:45:07.893: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-d73ba516-60f0-49d8-9fa7-4e80acc3fab8 12/14/22 08:45:08.237
STEP: Updating secret s-test-opt-upd-8d1560ed-da7b-4fc1-a52d-4743e5839cc8 12/14/22 08:45:08.266
STEP: Creating secret with name s-test-opt-create-67a2f696-fca6-4c7b-b6c8-d2bac66231d5 12/14/22 08:45:08.295
STEP: waiting to observe update in volume 12/14/22 08:45:08.323
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 08:46:19.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2115" for this suite. 12/14/22 08:46:19.91
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":79,"skipped":1473,"failed":0}
------------------------------
• [76.418 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:03.526
    Dec 14 08:45:03.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:45:03.527
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.661
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-d73ba516-60f0-49d8-9fa7-4e80acc3fab8 12/14/22 08:45:03.744
    STEP: Creating secret with name s-test-opt-upd-8d1560ed-da7b-4fc1-a52d-4743e5839cc8 12/14/22 08:45:03.771
    STEP: Creating the pod 12/14/22 08:45:03.799
    Dec 14 08:45:03.835: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259" in namespace "projected-2115" to be "running and ready"
    Dec 14 08:45:03.863: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Pending", Reason="", readiness=false. Elapsed: 28.141363ms
    Dec 14 08:45:03.863: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:45:05.892: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056750169s
    Dec 14 08:45:05.892: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:45:07.893: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259": Phase="Running", Reason="", readiness=true. Elapsed: 4.057697767s
    Dec 14 08:45:07.893: INFO: The phase of Pod pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259 is Running (Ready = true)
    Dec 14 08:45:07.893: INFO: Pod "pod-projected-secrets-51b92630-ebf5-4eca-afef-8e259a2ac259" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-d73ba516-60f0-49d8-9fa7-4e80acc3fab8 12/14/22 08:45:08.237
    STEP: Updating secret s-test-opt-upd-8d1560ed-da7b-4fc1-a52d-4743e5839cc8 12/14/22 08:45:08.266
    STEP: Creating secret with name s-test-opt-create-67a2f696-fca6-4c7b-b6c8-d2bac66231d5 12/14/22 08:45:08.295
    STEP: waiting to observe update in volume 12/14/22 08:45:08.323
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 08:46:19.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2115" for this suite. 12/14/22 08:46:19.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:19.945
Dec 14 08:46:19.945: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:46:19.946
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:20.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:20.079
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7703 12/14/22 08:46:20.131
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 08:46:20.171
STEP: creating service externalsvc in namespace services-7703 12/14/22 08:46:20.171
STEP: creating replication controller externalsvc in namespace services-7703 12/14/22 08:46:20.212
I1214 08:46:20.240536    6274 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7703, replica count: 2
I1214 08:46:23.292120    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 12/14/22 08:46:23.319
Dec 14 08:46:23.392: INFO: Creating new exec pod
Dec 14 08:46:23.425: INFO: Waiting up to 5m0s for pod "execpod8x4m5" in namespace "services-7703" to be "running"
Dec 14 08:46:23.453: INFO: Pod "execpod8x4m5": Phase="Pending", Reason="", readiness=false. Elapsed: 27.126001ms
Dec 14 08:46:25.485: INFO: Pod "execpod8x4m5": Phase="Running", Reason="", readiness=true. Elapsed: 2.059986328s
Dec 14 08:46:25.485: INFO: Pod "execpod8x4m5" satisfied condition "running"
Dec 14 08:46:25.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7703 exec execpod8x4m5 -- /bin/sh -x -c nslookup nodeport-service.services-7703.svc.cluster.local'
Dec 14 08:46:26.297: INFO: stderr: "+ nslookup nodeport-service.services-7703.svc.cluster.local\n"
Dec 14 08:46:26.297: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-7703.svc.cluster.local\tcanonical name = externalsvc.services-7703.svc.cluster.local.\nName:\texternalsvc.services-7703.svc.cluster.local\nAddress: 100.104.146.216\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7703, will wait for the garbage collector to delete the pods 12/14/22 08:46:26.297
Dec 14 08:46:26.403: INFO: Deleting ReplicationController externalsvc took: 28.550641ms
Dec 14 08:46:26.503: INFO: Terminating ReplicationController externalsvc pods took: 100.402468ms
Dec 14 08:46:28.549: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:46:28.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7703" for this suite. 12/14/22 08:46:28.643
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":80,"skipped":1482,"failed":0}
------------------------------
• [8.728 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:19.945
    Dec 14 08:46:19.945: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:46:19.946
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:20.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:20.079
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-7703 12/14/22 08:46:20.131
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 08:46:20.171
    STEP: creating service externalsvc in namespace services-7703 12/14/22 08:46:20.171
    STEP: creating replication controller externalsvc in namespace services-7703 12/14/22 08:46:20.212
    I1214 08:46:20.240536    6274 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7703, replica count: 2
    I1214 08:46:23.292120    6274 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 12/14/22 08:46:23.319
    Dec 14 08:46:23.392: INFO: Creating new exec pod
    Dec 14 08:46:23.425: INFO: Waiting up to 5m0s for pod "execpod8x4m5" in namespace "services-7703" to be "running"
    Dec 14 08:46:23.453: INFO: Pod "execpod8x4m5": Phase="Pending", Reason="", readiness=false. Elapsed: 27.126001ms
    Dec 14 08:46:25.485: INFO: Pod "execpod8x4m5": Phase="Running", Reason="", readiness=true. Elapsed: 2.059986328s
    Dec 14 08:46:25.485: INFO: Pod "execpod8x4m5" satisfied condition "running"
    Dec 14 08:46:25.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7703 exec execpod8x4m5 -- /bin/sh -x -c nslookup nodeport-service.services-7703.svc.cluster.local'
    Dec 14 08:46:26.297: INFO: stderr: "+ nslookup nodeport-service.services-7703.svc.cluster.local\n"
    Dec 14 08:46:26.297: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-7703.svc.cluster.local\tcanonical name = externalsvc.services-7703.svc.cluster.local.\nName:\texternalsvc.services-7703.svc.cluster.local\nAddress: 100.104.146.216\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7703, will wait for the garbage collector to delete the pods 12/14/22 08:46:26.297
    Dec 14 08:46:26.403: INFO: Deleting ReplicationController externalsvc took: 28.550641ms
    Dec 14 08:46:26.503: INFO: Terminating ReplicationController externalsvc pods took: 100.402468ms
    Dec 14 08:46:28.549: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:46:28.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7703" for this suite. 12/14/22 08:46:28.643
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:28.674
Dec 14 08:46:28.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:46:28.675
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:28.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:28.808
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-4a811e9c-36d2-4572-b8f2-111e88a3838e 12/14/22 08:46:28.892
STEP: Creating configMap with name cm-test-opt-upd-2cf6f702-ed0e-427a-9137-446ec1cccaae 12/14/22 08:46:28.92
STEP: Creating the pod 12/14/22 08:46:28.949
Dec 14 08:46:28.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351" in namespace "configmap-5114" to be "running and ready"
Dec 14 08:46:29.013: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351": Phase="Pending", Reason="", readiness=false. Elapsed: 27.529036ms
Dec 14 08:46:29.013: INFO: The phase of Pod pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:46:31.040: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351": Phase="Running", Reason="", readiness=true. Elapsed: 2.054172239s
Dec 14 08:46:31.040: INFO: The phase of Pod pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351 is Running (Ready = true)
Dec 14 08:46:31.040: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-4a811e9c-36d2-4572-b8f2-111e88a3838e 12/14/22 08:46:31.277
STEP: Updating configmap cm-test-opt-upd-2cf6f702-ed0e-427a-9137-446ec1cccaae 12/14/22 08:46:31.304
STEP: Creating configMap with name cm-test-opt-create-2fa2bb51-1069-4075-8548-e2cb8248c2dc 12/14/22 08:46:31.33
STEP: waiting to observe update in volume 12/14/22 08:46:31.356
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:47:42.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5114" for this suite. 12/14/22 08:47:42.877
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":81,"skipped":1490,"failed":0}
------------------------------
• [74.229 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:28.674
    Dec 14 08:46:28.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:46:28.675
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:28.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:28.808
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-4a811e9c-36d2-4572-b8f2-111e88a3838e 12/14/22 08:46:28.892
    STEP: Creating configMap with name cm-test-opt-upd-2cf6f702-ed0e-427a-9137-446ec1cccaae 12/14/22 08:46:28.92
    STEP: Creating the pod 12/14/22 08:46:28.949
    Dec 14 08:46:28.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351" in namespace "configmap-5114" to be "running and ready"
    Dec 14 08:46:29.013: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351": Phase="Pending", Reason="", readiness=false. Elapsed: 27.529036ms
    Dec 14 08:46:29.013: INFO: The phase of Pod pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:46:31.040: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351": Phase="Running", Reason="", readiness=true. Elapsed: 2.054172239s
    Dec 14 08:46:31.040: INFO: The phase of Pod pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351 is Running (Ready = true)
    Dec 14 08:46:31.040: INFO: Pod "pod-configmaps-bcf724ed-8fdf-4255-a171-000c3e4da351" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-4a811e9c-36d2-4572-b8f2-111e88a3838e 12/14/22 08:46:31.277
    STEP: Updating configmap cm-test-opt-upd-2cf6f702-ed0e-427a-9137-446ec1cccaae 12/14/22 08:46:31.304
    STEP: Creating configMap with name cm-test-opt-create-2fa2bb51-1069-4075-8548-e2cb8248c2dc 12/14/22 08:46:31.33
    STEP: waiting to observe update in volume 12/14/22 08:46:31.356
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:47:42.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5114" for this suite. 12/14/22 08:47:42.877
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:47:42.904
Dec 14 08:47:42.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:47:42.905
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:42.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:43.029
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 12/14/22 08:47:43.077
Dec 14 08:47:43.077: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Dec 14 08:47:43.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:44.253: INFO: stderr: ""
Dec 14 08:47:44.253: INFO: stdout: "service/agnhost-replica created\n"
Dec 14 08:47:44.253: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Dec 14 08:47:44.253: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:45.162: INFO: stderr: ""
Dec 14 08:47:45.162: INFO: stdout: "service/agnhost-primary created\n"
Dec 14 08:47:45.162: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 14 08:47:45.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:45.479: INFO: stderr: ""
Dec 14 08:47:45.479: INFO: stdout: "service/frontend created\n"
Dec 14 08:47:45.479: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec 14 08:47:45.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:45.785: INFO: stderr: ""
Dec 14 08:47:45.785: INFO: stdout: "deployment.apps/frontend created\n"
Dec 14 08:47:45.786: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 14 08:47:45.786: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:46.095: INFO: stderr: ""
Dec 14 08:47:46.095: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Dec 14 08:47:46.095: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 14 08:47:46.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
Dec 14 08:47:46.416: INFO: stderr: ""
Dec 14 08:47:46.416: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 12/14/22 08:47:46.416
Dec 14 08:47:46.416: INFO: Waiting for all frontend pods to be Running.
Dec 14 08:47:51.469: INFO: Waiting for frontend to serve content.
Dec 14 08:47:51.622: INFO: Trying to add a new entry to the guestbook.
Dec 14 08:47:51.676: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 12/14/22 08:47:51.81
Dec 14 08:47:51.810: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.001: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.001: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 08:47:52.001
Dec 14 08:47:52.001: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.187: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.187: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 08:47:52.187
Dec 14 08:47:52.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.363: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.363: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 08:47:52.363
Dec 14 08:47:52.363: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.529: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.529: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 08:47:52.529
Dec 14 08:47:52.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.705: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.705: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 08:47:52.705
Dec 14 08:47:52.705: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
Dec 14 08:47:52.875: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:47:52.875: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:47:52.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6564" for this suite. 12/14/22 08:47:52.924
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":82,"skipped":1520,"failed":0}
------------------------------
• [10.049 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:47:42.904
    Dec 14 08:47:42.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:47:42.905
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:42.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:43.029
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 12/14/22 08:47:43.077
    Dec 14 08:47:43.077: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Dec 14 08:47:43.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:44.253: INFO: stderr: ""
    Dec 14 08:47:44.253: INFO: stdout: "service/agnhost-replica created\n"
    Dec 14 08:47:44.253: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Dec 14 08:47:44.253: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:45.162: INFO: stderr: ""
    Dec 14 08:47:45.162: INFO: stdout: "service/agnhost-primary created\n"
    Dec 14 08:47:45.162: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Dec 14 08:47:45.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:45.479: INFO: stderr: ""
    Dec 14 08:47:45.479: INFO: stdout: "service/frontend created\n"
    Dec 14 08:47:45.479: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Dec 14 08:47:45.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:45.785: INFO: stderr: ""
    Dec 14 08:47:45.785: INFO: stdout: "deployment.apps/frontend created\n"
    Dec 14 08:47:45.786: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec 14 08:47:45.786: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:46.095: INFO: stderr: ""
    Dec 14 08:47:46.095: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Dec 14 08:47:46.095: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec 14 08:47:46.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 create -f -'
    Dec 14 08:47:46.416: INFO: stderr: ""
    Dec 14 08:47:46.416: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 12/14/22 08:47:46.416
    Dec 14 08:47:46.416: INFO: Waiting for all frontend pods to be Running.
    Dec 14 08:47:51.469: INFO: Waiting for frontend to serve content.
    Dec 14 08:47:51.622: INFO: Trying to add a new entry to the guestbook.
    Dec 14 08:47:51.676: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 12/14/22 08:47:51.81
    Dec 14 08:47:51.810: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.001: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.001: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 08:47:52.001
    Dec 14 08:47:52.001: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.187: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.187: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 08:47:52.187
    Dec 14 08:47:52.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.363: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.363: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 08:47:52.363
    Dec 14 08:47:52.363: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.529: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.529: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 08:47:52.529
    Dec 14 08:47:52.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.705: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.705: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 08:47:52.705
    Dec 14 08:47:52.705: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6564 delete --grace-period=0 --force -f -'
    Dec 14 08:47:52.875: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:47:52.875: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:47:52.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6564" for this suite. 12/14/22 08:47:52.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:47:52.954
Dec 14 08:47:52.954: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 08:47:52.955
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:53.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:53.084
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 12/14/22 08:47:53.161
STEP: create the rc2 12/14/22 08:47:53.187
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/14/22 08:47:58.246
STEP: delete the rc simpletest-rc-to-be-deleted 12/14/22 08:47:59.763
STEP: wait for the rc to be deleted 12/14/22 08:47:59.79
Dec 14 08:48:04.874: INFO: 65 pods remaining
Dec 14 08:48:04.874: INFO: 65 pods has nil DeletionTimestamp
Dec 14 08:48:04.874: INFO: 
STEP: Gathering metrics 12/14/22 08:48:09.875
W1214 08:48:09.934838    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 08:48:09.934: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 14 08:48:09.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-2h2d9" in namespace "gc-3611"
Dec 14 08:48:09.976: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hpkg" in namespace "gc-3611"
Dec 14 08:48:10.007: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zjzr" in namespace "gc-3611"
Dec 14 08:48:10.039: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zm79" in namespace "gc-3611"
Dec 14 08:48:10.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-467ct" in namespace "gc-3611"
Dec 14 08:48:10.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-48vm7" in namespace "gc-3611"
Dec 14 08:48:10.143: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cs2z" in namespace "gc-3611"
Dec 14 08:48:10.175: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f5gh" in namespace "gc-3611"
Dec 14 08:48:10.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fm4m" in namespace "gc-3611"
Dec 14 08:48:10.241: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l72l" in namespace "gc-3611"
Dec 14 08:48:10.280: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rhjc" in namespace "gc-3611"
Dec 14 08:48:10.314: INFO: Deleting pod "simpletest-rc-to-be-deleted-4tmwf" in namespace "gc-3611"
Dec 14 08:48:10.346: INFO: Deleting pod "simpletest-rc-to-be-deleted-58vmk" in namespace "gc-3611"
Dec 14 08:48:10.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-5d4gv" in namespace "gc-3611"
Dec 14 08:48:10.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wv2w" in namespace "gc-3611"
Dec 14 08:48:10.447: INFO: Deleting pod "simpletest-rc-to-be-deleted-68rb6" in namespace "gc-3611"
Dec 14 08:48:10.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-6brpk" in namespace "gc-3611"
Dec 14 08:48:10.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-6d4sv" in namespace "gc-3611"
Dec 14 08:48:10.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k68q" in namespace "gc-3611"
Dec 14 08:48:10.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-7bv78" in namespace "gc-3611"
Dec 14 08:48:10.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-82z4g" in namespace "gc-3611"
Dec 14 08:48:10.640: INFO: Deleting pod "simpletest-rc-to-be-deleted-84qf5" in namespace "gc-3611"
Dec 14 08:48:10.674: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nrn7" in namespace "gc-3611"
Dec 14 08:48:10.711: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qglt" in namespace "gc-3611"
Dec 14 08:48:10.744: INFO: Deleting pod "simpletest-rc-to-be-deleted-8td44" in namespace "gc-3611"
Dec 14 08:48:10.775: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zfgz" in namespace "gc-3611"
Dec 14 08:48:10.808: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zwv9" in namespace "gc-3611"
Dec 14 08:48:10.847: INFO: Deleting pod "simpletest-rc-to-be-deleted-96gsc" in namespace "gc-3611"
Dec 14 08:48:10.880: INFO: Deleting pod "simpletest-rc-to-be-deleted-96xx7" in namespace "gc-3611"
Dec 14 08:48:10.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-9f5jj" in namespace "gc-3611"
Dec 14 08:48:10.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ghxm" in namespace "gc-3611"
Dec 14 08:48:10.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqjhd" in namespace "gc-3611"
Dec 14 08:48:11.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxnnp" in namespace "gc-3611"
Dec 14 08:48:11.049: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctnnc" in namespace "gc-3611"
Dec 14 08:48:11.083: INFO: Deleting pod "simpletest-rc-to-be-deleted-d9qwm" in namespace "gc-3611"
Dec 14 08:48:11.122: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddkvc" in namespace "gc-3611"
Dec 14 08:48:11.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-dg42c" in namespace "gc-3611"
Dec 14 08:48:11.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-dwjcp" in namespace "gc-3611"
Dec 14 08:48:11.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzvmk" in namespace "gc-3611"
Dec 14 08:48:11.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7mmr" in namespace "gc-3611"
Dec 14 08:48:11.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-fc2hp" in namespace "gc-3611"
Dec 14 08:48:11.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-fk6nv" in namespace "gc-3611"
Dec 14 08:48:11.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-fltf7" in namespace "gc-3611"
Dec 14 08:48:11.400: INFO: Deleting pod "simpletest-rc-to-be-deleted-g22rd" in namespace "gc-3611"
Dec 14 08:48:11.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-g84xk" in namespace "gc-3611"
Dec 14 08:48:11.463: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdcmd" in namespace "gc-3611"
Dec 14 08:48:11.498: INFO: Deleting pod "simpletest-rc-to-be-deleted-gkqld" in namespace "gc-3611"
Dec 14 08:48:11.532: INFO: Deleting pod "simpletest-rc-to-be-deleted-glkf9" in namespace "gc-3611"
Dec 14 08:48:11.566: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqnp5" in namespace "gc-3611"
Dec 14 08:48:11.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-grdzw" in namespace "gc-3611"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 08:48:11.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3611" for this suite. 12/14/22 08:48:11.664
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":83,"skipped":1525,"failed":0}
------------------------------
• [18.741 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:47:52.954
    Dec 14 08:47:52.954: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 08:47:52.955
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:53.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:53.084
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 12/14/22 08:47:53.161
    STEP: create the rc2 12/14/22 08:47:53.187
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/14/22 08:47:58.246
    STEP: delete the rc simpletest-rc-to-be-deleted 12/14/22 08:47:59.763
    STEP: wait for the rc to be deleted 12/14/22 08:47:59.79
    Dec 14 08:48:04.874: INFO: 65 pods remaining
    Dec 14 08:48:04.874: INFO: 65 pods has nil DeletionTimestamp
    Dec 14 08:48:04.874: INFO: 
    STEP: Gathering metrics 12/14/22 08:48:09.875
    W1214 08:48:09.934838    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 08:48:09.934: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec 14 08:48:09.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-2h2d9" in namespace "gc-3611"
    Dec 14 08:48:09.976: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hpkg" in namespace "gc-3611"
    Dec 14 08:48:10.007: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zjzr" in namespace "gc-3611"
    Dec 14 08:48:10.039: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zm79" in namespace "gc-3611"
    Dec 14 08:48:10.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-467ct" in namespace "gc-3611"
    Dec 14 08:48:10.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-48vm7" in namespace "gc-3611"
    Dec 14 08:48:10.143: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cs2z" in namespace "gc-3611"
    Dec 14 08:48:10.175: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f5gh" in namespace "gc-3611"
    Dec 14 08:48:10.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fm4m" in namespace "gc-3611"
    Dec 14 08:48:10.241: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l72l" in namespace "gc-3611"
    Dec 14 08:48:10.280: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rhjc" in namespace "gc-3611"
    Dec 14 08:48:10.314: INFO: Deleting pod "simpletest-rc-to-be-deleted-4tmwf" in namespace "gc-3611"
    Dec 14 08:48:10.346: INFO: Deleting pod "simpletest-rc-to-be-deleted-58vmk" in namespace "gc-3611"
    Dec 14 08:48:10.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-5d4gv" in namespace "gc-3611"
    Dec 14 08:48:10.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wv2w" in namespace "gc-3611"
    Dec 14 08:48:10.447: INFO: Deleting pod "simpletest-rc-to-be-deleted-68rb6" in namespace "gc-3611"
    Dec 14 08:48:10.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-6brpk" in namespace "gc-3611"
    Dec 14 08:48:10.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-6d4sv" in namespace "gc-3611"
    Dec 14 08:48:10.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k68q" in namespace "gc-3611"
    Dec 14 08:48:10.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-7bv78" in namespace "gc-3611"
    Dec 14 08:48:10.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-82z4g" in namespace "gc-3611"
    Dec 14 08:48:10.640: INFO: Deleting pod "simpletest-rc-to-be-deleted-84qf5" in namespace "gc-3611"
    Dec 14 08:48:10.674: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nrn7" in namespace "gc-3611"
    Dec 14 08:48:10.711: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qglt" in namespace "gc-3611"
    Dec 14 08:48:10.744: INFO: Deleting pod "simpletest-rc-to-be-deleted-8td44" in namespace "gc-3611"
    Dec 14 08:48:10.775: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zfgz" in namespace "gc-3611"
    Dec 14 08:48:10.808: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zwv9" in namespace "gc-3611"
    Dec 14 08:48:10.847: INFO: Deleting pod "simpletest-rc-to-be-deleted-96gsc" in namespace "gc-3611"
    Dec 14 08:48:10.880: INFO: Deleting pod "simpletest-rc-to-be-deleted-96xx7" in namespace "gc-3611"
    Dec 14 08:48:10.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-9f5jj" in namespace "gc-3611"
    Dec 14 08:48:10.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ghxm" in namespace "gc-3611"
    Dec 14 08:48:10.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqjhd" in namespace "gc-3611"
    Dec 14 08:48:11.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxnnp" in namespace "gc-3611"
    Dec 14 08:48:11.049: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctnnc" in namespace "gc-3611"
    Dec 14 08:48:11.083: INFO: Deleting pod "simpletest-rc-to-be-deleted-d9qwm" in namespace "gc-3611"
    Dec 14 08:48:11.122: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddkvc" in namespace "gc-3611"
    Dec 14 08:48:11.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-dg42c" in namespace "gc-3611"
    Dec 14 08:48:11.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-dwjcp" in namespace "gc-3611"
    Dec 14 08:48:11.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzvmk" in namespace "gc-3611"
    Dec 14 08:48:11.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7mmr" in namespace "gc-3611"
    Dec 14 08:48:11.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-fc2hp" in namespace "gc-3611"
    Dec 14 08:48:11.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-fk6nv" in namespace "gc-3611"
    Dec 14 08:48:11.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-fltf7" in namespace "gc-3611"
    Dec 14 08:48:11.400: INFO: Deleting pod "simpletest-rc-to-be-deleted-g22rd" in namespace "gc-3611"
    Dec 14 08:48:11.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-g84xk" in namespace "gc-3611"
    Dec 14 08:48:11.463: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdcmd" in namespace "gc-3611"
    Dec 14 08:48:11.498: INFO: Deleting pod "simpletest-rc-to-be-deleted-gkqld" in namespace "gc-3611"
    Dec 14 08:48:11.532: INFO: Deleting pod "simpletest-rc-to-be-deleted-glkf9" in namespace "gc-3611"
    Dec 14 08:48:11.566: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqnp5" in namespace "gc-3611"
    Dec 14 08:48:11.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-grdzw" in namespace "gc-3611"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 08:48:11.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3611" for this suite. 12/14/22 08:48:11.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:48:11.697
Dec 14 08:48:11.698: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:48:11.698
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:48:11.774
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:48:11.821
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Dec 14 08:48:11.921: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 08:48:11.921
Dec 14 08:48:11.921: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-sfrv6" in namespace "deployment-8838" to be "running"
Dec 14 08:48:11.946: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.067993ms
Dec 14 08:48:13.972: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050687638s
Dec 14 08:48:15.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052131638s
Dec 14 08:48:17.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052482213s
Dec 14 08:48:19.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051805929s
Dec 14 08:48:21.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Running", Reason="", readiness=true. Elapsed: 10.052449046s
Dec 14 08:48:21.973: INFO: Pod "test-cleanup-controller-sfrv6" satisfied condition "running"
Dec 14 08:48:21.973: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/14/22 08:48:22.05
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:48:26.196: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8838  74c5ed50-b9d6-4ab1-bca3-39ce148c1116 20941 1 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d2b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:48:22 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-12-14 08:48:24 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 08:48:26.221: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-8838  a2fe3b4c-b27e-4980-93fc-2286bb9d6efd 20934 1 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 74c5ed50-b9d6-4ab1-bca3-39ce148c1116 0xc0037d3207 0xc0037d3208}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74c5ed50-b9d6-4ab1-bca3-39ce148c1116\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d33e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:48:26.247: INFO: Pod "test-cleanup-deployment-69cb9c5497-4sd4r" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-4sd4r test-cleanup-deployment-69cb9c5497- deployment-8838  b549f3fa-d603-4a2b-bc9d-36e83ef2a22d 20933 0 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:2eead40349dad09fe70efcc08470785f528695a8eb2e694c283a28da1d3d8978 cni.projectcalico.org/podIP:100.64.0.195/32 cni.projectcalico.org/podIPs:100.64.0.195/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 a2fe3b4c-b27e-4980-93fc-2286bb9d6efd 0xc0037d37c7 0xc0037d37c8}] [] [{Go-http-client Update v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a2fe3b4c-b27e-4980-93fc-2286bb9d6efd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.195\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g9qq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g9qq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.195,StartTime:2022-12-14 08:48:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:48:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ef668338a2f340bf8ec5a1fd8dbd9095109a1a46ed1a59581564baa931ca3d19,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.195,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:48:26.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8838" for this suite. 12/14/22 08:48:26.296
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":84,"skipped":1569,"failed":0}
------------------------------
• [14.626 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:48:11.697
    Dec 14 08:48:11.698: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:48:11.698
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:48:11.774
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:48:11.821
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Dec 14 08:48:11.921: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 08:48:11.921
    Dec 14 08:48:11.921: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-sfrv6" in namespace "deployment-8838" to be "running"
    Dec 14 08:48:11.946: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.067993ms
    Dec 14 08:48:13.972: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050687638s
    Dec 14 08:48:15.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052131638s
    Dec 14 08:48:17.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052482213s
    Dec 14 08:48:19.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051805929s
    Dec 14 08:48:21.973: INFO: Pod "test-cleanup-controller-sfrv6": Phase="Running", Reason="", readiness=true. Elapsed: 10.052449046s
    Dec 14 08:48:21.973: INFO: Pod "test-cleanup-controller-sfrv6" satisfied condition "running"
    Dec 14 08:48:21.973: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/14/22 08:48:22.05
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:48:26.196: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8838  74c5ed50-b9d6-4ab1-bca3-39ce148c1116 20941 1 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d2b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:48:22 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-12-14 08:48:24 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 08:48:26.221: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-8838  a2fe3b4c-b27e-4980-93fc-2286bb9d6efd 20934 1 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 74c5ed50-b9d6-4ab1-bca3-39ce148c1116 0xc0037d3207 0xc0037d3208}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74c5ed50-b9d6-4ab1-bca3-39ce148c1116\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d33e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:48:26.247: INFO: Pod "test-cleanup-deployment-69cb9c5497-4sd4r" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-4sd4r test-cleanup-deployment-69cb9c5497- deployment-8838  b549f3fa-d603-4a2b-bc9d-36e83ef2a22d 20933 0 2022-12-14 08:48:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:2eead40349dad09fe70efcc08470785f528695a8eb2e694c283a28da1d3d8978 cni.projectcalico.org/podIP:100.64.0.195/32 cni.projectcalico.org/podIPs:100.64.0.195/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 a2fe3b4c-b27e-4980-93fc-2286bb9d6efd 0xc0037d37c7 0xc0037d37c8}] [] [{Go-http-client Update v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:48:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a2fe3b4c-b27e-4980-93fc-2286bb9d6efd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:48:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.195\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g9qq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g9qq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:48:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.195,StartTime:2022-12-14 08:48:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:48:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ef668338a2f340bf8ec5a1fd8dbd9095109a1a46ed1a59581564baa931ca3d19,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.195,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:48:26.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8838" for this suite. 12/14/22 08:48:26.296
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:48:26.325
Dec 14 08:48:26.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:48:26.326
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:48:26.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:48:26.45
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-3264 12/14/22 08:48:26.499
Dec 14 08:48:26.545: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3264" to be "running and ready"
Dec 14 08:48:26.570: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 25.005416ms
Dec 14 08:48:26.570: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:48:28.596: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.051691043s
Dec 14 08:48:28.596: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 14 08:48:28.596: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec 14 08:48:28.622: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 14 08:48:29.239: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 14 08:48:29.239: INFO: stdout: "iptables"
Dec 14 08:48:29.239: INFO: proxyMode: iptables
Dec 14 08:48:29.271: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 14 08:48:29.296: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-3264 12/14/22 08:48:29.296
STEP: creating replication controller affinity-nodeport-timeout in namespace services-3264 12/14/22 08:48:29.334
I1214 08:48:29.362143    6274 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3264, replica count: 3
I1214 08:48:32.413259    6274 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 08:48:32.514: INFO: Creating new exec pod
Dec 14 08:48:32.545: INFO: Waiting up to 5m0s for pod "execpod-affinityppxm7" in namespace "services-3264" to be "running"
Dec 14 08:48:32.570: INFO: Pod "execpod-affinityppxm7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.626329ms
Dec 14 08:48:34.596: INFO: Pod "execpod-affinityppxm7": Phase="Running", Reason="", readiness=true. Elapsed: 2.051384207s
Dec 14 08:48:34.596: INFO: Pod "execpod-affinityppxm7" satisfied condition "running"
Dec 14 08:48:35.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Dec 14 08:48:36.239: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Dec 14 08:48:36.239: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:48:36.239: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.109.201.82 80'
Dec 14 08:48:36.786: INFO: stderr: "+ nc -v -t -w 2 100.109.201.82 80\n+ echo hostName\nConnection to 100.109.201.82 80 port [tcp/http] succeeded!\n"
Dec 14 08:48:36.786: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:48:36.787: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32125'
Dec 14 08:48:37.398: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32125\nConnection to 10.250.0.5 32125 port [tcp/*] succeeded!\n"
Dec 14 08:48:37.398: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:48:37.398: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32125'
Dec 14 08:48:37.983: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32125\n+ echo hostName\nConnection to 10.250.0.4 32125 port [tcp/*] succeeded!\n"
Dec 14 08:48:37.983: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 08:48:37.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:32125/ ; done'
Dec 14 08:48:38.728: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
Dec 14 08:48:38.728: INFO: stdout: "\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v"
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
Dec 14 08:48:38.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
Dec 14 08:48:39.329: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
Dec 14 08:48:39.329: INFO: stdout: "affinity-nodeport-timeout-54g9v"
Dec 14 08:48:59.330: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
Dec 14 08:49:00.029: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
Dec 14 08:49:00.029: INFO: stdout: "affinity-nodeport-timeout-54g9v"
Dec 14 08:49:20.029: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
Dec 14 08:49:20.668: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
Dec 14 08:49:20.668: INFO: stdout: "affinity-nodeport-timeout-54g9v"
Dec 14 08:49:40.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
Dec 14 08:49:41.303: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
Dec 14 08:49:41.303: INFO: stdout: "affinity-nodeport-timeout-q7d6v"
Dec 14 08:49:41.303: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3264, will wait for the garbage collector to delete the pods 12/14/22 08:49:41.336
Dec 14 08:49:41.440: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 27.154047ms
Dec 14 08:49:41.540: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.543331ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:49:43.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3264" for this suite. 12/14/22 08:49:43.515
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":85,"skipped":1590,"failed":0}
------------------------------
• [77.217 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:48:26.325
    Dec 14 08:48:26.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:48:26.326
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:48:26.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:48:26.45
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-3264 12/14/22 08:48:26.499
    Dec 14 08:48:26.545: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3264" to be "running and ready"
    Dec 14 08:48:26.570: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 25.005416ms
    Dec 14 08:48:26.570: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:48:28.596: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.051691043s
    Dec 14 08:48:28.596: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec 14 08:48:28.596: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec 14 08:48:28.622: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec 14 08:48:29.239: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec 14 08:48:29.239: INFO: stdout: "iptables"
    Dec 14 08:48:29.239: INFO: proxyMode: iptables
    Dec 14 08:48:29.271: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec 14 08:48:29.296: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-3264 12/14/22 08:48:29.296
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-3264 12/14/22 08:48:29.334
    I1214 08:48:29.362143    6274 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3264, replica count: 3
    I1214 08:48:32.413259    6274 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 08:48:32.514: INFO: Creating new exec pod
    Dec 14 08:48:32.545: INFO: Waiting up to 5m0s for pod "execpod-affinityppxm7" in namespace "services-3264" to be "running"
    Dec 14 08:48:32.570: INFO: Pod "execpod-affinityppxm7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.626329ms
    Dec 14 08:48:34.596: INFO: Pod "execpod-affinityppxm7": Phase="Running", Reason="", readiness=true. Elapsed: 2.051384207s
    Dec 14 08:48:34.596: INFO: Pod "execpod-affinityppxm7" satisfied condition "running"
    Dec 14 08:48:35.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Dec 14 08:48:36.239: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Dec 14 08:48:36.239: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:48:36.239: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.109.201.82 80'
    Dec 14 08:48:36.786: INFO: stderr: "+ nc -v -t -w 2 100.109.201.82 80\n+ echo hostName\nConnection to 100.109.201.82 80 port [tcp/http] succeeded!\n"
    Dec 14 08:48:36.786: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:48:36.787: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32125'
    Dec 14 08:48:37.398: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32125\nConnection to 10.250.0.5 32125 port [tcp/*] succeeded!\n"
    Dec 14 08:48:37.398: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:48:37.398: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32125'
    Dec 14 08:48:37.983: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32125\n+ echo hostName\nConnection to 10.250.0.4 32125 port [tcp/*] succeeded!\n"
    Dec 14 08:48:37.983: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 08:48:37.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:32125/ ; done'
    Dec 14 08:48:38.728: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
    Dec 14 08:48:38.728: INFO: stdout: "\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v\naffinity-nodeport-timeout-54g9v"
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Received response from host: affinity-nodeport-timeout-54g9v
    Dec 14 08:48:38.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
    Dec 14 08:48:39.329: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
    Dec 14 08:48:39.329: INFO: stdout: "affinity-nodeport-timeout-54g9v"
    Dec 14 08:48:59.330: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
    Dec 14 08:49:00.029: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
    Dec 14 08:49:00.029: INFO: stdout: "affinity-nodeport-timeout-54g9v"
    Dec 14 08:49:20.029: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
    Dec 14 08:49:20.668: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
    Dec 14 08:49:20.668: INFO: stdout: "affinity-nodeport-timeout-54g9v"
    Dec 14 08:49:40.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3264 exec execpod-affinityppxm7 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.0.5:32125/'
    Dec 14 08:49:41.303: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.0.5:32125/\n"
    Dec 14 08:49:41.303: INFO: stdout: "affinity-nodeport-timeout-q7d6v"
    Dec 14 08:49:41.303: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3264, will wait for the garbage collector to delete the pods 12/14/22 08:49:41.336
    Dec 14 08:49:41.440: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 27.154047ms
    Dec 14 08:49:41.540: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.543331ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:49:43.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3264" for this suite. 12/14/22 08:49:43.515
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:43.542
Dec 14 08:49:43.542: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 08:49:43.543
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:43.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:43.667
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 12/14/22 08:49:43.715
Dec 14 08:49:43.742: INFO: created test-podtemplate-1
Dec 14 08:49:43.767: INFO: created test-podtemplate-2
Dec 14 08:49:43.792: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 12/14/22 08:49:43.792
STEP: delete collection of pod templates 12/14/22 08:49:43.818
Dec 14 08:49:43.818: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 12/14/22 08:49:43.854
Dec 14 08:49:43.854: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 08:49:43.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2196" for this suite. 12/14/22 08:49:43.906
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":86,"skipped":1593,"failed":0}
------------------------------
• [0.391 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:43.542
    Dec 14 08:49:43.542: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 08:49:43.543
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:43.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:43.667
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 12/14/22 08:49:43.715
    Dec 14 08:49:43.742: INFO: created test-podtemplate-1
    Dec 14 08:49:43.767: INFO: created test-podtemplate-2
    Dec 14 08:49:43.792: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 12/14/22 08:49:43.792
    STEP: delete collection of pod templates 12/14/22 08:49:43.818
    Dec 14 08:49:43.818: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 12/14/22 08:49:43.854
    Dec 14 08:49:43.854: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 08:49:43.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2196" for this suite. 12/14/22 08:49:43.906
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:43.934
Dec 14 08:49:43.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:49:43.935
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:44.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:44.062
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-4f2fcfa4-f7e9-46f4-a581-088c8ef27928 12/14/22 08:49:44.111
STEP: Creating a pod to test consume configMaps 12/14/22 08:49:44.136
Dec 14 08:49:44.170: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07" in namespace "configmap-826" to be "Succeeded or Failed"
Dec 14 08:49:44.195: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Pending", Reason="", readiness=false. Elapsed: 25.124216ms
Dec 14 08:49:46.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052630662s
Dec 14 08:49:48.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052439727s
STEP: Saw pod success 12/14/22 08:49:48.222
Dec 14 08:49:48.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07" satisfied condition "Succeeded or Failed"
Dec 14 08:49:48.249: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 container configmap-volume-test: <nil>
STEP: delete the pod 12/14/22 08:49:48.39
Dec 14 08:49:48.425: INFO: Waiting for pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 to disappear
Dec 14 08:49:48.450: INFO: Pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:49:48.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-826" for this suite. 12/14/22 08:49:48.499
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":87,"skipped":1606,"failed":0}
------------------------------
• [4.599 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:43.934
    Dec 14 08:49:43.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:49:43.935
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:44.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:44.062
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-4f2fcfa4-f7e9-46f4-a581-088c8ef27928 12/14/22 08:49:44.111
    STEP: Creating a pod to test consume configMaps 12/14/22 08:49:44.136
    Dec 14 08:49:44.170: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07" in namespace "configmap-826" to be "Succeeded or Failed"
    Dec 14 08:49:44.195: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Pending", Reason="", readiness=false. Elapsed: 25.124216ms
    Dec 14 08:49:46.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052630662s
    Dec 14 08:49:48.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052439727s
    STEP: Saw pod success 12/14/22 08:49:48.222
    Dec 14 08:49:48.222: INFO: Pod "pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07" satisfied condition "Succeeded or Failed"
    Dec 14 08:49:48.249: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 container configmap-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:49:48.39
    Dec 14 08:49:48.425: INFO: Waiting for pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 to disappear
    Dec 14 08:49:48.450: INFO: Pod pod-configmaps-5e138987-0f20-41b4-ad94-6dc9a24eba07 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:49:48.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-826" for this suite. 12/14/22 08:49:48.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:48.534
Dec 14 08:49:48.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 08:49:48.535
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:48.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:48.658
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 08:49:48.731
Dec 14 08:49:48.763: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4359" to be "running and ready"
Dec 14 08:49:48.789: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.449007ms
Dec 14 08:49:48.789: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:49:50.821: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.057636806s
Dec 14 08:49:50.866: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 08:49:50.866: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 12/14/22 08:49:50.892
Dec 14 08:49:50.922: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-4359" to be "running and ready"
Dec 14 08:49:50.947: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 25.48187ms
Dec 14 08:49:50.947: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:49:52.974: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.052583847s
Dec 14 08:49:52.974: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Dec 14 08:49:52.974: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/14/22 08:49:53
Dec 14 08:49:53.027: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 08:49:53.052: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 14 08:49:55.053: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 08:49:55.079: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 14 08:49:57.054: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 08:49:57.079: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 12/14/22 08:49:57.079
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 08:49:57.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4359" for this suite. 12/14/22 08:49:57.174
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":88,"skipped":1628,"failed":0}
------------------------------
• [8.666 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:48.534
    Dec 14 08:49:48.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 08:49:48.535
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:48.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:48.658
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 08:49:48.731
    Dec 14 08:49:48.763: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4359" to be "running and ready"
    Dec 14 08:49:48.789: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.449007ms
    Dec 14 08:49:48.789: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:49:50.821: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.057636806s
    Dec 14 08:49:50.866: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 08:49:50.866: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 12/14/22 08:49:50.892
    Dec 14 08:49:50.922: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-4359" to be "running and ready"
    Dec 14 08:49:50.947: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 25.48187ms
    Dec 14 08:49:50.947: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:49:52.974: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.052583847s
    Dec 14 08:49:52.974: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Dec 14 08:49:52.974: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/14/22 08:49:53
    Dec 14 08:49:53.027: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 08:49:53.052: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec 14 08:49:55.053: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 08:49:55.079: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec 14 08:49:57.054: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 08:49:57.079: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 12/14/22 08:49:57.079
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 08:49:57.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4359" for this suite. 12/14/22 08:49:57.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:57.201
Dec 14 08:49:57.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook 12/14/22 08:49:57.202
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:57.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:57.343
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/14/22 08:49:57.397
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 08:49:58.069
STEP: Deploying the custom resource conversion webhook pod 12/14/22 08:49:58.096
STEP: Wait for the deployment to be ready 12/14/22 08:49:58.149
Dec 14 08:49:58.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:50:00.265
STEP: Verifying the service has paired with the endpoint 12/14/22 08:50:00.3
Dec 14 08:50:01.300: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Dec 14 08:50:01.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource 12/14/22 08:50:03.658
STEP: Create a v2 custom resource 12/14/22 08:50:03.74
STEP: List CRs in v1 12/14/22 08:50:03.851
STEP: List CRs in v2 12/14/22 08:50:03.895
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:50:04.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1420" for this suite. 12/14/22 08:50:04.577
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":89,"skipped":1644,"failed":0}
------------------------------
• [7.537 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:57.201
    Dec 14 08:49:57.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-webhook 12/14/22 08:49:57.202
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:57.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:57.343
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/14/22 08:49:57.397
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 08:49:58.069
    STEP: Deploying the custom resource conversion webhook pod 12/14/22 08:49:58.096
    STEP: Wait for the deployment to be ready 12/14/22 08:49:58.149
    Dec 14 08:49:58.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 49, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:50:00.265
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:50:00.3
    Dec 14 08:50:01.300: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Dec 14 08:50:01.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating a v1 custom resource 12/14/22 08:50:03.658
    STEP: Create a v2 custom resource 12/14/22 08:50:03.74
    STEP: List CRs in v1 12/14/22 08:50:03.851
    STEP: List CRs in v2 12/14/22 08:50:03.895
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:50:04.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-1420" for this suite. 12/14/22 08:50:04.577
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:04.74
Dec 14 08:50:04.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:50:04.741
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:04.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:04.865
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 08:50:04.990: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 08:51:05.227: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 12/14/22 08:51:05.253
Dec 14 08:51:05.324: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 14 08:51:05.354: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 14 08:51:05.421: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 14 08:51:05.452: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/14/22 08:51:05.452
Dec 14 08:51:05.453: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8592" to be "running"
Dec 14 08:51:05.478: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 25.040605ms
Dec 14 08:51:07.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051697625s
Dec 14 08:51:09.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051322449s
Dec 14 08:51:11.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051858704s
Dec 14 08:51:13.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.052294121s
Dec 14 08:51:13.505: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec 14 08:51:13.505: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
Dec 14 08:51:13.531: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.627112ms
Dec 14 08:51:13.531: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:51:13.531: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
Dec 14 08:51:13.556: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.236456ms
Dec 14 08:51:13.556: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:51:13.556: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
Dec 14 08:51:13.587: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 31.15258ms
Dec 14 08:51:13.587: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/14/22 08:51:13.587
Dec 14 08:51:13.618: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8592" to be "running"
Dec 14 08:51:13.646: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 27.70011ms
Dec 14 08:51:15.672: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053529599s
Dec 14 08:51:17.677: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058288368s
Dec 14 08:51:19.673: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.054789664s
Dec 14 08:51:19.673: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:51:19.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8592" for this suite. 12/14/22 08:51:19.848
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":90,"skipped":1686,"failed":0}
------------------------------
• [75.288 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:04.74
    Dec 14 08:50:04.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:50:04.741
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:04.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:04.865
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 08:50:04.990: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 08:51:05.227: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 12/14/22 08:51:05.253
    Dec 14 08:51:05.324: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec 14 08:51:05.354: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec 14 08:51:05.421: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec 14 08:51:05.452: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/14/22 08:51:05.452
    Dec 14 08:51:05.453: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8592" to be "running"
    Dec 14 08:51:05.478: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 25.040605ms
    Dec 14 08:51:07.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051697625s
    Dec 14 08:51:09.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051322449s
    Dec 14 08:51:11.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051858704s
    Dec 14 08:51:13.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.052294121s
    Dec 14 08:51:13.505: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec 14 08:51:13.505: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
    Dec 14 08:51:13.531: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.627112ms
    Dec 14 08:51:13.531: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:51:13.531: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
    Dec 14 08:51:13.556: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.236456ms
    Dec 14 08:51:13.556: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:51:13.556: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8592" to be "running"
    Dec 14 08:51:13.587: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 31.15258ms
    Dec 14 08:51:13.587: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/14/22 08:51:13.587
    Dec 14 08:51:13.618: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8592" to be "running"
    Dec 14 08:51:13.646: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 27.70011ms
    Dec 14 08:51:15.672: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053529599s
    Dec 14 08:51:17.677: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058288368s
    Dec 14 08:51:19.673: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.054789664s
    Dec 14 08:51:19.673: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:51:19.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8592" for this suite. 12/14/22 08:51:19.848
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:20.029
Dec 14 08:51:20.029: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:51:20.03
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:20.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:20.164
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-61bd0a14-3450-4900-8667-9da6e3464472 12/14/22 08:51:20.242
STEP: Creating the pod 12/14/22 08:51:20.27
Dec 14 08:51:20.303: INFO: Waiting up to 5m0s for pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f" in namespace "configmap-9975" to be "running and ready"
Dec 14 08:51:20.329: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.66896ms
Dec 14 08:51:20.329: INFO: The phase of Pod pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:51:22.356: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f": Phase="Running", Reason="", readiness=true. Elapsed: 2.05251955s
Dec 14 08:51:22.356: INFO: The phase of Pod pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f is Running (Ready = true)
Dec 14 08:51:22.356: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-61bd0a14-3450-4900-8667-9da6e3464472 12/14/22 08:51:22.545
STEP: waiting to observe update in volume 12/14/22 08:51:22.572
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:51:24.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9975" for this suite. 12/14/22 08:51:24.688
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":91,"skipped":1705,"failed":0}
------------------------------
• [4.686 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:20.029
    Dec 14 08:51:20.029: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:51:20.03
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:20.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:20.164
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-61bd0a14-3450-4900-8667-9da6e3464472 12/14/22 08:51:20.242
    STEP: Creating the pod 12/14/22 08:51:20.27
    Dec 14 08:51:20.303: INFO: Waiting up to 5m0s for pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f" in namespace "configmap-9975" to be "running and ready"
    Dec 14 08:51:20.329: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.66896ms
    Dec 14 08:51:20.329: INFO: The phase of Pod pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:51:22.356: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f": Phase="Running", Reason="", readiness=true. Elapsed: 2.05251955s
    Dec 14 08:51:22.356: INFO: The phase of Pod pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f is Running (Ready = true)
    Dec 14 08:51:22.356: INFO: Pod "pod-configmaps-5af50a9a-2898-49bf-90cc-4d00e7aa903f" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-61bd0a14-3450-4900-8667-9da6e3464472 12/14/22 08:51:22.545
    STEP: waiting to observe update in volume 12/14/22 08:51:22.572
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:51:24.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9975" for this suite. 12/14/22 08:51:24.688
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:24.715
Dec 14 08:51:24.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/14/22 08:51:24.716
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:24.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:24.843
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 12/14/22 08:51:24.891
STEP: Creating hostNetwork=false pod 12/14/22 08:51:24.891
Dec 14 08:51:24.925: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1720" to be "running and ready"
Dec 14 08:51:24.951: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.588373ms
Dec 14 08:51:24.951: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:51:26.979: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.054095068s
Dec 14 08:51:26.979: INFO: The phase of Pod test-pod is Running (Ready = true)
Dec 14 08:51:26.979: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 12/14/22 08:51:27.005
Dec 14 08:51:27.035: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1720" to be "running and ready"
Dec 14 08:51:27.062: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.095089ms
Dec 14 08:51:27.062: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:51:29.099: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.063169936s
Dec 14 08:51:29.099: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Dec 14 08:51:29.099: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 12/14/22 08:51:29.124
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/14/22 08:51:29.124
Dec 14 08:51:29.125: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:29.125: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:29.125: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:29.126: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 08:51:29.604: INFO: Exec stderr: ""
Dec 14 08:51:29.604: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:29.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:29.605: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:29.605: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 08:51:30.035: INFO: Exec stderr: ""
Dec 14 08:51:30.035: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:30.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:30.036: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:30.036: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 08:51:30.485: INFO: Exec stderr: ""
Dec 14 08:51:30.485: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:30.485: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:30.486: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:30.486: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 08:51:30.956: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/14/22 08:51:30.956
Dec 14 08:51:30.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:30.956: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:30.957: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:30.957: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec 14 08:51:31.441: INFO: Exec stderr: ""
Dec 14 08:51:31.441: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:31.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:31.442: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:31.442: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec 14 08:51:31.917: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/14/22 08:51:31.917
Dec 14 08:51:31.917: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:31.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:31.917: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:31.917: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 08:51:32.417: INFO: Exec stderr: ""
Dec 14 08:51:32.417: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:32.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:32.417: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:32.417: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 08:51:32.893: INFO: Exec stderr: ""
Dec 14 08:51:32.893: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:32.893: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:32.893: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:32.893: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 08:51:33.342: INFO: Exec stderr: ""
Dec 14 08:51:33.342: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:51:33.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:51:33.342: INFO: ExecWithOptions: Clientset creation
Dec 14 08:51:33.342: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 08:51:33.845: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Dec 14 08:51:33.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1720" for this suite. 12/14/22 08:51:33.895
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":92,"skipped":1710,"failed":0}
------------------------------
• [9.208 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:24.715
    Dec 14 08:51:24.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/14/22 08:51:24.716
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:24.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:24.843
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 12/14/22 08:51:24.891
    STEP: Creating hostNetwork=false pod 12/14/22 08:51:24.891
    Dec 14 08:51:24.925: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1720" to be "running and ready"
    Dec 14 08:51:24.951: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.588373ms
    Dec 14 08:51:24.951: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:51:26.979: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.054095068s
    Dec 14 08:51:26.979: INFO: The phase of Pod test-pod is Running (Ready = true)
    Dec 14 08:51:26.979: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 12/14/22 08:51:27.005
    Dec 14 08:51:27.035: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1720" to be "running and ready"
    Dec 14 08:51:27.062: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.095089ms
    Dec 14 08:51:27.062: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:51:29.099: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.063169936s
    Dec 14 08:51:29.099: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Dec 14 08:51:29.099: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 12/14/22 08:51:29.124
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/14/22 08:51:29.124
    Dec 14 08:51:29.125: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:29.125: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:29.125: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:29.126: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 08:51:29.604: INFO: Exec stderr: ""
    Dec 14 08:51:29.604: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:29.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:29.605: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:29.605: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 08:51:30.035: INFO: Exec stderr: ""
    Dec 14 08:51:30.035: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:30.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:30.036: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:30.036: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 08:51:30.485: INFO: Exec stderr: ""
    Dec 14 08:51:30.485: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:30.485: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:30.486: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:30.486: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 08:51:30.956: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/14/22 08:51:30.956
    Dec 14 08:51:30.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:30.956: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:30.957: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:30.957: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec 14 08:51:31.441: INFO: Exec stderr: ""
    Dec 14 08:51:31.441: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:31.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:31.442: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:31.442: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec 14 08:51:31.917: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/14/22 08:51:31.917
    Dec 14 08:51:31.917: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:31.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:31.917: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:31.917: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 08:51:32.417: INFO: Exec stderr: ""
    Dec 14 08:51:32.417: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:32.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:32.417: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:32.417: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 08:51:32.893: INFO: Exec stderr: ""
    Dec 14 08:51:32.893: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:32.893: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:32.893: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:32.893: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 08:51:33.342: INFO: Exec stderr: ""
    Dec 14 08:51:33.342: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1720 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:51:33.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:51:33.342: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:51:33.342: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-1720/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 08:51:33.845: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Dec 14 08:51:33.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-1720" for this suite. 12/14/22 08:51:33.895
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:33.925
Dec 14 08:51:33.925: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:51:33.926
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:34.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:34.05
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-f51f1332-1468-47d9-98f3-b35ede1f1ac5 12/14/22 08:51:34.099
STEP: Creating secret with name secret-projected-all-test-volume-77debbb9-464d-4140-bc9f-c3252ff86bd5 12/14/22 08:51:34.125
STEP: Creating a pod to test Check all projections for projected volume plugin 12/14/22 08:51:34.15
Dec 14 08:51:34.182: INFO: Waiting up to 5m0s for pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111" in namespace "projected-8837" to be "Succeeded or Failed"
Dec 14 08:51:34.207: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Pending", Reason="", readiness=false. Elapsed: 25.090765ms
Dec 14 08:51:36.233: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051194762s
Dec 14 08:51:38.237: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054645796s
STEP: Saw pod success 12/14/22 08:51:38.237
Dec 14 08:51:38.237: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111" satisfied condition "Succeeded or Failed"
Dec 14 08:51:38.263: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 container projected-all-volume-test: <nil>
STEP: delete the pod 12/14/22 08:51:38.298
Dec 14 08:51:38.338: INFO: Waiting for pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 to disappear
Dec 14 08:51:38.363: INFO: Pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Dec 14 08:51:38.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8837" for this suite. 12/14/22 08:51:38.412
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":93,"skipped":1722,"failed":0}
------------------------------
• [4.521 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:33.925
    Dec 14 08:51:33.925: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:51:33.926
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:34.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:34.05
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-f51f1332-1468-47d9-98f3-b35ede1f1ac5 12/14/22 08:51:34.099
    STEP: Creating secret with name secret-projected-all-test-volume-77debbb9-464d-4140-bc9f-c3252ff86bd5 12/14/22 08:51:34.125
    STEP: Creating a pod to test Check all projections for projected volume plugin 12/14/22 08:51:34.15
    Dec 14 08:51:34.182: INFO: Waiting up to 5m0s for pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111" in namespace "projected-8837" to be "Succeeded or Failed"
    Dec 14 08:51:34.207: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Pending", Reason="", readiness=false. Elapsed: 25.090765ms
    Dec 14 08:51:36.233: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051194762s
    Dec 14 08:51:38.237: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054645796s
    STEP: Saw pod success 12/14/22 08:51:38.237
    Dec 14 08:51:38.237: INFO: Pod "projected-volume-1bd19858-d477-4931-ae85-955a0c435111" satisfied condition "Succeeded or Failed"
    Dec 14 08:51:38.263: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 container projected-all-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:51:38.298
    Dec 14 08:51:38.338: INFO: Waiting for pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 to disappear
    Dec 14 08:51:38.363: INFO: Pod projected-volume-1bd19858-d477-4931-ae85-955a0c435111 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Dec 14 08:51:38.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8837" for this suite. 12/14/22 08:51:38.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:38.446
Dec 14 08:51:38.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 08:51:38.447
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:38.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:38.571
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8976 12/14/22 08:51:38.62
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 12/14/22 08:51:38.646
Dec 14 08:51:38.698: INFO: Found 1 stateful pods, waiting for 3
Dec 14 08:51:48.728: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 08:51:48.728: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 08:51:48.728: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 08:51:48.808: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 08:51:49.349: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 08:51:49.349: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 08:51:49.349: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 08:51:59.456
Dec 14 08:51:59.524: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/14/22 08:51:59.524
STEP: Updating Pods in reverse ordinal order 12/14/22 08:51:59.576
Dec 14 08:51:59.603: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 08:52:00.275: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 08:52:00.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 08:52:00.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 08:52:20.432: INFO: Waiting for StatefulSet statefulset-8976/ss2 to complete update
Dec 14 08:52:20.433: INFO: Waiting for Pod statefulset-8976/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Rolling back to a previous revision 12/14/22 08:52:30.496
Dec 14 08:52:30.496: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 08:52:31.121: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 08:52:31.121: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 08:52:31.121: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 08:52:41.288: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 12/14/22 08:52:41.339
Dec 14 08:52:41.365: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 08:52:41.909: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 08:52:41.909: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 08:52:41.909: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 08:52:52.065: INFO: Waiting for StatefulSet statefulset-8976/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 08:53:02.118: INFO: Deleting all statefulset in ns statefulset-8976
Dec 14 08:53:02.147: INFO: Scaling statefulset ss2 to 0
Dec 14 08:53:12.251: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 08:53:12.276: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 08:53:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8976" for this suite. 12/14/22 08:53:12.416
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":94,"skipped":1727,"failed":0}
------------------------------
• [93.998 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:38.446
    Dec 14 08:51:38.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 08:51:38.447
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:38.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:38.571
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8976 12/14/22 08:51:38.62
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 12/14/22 08:51:38.646
    Dec 14 08:51:38.698: INFO: Found 1 stateful pods, waiting for 3
    Dec 14 08:51:48.728: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 08:51:48.728: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 08:51:48.728: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 08:51:48.808: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 08:51:49.349: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 08:51:49.349: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 08:51:49.349: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 08:51:59.456
    Dec 14 08:51:59.524: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/14/22 08:51:59.524
    STEP: Updating Pods in reverse ordinal order 12/14/22 08:51:59.576
    Dec 14 08:51:59.603: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 08:52:00.275: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 08:52:00.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 08:52:00.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 08:52:20.432: INFO: Waiting for StatefulSet statefulset-8976/ss2 to complete update
    Dec 14 08:52:20.433: INFO: Waiting for Pod statefulset-8976/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Rolling back to a previous revision 12/14/22 08:52:30.496
    Dec 14 08:52:30.496: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 08:52:31.121: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 08:52:31.121: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 08:52:31.121: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 08:52:41.288: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 12/14/22 08:52:41.339
    Dec 14 08:52:41.365: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-8976 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 08:52:41.909: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 08:52:41.909: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 08:52:41.909: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 08:52:52.065: INFO: Waiting for StatefulSet statefulset-8976/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 08:53:02.118: INFO: Deleting all statefulset in ns statefulset-8976
    Dec 14 08:53:02.147: INFO: Scaling statefulset ss2 to 0
    Dec 14 08:53:12.251: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 08:53:12.276: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 08:53:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8976" for this suite. 12/14/22 08:53:12.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:12.446
Dec 14 08:53:12.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:53:12.446
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:12.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:12.571
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 12/14/22 08:53:12.623
STEP: Ensuring ResourceQuota status is calculated 12/14/22 08:53:12.65
STEP: Creating a ResourceQuota with not terminating scope 12/14/22 08:53:14.676
STEP: Ensuring ResourceQuota status is calculated 12/14/22 08:53:14.702
STEP: Creating a long running pod 12/14/22 08:53:16.729
STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/14/22 08:53:16.781
STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/14/22 08:53:18.808
STEP: Deleting the pod 12/14/22 08:53:20.835
STEP: Ensuring resource quota status released the pod usage 12/14/22 08:53:20.875
STEP: Creating a terminating pod 12/14/22 08:53:22.903
STEP: Ensuring resource quota with terminating scope captures the pod usage 12/14/22 08:53:22.941
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/14/22 08:53:24.97
STEP: Deleting the pod 12/14/22 08:53:26.997
STEP: Ensuring resource quota status released the pod usage 12/14/22 08:53:27.032
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:53:29.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4236" for this suite. 12/14/22 08:53:29.108
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":95,"skipped":1746,"failed":0}
------------------------------
• [16.689 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:12.446
    Dec 14 08:53:12.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:53:12.446
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:12.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:12.571
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 12/14/22 08:53:12.623
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 08:53:12.65
    STEP: Creating a ResourceQuota with not terminating scope 12/14/22 08:53:14.676
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 08:53:14.702
    STEP: Creating a long running pod 12/14/22 08:53:16.729
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/14/22 08:53:16.781
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/14/22 08:53:18.808
    STEP: Deleting the pod 12/14/22 08:53:20.835
    STEP: Ensuring resource quota status released the pod usage 12/14/22 08:53:20.875
    STEP: Creating a terminating pod 12/14/22 08:53:22.903
    STEP: Ensuring resource quota with terminating scope captures the pod usage 12/14/22 08:53:22.941
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/14/22 08:53:24.97
    STEP: Deleting the pod 12/14/22 08:53:26.997
    STEP: Ensuring resource quota status released the pod usage 12/14/22 08:53:27.032
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:53:29.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4236" for this suite. 12/14/22 08:53:29.108
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:29.135
Dec 14 08:53:29.135: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 08:53:29.136
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:29.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:29.26
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Dec 14 08:53:29.343: INFO: Waiting up to 5m0s for pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3" in namespace "security-context-test-4555" to be "Succeeded or Failed"
Dec 14 08:53:29.368: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.310002ms
Dec 14 08:53:31.394: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051618487s
Dec 14 08:53:33.396: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05371078s
Dec 14 08:53:33.397: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:53:33.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4555" for this suite. 12/14/22 08:53:33.446
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":96,"skipped":1759,"failed":0}
------------------------------
• [4.337 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:29.135
    Dec 14 08:53:29.135: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 08:53:29.136
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:29.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:29.26
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Dec 14 08:53:29.343: INFO: Waiting up to 5m0s for pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3" in namespace "security-context-test-4555" to be "Succeeded or Failed"
    Dec 14 08:53:29.368: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.310002ms
    Dec 14 08:53:31.394: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051618487s
    Dec 14 08:53:33.396: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05371078s
    Dec 14 08:53:33.397: INFO: Pod "busybox-user-65534-869bafd8-4788-40e4-80fb-a233c4a0e0b3" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:53:33.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4555" for this suite. 12/14/22 08:53:33.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:33.473
Dec 14 08:53:33.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:53:33.474
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:33.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:33.604
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 12/14/22 08:53:33.652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:53:33.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5872" for this suite. 12/14/22 08:53:33.707
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":97,"skipped":1774,"failed":0}
------------------------------
• [0.265 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:33.473
    Dec 14 08:53:33.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:53:33.474
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:33.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:33.604
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 12/14/22 08:53:33.652
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:53:33.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5872" for this suite. 12/14/22 08:53:33.707
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:33.739
Dec 14 08:53:33.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 08:53:33.74
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:33.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:33.865
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Dec 14 08:53:33.971: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9089 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 08:53:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9089" for this suite. 12/14/22 08:53:34.049
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":98,"skipped":1777,"failed":0}
------------------------------
• [0.340 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:33.739
    Dec 14 08:53:33.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 08:53:33.74
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:33.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:33.865
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Dec 14 08:53:33.971: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9089 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 08:53:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9089" for this suite. 12/14/22 08:53:34.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:34.079
Dec 14 08:53:34.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:53:34.08
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:34.158
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:34.206
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 12/14/22 08:53:34.254
Dec 14 08:53:34.254: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 create -f -'
Dec 14 08:53:35.445: INFO: stderr: ""
Dec 14 08:53:35.445: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:35.445
Dec 14 08:53:35.445: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:35.610: INFO: stderr: ""
Dec 14 08:53:35.611: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
Dec 14 08:53:35.611: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:35.772: INFO: stderr: ""
Dec 14 08:53:35.772: INFO: stdout: ""
Dec 14 08:53:35.772: INFO: update-demo-nautilus-8n4rc is created but not running
Dec 14 08:53:40.773: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:40.933: INFO: stderr: ""
Dec 14 08:53:40.933: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
Dec 14 08:53:40.933: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:41.079: INFO: stderr: ""
Dec 14 08:53:41.079: INFO: stdout: ""
Dec 14 08:53:41.079: INFO: update-demo-nautilus-8n4rc is created but not running
Dec 14 08:53:46.081: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:46.247: INFO: stderr: ""
Dec 14 08:53:46.247: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
Dec 14 08:53:46.247: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:46.393: INFO: stderr: ""
Dec 14 08:53:46.393: INFO: stdout: "true"
Dec 14 08:53:46.393: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:46.549: INFO: stderr: ""
Dec 14 08:53:46.549: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:46.549: INFO: validating pod update-demo-nautilus-8n4rc
Dec 14 08:53:46.677: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:46.677: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:46.677: INFO: update-demo-nautilus-8n4rc is verified up and running
Dec 14 08:53:46.677: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-b2bbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:46.825: INFO: stderr: ""
Dec 14 08:53:46.825: INFO: stdout: "true"
Dec 14 08:53:46.825: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-b2bbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:46.970: INFO: stderr: ""
Dec 14 08:53:46.970: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:46.970: INFO: validating pod update-demo-nautilus-b2bbq
Dec 14 08:53:47.093: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:47.094: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:47.094: INFO: update-demo-nautilus-b2bbq is verified up and running
STEP: scaling down the replication controller 12/14/22 08:53:47.094
Dec 14 08:53:47.095: INFO: scanned /root for discovery docs: <nil>
Dec 14 08:53:47.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Dec 14 08:53:47.298: INFO: stderr: ""
Dec 14 08:53:47.298: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:47.298
Dec 14 08:53:47.298: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:47.453: INFO: stderr: ""
Dec 14 08:53:47.453: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
STEP: Replicas for name=update-demo: expected=1 actual=2 12/14/22 08:53:47.453
Dec 14 08:53:52.457: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:52.622: INFO: stderr: ""
Dec 14 08:53:52.622: INFO: stdout: "update-demo-nautilus-8n4rc "
Dec 14 08:53:52.622: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:52.780: INFO: stderr: ""
Dec 14 08:53:52.784: INFO: stdout: "true"
Dec 14 08:53:52.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:52.941: INFO: stderr: ""
Dec 14 08:53:52.941: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:52.941: INFO: validating pod update-demo-nautilus-8n4rc
Dec 14 08:53:52.970: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:52.970: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:52.970: INFO: update-demo-nautilus-8n4rc is verified up and running
STEP: scaling up the replication controller 12/14/22 08:53:52.97
Dec 14 08:53:52.973: INFO: scanned /root for discovery docs: <nil>
Dec 14 08:53:52.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Dec 14 08:53:53.186: INFO: stderr: ""
Dec 14 08:53:53.186: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:53.186
Dec 14 08:53:53.186: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:53.340: INFO: stderr: ""
Dec 14 08:53:53.340: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-gsnzv "
Dec 14 08:53:53.340: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:53.487: INFO: stderr: ""
Dec 14 08:53:53.487: INFO: stdout: "true"
Dec 14 08:53:53.487: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:53.646: INFO: stderr: ""
Dec 14 08:53:53.646: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:53.646: INFO: validating pod update-demo-nautilus-8n4rc
Dec 14 08:53:53.675: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:53.675: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:53.676: INFO: update-demo-nautilus-8n4rc is verified up and running
Dec 14 08:53:53.676: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:53.821: INFO: stderr: ""
Dec 14 08:53:53.821: INFO: stdout: ""
Dec 14 08:53:53.821: INFO: update-demo-nautilus-gsnzv is created but not running
Dec 14 08:53:58.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 08:53:58.979: INFO: stderr: ""
Dec 14 08:53:58.979: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-gsnzv "
Dec 14 08:53:58.979: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:59.137: INFO: stderr: ""
Dec 14 08:53:59.137: INFO: stdout: "true"
Dec 14 08:53:59.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:59.291: INFO: stderr: ""
Dec 14 08:53:59.291: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:59.291: INFO: validating pod update-demo-nautilus-8n4rc
Dec 14 08:53:59.319: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:59.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:59.319: INFO: update-demo-nautilus-8n4rc is verified up and running
Dec 14 08:53:59.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 08:53:59.469: INFO: stderr: ""
Dec 14 08:53:59.469: INFO: stdout: "true"
Dec 14 08:53:59.469: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 08:53:59.615: INFO: stderr: ""
Dec 14 08:53:59.615: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 08:53:59.615: INFO: validating pod update-demo-nautilus-gsnzv
Dec 14 08:53:59.749: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 08:53:59.749: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 08:53:59.749: INFO: update-demo-nautilus-gsnzv is verified up and running
STEP: using delete to clean up resources 12/14/22 08:53:59.749
Dec 14 08:53:59.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 delete --grace-period=0 --force -f -'
Dec 14 08:53:59.918: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 08:53:59.919: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 14 08:53:59.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get rc,svc -l name=update-demo --no-headers'
Dec 14 08:54:00.088: INFO: stderr: "No resources found in kubectl-1582 namespace.\n"
Dec 14 08:54:00.088: INFO: stdout: ""
Dec 14 08:54:00.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 08:54:00.239: INFO: stderr: ""
Dec 14 08:54:00.239: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:54:00.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1582" for this suite. 12/14/22 08:54:00.289
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":99,"skipped":1782,"failed":0}
------------------------------
• [26.236 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:34.079
    Dec 14 08:53:34.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:53:34.08
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:34.158
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:34.206
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 12/14/22 08:53:34.254
    Dec 14 08:53:34.254: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 create -f -'
    Dec 14 08:53:35.445: INFO: stderr: ""
    Dec 14 08:53:35.445: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:35.445
    Dec 14 08:53:35.445: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:35.610: INFO: stderr: ""
    Dec 14 08:53:35.611: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
    Dec 14 08:53:35.611: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:35.772: INFO: stderr: ""
    Dec 14 08:53:35.772: INFO: stdout: ""
    Dec 14 08:53:35.772: INFO: update-demo-nautilus-8n4rc is created but not running
    Dec 14 08:53:40.773: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:40.933: INFO: stderr: ""
    Dec 14 08:53:40.933: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
    Dec 14 08:53:40.933: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:41.079: INFO: stderr: ""
    Dec 14 08:53:41.079: INFO: stdout: ""
    Dec 14 08:53:41.079: INFO: update-demo-nautilus-8n4rc is created but not running
    Dec 14 08:53:46.081: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:46.247: INFO: stderr: ""
    Dec 14 08:53:46.247: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
    Dec 14 08:53:46.247: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:46.393: INFO: stderr: ""
    Dec 14 08:53:46.393: INFO: stdout: "true"
    Dec 14 08:53:46.393: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:46.549: INFO: stderr: ""
    Dec 14 08:53:46.549: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:46.549: INFO: validating pod update-demo-nautilus-8n4rc
    Dec 14 08:53:46.677: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:46.677: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:46.677: INFO: update-demo-nautilus-8n4rc is verified up and running
    Dec 14 08:53:46.677: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-b2bbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:46.825: INFO: stderr: ""
    Dec 14 08:53:46.825: INFO: stdout: "true"
    Dec 14 08:53:46.825: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-b2bbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:46.970: INFO: stderr: ""
    Dec 14 08:53:46.970: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:46.970: INFO: validating pod update-demo-nautilus-b2bbq
    Dec 14 08:53:47.093: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:47.094: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:47.094: INFO: update-demo-nautilus-b2bbq is verified up and running
    STEP: scaling down the replication controller 12/14/22 08:53:47.094
    Dec 14 08:53:47.095: INFO: scanned /root for discovery docs: <nil>
    Dec 14 08:53:47.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Dec 14 08:53:47.298: INFO: stderr: ""
    Dec 14 08:53:47.298: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:47.298
    Dec 14 08:53:47.298: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:47.453: INFO: stderr: ""
    Dec 14 08:53:47.453: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-b2bbq "
    STEP: Replicas for name=update-demo: expected=1 actual=2 12/14/22 08:53:47.453
    Dec 14 08:53:52.457: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:52.622: INFO: stderr: ""
    Dec 14 08:53:52.622: INFO: stdout: "update-demo-nautilus-8n4rc "
    Dec 14 08:53:52.622: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:52.780: INFO: stderr: ""
    Dec 14 08:53:52.784: INFO: stdout: "true"
    Dec 14 08:53:52.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:52.941: INFO: stderr: ""
    Dec 14 08:53:52.941: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:52.941: INFO: validating pod update-demo-nautilus-8n4rc
    Dec 14 08:53:52.970: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:52.970: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:52.970: INFO: update-demo-nautilus-8n4rc is verified up and running
    STEP: scaling up the replication controller 12/14/22 08:53:52.97
    Dec 14 08:53:52.973: INFO: scanned /root for discovery docs: <nil>
    Dec 14 08:53:52.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Dec 14 08:53:53.186: INFO: stderr: ""
    Dec 14 08:53:53.186: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 08:53:53.186
    Dec 14 08:53:53.186: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:53.340: INFO: stderr: ""
    Dec 14 08:53:53.340: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-gsnzv "
    Dec 14 08:53:53.340: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:53.487: INFO: stderr: ""
    Dec 14 08:53:53.487: INFO: stdout: "true"
    Dec 14 08:53:53.487: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:53.646: INFO: stderr: ""
    Dec 14 08:53:53.646: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:53.646: INFO: validating pod update-demo-nautilus-8n4rc
    Dec 14 08:53:53.675: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:53.675: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:53.676: INFO: update-demo-nautilus-8n4rc is verified up and running
    Dec 14 08:53:53.676: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:53.821: INFO: stderr: ""
    Dec 14 08:53:53.821: INFO: stdout: ""
    Dec 14 08:53:53.821: INFO: update-demo-nautilus-gsnzv is created but not running
    Dec 14 08:53:58.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 08:53:58.979: INFO: stderr: ""
    Dec 14 08:53:58.979: INFO: stdout: "update-demo-nautilus-8n4rc update-demo-nautilus-gsnzv "
    Dec 14 08:53:58.979: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:59.137: INFO: stderr: ""
    Dec 14 08:53:59.137: INFO: stdout: "true"
    Dec 14 08:53:59.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-8n4rc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:59.291: INFO: stderr: ""
    Dec 14 08:53:59.291: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:59.291: INFO: validating pod update-demo-nautilus-8n4rc
    Dec 14 08:53:59.319: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:59.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:59.319: INFO: update-demo-nautilus-8n4rc is verified up and running
    Dec 14 08:53:59.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 08:53:59.469: INFO: stderr: ""
    Dec 14 08:53:59.469: INFO: stdout: "true"
    Dec 14 08:53:59.469: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods update-demo-nautilus-gsnzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 08:53:59.615: INFO: stderr: ""
    Dec 14 08:53:59.615: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 08:53:59.615: INFO: validating pod update-demo-nautilus-gsnzv
    Dec 14 08:53:59.749: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 08:53:59.749: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 08:53:59.749: INFO: update-demo-nautilus-gsnzv is verified up and running
    STEP: using delete to clean up resources 12/14/22 08:53:59.749
    Dec 14 08:53:59.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 delete --grace-period=0 --force -f -'
    Dec 14 08:53:59.918: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 08:53:59.919: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec 14 08:53:59.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get rc,svc -l name=update-demo --no-headers'
    Dec 14 08:54:00.088: INFO: stderr: "No resources found in kubectl-1582 namespace.\n"
    Dec 14 08:54:00.088: INFO: stdout: ""
    Dec 14 08:54:00.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1582 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 08:54:00.239: INFO: stderr: ""
    Dec 14 08:54:00.239: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:54:00.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1582" for this suite. 12/14/22 08:54:00.289
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:00.316
Dec 14 08:54:00.316: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:54:00.317
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:00.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:00.441
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Dec 14 08:54:00.573: INFO: Waiting up to 5m0s for pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97" in namespace "emptydir-wrapper-1419" to be "running and ready"
Dec 14 08:54:00.598: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97": Phase="Pending", Reason="", readiness=false. Elapsed: 25.364875ms
Dec 14 08:54:00.598: INFO: The phase of Pod pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:54:02.624: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97": Phase="Running", Reason="", readiness=true. Elapsed: 2.050937661s
Dec 14 08:54:02.624: INFO: The phase of Pod pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97 is Running (Ready = true)
Dec 14 08:54:02.624: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97" satisfied condition "running and ready"
STEP: Cleaning up the secret 12/14/22 08:54:02.653
STEP: Cleaning up the configmap 12/14/22 08:54:02.681
STEP: Cleaning up the pod 12/14/22 08:54:02.707
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec 14 08:54:02.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1419" for this suite. 12/14/22 08:54:02.793
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":100,"skipped":1784,"failed":0}
------------------------------
• [2.504 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:00.316
    Dec 14 08:54:00.316: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:54:00.317
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:00.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:00.441
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Dec 14 08:54:00.573: INFO: Waiting up to 5m0s for pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97" in namespace "emptydir-wrapper-1419" to be "running and ready"
    Dec 14 08:54:00.598: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97": Phase="Pending", Reason="", readiness=false. Elapsed: 25.364875ms
    Dec 14 08:54:00.598: INFO: The phase of Pod pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:54:02.624: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97": Phase="Running", Reason="", readiness=true. Elapsed: 2.050937661s
    Dec 14 08:54:02.624: INFO: The phase of Pod pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97 is Running (Ready = true)
    Dec 14 08:54:02.624: INFO: Pod "pod-secrets-a45bc7ef-0efc-4e36-a600-ccc685226f97" satisfied condition "running and ready"
    STEP: Cleaning up the secret 12/14/22 08:54:02.653
    STEP: Cleaning up the configmap 12/14/22 08:54:02.681
    STEP: Cleaning up the pod 12/14/22 08:54:02.707
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:54:02.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-1419" for this suite. 12/14/22 08:54:02.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:02.82
Dec 14 08:54:02.820: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:54:02.821
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:02.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:02.946
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-efe5a349-d357-4bdd-b83b-f69ef0692f22 12/14/22 08:54:02.995
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:54:03.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2024" for this suite. 12/14/22 08:54:03.047
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":101,"skipped":1789,"failed":0}
------------------------------
• [0.261 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:02.82
    Dec 14 08:54:02.820: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:54:02.821
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:02.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:02.946
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-efe5a349-d357-4bdd-b83b-f69ef0692f22 12/14/22 08:54:02.995
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:54:03.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2024" for this suite. 12/14/22 08:54:03.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:03.083
Dec 14 08:54:03.083: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:54:03.084
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:03.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:03.209
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:54:03.269
Dec 14 08:54:03.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52" in namespace "projected-763" to be "Succeeded or Failed"
Dec 14 08:54:03.334: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Pending", Reason="", readiness=false. Elapsed: 29.993936ms
Dec 14 08:54:05.361: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057433762s
Dec 14 08:54:07.361: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05756907s
STEP: Saw pod success 12/14/22 08:54:07.361
Dec 14 08:54:07.362: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52" satisfied condition "Succeeded or Failed"
Dec 14 08:54:07.387: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 container client-container: <nil>
STEP: delete the pod 12/14/22 08:54:07.538
Dec 14 08:54:07.572: INFO: Waiting for pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 to disappear
Dec 14 08:54:07.601: INFO: Pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:54:07.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-763" for this suite. 12/14/22 08:54:07.651
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":102,"skipped":1816,"failed":0}
------------------------------
• [4.595 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:03.083
    Dec 14 08:54:03.083: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:54:03.084
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:03.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:03.209
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:54:03.269
    Dec 14 08:54:03.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52" in namespace "projected-763" to be "Succeeded or Failed"
    Dec 14 08:54:03.334: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Pending", Reason="", readiness=false. Elapsed: 29.993936ms
    Dec 14 08:54:05.361: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057433762s
    Dec 14 08:54:07.361: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05756907s
    STEP: Saw pod success 12/14/22 08:54:07.361
    Dec 14 08:54:07.362: INFO: Pod "downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52" satisfied condition "Succeeded or Failed"
    Dec 14 08:54:07.387: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:54:07.538
    Dec 14 08:54:07.572: INFO: Waiting for pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 to disappear
    Dec 14 08:54:07.601: INFO: Pod downwardapi-volume-99d3c685-43ed-453d-aec7-9958cb897f52 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:54:07.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-763" for this suite. 12/14/22 08:54:07.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:07.679
Dec 14 08:54:07.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 08:54:07.68
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:07.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:07.807
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 12/14/22 08:54:07.854
Dec 14 08:54:07.855: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:54:13.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9839" for this suite. 12/14/22 08:54:13.089
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":103,"skipped":1824,"failed":0}
------------------------------
• [5.439 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:07.679
    Dec 14 08:54:07.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 08:54:07.68
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:07.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:07.807
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 12/14/22 08:54:07.854
    Dec 14 08:54:07.855: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:54:13.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9839" for this suite. 12/14/22 08:54:13.089
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:13.119
Dec 14 08:54:13.119: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:54:13.12
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:13.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:13.245
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 12/14/22 08:54:13.293
Dec 14 08:54:13.326: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f" in namespace "emptydir-3206" to be "running"
Dec 14 08:54:13.351: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.128358ms
Dec 14 08:54:15.382: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f": Phase="Running", Reason="", readiness=false. Elapsed: 2.055557025s
Dec 14 08:54:15.382: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f" satisfied condition "running"
STEP: Reading file content from the nginx-container 12/14/22 08:54:15.382
Dec 14 08:54:15.382: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3206 PodName:pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:54:15.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:54:15.382: INFO: ExecWithOptions: Clientset creation
Dec 14 08:54:15.382: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/emptydir-3206/pods/pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Dec 14 08:54:15.827: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:54:15.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3206" for this suite. 12/14/22 08:54:15.876
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":104,"skipped":1859,"failed":0}
------------------------------
• [2.784 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:13.119
    Dec 14 08:54:13.119: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:54:13.12
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:13.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:13.245
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 12/14/22 08:54:13.293
    Dec 14 08:54:13.326: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f" in namespace "emptydir-3206" to be "running"
    Dec 14 08:54:13.351: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.128358ms
    Dec 14 08:54:15.382: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f": Phase="Running", Reason="", readiness=false. Elapsed: 2.055557025s
    Dec 14 08:54:15.382: INFO: Pod "pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f" satisfied condition "running"
    STEP: Reading file content from the nginx-container 12/14/22 08:54:15.382
    Dec 14 08:54:15.382: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3206 PodName:pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:54:15.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:54:15.382: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:54:15.382: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/emptydir-3206/pods/pod-sharedvolume-e4618d0f-8c1a-49c0-b423-362666c95f0f/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Dec 14 08:54:15.827: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:54:15.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3206" for this suite. 12/14/22 08:54:15.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:15.904
Dec 14 08:54:15.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context 12/14/22 08:54:15.905
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:15.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:16.033
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 08:54:16.081
Dec 14 08:54:16.116: INFO: Waiting up to 5m0s for pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91" in namespace "security-context-3635" to be "Succeeded or Failed"
Dec 14 08:54:16.141: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Pending", Reason="", readiness=false. Elapsed: 25.357397ms
Dec 14 08:54:18.168: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Running", Reason="", readiness=false. Elapsed: 2.052481723s
Dec 14 08:54:20.167: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051245965s
STEP: Saw pod success 12/14/22 08:54:20.167
Dec 14 08:54:20.167: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91" satisfied condition "Succeeded or Failed"
Dec 14 08:54:20.193: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 container test-container: <nil>
STEP: delete the pod 12/14/22 08:54:20.265
Dec 14 08:54:20.298: INFO: Waiting for pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 to disappear
Dec 14 08:54:20.323: INFO: Pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:54:20.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3635" for this suite. 12/14/22 08:54:20.373
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":105,"skipped":1868,"failed":0}
------------------------------
• [4.496 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:15.904
    Dec 14 08:54:15.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context 12/14/22 08:54:15.905
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:15.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:16.033
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 08:54:16.081
    Dec 14 08:54:16.116: INFO: Waiting up to 5m0s for pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91" in namespace "security-context-3635" to be "Succeeded or Failed"
    Dec 14 08:54:16.141: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Pending", Reason="", readiness=false. Elapsed: 25.357397ms
    Dec 14 08:54:18.168: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Running", Reason="", readiness=false. Elapsed: 2.052481723s
    Dec 14 08:54:20.167: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051245965s
    STEP: Saw pod success 12/14/22 08:54:20.167
    Dec 14 08:54:20.167: INFO: Pod "security-context-894d3a34-0989-4717-ab16-d129b8424d91" satisfied condition "Succeeded or Failed"
    Dec 14 08:54:20.193: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 container test-container: <nil>
    STEP: delete the pod 12/14/22 08:54:20.265
    Dec 14 08:54:20.298: INFO: Waiting for pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 to disappear
    Dec 14 08:54:20.323: INFO: Pod security-context-894d3a34-0989-4717-ab16-d129b8424d91 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:54:20.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3635" for this suite. 12/14/22 08:54:20.373
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:20.401
Dec 14 08:54:20.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:54:20.402
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:20.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:20.534
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 12/14/22 08:54:20.583
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-690;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-690;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +notcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_tcp@PTR;sleep 1; done
 12/14/22 08:54:20.652
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-690;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-690;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +notcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_tcp@PTR;sleep 1; done
 12/14/22 08:54:20.652
STEP: creating a pod to probe DNS 12/14/22 08:54:20.652
STEP: submitting the pod to kubernetes 12/14/22 08:54:20.653
Dec 14 08:54:20.688: INFO: Waiting up to 15m0s for pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7" in namespace "dns-690" to be "running"
Dec 14 08:54:20.714: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.34592ms
Dec 14 08:54:22.741: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.052321662s
Dec 14 08:54:22.741: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:54:22.741
STEP: looking for the results for each expected name from probers 12/14/22 08:54:22.769
Dec 14 08:54:22.898: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:22.944: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:22.974: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.003: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.033: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.063: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.269: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.298: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.327: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.356: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.385: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.415: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:23.599: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:28.633: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:28.680: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:28.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:28.739: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:28.769: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:28.800: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.007: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.037: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.068: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.097: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.128: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.158: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:29.336: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:33.632: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:33.683: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:33.713: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:33.743: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:33.829: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:33.880: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.172: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.203: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.251: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.281: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.310: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.373: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:34.552: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:38.634: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:38.683: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:38.713: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:38.742: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:38.771: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:38.800: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.008: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.041: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.071: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.107: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.137: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.207: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:39.385: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:43.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:43.674: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:43.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:43.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:43.764: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:43.795: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.041: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.070: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.100: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.130: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.159: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.188: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:44.366: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:48.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:48.676: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:48.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:48.751: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:48.781: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:48.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.041: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.070: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.103: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.132: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.162: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.191: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:49.416: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

Dec 14 08:54:53.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:53.675: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:53.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:53.734: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:53.770: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:53.799: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.007: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.063: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.093: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.122: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.153: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
Dec 14 08:54:54.357: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc]

Dec 14 08:54:59.349: INFO: DNS probes using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 succeeded

STEP: deleting the pod 12/14/22 08:54:59.349
STEP: deleting the test service 12/14/22 08:54:59.39
STEP: deleting the test headless service 12/14/22 08:54:59.432
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:54:59.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-690" for this suite. 12/14/22 08:54:59.517
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":106,"skipped":1872,"failed":0}
------------------------------
• [39.143 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:20.401
    Dec 14 08:54:20.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:54:20.402
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:20.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:20.534
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 12/14/22 08:54:20.583
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-690;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-690;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +notcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_tcp@PTR;sleep 1; done
     12/14/22 08:54:20.652
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-690;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-690;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-690.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-690.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-690.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-690.svc;check="$$(dig +notcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.192.107.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.107.192.11_tcp@PTR;sleep 1; done
     12/14/22 08:54:20.652
    STEP: creating a pod to probe DNS 12/14/22 08:54:20.652
    STEP: submitting the pod to kubernetes 12/14/22 08:54:20.653
    Dec 14 08:54:20.688: INFO: Waiting up to 15m0s for pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7" in namespace "dns-690" to be "running"
    Dec 14 08:54:20.714: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.34592ms
    Dec 14 08:54:22.741: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.052321662s
    Dec 14 08:54:22.741: INFO: Pod "dns-test-322caad8-8433-4b86-9968-cfb83a4939b7" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:54:22.741
    STEP: looking for the results for each expected name from probers 12/14/22 08:54:22.769
    Dec 14 08:54:22.898: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:22.944: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:22.974: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.003: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.033: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.063: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.269: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.298: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.327: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.356: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.385: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.415: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:23.599: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:28.633: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:28.680: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:28.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:28.739: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:28.769: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:28.800: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.007: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.037: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.068: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.097: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.128: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.158: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:29.336: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:33.632: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:33.683: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:33.713: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:33.743: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:33.829: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:33.880: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.172: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.203: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.251: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.281: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.310: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.373: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:34.552: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:38.634: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:38.683: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:38.713: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:38.742: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:38.771: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:38.800: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.008: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.041: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.071: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.107: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.137: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.207: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:39.385: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:43.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:43.674: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:43.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:43.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:43.764: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:43.795: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.041: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.070: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.100: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.130: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.159: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.188: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:44.366: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:48.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:48.676: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:48.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:48.751: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:48.781: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:48.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.041: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.070: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.103: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.132: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.162: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.191: INFO: Unable to read jessie_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:49.416: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc jessie_tcp@dns-test-service.dns-690.svc]

    Dec 14 08:54:53.631: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:53.675: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:53.705: INFO: Unable to read wheezy_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:53.734: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:53.770: INFO: Unable to read wheezy_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:53.799: INFO: Unable to read wheezy_tcp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.007: INFO: Unable to read jessie_udp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.063: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.093: INFO: Unable to read jessie_udp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.122: INFO: Unable to read jessie_tcp@dns-test-service.dns-690 from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.153: INFO: Unable to read jessie_udp@dns-test-service.dns-690.svc from pod dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7: the server could not find the requested resource (get pods dns-test-322caad8-8433-4b86-9968-cfb83a4939b7)
    Dec 14 08:54:54.357: INFO: Lookups using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-690 wheezy_tcp@dns-test-service.dns-690 wheezy_udp@dns-test-service.dns-690.svc wheezy_tcp@dns-test-service.dns-690.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-690 jessie_tcp@dns-test-service.dns-690 jessie_udp@dns-test-service.dns-690.svc]

    Dec 14 08:54:59.349: INFO: DNS probes using dns-690/dns-test-322caad8-8433-4b86-9968-cfb83a4939b7 succeeded

    STEP: deleting the pod 12/14/22 08:54:59.349
    STEP: deleting the test service 12/14/22 08:54:59.39
    STEP: deleting the test headless service 12/14/22 08:54:59.432
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:54:59.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-690" for this suite. 12/14/22 08:54:59.517
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:54:59.545
Dec 14 08:54:59.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 08:54:59.547
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:59.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:59.672
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 12/14/22 08:54:59.72
Dec 14 08:54:59.720: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:55:04.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2049" for this suite. 12/14/22 08:55:04.215
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":107,"skipped":1893,"failed":0}
------------------------------
• [4.697 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:54:59.545
    Dec 14 08:54:59.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 08:54:59.547
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:54:59.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:54:59.672
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 12/14/22 08:54:59.72
    Dec 14 08:54:59.720: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:55:04.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2049" for this suite. 12/14/22 08:55:04.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:04.243
Dec 14 08:55:04.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:55:04.244
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:04.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:04.371
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 12/14/22 08:55:04.419
Dec 14 08:55:04.419: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 14 08:55:04.603: INFO: stderr: ""
Dec 14 08:55:04.603: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 12/14/22 08:55:04.603
Dec 14 08:55:04.603: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 14 08:55:04.603: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8851" to be "running and ready, or succeeded"
Dec 14 08:55:04.628: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 25.569535ms
Dec 14 08:55:04.628: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'shoot--it--tm0ct-io0-worker-1-6f755-hwmlx' to be 'Running' but was 'Pending'
Dec 14 08:55:06.658: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.054943483s
Dec 14 08:55:06.658: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 14 08:55:06.658: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 12/14/22 08:55:06.658
Dec 14 08:55:06.658: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator'
Dec 14 08:55:06.857: INFO: stderr: ""
Dec 14 08:55:06.857: INFO: stdout: "I1214 08:55:05.354029       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/tfvj 351\nI1214 08:55:05.554144       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/xdt 385\nI1214 08:55:05.754422       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/p95 522\nI1214 08:55:05.954736       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/4p7 323\nI1214 08:55:06.155527       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/6djg 376\nI1214 08:55:06.355050       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/rbw 280\nI1214 08:55:06.554393       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/l9n 570\nI1214 08:55:06.754724       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/mgn 235\n"
STEP: limiting log lines 12/14/22 08:55:06.857
Dec 14 08:55:06.857: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --tail=1'
Dec 14 08:55:07.072: INFO: stderr: ""
Dec 14 08:55:07.072: INFO: stdout: "I1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\n"
Dec 14 08:55:07.072: INFO: got output "I1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\n"
STEP: limiting log bytes 12/14/22 08:55:07.072
Dec 14 08:55:07.072: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --limit-bytes=1'
Dec 14 08:55:07.260: INFO: stderr: ""
Dec 14 08:55:07.260: INFO: stdout: "I"
Dec 14 08:55:07.260: INFO: got output "I"
STEP: exposing timestamps 12/14/22 08:55:07.26
Dec 14 08:55:07.260: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --tail=1 --timestamps'
Dec 14 08:55:07.455: INFO: stderr: ""
Dec 14 08:55:07.455: INFO: stdout: "2022-12-14T08:55:07.354802645Z I1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\n"
Dec 14 08:55:07.455: INFO: got output "2022-12-14T08:55:07.354802645Z I1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\n"
STEP: restricting to a time range 12/14/22 08:55:07.455
Dec 14 08:55:09.956: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --since=1s'
Dec 14 08:55:10.153: INFO: stderr: ""
Dec 14 08:55:10.153: INFO: stdout: "I1214 08:55:09.155164       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kh89 302\nI1214 08:55:09.354545       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/66v 262\nI1214 08:55:09.554917       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/jxt 216\nI1214 08:55:09.754369       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/8996 391\nI1214 08:55:09.954806       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/jqs 519\n"
Dec 14 08:55:10.153: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --since=24h'
Dec 14 08:55:10.336: INFO: stderr: ""
Dec 14 08:55:10.336: INFO: stdout: "I1214 08:55:05.354029       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/tfvj 351\nI1214 08:55:05.554144       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/xdt 385\nI1214 08:55:05.754422       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/p95 522\nI1214 08:55:05.954736       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/4p7 323\nI1214 08:55:06.155527       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/6djg 376\nI1214 08:55:06.355050       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/rbw 280\nI1214 08:55:06.554393       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/l9n 570\nI1214 08:55:06.754724       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/mgn 235\nI1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\nI1214 08:55:07.154375       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/xn5 496\nI1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\nI1214 08:55:07.555097       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/kcw 329\nI1214 08:55:07.754466       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/pq7r 399\nI1214 08:55:07.954839       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/pwc4 432\nI1214 08:55:08.154156       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/qfqp 440\nI1214 08:55:08.354553       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/x8q 330\nI1214 08:55:08.555013       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/stxk 582\nI1214 08:55:08.754316       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/rz8t 264\nI1214 08:55:08.954710       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/g4w4 245\nI1214 08:55:09.155164       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kh89 302\nI1214 08:55:09.354545       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/66v 262\nI1214 08:55:09.554917       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/jxt 216\nI1214 08:55:09.754369       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/8996 391\nI1214 08:55:09.954806       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/jqs 519\nI1214 08:55:10.154057       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2fsk 451\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Dec 14 08:55:10.336: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 delete pod logs-generator'
Dec 14 08:55:11.218: INFO: stderr: ""
Dec 14 08:55:11.218: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:55:11.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8851" for this suite. 12/14/22 08:55:11.27
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":108,"skipped":1899,"failed":0}
------------------------------
• [7.055 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:04.243
    Dec 14 08:55:04.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:55:04.244
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:04.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:04.371
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 12/14/22 08:55:04.419
    Dec 14 08:55:04.419: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Dec 14 08:55:04.603: INFO: stderr: ""
    Dec 14 08:55:04.603: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 12/14/22 08:55:04.603
    Dec 14 08:55:04.603: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Dec 14 08:55:04.603: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8851" to be "running and ready, or succeeded"
    Dec 14 08:55:04.628: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 25.569535ms
    Dec 14 08:55:04.628: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'shoot--it--tm0ct-io0-worker-1-6f755-hwmlx' to be 'Running' but was 'Pending'
    Dec 14 08:55:06.658: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.054943483s
    Dec 14 08:55:06.658: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Dec 14 08:55:06.658: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 12/14/22 08:55:06.658
    Dec 14 08:55:06.658: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator'
    Dec 14 08:55:06.857: INFO: stderr: ""
    Dec 14 08:55:06.857: INFO: stdout: "I1214 08:55:05.354029       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/tfvj 351\nI1214 08:55:05.554144       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/xdt 385\nI1214 08:55:05.754422       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/p95 522\nI1214 08:55:05.954736       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/4p7 323\nI1214 08:55:06.155527       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/6djg 376\nI1214 08:55:06.355050       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/rbw 280\nI1214 08:55:06.554393       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/l9n 570\nI1214 08:55:06.754724       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/mgn 235\n"
    STEP: limiting log lines 12/14/22 08:55:06.857
    Dec 14 08:55:06.857: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --tail=1'
    Dec 14 08:55:07.072: INFO: stderr: ""
    Dec 14 08:55:07.072: INFO: stdout: "I1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\n"
    Dec 14 08:55:07.072: INFO: got output "I1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\n"
    STEP: limiting log bytes 12/14/22 08:55:07.072
    Dec 14 08:55:07.072: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --limit-bytes=1'
    Dec 14 08:55:07.260: INFO: stderr: ""
    Dec 14 08:55:07.260: INFO: stdout: "I"
    Dec 14 08:55:07.260: INFO: got output "I"
    STEP: exposing timestamps 12/14/22 08:55:07.26
    Dec 14 08:55:07.260: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --tail=1 --timestamps'
    Dec 14 08:55:07.455: INFO: stderr: ""
    Dec 14 08:55:07.455: INFO: stdout: "2022-12-14T08:55:07.354802645Z I1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\n"
    Dec 14 08:55:07.455: INFO: got output "2022-12-14T08:55:07.354802645Z I1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\n"
    STEP: restricting to a time range 12/14/22 08:55:07.455
    Dec 14 08:55:09.956: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --since=1s'
    Dec 14 08:55:10.153: INFO: stderr: ""
    Dec 14 08:55:10.153: INFO: stdout: "I1214 08:55:09.155164       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kh89 302\nI1214 08:55:09.354545       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/66v 262\nI1214 08:55:09.554917       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/jxt 216\nI1214 08:55:09.754369       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/8996 391\nI1214 08:55:09.954806       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/jqs 519\n"
    Dec 14 08:55:10.153: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 logs logs-generator logs-generator --since=24h'
    Dec 14 08:55:10.336: INFO: stderr: ""
    Dec 14 08:55:10.336: INFO: stdout: "I1214 08:55:05.354029       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/tfvj 351\nI1214 08:55:05.554144       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/xdt 385\nI1214 08:55:05.754422       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/p95 522\nI1214 08:55:05.954736       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/4p7 323\nI1214 08:55:06.155527       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/6djg 376\nI1214 08:55:06.355050       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/rbw 280\nI1214 08:55:06.554393       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/l9n 570\nI1214 08:55:06.754724       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/mgn 235\nI1214 08:55:06.955035       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/n2z6 550\nI1214 08:55:07.154375       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/xn5 496\nI1214 08:55:07.354715       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/ddv 392\nI1214 08:55:07.555097       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/kcw 329\nI1214 08:55:07.754466       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/pq7r 399\nI1214 08:55:07.954839       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/pwc4 432\nI1214 08:55:08.154156       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/qfqp 440\nI1214 08:55:08.354553       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/x8q 330\nI1214 08:55:08.555013       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/stxk 582\nI1214 08:55:08.754316       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/rz8t 264\nI1214 08:55:08.954710       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/g4w4 245\nI1214 08:55:09.155164       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kh89 302\nI1214 08:55:09.354545       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/66v 262\nI1214 08:55:09.554917       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/jxt 216\nI1214 08:55:09.754369       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/8996 391\nI1214 08:55:09.954806       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/jqs 519\nI1214 08:55:10.154057       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2fsk 451\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Dec 14 08:55:10.336: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8851 delete pod logs-generator'
    Dec 14 08:55:11.218: INFO: stderr: ""
    Dec 14 08:55:11.218: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:55:11.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8851" for this suite. 12/14/22 08:55:11.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:11.299
Dec 14 08:55:11.299: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 08:55:11.3
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:11.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:11.424
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Dec 14 08:55:11.579: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:55:11.607
Dec 14 08:55:11.662: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:55:11.662: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:55:12.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:55:12.739: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:55:13.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 08:55:13.739: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image. 12/14/22 08:55:13.849
STEP: Check that daemon pods images are updated. 12/14/22 08:55:13.909
Dec 14 08:55:13.937: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 08:55:14.994: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 08:55:15.995: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 08:55:16.995: INFO: Pod daemon-set-5rkr9 is not available
Dec 14 08:55:16.995: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 08:55:18.996: INFO: Pod daemon-set-whjtc is not available
STEP: Check that daemon pods are still running on every node of the cluster. 12/14/22 08:55:19.047
Dec 14 08:55:19.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 08:55:19.099: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 08:55:19.226
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8282, will wait for the garbage collector to delete the pods 12/14/22 08:55:19.226
Dec 14 08:55:19.331: INFO: Deleting DaemonSet.extensions daemon-set took: 26.846245ms
Dec 14 08:55:19.432: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.047289ms
Dec 14 08:55:22.158: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:55:22.158: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 08:55:22.183: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24520"},"items":null}

Dec 14 08:55:22.209: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24520"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:55:22.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8282" for this suite. 12/14/22 08:55:22.337
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":109,"skipped":1930,"failed":0}
------------------------------
• [11.064 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:11.299
    Dec 14 08:55:11.299: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 08:55:11.3
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:11.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:11.424
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Dec 14 08:55:11.579: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:55:11.607
    Dec 14 08:55:11.662: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:55:11.662: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:55:12.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:55:12.739: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:55:13.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 08:55:13.739: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Update daemon pods image. 12/14/22 08:55:13.849
    STEP: Check that daemon pods images are updated. 12/14/22 08:55:13.909
    Dec 14 08:55:13.937: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 08:55:14.994: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 08:55:15.995: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 08:55:16.995: INFO: Pod daemon-set-5rkr9 is not available
    Dec 14 08:55:16.995: INFO: Wrong image for pod: daemon-set-8qmnq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 08:55:18.996: INFO: Pod daemon-set-whjtc is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 12/14/22 08:55:19.047
    Dec 14 08:55:19.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 08:55:19.099: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 08:55:19.226
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8282, will wait for the garbage collector to delete the pods 12/14/22 08:55:19.226
    Dec 14 08:55:19.331: INFO: Deleting DaemonSet.extensions daemon-set took: 26.846245ms
    Dec 14 08:55:19.432: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.047289ms
    Dec 14 08:55:22.158: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:55:22.158: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 08:55:22.183: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24520"},"items":null}

    Dec 14 08:55:22.209: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24520"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:55:22.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8282" for this suite. 12/14/22 08:55:22.337
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:22.366
Dec 14 08:55:22.366: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:55:22.367
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:22.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:22.494
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-9ae9518c-a81e-4daa-b687-87b8c2d6461f 12/14/22 08:55:22.542
STEP: Creating a pod to test consume secrets 12/14/22 08:55:22.568
Dec 14 08:55:22.604: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566" in namespace "projected-7163" to be "Succeeded or Failed"
Dec 14 08:55:22.634: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Pending", Reason="", readiness=false. Elapsed: 29.224902ms
Dec 14 08:55:24.660: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055464846s
Dec 14 08:55:26.662: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058010969s
STEP: Saw pod success 12/14/22 08:55:26.662
Dec 14 08:55:26.662: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566" satisfied condition "Succeeded or Failed"
Dec 14 08:55:26.688: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 08:55:26.721
Dec 14 08:55:26.759: INFO: Waiting for pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 to disappear
Dec 14 08:55:26.784: INFO: Pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 08:55:26.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7163" for this suite. 12/14/22 08:55:26.837
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":110,"skipped":1988,"failed":0}
------------------------------
• [4.498 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:22.366
    Dec 14 08:55:22.366: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:55:22.367
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:22.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:22.494
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-9ae9518c-a81e-4daa-b687-87b8c2d6461f 12/14/22 08:55:22.542
    STEP: Creating a pod to test consume secrets 12/14/22 08:55:22.568
    Dec 14 08:55:22.604: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566" in namespace "projected-7163" to be "Succeeded or Failed"
    Dec 14 08:55:22.634: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Pending", Reason="", readiness=false. Elapsed: 29.224902ms
    Dec 14 08:55:24.660: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055464846s
    Dec 14 08:55:26.662: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058010969s
    STEP: Saw pod success 12/14/22 08:55:26.662
    Dec 14 08:55:26.662: INFO: Pod "pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566" satisfied condition "Succeeded or Failed"
    Dec 14 08:55:26.688: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:55:26.721
    Dec 14 08:55:26.759: INFO: Waiting for pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 to disappear
    Dec 14 08:55:26.784: INFO: Pod pod-projected-secrets-ecc99256-c59b-470a-b7cc-43b8fdc92566 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 08:55:26.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7163" for this suite. 12/14/22 08:55:26.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:26.864
Dec 14 08:55:26.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:55:26.865
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:26.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:26.993
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 12/14/22 08:55:27.042
STEP: Getting a ResourceQuota 12/14/22 08:55:27.068
STEP: Updating a ResourceQuota 12/14/22 08:55:27.093
STEP: Verifying a ResourceQuota was modified 12/14/22 08:55:27.12
STEP: Deleting a ResourceQuota 12/14/22 08:55:27.145
STEP: Verifying the deleted ResourceQuota 12/14/22 08:55:27.173
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:55:27.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8931" for this suite. 12/14/22 08:55:27.226
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":111,"skipped":2003,"failed":0}
------------------------------
• [0.389 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:26.864
    Dec 14 08:55:26.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:55:26.865
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:26.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:26.993
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 12/14/22 08:55:27.042
    STEP: Getting a ResourceQuota 12/14/22 08:55:27.068
    STEP: Updating a ResourceQuota 12/14/22 08:55:27.093
    STEP: Verifying a ResourceQuota was modified 12/14/22 08:55:27.12
    STEP: Deleting a ResourceQuota 12/14/22 08:55:27.145
    STEP: Verifying the deleted ResourceQuota 12/14/22 08:55:27.173
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:55:27.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8931" for this suite. 12/14/22 08:55:27.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:27.254
Dec 14 08:55:27.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:55:27.255
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:27.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:27.38
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:55:27.488
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:55:27.84
STEP: Deploying the webhook pod 12/14/22 08:55:27.869
STEP: Wait for the deployment to be ready 12/14/22 08:55:27.922
Dec 14 08:55:28.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:55:30.058
STEP: Verifying the service has paired with the endpoint 12/14/22 08:55:30.094
Dec 14 08:55:31.094: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 08:55:31.121
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 08:55:31.285
STEP: Creating a dummy validating-webhook-configuration object 12/14/22 08:55:31.473
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/14/22 08:55:31.528
STEP: Creating a dummy mutating-webhook-configuration object 12/14/22 08:55:31.555
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/14/22 08:55:31.654
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:55:31.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6153" for this suite. 12/14/22 08:55:31.786
STEP: Destroying namespace "webhook-6153-markers" for this suite. 12/14/22 08:55:31.817
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":112,"skipped":2017,"failed":0}
------------------------------
• [4.713 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:27.254
    Dec 14 08:55:27.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:55:27.255
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:27.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:27.38
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:55:27.488
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:55:27.84
    STEP: Deploying the webhook pod 12/14/22 08:55:27.869
    STEP: Wait for the deployment to be ready 12/14/22 08:55:27.922
    Dec 14 08:55:28.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 55, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:55:30.058
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:55:30.094
    Dec 14 08:55:31.094: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 08:55:31.121
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 08:55:31.285
    STEP: Creating a dummy validating-webhook-configuration object 12/14/22 08:55:31.473
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/14/22 08:55:31.528
    STEP: Creating a dummy mutating-webhook-configuration object 12/14/22 08:55:31.555
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/14/22 08:55:31.654
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:55:31.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6153" for this suite. 12/14/22 08:55:31.786
    STEP: Destroying namespace "webhook-6153-markers" for this suite. 12/14/22 08:55:31.817
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:31.967
Dec 14 08:55:31.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:55:31.968
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:32.044
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:32.094
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-39e19756-27bf-46a5-9489-2b0cdc76abba 12/14/22 08:55:32.143
STEP: Creating a pod to test consume configMaps 12/14/22 08:55:32.168
Dec 14 08:55:32.202: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3" in namespace "configmap-2444" to be "Succeeded or Failed"
Dec 14 08:55:32.228: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.714255ms
Dec 14 08:55:34.254: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051912942s
Dec 14 08:55:36.259: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056842472s
STEP: Saw pod success 12/14/22 08:55:36.259
Dec 14 08:55:36.260: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3" satisfied condition "Succeeded or Failed"
Dec 14 08:55:36.285: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:55:36.319
Dec 14 08:55:36.357: INFO: Waiting for pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 to disappear
Dec 14 08:55:36.383: INFO: Pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:55:36.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2444" for this suite. 12/14/22 08:55:36.432
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":113,"skipped":2019,"failed":0}
------------------------------
• [4.492 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:31.967
    Dec 14 08:55:31.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:55:31.968
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:32.044
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:32.094
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-39e19756-27bf-46a5-9489-2b0cdc76abba 12/14/22 08:55:32.143
    STEP: Creating a pod to test consume configMaps 12/14/22 08:55:32.168
    Dec 14 08:55:32.202: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3" in namespace "configmap-2444" to be "Succeeded or Failed"
    Dec 14 08:55:32.228: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.714255ms
    Dec 14 08:55:34.254: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051912942s
    Dec 14 08:55:36.259: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056842472s
    STEP: Saw pod success 12/14/22 08:55:36.259
    Dec 14 08:55:36.260: INFO: Pod "pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3" satisfied condition "Succeeded or Failed"
    Dec 14 08:55:36.285: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:55:36.319
    Dec 14 08:55:36.357: INFO: Waiting for pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 to disappear
    Dec 14 08:55:36.383: INFO: Pod pod-configmaps-5d022879-1f5e-4f9c-8662-3886e2ec03f3 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:55:36.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2444" for this suite. 12/14/22 08:55:36.432
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:55:36.461
Dec 14 08:55:36.461: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:55:36.461
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:36.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:36.591
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 12/14/22 08:55:36.639
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:37.986
Dec 14 08:55:38.048: INFO: Pod name wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f: Found 1 pods out of 5
Dec 14 08:55:43.150: INFO: Pod name wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:55:43.15
Dec 14 08:55:43.150: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:43.176: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6": Phase="Running", Reason="", readiness=true. Elapsed: 26.254815ms
Dec 14 08:55:43.176: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6" satisfied condition "running"
Dec 14 08:55:43.176: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:43.203: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n": Phase="Running", Reason="", readiness=true. Elapsed: 27.162713ms
Dec 14 08:55:43.203: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n" satisfied condition "running"
Dec 14 08:55:43.203: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:43.230: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb": Phase="Running", Reason="", readiness=true. Elapsed: 26.791964ms
Dec 14 08:55:43.230: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb" satisfied condition "running"
Dec 14 08:55:43.230: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:43.257: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg": Phase="Running", Reason="", readiness=true. Elapsed: 27.124123ms
Dec 14 08:55:43.257: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg" satisfied condition "running"
Dec 14 08:55:43.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:43.284: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4": Phase="Running", Reason="", readiness=true. Elapsed: 26.68658ms
Dec 14 08:55:43.284: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:43.284
Dec 14 08:55:43.390: INFO: Deleting ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f took: 28.03363ms
Dec 14 08:55:43.490: INFO: Terminating ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f pods took: 100.191248ms
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:44.817
Dec 14 08:55:44.880: INFO: Pod name wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202: Found 1 pods out of 5
Dec 14 08:55:49.978: INFO: Pod name wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:55:49.978
Dec 14 08:55:49.978: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:50.005: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht": Phase="Running", Reason="", readiness=true. Elapsed: 26.690968ms
Dec 14 08:55:50.005: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht" satisfied condition "running"
Dec 14 08:55:50.005: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:50.030: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv": Phase="Running", Reason="", readiness=true. Elapsed: 25.628015ms
Dec 14 08:55:50.030: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv" satisfied condition "running"
Dec 14 08:55:50.030: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:50.057: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn": Phase="Running", Reason="", readiness=true. Elapsed: 26.382326ms
Dec 14 08:55:50.057: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn" satisfied condition "running"
Dec 14 08:55:50.057: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:50.083: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625": Phase="Running", Reason="", readiness=true. Elapsed: 25.733273ms
Dec 14 08:55:50.083: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625" satisfied condition "running"
Dec 14 08:55:50.083: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:50.108: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb": Phase="Running", Reason="", readiness=true. Elapsed: 25.375955ms
Dec 14 08:55:50.108: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:50.108
Dec 14 08:55:50.212: INFO: Deleting ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 took: 27.327836ms
Dec 14 08:55:50.313: INFO: Terminating ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 pods took: 100.686924ms
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:52.241
Dec 14 08:55:52.303: INFO: Pod name wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00: Found 1 pods out of 5
Dec 14 08:55:57.414: INFO: Pod name wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:55:57.414
Dec 14 08:55:57.414: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:57.441: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq": Phase="Running", Reason="", readiness=true. Elapsed: 26.740245ms
Dec 14 08:55:57.441: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq" satisfied condition "running"
Dec 14 08:55:57.441: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:57.467: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p": Phase="Running", Reason="", readiness=true. Elapsed: 26.048645ms
Dec 14 08:55:57.467: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p" satisfied condition "running"
Dec 14 08:55:57.467: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:57.493: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d": Phase="Running", Reason="", readiness=true. Elapsed: 26.272534ms
Dec 14 08:55:57.493: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d" satisfied condition "running"
Dec 14 08:55:57.493: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:57.519: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl": Phase="Running", Reason="", readiness=true. Elapsed: 25.858297ms
Dec 14 08:55:57.519: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl" satisfied condition "running"
Dec 14 08:55:57.519: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c" in namespace "emptydir-wrapper-9177" to be "running"
Dec 14 08:55:57.545: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c": Phase="Running", Reason="", readiness=true. Elapsed: 25.840644ms
Dec 14 08:55:57.545: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:57.545
Dec 14 08:55:57.650: INFO: Deleting ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 took: 28.106501ms
Dec 14 08:55:57.750: INFO: Terminating ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 pods took: 100.679778ms
STEP: Cleaning up the configMaps 12/14/22 08:55:59.452
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec 14 08:56:00.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9177" for this suite. 12/14/22 08:56:00.858
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":114,"skipped":2048,"failed":0}
------------------------------
• [24.425 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:55:36.461
    Dec 14 08:55:36.461: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:55:36.461
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:55:36.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:55:36.591
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 12/14/22 08:55:36.639
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:37.986
    Dec 14 08:55:38.048: INFO: Pod name wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f: Found 1 pods out of 5
    Dec 14 08:55:43.150: INFO: Pod name wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:55:43.15
    Dec 14 08:55:43.150: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:43.176: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6": Phase="Running", Reason="", readiness=true. Elapsed: 26.254815ms
    Dec 14 08:55:43.176: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-67zn6" satisfied condition "running"
    Dec 14 08:55:43.176: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:43.203: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n": Phase="Running", Reason="", readiness=true. Elapsed: 27.162713ms
    Dec 14 08:55:43.203: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-6rl8n" satisfied condition "running"
    Dec 14 08:55:43.203: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:43.230: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb": Phase="Running", Reason="", readiness=true. Elapsed: 26.791964ms
    Dec 14 08:55:43.230: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-lcwhb" satisfied condition "running"
    Dec 14 08:55:43.230: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:43.257: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg": Phase="Running", Reason="", readiness=true. Elapsed: 27.124123ms
    Dec 14 08:55:43.257: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tdnwg" satisfied condition "running"
    Dec 14 08:55:43.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:43.284: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4": Phase="Running", Reason="", readiness=true. Elapsed: 26.68658ms
    Dec 14 08:55:43.284: INFO: Pod "wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f-tf4v4" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:43.284
    Dec 14 08:55:43.390: INFO: Deleting ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f took: 28.03363ms
    Dec 14 08:55:43.490: INFO: Terminating ReplicationController wrapped-volume-race-d8d7dab9-ec06-4a9b-8ca7-3dab9cab2d3f pods took: 100.191248ms
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:44.817
    Dec 14 08:55:44.880: INFO: Pod name wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202: Found 1 pods out of 5
    Dec 14 08:55:49.978: INFO: Pod name wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:55:49.978
    Dec 14 08:55:49.978: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:50.005: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht": Phase="Running", Reason="", readiness=true. Elapsed: 26.690968ms
    Dec 14 08:55:50.005: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-22tht" satisfied condition "running"
    Dec 14 08:55:50.005: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:50.030: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv": Phase="Running", Reason="", readiness=true. Elapsed: 25.628015ms
    Dec 14 08:55:50.030: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-6zzjv" satisfied condition "running"
    Dec 14 08:55:50.030: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:50.057: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn": Phase="Running", Reason="", readiness=true. Elapsed: 26.382326ms
    Dec 14 08:55:50.057: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-cjtkn" satisfied condition "running"
    Dec 14 08:55:50.057: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:50.083: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625": Phase="Running", Reason="", readiness=true. Elapsed: 25.733273ms
    Dec 14 08:55:50.083: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-sx625" satisfied condition "running"
    Dec 14 08:55:50.083: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:50.108: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb": Phase="Running", Reason="", readiness=true. Elapsed: 25.375955ms
    Dec 14 08:55:50.108: INFO: Pod "wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202-vqdxb" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:50.108
    Dec 14 08:55:50.212: INFO: Deleting ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 took: 27.327836ms
    Dec 14 08:55:50.313: INFO: Terminating ReplicationController wrapped-volume-race-8a64c334-f6ac-4bf6-874d-fa1446300202 pods took: 100.686924ms
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:55:52.241
    Dec 14 08:55:52.303: INFO: Pod name wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00: Found 1 pods out of 5
    Dec 14 08:55:57.414: INFO: Pod name wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:55:57.414
    Dec 14 08:55:57.414: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:57.441: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq": Phase="Running", Reason="", readiness=true. Elapsed: 26.740245ms
    Dec 14 08:55:57.441: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-5t7fq" satisfied condition "running"
    Dec 14 08:55:57.441: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:57.467: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p": Phase="Running", Reason="", readiness=true. Elapsed: 26.048645ms
    Dec 14 08:55:57.467: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-6x28p" satisfied condition "running"
    Dec 14 08:55:57.467: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:57.493: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d": Phase="Running", Reason="", readiness=true. Elapsed: 26.272534ms
    Dec 14 08:55:57.493: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-7nx8d" satisfied condition "running"
    Dec 14 08:55:57.493: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:57.519: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl": Phase="Running", Reason="", readiness=true. Elapsed: 25.858297ms
    Dec 14 08:55:57.519: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-8rtxl" satisfied condition "running"
    Dec 14 08:55:57.519: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c" in namespace "emptydir-wrapper-9177" to be "running"
    Dec 14 08:55:57.545: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c": Phase="Running", Reason="", readiness=true. Elapsed: 25.840644ms
    Dec 14 08:55:57.545: INFO: Pod "wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00-rdz5c" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 in namespace emptydir-wrapper-9177, will wait for the garbage collector to delete the pods 12/14/22 08:55:57.545
    Dec 14 08:55:57.650: INFO: Deleting ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 took: 28.106501ms
    Dec 14 08:55:57.750: INFO: Terminating ReplicationController wrapped-volume-race-0171eb7a-f7b2-408d-afeb-d7a2b2871f00 pods took: 100.679778ms
    STEP: Cleaning up the configMaps 12/14/22 08:55:59.452
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:56:00.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-9177" for this suite. 12/14/22 08:56:00.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:00.887
Dec 14 08:56:00.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 08:56:00.888
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:00.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:01.017
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 12/14/22 08:56:01.092
STEP: delete the rc 12/14/22 08:56:06.15
STEP: wait for the rc to be deleted 12/14/22 08:56:06.177
Dec 14 08:56:07.264: INFO: 89 pods remaining
Dec 14 08:56:07.264: INFO: 89 pods has nil DeletionTimestamp
Dec 14 08:56:07.264: INFO: 
Dec 14 08:56:08.262: INFO: 70 pods remaining
Dec 14 08:56:08.262: INFO: 70 pods has nil DeletionTimestamp
Dec 14 08:56:08.262: INFO: 
Dec 14 08:56:09.268: INFO: 69 pods remaining
Dec 14 08:56:09.268: INFO: 69 pods has nil DeletionTimestamp
Dec 14 08:56:09.268: INFO: 
Dec 14 08:56:10.303: INFO: 40 pods remaining
Dec 14 08:56:10.303: INFO: 40 pods has nil DeletionTimestamp
Dec 14 08:56:10.303: INFO: 
Dec 14 08:56:11.301: INFO: 40 pods remaining
Dec 14 08:56:11.301: INFO: 40 pods has nil DeletionTimestamp
Dec 14 08:56:11.301: INFO: 
Dec 14 08:56:12.253: INFO: 10 pods remaining
Dec 14 08:56:12.253: INFO: 10 pods has nil DeletionTimestamp
Dec 14 08:56:12.253: INFO: 
STEP: Gathering metrics 12/14/22 08:56:13.23
W1214 08:56:13.315971    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 08:56:13.316: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 08:56:13.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1270" for this suite. 12/14/22 08:56:13.343
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":115,"skipped":2093,"failed":0}
------------------------------
• [12.484 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:00.887
    Dec 14 08:56:00.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 08:56:00.888
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:00.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:01.017
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 12/14/22 08:56:01.092
    STEP: delete the rc 12/14/22 08:56:06.15
    STEP: wait for the rc to be deleted 12/14/22 08:56:06.177
    Dec 14 08:56:07.264: INFO: 89 pods remaining
    Dec 14 08:56:07.264: INFO: 89 pods has nil DeletionTimestamp
    Dec 14 08:56:07.264: INFO: 
    Dec 14 08:56:08.262: INFO: 70 pods remaining
    Dec 14 08:56:08.262: INFO: 70 pods has nil DeletionTimestamp
    Dec 14 08:56:08.262: INFO: 
    Dec 14 08:56:09.268: INFO: 69 pods remaining
    Dec 14 08:56:09.268: INFO: 69 pods has nil DeletionTimestamp
    Dec 14 08:56:09.268: INFO: 
    Dec 14 08:56:10.303: INFO: 40 pods remaining
    Dec 14 08:56:10.303: INFO: 40 pods has nil DeletionTimestamp
    Dec 14 08:56:10.303: INFO: 
    Dec 14 08:56:11.301: INFO: 40 pods remaining
    Dec 14 08:56:11.301: INFO: 40 pods has nil DeletionTimestamp
    Dec 14 08:56:11.301: INFO: 
    Dec 14 08:56:12.253: INFO: 10 pods remaining
    Dec 14 08:56:12.253: INFO: 10 pods has nil DeletionTimestamp
    Dec 14 08:56:12.253: INFO: 
    STEP: Gathering metrics 12/14/22 08:56:13.23
    W1214 08:56:13.315971    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 08:56:13.316: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 08:56:13.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1270" for this suite. 12/14/22 08:56:13.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:13.372
Dec 14 08:56:13.372: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 08:56:13.373
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:13.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:13.5
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Dec 14 08:56:13.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 08:56:18.108
Dec 14 08:56:18.108: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 create -f -'
Dec 14 08:56:19.046: INFO: stderr: ""
Dec 14 08:56:19.046: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 14 08:56:19.046: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 delete e2e-test-crd-publish-openapi-7994-crds test-cr'
Dec 14 08:56:19.226: INFO: stderr: ""
Dec 14 08:56:19.226: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 14 08:56:19.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 apply -f -'
Dec 14 08:56:19.602: INFO: stderr: ""
Dec 14 08:56:19.602: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 14 08:56:19.602: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 delete e2e-test-crd-publish-openapi-7994-crds test-cr'
Dec 14 08:56:19.784: INFO: stderr: ""
Dec 14 08:56:19.784: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/14/22 08:56:19.784
Dec 14 08:56:19.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 explain e2e-test-crd-publish-openapi-7994-crds'
Dec 14 08:56:20.089: INFO: stderr: ""
Dec 14 08:56:20.089: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7994-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:56:24.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7328" for this suite. 12/14/22 08:56:24.761
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":116,"skipped":2117,"failed":0}
------------------------------
• [11.417 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:13.372
    Dec 14 08:56:13.372: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 08:56:13.373
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:13.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:13.5
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Dec 14 08:56:13.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 08:56:18.108
    Dec 14 08:56:18.108: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 create -f -'
    Dec 14 08:56:19.046: INFO: stderr: ""
    Dec 14 08:56:19.046: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec 14 08:56:19.046: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 delete e2e-test-crd-publish-openapi-7994-crds test-cr'
    Dec 14 08:56:19.226: INFO: stderr: ""
    Dec 14 08:56:19.226: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Dec 14 08:56:19.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 apply -f -'
    Dec 14 08:56:19.602: INFO: stderr: ""
    Dec 14 08:56:19.602: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec 14 08:56:19.602: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 --namespace=crd-publish-openapi-7328 delete e2e-test-crd-publish-openapi-7994-crds test-cr'
    Dec 14 08:56:19.784: INFO: stderr: ""
    Dec 14 08:56:19.784: INFO: stdout: "e2e-test-crd-publish-openapi-7994-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/14/22 08:56:19.784
    Dec 14 08:56:19.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7328 explain e2e-test-crd-publish-openapi-7994-crds'
    Dec 14 08:56:20.089: INFO: stderr: ""
    Dec 14 08:56:20.089: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7994-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:56:24.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7328" for this suite. 12/14/22 08:56:24.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:24.791
Dec 14 08:56:24.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:56:24.792
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:24.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:24.913
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:56:25.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2366" for this suite. 12/14/22 08:56:25.212
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":117,"skipped":2172,"failed":0}
------------------------------
• [0.449 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:24.791
    Dec 14 08:56:24.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:56:24.792
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:24.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:24.913
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:56:25.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2366" for this suite. 12/14/22 08:56:25.212
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:25.241
Dec 14 08:56:25.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 08:56:25.241
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:25.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:25.363
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 08:56:25.514
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:56:25.539
Dec 14 08:56:25.594: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:56:25.594: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:56:26.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:56:26.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:56:27.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:56:27.667: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 08:56:28.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:28.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:29.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:29.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:30.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 08:56:30.667: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 12/14/22 08:56:30.692
Dec 14 08:56:30.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:30.793: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:31.866: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:31.866: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:32.868: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:32.868: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:33.867: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 08:56:33.867: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 08:56:34.869: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 08:56:34.869: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 08:56:34.893
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5493, will wait for the garbage collector to delete the pods 12/14/22 08:56:34.893
Dec 14 08:56:34.995: INFO: Deleting DaemonSet.extensions daemon-set took: 25.704731ms
Dec 14 08:56:35.096: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.619062ms
Dec 14 08:56:38.023: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 08:56:38.056: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 08:56:38.081: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26198"},"items":null}

Dec 14 08:56:38.106: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26198"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:56:38.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5493" for this suite. 12/14/22 08:56:38.289
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":118,"skipped":2181,"failed":0}
------------------------------
• [13.139 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:25.241
    Dec 14 08:56:25.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 08:56:25.241
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:25.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:25.363
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 08:56:25.514
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 08:56:25.539
    Dec 14 08:56:25.594: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:56:25.594: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:56:26.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:56:26.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:56:27.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:56:27.667: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 08:56:28.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:28.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:29.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:29.668: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:30.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 08:56:30.667: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 12/14/22 08:56:30.692
    Dec 14 08:56:30.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:30.793: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:31.866: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:31.866: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:32.868: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:32.868: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:33.867: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 08:56:33.867: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 08:56:34.869: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 08:56:34.869: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 08:56:34.893
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5493, will wait for the garbage collector to delete the pods 12/14/22 08:56:34.893
    Dec 14 08:56:34.995: INFO: Deleting DaemonSet.extensions daemon-set took: 25.704731ms
    Dec 14 08:56:35.096: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.619062ms
    Dec 14 08:56:38.023: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 08:56:38.056: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 08:56:38.081: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26198"},"items":null}

    Dec 14 08:56:38.106: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26198"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:56:38.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5493" for this suite. 12/14/22 08:56:38.289
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:38.382
Dec 14 08:56:38.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 08:56:38.383
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:38.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:38.507
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 12/14/22 08:56:38.601
Dec 14 08:56:38.631: INFO: created test-pod-1
Dec 14 08:56:38.660: INFO: created test-pod-2
Dec 14 08:56:38.689: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 12/14/22 08:56:38.689
Dec 14 08:56:38.689: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6158' to be running and ready
Dec 14 08:56:38.763: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 08:56:38.763: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 08:56:38.763: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 08:56:38.763: INFO: 0 / 3 pods in namespace 'pods-6158' are running and ready (0 seconds elapsed)
Dec 14 08:56:38.763: INFO: expected 0 pod replicas in namespace 'pods-6158', 0 are Running and Ready.
Dec 14 08:56:38.763: INFO: POD         NODE                                       PHASE    GRACE  CONDITIONS
Dec 14 08:56:38.763: INFO: test-pod-1  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
Dec 14 08:56:38.763: INFO: test-pod-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
Dec 14 08:56:38.763: INFO: test-pod-3  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
Dec 14 08:56:38.763: INFO: 
Dec 14 08:56:40.840: INFO: 3 / 3 pods in namespace 'pods-6158' are running and ready (2 seconds elapsed)
Dec 14 08:56:40.840: INFO: expected 0 pod replicas in namespace 'pods-6158', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 12/14/22 08:56:40.886
Dec 14 08:56:40.912: INFO: Pod quantity 3 is different from expected quantity 0
Dec 14 08:56:41.937: INFO: Pod quantity 3 is different from expected quantity 0
Dec 14 08:56:42.939: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 08:56:43.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6158" for this suite. 12/14/22 08:56:43.986
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":119,"skipped":2216,"failed":0}
------------------------------
• [5.632 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:38.382
    Dec 14 08:56:38.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 08:56:38.383
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:38.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:38.507
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 12/14/22 08:56:38.601
    Dec 14 08:56:38.631: INFO: created test-pod-1
    Dec 14 08:56:38.660: INFO: created test-pod-2
    Dec 14 08:56:38.689: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 12/14/22 08:56:38.689
    Dec 14 08:56:38.689: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6158' to be running and ready
    Dec 14 08:56:38.763: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 08:56:38.763: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 08:56:38.763: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 08:56:38.763: INFO: 0 / 3 pods in namespace 'pods-6158' are running and ready (0 seconds elapsed)
    Dec 14 08:56:38.763: INFO: expected 0 pod replicas in namespace 'pods-6158', 0 are Running and Ready.
    Dec 14 08:56:38.763: INFO: POD         NODE                                       PHASE    GRACE  CONDITIONS
    Dec 14 08:56:38.763: INFO: test-pod-1  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
    Dec 14 08:56:38.763: INFO: test-pod-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
    Dec 14 08:56:38.763: INFO: test-pod-3  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 08:56:38 +0000 UTC  }]
    Dec 14 08:56:38.763: INFO: 
    Dec 14 08:56:40.840: INFO: 3 / 3 pods in namespace 'pods-6158' are running and ready (2 seconds elapsed)
    Dec 14 08:56:40.840: INFO: expected 0 pod replicas in namespace 'pods-6158', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 12/14/22 08:56:40.886
    Dec 14 08:56:40.912: INFO: Pod quantity 3 is different from expected quantity 0
    Dec 14 08:56:41.937: INFO: Pod quantity 3 is different from expected quantity 0
    Dec 14 08:56:42.939: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 08:56:43.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6158" for this suite. 12/14/22 08:56:43.986
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:44.015
Dec 14 08:56:44.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:56:44.016
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:44.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:44.136
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/14/22 08:56:44.184
Dec 14 08:56:44.214: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3460  6357802e-bc95-4eee-9f48-6349754ea0cb 26275 0 2022-12-14 08:56:44 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-14 08:56:44 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tw7pq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tw7pq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 08:56:44.215: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3460" to be "running and ready"
Dec 14 08:56:44.238: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 23.866608ms
Dec 14 08:56:44.239: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:56:46.267: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.052058525s
Dec 14 08:56:46.267: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Dec 14 08:56:46.267: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 12/14/22 08:56:46.267
Dec 14 08:56:46.267: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3460 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:56:46.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:56:46.268: INFO: ExecWithOptions: Clientset creation
Dec 14 08:56:46.268: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-3460/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 12/14/22 08:56:46.754
Dec 14 08:56:46.754: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3460 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:56:46.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:56:46.755: INFO: ExecWithOptions: Clientset creation
Dec 14 08:56:46.755: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-3460/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 08:56:47.259: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:56:47.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3460" for this suite. 12/14/22 08:56:47.345
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":120,"skipped":2260,"failed":0}
------------------------------
• [3.356 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:44.015
    Dec 14 08:56:44.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:56:44.016
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:44.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:44.136
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/14/22 08:56:44.184
    Dec 14 08:56:44.214: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3460  6357802e-bc95-4eee-9f48-6349754ea0cb 26275 0 2022-12-14 08:56:44 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-14 08:56:44 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tw7pq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tw7pq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 08:56:44.215: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3460" to be "running and ready"
    Dec 14 08:56:44.238: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 23.866608ms
    Dec 14 08:56:44.239: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:56:46.267: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.052058525s
    Dec 14 08:56:46.267: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Dec 14 08:56:46.267: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 12/14/22 08:56:46.267
    Dec 14 08:56:46.267: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3460 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:56:46.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:56:46.268: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:56:46.268: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-3460/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 12/14/22 08:56:46.754
    Dec 14 08:56:46.754: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3460 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:56:46.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:56:46.755: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:56:46.755: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-3460/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 08:56:47.259: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:56:47.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3460" for this suite. 12/14/22 08:56:47.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:47.373
Dec 14 08:56:47.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 08:56:47.374
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:47.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:47.495
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 12/14/22 08:56:47.542
STEP: Ensuring active pods == parallelism 12/14/22 08:56:47.567
STEP: Orphaning one of the Job's Pods 12/14/22 08:56:49.595
Dec 14 08:56:50.173: INFO: Successfully updated pod "adopt-release-8chr5"
STEP: Checking that the Job readopts the Pod 12/14/22 08:56:50.173
Dec 14 08:56:50.173: INFO: Waiting up to 15m0s for pod "adopt-release-8chr5" in namespace "job-7674" to be "adopted"
Dec 14 08:56:50.200: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 27.084378ms
Dec 14 08:56:52.226: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 2.052565634s
Dec 14 08:56:52.226: INFO: Pod "adopt-release-8chr5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 12/14/22 08:56:52.226
Dec 14 08:56:52.780: INFO: Successfully updated pod "adopt-release-8chr5"
STEP: Checking that the Job releases the Pod 12/14/22 08:56:52.78
Dec 14 08:56:52.780: INFO: Waiting up to 15m0s for pod "adopt-release-8chr5" in namespace "job-7674" to be "released"
Dec 14 08:56:52.805: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 24.776738ms
Dec 14 08:56:54.836: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 2.055830203s
Dec 14 08:56:54.836: INFO: Pod "adopt-release-8chr5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 08:56:54.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7674" for this suite. 12/14/22 08:56:54.892
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":121,"skipped":2297,"failed":0}
------------------------------
• [7.545 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:47.373
    Dec 14 08:56:47.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 08:56:47.374
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:47.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:47.495
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 12/14/22 08:56:47.542
    STEP: Ensuring active pods == parallelism 12/14/22 08:56:47.567
    STEP: Orphaning one of the Job's Pods 12/14/22 08:56:49.595
    Dec 14 08:56:50.173: INFO: Successfully updated pod "adopt-release-8chr5"
    STEP: Checking that the Job readopts the Pod 12/14/22 08:56:50.173
    Dec 14 08:56:50.173: INFO: Waiting up to 15m0s for pod "adopt-release-8chr5" in namespace "job-7674" to be "adopted"
    Dec 14 08:56:50.200: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 27.084378ms
    Dec 14 08:56:52.226: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 2.052565634s
    Dec 14 08:56:52.226: INFO: Pod "adopt-release-8chr5" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 12/14/22 08:56:52.226
    Dec 14 08:56:52.780: INFO: Successfully updated pod "adopt-release-8chr5"
    STEP: Checking that the Job releases the Pod 12/14/22 08:56:52.78
    Dec 14 08:56:52.780: INFO: Waiting up to 15m0s for pod "adopt-release-8chr5" in namespace "job-7674" to be "released"
    Dec 14 08:56:52.805: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 24.776738ms
    Dec 14 08:56:54.836: INFO: Pod "adopt-release-8chr5": Phase="Running", Reason="", readiness=true. Elapsed: 2.055830203s
    Dec 14 08:56:54.836: INFO: Pod "adopt-release-8chr5" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 08:56:54.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7674" for this suite. 12/14/22 08:56:54.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:54.919
Dec 14 08:56:54.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 08:56:54.919
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:54.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:55.046
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 08:56:55.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5993" for this suite. 12/14/22 08:56:55.317
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":122,"skipped":2305,"failed":0}
------------------------------
• [0.434 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:54.919
    Dec 14 08:56:54.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 08:56:54.919
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:54.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:55.046
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 08:56:55.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5993" for this suite. 12/14/22 08:56:55.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:55.354
Dec 14 08:56:55.354: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:56:55.355
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:55.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:55.508
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 08:56:55.555
Dec 14 08:56:55.598: INFO: Waiting up to 5m0s for pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e" in namespace "emptydir-7366" to be "Succeeded or Failed"
Dec 14 08:56:55.624: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.961056ms
Dec 14 08:56:57.657: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059235086s
Dec 14 08:56:59.650: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05240766s
STEP: Saw pod success 12/14/22 08:56:59.65
Dec 14 08:56:59.650: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e" satisfied condition "Succeeded or Failed"
Dec 14 08:56:59.675: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-39620608-965b-4598-a8f7-ea5cd70d002e container test-container: <nil>
STEP: delete the pod 12/14/22 08:56:59.749
Dec 14 08:56:59.786: INFO: Waiting for pod pod-39620608-965b-4598-a8f7-ea5cd70d002e to disappear
Dec 14 08:56:59.810: INFO: Pod pod-39620608-965b-4598-a8f7-ea5cd70d002e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:56:59.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7366" for this suite. 12/14/22 08:56:59.858
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":123,"skipped":2329,"failed":0}
------------------------------
• [4.530 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:55.354
    Dec 14 08:56:55.354: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:56:55.355
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:55.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:56:55.508
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 08:56:55.555
    Dec 14 08:56:55.598: INFO: Waiting up to 5m0s for pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e" in namespace "emptydir-7366" to be "Succeeded or Failed"
    Dec 14 08:56:55.624: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.961056ms
    Dec 14 08:56:57.657: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059235086s
    Dec 14 08:56:59.650: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05240766s
    STEP: Saw pod success 12/14/22 08:56:59.65
    Dec 14 08:56:59.650: INFO: Pod "pod-39620608-965b-4598-a8f7-ea5cd70d002e" satisfied condition "Succeeded or Failed"
    Dec 14 08:56:59.675: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-39620608-965b-4598-a8f7-ea5cd70d002e container test-container: <nil>
    STEP: delete the pod 12/14/22 08:56:59.749
    Dec 14 08:56:59.786: INFO: Waiting for pod pod-39620608-965b-4598-a8f7-ea5cd70d002e to disappear
    Dec 14 08:56:59.810: INFO: Pod pod-39620608-965b-4598-a8f7-ea5cd70d002e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:56:59.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7366" for this suite. 12/14/22 08:56:59.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:56:59.887
Dec 14 08:56:59.887: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:56:59.888
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:59.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:00.01
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Dec 14 08:57:00.058: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 14 08:57:00.108: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 08:57:00.108
Dec 14 08:57:00.108: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-h28nz" in namespace "deployment-7081" to be "running"
Dec 14 08:57:00.137: INFO: Pod "test-rolling-update-controller-h28nz": Phase="Pending", Reason="", readiness=false. Elapsed: 28.514582ms
Dec 14 08:57:02.162: INFO: Pod "test-rolling-update-controller-h28nz": Phase="Running", Reason="", readiness=true. Elapsed: 2.053918901s
Dec 14 08:57:02.162: INFO: Pod "test-rolling-update-controller-h28nz" satisfied condition "running"
Dec 14 08:57:02.162: INFO: Creating deployment "test-rolling-update-deployment"
Dec 14 08:57:02.194: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 14 08:57:02.242: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 14 08:57:02.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 08:57:04.293: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:57:04.368: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7081  c34a33a8-8955-4530-8518-080ff83093d3 26498 1 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00625a768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:57:02 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-14 08:57:03 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 08:57:04.393: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7081  80700962-9297-473d-ba1f-b340efc4b2a4 26491 1 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c34a33a8-8955-4530-8518-080ff83093d3 0xc00625aea7 0xc00625aea8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c34a33a8-8955-4530-8518-080ff83093d3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00625afe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:57:04.393: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 14 08:57:04.393: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7081  5fbb75d6-0136-4ca7-9577-a51f0c0f4e54 26497 2 2022-12-14 08:57:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c34a33a8-8955-4530-8518-080ff83093d3 0xc00625aca7 0xc00625aca8}] [] [{e2e.test Update apps/v1 2022-12-14 08:57:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c34a33a8-8955-4530-8518-080ff83093d3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00625adf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:57:04.418: INFO: Pod "test-rolling-update-deployment-78f575d8ff-vk6vt" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-vk6vt test-rolling-update-deployment-78f575d8ff- deployment-7081  de57241e-064f-4677-ae6f-1115a244cc74 26490 0 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:db89fa71d49a35974cb3cc19f425f7cd0e1df9f962f712f965f19f58271d47ab cni.projectcalico.org/podIP:100.64.0.54/32 cni.projectcalico.org/podIPs:100.64.0.54/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 80700962-9297-473d-ba1f-b340efc4b2a4 0xc006089367 0xc006089368}] [] [{Go-http-client Update v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"80700962-9297-473d-ba1f-b340efc4b2a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p2np7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p2np7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.54,StartTime:2022-12-14 08:57:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:57:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://9c695a804f7e67dac56cb5b2ef7ba36b147ebbafaf1325dc043ba7c080b0a5b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:57:04.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7081" for this suite. 12/14/22 08:57:04.466
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":124,"skipped":2344,"failed":0}
------------------------------
• [4.605 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:56:59.887
    Dec 14 08:56:59.887: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:56:59.888
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:56:59.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:00.01
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Dec 14 08:57:00.058: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Dec 14 08:57:00.108: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 08:57:00.108
    Dec 14 08:57:00.108: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-h28nz" in namespace "deployment-7081" to be "running"
    Dec 14 08:57:00.137: INFO: Pod "test-rolling-update-controller-h28nz": Phase="Pending", Reason="", readiness=false. Elapsed: 28.514582ms
    Dec 14 08:57:02.162: INFO: Pod "test-rolling-update-controller-h28nz": Phase="Running", Reason="", readiness=true. Elapsed: 2.053918901s
    Dec 14 08:57:02.162: INFO: Pod "test-rolling-update-controller-h28nz" satisfied condition "running"
    Dec 14 08:57:02.162: INFO: Creating deployment "test-rolling-update-deployment"
    Dec 14 08:57:02.194: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Dec 14 08:57:02.242: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Dec 14 08:57:02.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 57, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 08:57:04.293: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:57:04.368: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7081  c34a33a8-8955-4530-8518-080ff83093d3 26498 1 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00625a768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:57:02 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-14 08:57:03 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 08:57:04.393: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7081  80700962-9297-473d-ba1f-b340efc4b2a4 26491 1 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c34a33a8-8955-4530-8518-080ff83093d3 0xc00625aea7 0xc00625aea8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c34a33a8-8955-4530-8518-080ff83093d3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00625afe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:57:04.393: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Dec 14 08:57:04.393: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7081  5fbb75d6-0136-4ca7-9577-a51f0c0f4e54 26497 2 2022-12-14 08:57:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c34a33a8-8955-4530-8518-080ff83093d3 0xc00625aca7 0xc00625aca8}] [] [{e2e.test Update apps/v1 2022-12-14 08:57:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c34a33a8-8955-4530-8518-080ff83093d3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00625adf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:57:04.418: INFO: Pod "test-rolling-update-deployment-78f575d8ff-vk6vt" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-vk6vt test-rolling-update-deployment-78f575d8ff- deployment-7081  de57241e-064f-4677-ae6f-1115a244cc74 26490 0 2022-12-14 08:57:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:db89fa71d49a35974cb3cc19f425f7cd0e1df9f962f712f965f19f58271d47ab cni.projectcalico.org/podIP:100.64.0.54/32 cni.projectcalico.org/podIPs:100.64.0.54/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 80700962-9297-473d-ba1f-b340efc4b2a4 0xc006089367 0xc006089368}] [] [{Go-http-client Update v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 08:57:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"80700962-9297-473d-ba1f-b340efc4b2a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 08:57:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p2np7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p2np7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:57:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.54,StartTime:2022-12-14 08:57:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:57:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://9c695a804f7e67dac56cb5b2ef7ba36b147ebbafaf1325dc043ba7c080b0a5b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:57:04.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7081" for this suite. 12/14/22 08:57:04.466
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:57:04.492
Dec 14 08:57:04.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 08:57:04.493
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:04.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:04.616
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 12/14/22 08:57:04.666
STEP: submitting the pod to kubernetes 12/14/22 08:57:04.667
Dec 14 08:57:04.697: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" in namespace "pods-3299" to be "running and ready"
Dec 14 08:57:04.722: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.581734ms
Dec 14 08:57:04.722: INFO: The phase of Pod pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:57:06.751: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=true. Elapsed: 2.053712665s
Dec 14 08:57:06.751: INFO: The phase of Pod pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e is Running (Ready = true)
Dec 14 08:57:06.751: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/14/22 08:57:06.777
STEP: updating the pod 12/14/22 08:57:06.802
Dec 14 08:57:07.361: INFO: Successfully updated pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e"
Dec 14 08:57:07.362: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" in namespace "pods-3299" to be "terminated with reason DeadlineExceeded"
Dec 14 08:57:07.386: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=true. Elapsed: 24.638285ms
Dec 14 08:57:09.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=false. Elapsed: 2.050941083s
Dec 14 08:57:11.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.051131027s
Dec 14 08:57:11.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 08:57:11.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3299" for this suite. 12/14/22 08:57:11.461
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":125,"skipped":2344,"failed":0}
------------------------------
• [6.995 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:57:04.492
    Dec 14 08:57:04.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 08:57:04.493
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:04.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:04.616
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 12/14/22 08:57:04.666
    STEP: submitting the pod to kubernetes 12/14/22 08:57:04.667
    Dec 14 08:57:04.697: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" in namespace "pods-3299" to be "running and ready"
    Dec 14 08:57:04.722: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.581734ms
    Dec 14 08:57:04.722: INFO: The phase of Pod pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:57:06.751: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=true. Elapsed: 2.053712665s
    Dec 14 08:57:06.751: INFO: The phase of Pod pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e is Running (Ready = true)
    Dec 14 08:57:06.751: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/14/22 08:57:06.777
    STEP: updating the pod 12/14/22 08:57:06.802
    Dec 14 08:57:07.361: INFO: Successfully updated pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e"
    Dec 14 08:57:07.362: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" in namespace "pods-3299" to be "terminated with reason DeadlineExceeded"
    Dec 14 08:57:07.386: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=true. Elapsed: 24.638285ms
    Dec 14 08:57:09.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Running", Reason="", readiness=false. Elapsed: 2.050941083s
    Dec 14 08:57:11.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.051131027s
    Dec 14 08:57:11.413: INFO: Pod "pod-update-activedeadlineseconds-5aeb1369-c64f-4d89-809d-1dfefa73699e" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 08:57:11.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3299" for this suite. 12/14/22 08:57:11.461
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:57:11.488
Dec 14 08:57:11.488: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostport 12/14/22 08:57:11.489
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:11.564
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:11.611
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/14/22 08:57:11.686
Dec 14 08:57:11.716: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1809" to be "running and ready"
Dec 14 08:57:11.741: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.310907ms
Dec 14 08:57:11.741: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:57:13.768: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051841929s
Dec 14 08:57:13.768: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 08:57:13.768: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.0.4 on the node which pod1 resides and expect scheduled 12/14/22 08:57:13.768
Dec 14 08:57:13.797: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1809" to be "running and ready"
Dec 14 08:57:13.823: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.019406ms
Dec 14 08:57:13.823: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:57:15.848: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.051207405s
Dec 14 08:57:15.848: INFO: The phase of Pod pod2 is Running (Ready = false)
Dec 14 08:57:17.850: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.053232579s
Dec 14 08:57:17.850: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 08:57:17.850: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.0.4 but use UDP protocol on the node which pod2 resides 12/14/22 08:57:17.851
Dec 14 08:57:17.884: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1809" to be "running and ready"
Dec 14 08:57:17.909: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.518804ms
Dec 14 08:57:17.909: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:57:19.936: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.052596643s
Dec 14 08:57:19.937: INFO: The phase of Pod pod3 is Running (Ready = true)
Dec 14 08:57:19.937: INFO: Pod "pod3" satisfied condition "running and ready"
Dec 14 08:57:19.965: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1809" to be "running and ready"
Dec 14 08:57:19.992: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 26.208488ms
Dec 14 08:57:19.992: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:57:22.018: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.052376012s
Dec 14 08:57:22.018: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Dec 14 08:57:22.018: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/14/22 08:57:22.043
Dec 14 08:57:22.043: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.0.4 http://127.0.0.1:54323/hostname] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:57:22.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:57:22.043: INFO: ExecWithOptions: Clientset creation
Dec 14 08:57:22.043: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.0.4+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.0.4, port: 54323 12/14/22 08:57:22.475
Dec 14 08:57:22.475: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.0.4:54323/hostname] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:57:22.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:57:22.475: INFO: ExecWithOptions: Clientset creation
Dec 14 08:57:22.476: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.0.4%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.0.4, port: 54323 UDP 12/14/22 08:57:23.002
Dec 14 08:57:23.002: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.0.4 54323] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:57:23.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:57:23.002: INFO: ExecWithOptions: Clientset creation
Dec 14 08:57:23.002: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.0.4+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Dec 14 08:57:28.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-1809" for this suite. 12/14/22 08:57:28.543
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":126,"skipped":2354,"failed":0}
------------------------------
• [17.082 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:57:11.488
    Dec 14 08:57:11.488: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename hostport 12/14/22 08:57:11.489
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:11.564
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:11.611
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/14/22 08:57:11.686
    Dec 14 08:57:11.716: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1809" to be "running and ready"
    Dec 14 08:57:11.741: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.310907ms
    Dec 14 08:57:11.741: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:57:13.768: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051841929s
    Dec 14 08:57:13.768: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 08:57:13.768: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.0.4 on the node which pod1 resides and expect scheduled 12/14/22 08:57:13.768
    Dec 14 08:57:13.797: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1809" to be "running and ready"
    Dec 14 08:57:13.823: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.019406ms
    Dec 14 08:57:13.823: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:57:15.848: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.051207405s
    Dec 14 08:57:15.848: INFO: The phase of Pod pod2 is Running (Ready = false)
    Dec 14 08:57:17.850: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.053232579s
    Dec 14 08:57:17.850: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 08:57:17.850: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.0.4 but use UDP protocol on the node which pod2 resides 12/14/22 08:57:17.851
    Dec 14 08:57:17.884: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1809" to be "running and ready"
    Dec 14 08:57:17.909: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.518804ms
    Dec 14 08:57:17.909: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:57:19.936: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.052596643s
    Dec 14 08:57:19.937: INFO: The phase of Pod pod3 is Running (Ready = true)
    Dec 14 08:57:19.937: INFO: Pod "pod3" satisfied condition "running and ready"
    Dec 14 08:57:19.965: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1809" to be "running and ready"
    Dec 14 08:57:19.992: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 26.208488ms
    Dec 14 08:57:19.992: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:57:22.018: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.052376012s
    Dec 14 08:57:22.018: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Dec 14 08:57:22.018: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/14/22 08:57:22.043
    Dec 14 08:57:22.043: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.0.4 http://127.0.0.1:54323/hostname] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:57:22.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:57:22.043: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:57:22.043: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.0.4+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.0.4, port: 54323 12/14/22 08:57:22.475
    Dec 14 08:57:22.475: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.0.4:54323/hostname] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:57:22.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:57:22.475: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:57:22.476: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.0.4%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.0.4, port: 54323 UDP 12/14/22 08:57:23.002
    Dec 14 08:57:23.002: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.0.4 54323] Namespace:hostport-1809 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:57:23.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:57:23.002: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:57:23.002: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-1809/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.0.4+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Dec 14 08:57:28.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-1809" for this suite. 12/14/22 08:57:28.543
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:57:28.57
Dec 14 08:57:28.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:57:28.571
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:28.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:28.695
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 12/14/22 08:57:28.742
Dec 14 08:57:28.772: INFO: Waiting up to 5m0s for pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09" in namespace "downward-api-1972" to be "Succeeded or Failed"
Dec 14 08:57:28.797: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Pending", Reason="", readiness=false. Elapsed: 24.28564ms
Dec 14 08:57:30.822: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050137165s
Dec 14 08:57:32.823: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05075458s
STEP: Saw pod success 12/14/22 08:57:32.823
Dec 14 08:57:32.823: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09" satisfied condition "Succeeded or Failed"
Dec 14 08:57:32.848: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 container dapi-container: <nil>
STEP: delete the pod 12/14/22 08:57:32.881
Dec 14 08:57:32.916: INFO: Waiting for pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 to disappear
Dec 14 08:57:32.940: INFO: Pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 08:57:32.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1972" for this suite. 12/14/22 08:57:32.989
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":127,"skipped":2361,"failed":0}
------------------------------
• [4.447 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:57:28.57
    Dec 14 08:57:28.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:57:28.571
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:28.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:28.695
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 12/14/22 08:57:28.742
    Dec 14 08:57:28.772: INFO: Waiting up to 5m0s for pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09" in namespace "downward-api-1972" to be "Succeeded or Failed"
    Dec 14 08:57:28.797: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Pending", Reason="", readiness=false. Elapsed: 24.28564ms
    Dec 14 08:57:30.822: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050137165s
    Dec 14 08:57:32.823: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05075458s
    STEP: Saw pod success 12/14/22 08:57:32.823
    Dec 14 08:57:32.823: INFO: Pod "downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09" satisfied condition "Succeeded or Failed"
    Dec 14 08:57:32.848: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 08:57:32.881
    Dec 14 08:57:32.916: INFO: Waiting for pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 to disappear
    Dec 14 08:57:32.940: INFO: Pod downward-api-381a9f87-432e-43bb-a18c-648ffaf6db09 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 08:57:32.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1972" for this suite. 12/14/22 08:57:32.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:57:33.018
Dec 14 08:57:33.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:57:33.019
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:33.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:33.141
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Dec 14 08:57:33.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:57:34.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-222" for this suite. 12/14/22 08:57:35.016
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":128,"skipped":2378,"failed":0}
------------------------------
• [2.024 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:57:33.018
    Dec 14 08:57:33.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:57:33.019
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:33.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:33.141
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Dec 14 08:57:33.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:57:34.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-222" for this suite. 12/14/22 08:57:35.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:57:35.043
Dec 14 08:57:35.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 08:57:35.044
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:35.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:35.165
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 08:58:35.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8906" for this suite. 12/14/22 08:58:35.32
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":129,"skipped":2405,"failed":0}
------------------------------
• [60.305 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:57:35.043
    Dec 14 08:57:35.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 08:57:35.044
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:57:35.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:57:35.165
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 08:58:35.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8906" for this suite. 12/14/22 08:58:35.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:35.349
Dec 14 08:58:35.349: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 08:58:35.35
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:35.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:35.477
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 12/14/22 08:58:35.523
STEP: Verify that the required pods have come up 12/14/22 08:58:35.549
Dec 14 08:58:35.575: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 12/14/22 08:58:35.575
Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-ztf2h" in namespace "replicaset-490" to be "running"
Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-djm56" in namespace "replicaset-490" to be "running"
Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-vvvs8" in namespace "replicaset-490" to be "running"
Dec 14 08:58:35.600: INFO: Pod "test-rs-djm56": Phase="Pending", Reason="", readiness=false. Elapsed: 24.255519ms
Dec 14 08:58:35.600: INFO: Pod "test-rs-ztf2h": Phase="Pending", Reason="", readiness=false. Elapsed: 24.622202ms
Dec 14 08:58:35.600: INFO: Pod "test-rs-vvvs8": Phase="Pending", Reason="", readiness=false. Elapsed: 24.336728ms
Dec 14 08:58:37.626: INFO: Pod "test-rs-vvvs8": Phase="Running", Reason="", readiness=true. Elapsed: 2.049932954s
Dec 14 08:58:37.626: INFO: Pod "test-rs-vvvs8" satisfied condition "running"
Dec 14 08:58:37.626: INFO: Pod "test-rs-ztf2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.050426246s
Dec 14 08:58:37.626: INFO: Pod "test-rs-ztf2h" satisfied condition "running"
Dec 14 08:58:37.626: INFO: Pod "test-rs-djm56": Phase="Running", Reason="", readiness=true. Elapsed: 2.05027674s
Dec 14 08:58:37.626: INFO: Pod "test-rs-djm56" satisfied condition "running"
Dec 14 08:58:37.651: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 12/14/22 08:58:37.651
STEP: DeleteCollection of the ReplicaSets 12/14/22 08:58:37.677
STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/14/22 08:58:37.704
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 08:58:37.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-490" for this suite. 12/14/22 08:58:37.778
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":130,"skipped":2430,"failed":0}
------------------------------
• [2.456 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:35.349
    Dec 14 08:58:35.349: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 08:58:35.35
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:35.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:35.477
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 12/14/22 08:58:35.523
    STEP: Verify that the required pods have come up 12/14/22 08:58:35.549
    Dec 14 08:58:35.575: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 12/14/22 08:58:35.575
    Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-ztf2h" in namespace "replicaset-490" to be "running"
    Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-djm56" in namespace "replicaset-490" to be "running"
    Dec 14 08:58:35.576: INFO: Waiting up to 5m0s for pod "test-rs-vvvs8" in namespace "replicaset-490" to be "running"
    Dec 14 08:58:35.600: INFO: Pod "test-rs-djm56": Phase="Pending", Reason="", readiness=false. Elapsed: 24.255519ms
    Dec 14 08:58:35.600: INFO: Pod "test-rs-ztf2h": Phase="Pending", Reason="", readiness=false. Elapsed: 24.622202ms
    Dec 14 08:58:35.600: INFO: Pod "test-rs-vvvs8": Phase="Pending", Reason="", readiness=false. Elapsed: 24.336728ms
    Dec 14 08:58:37.626: INFO: Pod "test-rs-vvvs8": Phase="Running", Reason="", readiness=true. Elapsed: 2.049932954s
    Dec 14 08:58:37.626: INFO: Pod "test-rs-vvvs8" satisfied condition "running"
    Dec 14 08:58:37.626: INFO: Pod "test-rs-ztf2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.050426246s
    Dec 14 08:58:37.626: INFO: Pod "test-rs-ztf2h" satisfied condition "running"
    Dec 14 08:58:37.626: INFO: Pod "test-rs-djm56": Phase="Running", Reason="", readiness=true. Elapsed: 2.05027674s
    Dec 14 08:58:37.626: INFO: Pod "test-rs-djm56" satisfied condition "running"
    Dec 14 08:58:37.651: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 12/14/22 08:58:37.651
    STEP: DeleteCollection of the ReplicaSets 12/14/22 08:58:37.677
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/14/22 08:58:37.704
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 08:58:37.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-490" for this suite. 12/14/22 08:58:37.778
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:37.805
Dec 14 08:58:37.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test 12/14/22 08:58:37.806
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:37.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:37.927
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Dec 14 08:58:38.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-1246" for this suite. 12/14/22 08:58:38.347
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":131,"skipped":2431,"failed":0}
------------------------------
• [0.567 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:37.805
    Dec 14 08:58:37.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename lease-test 12/14/22 08:58:37.806
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:37.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:37.927
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Dec 14 08:58:38.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-1246" for this suite. 12/14/22 08:58:38.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:38.374
Dec 14 08:58:38.374: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 08:58:38.375
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:38.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:38.506
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2985 12/14/22 08:58:38.552
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Dec 14 08:58:38.633: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec 14 08:58:48.669: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 12/14/22 08:58:48.735
W1214 08:58:48.764732    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 08:58:48.821: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 08:58:48.821: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
Dec 14 08:58:58.848: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 08:58:58.848: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 12/14/22 08:58:58.911
STEP: Delete all of the StatefulSets 12/14/22 08:58:58.938
STEP: Verify that StatefulSets have been deleted 12/14/22 08:58:58.966
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 08:58:58.992: INFO: Deleting all statefulset in ns statefulset-2985
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 08:58:59.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2985" for this suite. 12/14/22 08:58:59.116
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":132,"skipped":2466,"failed":0}
------------------------------
• [20.769 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:38.374
    Dec 14 08:58:38.374: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 08:58:38.375
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:38.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:38.506
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2985 12/14/22 08:58:38.552
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Dec 14 08:58:38.633: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Dec 14 08:58:48.669: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 12/14/22 08:58:48.735
    W1214 08:58:48.764732    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 08:58:48.821: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 08:58:48.821: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
    Dec 14 08:58:58.848: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 08:58:58.848: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 12/14/22 08:58:58.911
    STEP: Delete all of the StatefulSets 12/14/22 08:58:58.938
    STEP: Verify that StatefulSets have been deleted 12/14/22 08:58:58.966
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 08:58:58.992: INFO: Deleting all statefulset in ns statefulset-2985
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 08:58:59.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2985" for this suite. 12/14/22 08:58:59.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:59.145
Dec 14 08:58:59.145: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:58:59.146
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:59.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:59.268
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:58:59.316
Dec 14 08:58:59.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947" in namespace "projected-8590" to be "Succeeded or Failed"
Dec 14 08:58:59.375: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Pending", Reason="", readiness=false. Elapsed: 24.615978ms
Dec 14 08:59:01.401: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049918288s
Dec 14 08:59:03.401: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050639736s
STEP: Saw pod success 12/14/22 08:59:03.402
Dec 14 08:59:03.402: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947" satisfied condition "Succeeded or Failed"
Dec 14 08:59:03.427: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 container client-container: <nil>
STEP: delete the pod 12/14/22 08:59:03.501
Dec 14 08:59:03.535: INFO: Waiting for pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 to disappear
Dec 14 08:59:03.560: INFO: Pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:59:03.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8590" for this suite. 12/14/22 08:59:03.607
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":133,"skipped":2487,"failed":0}
------------------------------
• [4.488 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:59.145
    Dec 14 08:58:59.145: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:58:59.146
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:59.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:59.268
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:58:59.316
    Dec 14 08:58:59.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947" in namespace "projected-8590" to be "Succeeded or Failed"
    Dec 14 08:58:59.375: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Pending", Reason="", readiness=false. Elapsed: 24.615978ms
    Dec 14 08:59:01.401: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049918288s
    Dec 14 08:59:03.401: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050639736s
    STEP: Saw pod success 12/14/22 08:59:03.402
    Dec 14 08:59:03.402: INFO: Pod "downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:03.427: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:59:03.501
    Dec 14 08:59:03.535: INFO: Waiting for pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 to disappear
    Dec 14 08:59:03.560: INFO: Pod downwardapi-volume-6fbb46dd-99be-4fdb-95f6-042e613b0947 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:59:03.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8590" for this suite. 12/14/22 08:59:03.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:03.634
Dec 14 08:59:03.634: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 08:59:03.635
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:03.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:03.76
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 12/14/22 08:59:03.807
STEP: starting a background goroutine to produce watch events 12/14/22 08:59:03.832
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/14/22 08:59:03.832
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 08:59:06.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3387" for this suite. 12/14/22 08:59:06.649
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":134,"skipped":2506,"failed":0}
------------------------------
• [3.044 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:03.634
    Dec 14 08:59:03.634: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 08:59:03.635
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:03.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:03.76
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 12/14/22 08:59:03.807
    STEP: starting a background goroutine to produce watch events 12/14/22 08:59:03.832
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/14/22 08:59:03.832
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 08:59:06.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3387" for this suite. 12/14/22 08:59:06.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:06.679
Dec 14 08:59:06.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:06.68
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:06.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:06.805
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:06.853
Dec 14 08:59:06.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837" in namespace "downward-api-5818" to be "Succeeded or Failed"
Dec 14 08:59:06.911: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Pending", Reason="", readiness=false. Elapsed: 26.440767ms
Dec 14 08:59:08.936: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051840948s
Dec 14 08:59:10.938: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053241859s
STEP: Saw pod success 12/14/22 08:59:10.938
Dec 14 08:59:10.938: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837" satisfied condition "Succeeded or Failed"
Dec 14 08:59:10.963: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 container client-container: <nil>
STEP: delete the pod 12/14/22 08:59:10.994
Dec 14 08:59:11.029: INFO: Waiting for pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 to disappear
Dec 14 08:59:11.054: INFO: Pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 08:59:11.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5818" for this suite. 12/14/22 08:59:11.103
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":135,"skipped":2511,"failed":0}
------------------------------
• [4.451 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:06.679
    Dec 14 08:59:06.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:06.68
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:06.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:06.805
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:06.853
    Dec 14 08:59:06.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837" in namespace "downward-api-5818" to be "Succeeded or Failed"
    Dec 14 08:59:06.911: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Pending", Reason="", readiness=false. Elapsed: 26.440767ms
    Dec 14 08:59:08.936: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051840948s
    Dec 14 08:59:10.938: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053241859s
    STEP: Saw pod success 12/14/22 08:59:10.938
    Dec 14 08:59:10.938: INFO: Pod "downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:10.963: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:59:10.994
    Dec 14 08:59:11.029: INFO: Waiting for pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 to disappear
    Dec 14 08:59:11.054: INFO: Pod downwardapi-volume-20669f38-9eec-435d-be05-11501cf83837 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 08:59:11.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5818" for this suite. 12/14/22 08:59:11.103
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:11.132
Dec 14 08:59:11.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:59:11.133
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:11.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:11.256
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 08:59:11.304
Dec 14 08:59:11.334: INFO: Waiting up to 5m0s for pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6" in namespace "emptydir-1720" to be "Succeeded or Failed"
Dec 14 08:59:11.361: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.980054ms
Dec 14 08:59:13.387: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052284201s
Dec 14 08:59:15.388: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053560381s
STEP: Saw pod success 12/14/22 08:59:15.388
Dec 14 08:59:15.388: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6" satisfied condition "Succeeded or Failed"
Dec 14 08:59:15.413: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 container test-container: <nil>
STEP: delete the pod 12/14/22 08:59:15.446
Dec 14 08:59:15.481: INFO: Waiting for pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 to disappear
Dec 14 08:59:15.506: INFO: Pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:59:15.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1720" for this suite. 12/14/22 08:59:15.564
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":136,"skipped":2557,"failed":0}
------------------------------
• [4.458 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:11.132
    Dec 14 08:59:11.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:59:11.133
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:11.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:11.256
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 08:59:11.304
    Dec 14 08:59:11.334: INFO: Waiting up to 5m0s for pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6" in namespace "emptydir-1720" to be "Succeeded or Failed"
    Dec 14 08:59:11.361: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.980054ms
    Dec 14 08:59:13.387: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052284201s
    Dec 14 08:59:15.388: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053560381s
    STEP: Saw pod success 12/14/22 08:59:15.388
    Dec 14 08:59:15.388: INFO: Pod "pod-d47cffb7-2392-4715-9df7-5cff45eff2b6" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:15.413: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 container test-container: <nil>
    STEP: delete the pod 12/14/22 08:59:15.446
    Dec 14 08:59:15.481: INFO: Waiting for pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 to disappear
    Dec 14 08:59:15.506: INFO: Pod pod-d47cffb7-2392-4715-9df7-5cff45eff2b6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:59:15.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1720" for this suite. 12/14/22 08:59:15.564
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:15.591
Dec 14 08:59:15.592: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 08:59:15.593
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:15.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:15.717
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 12/14/22 08:59:15.763
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:15.837
STEP: Creating a service in the namespace 12/14/22 08:59:15.883
STEP: Deleting the namespace 12/14/22 08:59:15.918
STEP: Waiting for the namespace to be removed. 12/14/22 08:59:15.954
STEP: Recreating the namespace 12/14/22 08:59:21.98
STEP: Verifying there is no service in the namespace 12/14/22 08:59:22.055
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:59:22.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1237" for this suite. 12/14/22 08:59:22.129
STEP: Destroying namespace "nsdeletetest-2875" for this suite. 12/14/22 08:59:22.161
Dec 14 08:59:22.186: INFO: Namespace nsdeletetest-2875 was already deleted
STEP: Destroying namespace "nsdeletetest-7427" for this suite. 12/14/22 08:59:22.186
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":137,"skipped":2588,"failed":0}
------------------------------
• [6.621 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:15.591
    Dec 14 08:59:15.592: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 08:59:15.593
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:15.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:15.717
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 12/14/22 08:59:15.763
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:15.837
    STEP: Creating a service in the namespace 12/14/22 08:59:15.883
    STEP: Deleting the namespace 12/14/22 08:59:15.918
    STEP: Waiting for the namespace to be removed. 12/14/22 08:59:15.954
    STEP: Recreating the namespace 12/14/22 08:59:21.98
    STEP: Verifying there is no service in the namespace 12/14/22 08:59:22.055
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:59:22.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1237" for this suite. 12/14/22 08:59:22.129
    STEP: Destroying namespace "nsdeletetest-2875" for this suite. 12/14/22 08:59:22.161
    Dec 14 08:59:22.186: INFO: Namespace nsdeletetest-2875 was already deleted
    STEP: Destroying namespace "nsdeletetest-7427" for this suite. 12/14/22 08:59:22.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:22.213
Dec 14 08:59:22.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ingress 12/14/22 08:59:22.214
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:22.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:22.349
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 12/14/22 08:59:22.396
STEP: getting /apis/networking.k8s.io 12/14/22 08:59:22.442
STEP: getting /apis/networking.k8s.iov1 12/14/22 08:59:22.466
STEP: creating 12/14/22 08:59:22.489
STEP: getting 12/14/22 08:59:22.566
STEP: listing 12/14/22 08:59:22.601
STEP: watching 12/14/22 08:59:22.626
Dec 14 08:59:22.626: INFO: starting watch
STEP: cluster-wide listing 12/14/22 08:59:22.649
STEP: cluster-wide watching 12/14/22 08:59:22.676
Dec 14 08:59:22.676: INFO: starting watch
STEP: patching 12/14/22 08:59:22.699
STEP: updating 12/14/22 08:59:22.729
Dec 14 08:59:22.781: INFO: waiting for watch events with expected annotations
Dec 14 08:59:22.782: INFO: saw patched and updated annotations
STEP: patching /status 12/14/22 08:59:22.782
STEP: updating /status 12/14/22 08:59:22.808
STEP: get /status 12/14/22 08:59:22.858
STEP: deleting 12/14/22 08:59:22.883
STEP: deleting a collection 12/14/22 08:59:22.962
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Dec 14 08:59:23.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-2166" for this suite. 12/14/22 08:59:23.047
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":138,"skipped":2595,"failed":0}
------------------------------
• [0.860 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:22.213
    Dec 14 08:59:22.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ingress 12/14/22 08:59:22.214
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:22.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:22.349
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 12/14/22 08:59:22.396
    STEP: getting /apis/networking.k8s.io 12/14/22 08:59:22.442
    STEP: getting /apis/networking.k8s.iov1 12/14/22 08:59:22.466
    STEP: creating 12/14/22 08:59:22.489
    STEP: getting 12/14/22 08:59:22.566
    STEP: listing 12/14/22 08:59:22.601
    STEP: watching 12/14/22 08:59:22.626
    Dec 14 08:59:22.626: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 08:59:22.649
    STEP: cluster-wide watching 12/14/22 08:59:22.676
    Dec 14 08:59:22.676: INFO: starting watch
    STEP: patching 12/14/22 08:59:22.699
    STEP: updating 12/14/22 08:59:22.729
    Dec 14 08:59:22.781: INFO: waiting for watch events with expected annotations
    Dec 14 08:59:22.782: INFO: saw patched and updated annotations
    STEP: patching /status 12/14/22 08:59:22.782
    STEP: updating /status 12/14/22 08:59:22.808
    STEP: get /status 12/14/22 08:59:22.858
    STEP: deleting 12/14/22 08:59:22.883
    STEP: deleting a collection 12/14/22 08:59:22.962
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Dec 14 08:59:23.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-2166" for this suite. 12/14/22 08:59:23.047
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:23.073
Dec 14 08:59:23.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:59:23.075
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:23.158
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:23.205
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:59:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6501" for this suite. 12/14/22 08:59:23.315
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":139,"skipped":2596,"failed":0}
------------------------------
• [0.268 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:23.073
    Dec 14 08:59:23.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:59:23.075
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:23.158
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:23.205
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:59:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6501" for this suite. 12/14/22 08:59:23.315
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:23.342
Dec 14 08:59:23.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 08:59:23.343
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:23.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:23.47
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/14/22 08:59:23.517
Dec 14 08:59:23.567: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 08:59:23.567
Dec 14 08:59:23.567: INFO: Waiting up to 5m0s for pod "test-rs-jhhh2" in namespace "replicaset-7567" to be "running"
Dec 14 08:59:23.594: INFO: Pod "test-rs-jhhh2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.423484ms
Dec 14 08:59:25.620: INFO: Pod "test-rs-jhhh2": Phase="Running", Reason="", readiness=true. Elapsed: 2.052819162s
Dec 14 08:59:25.620: INFO: Pod "test-rs-jhhh2" satisfied condition "running"
STEP: getting scale subresource 12/14/22 08:59:25.62
STEP: updating a scale subresource 12/14/22 08:59:25.645
STEP: verifying the replicaset Spec.Replicas was modified 12/14/22 08:59:25.675
STEP: Patch a scale subresource 12/14/22 08:59:25.704
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 08:59:25.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7567" for this suite. 12/14/22 08:59:25.807
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":140,"skipped":2597,"failed":0}
------------------------------
• [2.491 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:23.342
    Dec 14 08:59:23.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 08:59:23.343
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:23.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:23.47
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/14/22 08:59:23.517
    Dec 14 08:59:23.567: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 08:59:23.567
    Dec 14 08:59:23.567: INFO: Waiting up to 5m0s for pod "test-rs-jhhh2" in namespace "replicaset-7567" to be "running"
    Dec 14 08:59:23.594: INFO: Pod "test-rs-jhhh2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.423484ms
    Dec 14 08:59:25.620: INFO: Pod "test-rs-jhhh2": Phase="Running", Reason="", readiness=true. Elapsed: 2.052819162s
    Dec 14 08:59:25.620: INFO: Pod "test-rs-jhhh2" satisfied condition "running"
    STEP: getting scale subresource 12/14/22 08:59:25.62
    STEP: updating a scale subresource 12/14/22 08:59:25.645
    STEP: verifying the replicaset Spec.Replicas was modified 12/14/22 08:59:25.675
    STEP: Patch a scale subresource 12/14/22 08:59:25.704
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 08:59:25.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7567" for this suite. 12/14/22 08:59:25.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:25.834
Dec 14 08:59:25.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 08:59:25.836
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:25.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:25.957
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 12/14/22 08:59:26.004
STEP: wait for the container to reach Failed 12/14/22 08:59:26.035
STEP: get the container status 12/14/22 08:59:29.146
STEP: the container should be terminated 12/14/22 08:59:29.171
STEP: the termination message should be set 12/14/22 08:59:29.172
Dec 14 08:59:29.172: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/14/22 08:59:29.172
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 08:59:29.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5503" for this suite. 12/14/22 08:59:29.285
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":141,"skipped":2623,"failed":0}
------------------------------
• [3.477 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:25.834
    Dec 14 08:59:25.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 08:59:25.836
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:25.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:25.957
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 12/14/22 08:59:26.004
    STEP: wait for the container to reach Failed 12/14/22 08:59:26.035
    STEP: get the container status 12/14/22 08:59:29.146
    STEP: the container should be terminated 12/14/22 08:59:29.171
    STEP: the termination message should be set 12/14/22 08:59:29.172
    Dec 14 08:59:29.172: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/14/22 08:59:29.172
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 08:59:29.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5503" for this suite. 12/14/22 08:59:29.285
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:29.312
Dec 14 08:59:29.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:59:29.313
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:29.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:29.435
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:59:29.535
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:59:30.524
STEP: Deploying the webhook pod 12/14/22 08:59:30.551
STEP: Wait for the deployment to be ready 12/14/22 08:59:30.603
Dec 14 08:59:30.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:59:32.705
STEP: Verifying the service has paired with the endpoint 12/14/22 08:59:32.738
Dec 14 08:59:33.739: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Dec 14 08:59:33.766: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5361-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 08:59:33.815
STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 08:59:33.934
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:59:36.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1980" for this suite. 12/14/22 08:59:36.268
STEP: Destroying namespace "webhook-1980-markers" for this suite. 12/14/22 08:59:36.294
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":142,"skipped":2625,"failed":0}
------------------------------
• [7.157 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:29.312
    Dec 14 08:59:29.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:59:29.313
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:29.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:29.435
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:59:29.535
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:59:30.524
    STEP: Deploying the webhook pod 12/14/22 08:59:30.551
    STEP: Wait for the deployment to be ready 12/14/22 08:59:30.603
    Dec 14 08:59:30.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 59, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:59:32.705
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:59:32.738
    Dec 14 08:59:33.739: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Dec 14 08:59:33.766: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5361-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 08:59:33.815
    STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 08:59:33.934
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:59:36.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1980" for this suite. 12/14/22 08:59:36.268
    STEP: Destroying namespace "webhook-1980-markers" for this suite. 12/14/22 08:59:36.294
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:36.471
Dec 14 08:59:36.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:59:36.472
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:36.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:36.594
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 08:59:36.716: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 09:00:36.991: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 12/14/22 09:00:37.015
Dec 14 09:00:37.084: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 14 09:00:37.113: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 14 09:00:37.175: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 14 09:00:37.204: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/14/22 09:00:37.204
Dec 14 09:00:37.204: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8072" to be "running"
Dec 14 09:00:37.229: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 24.909174ms
Dec 14 09:00:39.255: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.051607664s
Dec 14 09:00:39.281: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec 14 09:00:39.281: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
Dec 14 09:00:39.307: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.421477ms
Dec 14 09:00:39.307: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 09:00:39.307: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
Dec 14 09:00:39.332: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 24.82001ms
Dec 14 09:00:39.332: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 09:00:39.332: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
Dec 14 09:00:39.357: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 24.710836ms
Dec 14 09:00:39.357: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 12/14/22 09:00:39.357
Dec 14 09:00:39.395: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Dec 14 09:00:39.420: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.312852ms
Dec 14 09:00:41.446: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05035774s
Dec 14 09:00:43.446: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.050794964s
Dec 14 09:00:43.446: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:00:43.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8072" for this suite. 12/14/22 09:00:43.685
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":143,"skipped":2672,"failed":0}
------------------------------
• [67.387 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:36.471
    Dec 14 08:59:36.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:59:36.472
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:36.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:36.594
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 08:59:36.716: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 09:00:36.991: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 12/14/22 09:00:37.015
    Dec 14 09:00:37.084: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec 14 09:00:37.113: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec 14 09:00:37.175: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec 14 09:00:37.204: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/14/22 09:00:37.204
    Dec 14 09:00:37.204: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8072" to be "running"
    Dec 14 09:00:37.229: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 24.909174ms
    Dec 14 09:00:39.255: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.051607664s
    Dec 14 09:00:39.281: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec 14 09:00:39.281: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
    Dec 14 09:00:39.307: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 25.421477ms
    Dec 14 09:00:39.307: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 09:00:39.307: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
    Dec 14 09:00:39.332: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 24.82001ms
    Dec 14 09:00:39.332: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 09:00:39.332: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8072" to be "running"
    Dec 14 09:00:39.357: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 24.710836ms
    Dec 14 09:00:39.357: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 12/14/22 09:00:39.357
    Dec 14 09:00:39.395: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Dec 14 09:00:39.420: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.312852ms
    Dec 14 09:00:41.446: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05035774s
    Dec 14 09:00:43.446: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.050794964s
    Dec 14 09:00:43.446: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:00:43.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8072" for this suite. 12/14/22 09:00:43.685
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:43.86
Dec 14 09:00:43.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:00:43.861
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:43.936
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:43.989
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3285 12/14/22 09:00:44.036
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 12/14/22 09:00:44.061
STEP: Creating pod with conflicting port in namespace statefulset-3285 12/14/22 09:00:44.089
STEP: Waiting until pod test-pod will start running in namespace statefulset-3285 12/14/22 09:00:44.12
Dec 14 09:00:44.120: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3285" to be "running"
Dec 14 09:00:44.144: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.146424ms
Dec 14 09:00:46.170: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.050677093s
Dec 14 09:00:46.170: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-3285 12/14/22 09:00:46.17
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3285 12/14/22 09:00:46.202
Dec 14 09:00:46.227: INFO: Observed stateful pod in namespace: statefulset-3285, name: ss-0, uid: 07dc3d76-05a0-4cea-b9f7-b2cffbea9312, status phase: Failed. Waiting for statefulset controller to delete.
Dec 14 09:00:46.261: INFO: Observed stateful pod in namespace: statefulset-3285, name: ss-0, uid: 07dc3d76-05a0-4cea-b9f7-b2cffbea9312, status phase: Failed. Waiting for statefulset controller to delete.
Dec 14 09:00:46.262: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3285
STEP: Removing pod with conflicting port in namespace statefulset-3285 12/14/22 09:00:46.262
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3285 and will be in running state 12/14/22 09:00:46.295
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:00:48.359: INFO: Deleting all statefulset in ns statefulset-3285
Dec 14 09:00:48.384: INFO: Scaling statefulset ss to 0
Dec 14 09:00:58.491: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:00:58.516: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:00:58.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3285" for this suite. 12/14/22 09:00:58.651
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":144,"skipped":2683,"failed":0}
------------------------------
• [14.817 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:43.86
    Dec 14 09:00:43.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:00:43.861
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:43.936
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:43.989
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3285 12/14/22 09:00:44.036
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 12/14/22 09:00:44.061
    STEP: Creating pod with conflicting port in namespace statefulset-3285 12/14/22 09:00:44.089
    STEP: Waiting until pod test-pod will start running in namespace statefulset-3285 12/14/22 09:00:44.12
    Dec 14 09:00:44.120: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3285" to be "running"
    Dec 14 09:00:44.144: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.146424ms
    Dec 14 09:00:46.170: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.050677093s
    Dec 14 09:00:46.170: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-3285 12/14/22 09:00:46.17
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3285 12/14/22 09:00:46.202
    Dec 14 09:00:46.227: INFO: Observed stateful pod in namespace: statefulset-3285, name: ss-0, uid: 07dc3d76-05a0-4cea-b9f7-b2cffbea9312, status phase: Failed. Waiting for statefulset controller to delete.
    Dec 14 09:00:46.261: INFO: Observed stateful pod in namespace: statefulset-3285, name: ss-0, uid: 07dc3d76-05a0-4cea-b9f7-b2cffbea9312, status phase: Failed. Waiting for statefulset controller to delete.
    Dec 14 09:00:46.262: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3285
    STEP: Removing pod with conflicting port in namespace statefulset-3285 12/14/22 09:00:46.262
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3285 and will be in running state 12/14/22 09:00:46.295
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:00:48.359: INFO: Deleting all statefulset in ns statefulset-3285
    Dec 14 09:00:48.384: INFO: Scaling statefulset ss to 0
    Dec 14 09:00:58.491: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:00:58.516: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:00:58.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3285" for this suite. 12/14/22 09:00:58.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:58.679
Dec 14 09:00:58.680: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:00:58.68
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:58.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:58.808
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-08d31f5f-bacd-4fb8-8979-3f920a8c9580 12/14/22 09:00:58.893
STEP: Creating the pod 12/14/22 09:00:58.919
Dec 14 09:00:58.950: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6" in namespace "projected-9538" to be "running and ready"
Dec 14 09:00:58.977: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 27.221053ms
Dec 14 09:00:58.977: INFO: The phase of Pod pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:01:01.006: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6": Phase="Running", Reason="", readiness=true. Elapsed: 2.056224938s
Dec 14 09:01:01.006: INFO: The phase of Pod pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6 is Running (Ready = true)
Dec 14 09:01:01.006: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-08d31f5f-bacd-4fb8-8979-3f920a8c9580 12/14/22 09:01:01.109
STEP: waiting to observe update in volume 12/14/22 09:01:01.135
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:01:03.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9538" for this suite. 12/14/22 09:01:03.251
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":145,"skipped":2728,"failed":0}
------------------------------
• [4.598 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:58.679
    Dec 14 09:00:58.680: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:00:58.68
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:58.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:58.808
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-08d31f5f-bacd-4fb8-8979-3f920a8c9580 12/14/22 09:00:58.893
    STEP: Creating the pod 12/14/22 09:00:58.919
    Dec 14 09:00:58.950: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6" in namespace "projected-9538" to be "running and ready"
    Dec 14 09:00:58.977: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 27.221053ms
    Dec 14 09:00:58.977: INFO: The phase of Pod pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:01:01.006: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6": Phase="Running", Reason="", readiness=true. Elapsed: 2.056224938s
    Dec 14 09:01:01.006: INFO: The phase of Pod pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6 is Running (Ready = true)
    Dec 14 09:01:01.006: INFO: Pod "pod-projected-configmaps-53ab8a7f-e9f5-4716-a95d-03e45b682ce6" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-08d31f5f-bacd-4fb8-8979-3f920a8c9580 12/14/22 09:01:01.109
    STEP: waiting to observe update in volume 12/14/22 09:01:01.135
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:01:03.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9538" for this suite. 12/14/22 09:01:03.251
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:03.278
Dec 14 09:01:03.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:01:03.279
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:03.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:03.404
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Dec 14 09:01:03.583: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6bc9e779-82df-48f9-a246-e6d136f2f2fe", Controller:(*bool)(0xc006210bc6), BlockOwnerDeletion:(*bool)(0xc006210bc7)}}
Dec 14 09:01:03.610: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a5ca5026-16a4-4a77-a93d-6ea8d32f76e5", Controller:(*bool)(0xc003d2c496), BlockOwnerDeletion:(*bool)(0xc003d2c497)}}
Dec 14 09:01:03.637: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"20b23710-89c5-4e86-9da8-df2e8a735f80", Controller:(*bool)(0xc0058a969e), BlockOwnerDeletion:(*bool)(0xc0058a969f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:01:08.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8921" for this suite. 12/14/22 09:01:08.738
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":146,"skipped":2743,"failed":0}
------------------------------
• [5.486 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:03.278
    Dec 14 09:01:03.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:01:03.279
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:03.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:03.404
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Dec 14 09:01:03.583: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6bc9e779-82df-48f9-a246-e6d136f2f2fe", Controller:(*bool)(0xc006210bc6), BlockOwnerDeletion:(*bool)(0xc006210bc7)}}
    Dec 14 09:01:03.610: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a5ca5026-16a4-4a77-a93d-6ea8d32f76e5", Controller:(*bool)(0xc003d2c496), BlockOwnerDeletion:(*bool)(0xc003d2c497)}}
    Dec 14 09:01:03.637: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"20b23710-89c5-4e86-9da8-df2e8a735f80", Controller:(*bool)(0xc0058a969e), BlockOwnerDeletion:(*bool)(0xc0058a969f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:01:08.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8921" for this suite. 12/14/22 09:01:08.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:08.765
Dec 14 09:01:08.765: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:01:08.766
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:08.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:08.918
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 12/14/22 09:01:08.964
Dec 14 09:01:08.996: INFO: Waiting up to 5m0s for pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4" in namespace "var-expansion-1440" to be "Succeeded or Failed"
Dec 14 09:01:09.020: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.288513ms
Dec 14 09:01:11.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049804569s
Dec 14 09:01:13.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050046285s
STEP: Saw pod success 12/14/22 09:01:13.046
Dec 14 09:01:13.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4" satisfied condition "Succeeded or Failed"
Dec 14 09:01:13.071: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:01:13.138
Dec 14 09:01:13.171: INFO: Waiting for pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 to disappear
Dec 14 09:01:13.196: INFO: Pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:01:13.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1440" for this suite. 12/14/22 09:01:13.244
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":147,"skipped":2755,"failed":0}
------------------------------
• [4.508 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:08.765
    Dec 14 09:01:08.765: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:01:08.766
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:08.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:08.918
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 12/14/22 09:01:08.964
    Dec 14 09:01:08.996: INFO: Waiting up to 5m0s for pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4" in namespace "var-expansion-1440" to be "Succeeded or Failed"
    Dec 14 09:01:09.020: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.288513ms
    Dec 14 09:01:11.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049804569s
    Dec 14 09:01:13.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050046285s
    STEP: Saw pod success 12/14/22 09:01:13.046
    Dec 14 09:01:13.046: INFO: Pod "var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:13.071: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:01:13.138
    Dec 14 09:01:13.171: INFO: Waiting for pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 to disappear
    Dec 14 09:01:13.196: INFO: Pod var-expansion-6d6d845a-bac6-473f-b957-7c4e01b7b2d4 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:01:13.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1440" for this suite. 12/14/22 09:01:13.244
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:13.273
Dec 14 09:01:13.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:01:13.274
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:13.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:13.4
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-062b1b0c-ae80-4e58-b5a4-08a7731b1524 12/14/22 09:01:13.447
STEP: Creating a pod to test consume configMaps 12/14/22 09:01:13.473
Dec 14 09:01:13.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08" in namespace "configmap-9740" to be "Succeeded or Failed"
Dec 14 09:01:13.529: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Pending", Reason="", readiness=false. Elapsed: 24.436531ms
Dec 14 09:01:15.556: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Running", Reason="", readiness=false. Elapsed: 2.051119905s
Dec 14 09:01:17.557: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051714755s
STEP: Saw pod success 12/14/22 09:01:17.557
Dec 14 09:01:17.557: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08" satisfied condition "Succeeded or Failed"
Dec 14 09:01:17.583: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:01:17.615
Dec 14 09:01:17.651: INFO: Waiting for pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 to disappear
Dec 14 09:01:17.675: INFO: Pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:01:17.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9740" for this suite. 12/14/22 09:01:17.723
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":148,"skipped":2755,"failed":0}
------------------------------
• [4.477 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:13.273
    Dec 14 09:01:13.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:01:13.274
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:13.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:13.4
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-062b1b0c-ae80-4e58-b5a4-08a7731b1524 12/14/22 09:01:13.447
    STEP: Creating a pod to test consume configMaps 12/14/22 09:01:13.473
    Dec 14 09:01:13.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08" in namespace "configmap-9740" to be "Succeeded or Failed"
    Dec 14 09:01:13.529: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Pending", Reason="", readiness=false. Elapsed: 24.436531ms
    Dec 14 09:01:15.556: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Running", Reason="", readiness=false. Elapsed: 2.051119905s
    Dec 14 09:01:17.557: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051714755s
    STEP: Saw pod success 12/14/22 09:01:17.557
    Dec 14 09:01:17.557: INFO: Pod "pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:17.583: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:01:17.615
    Dec 14 09:01:17.651: INFO: Waiting for pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 to disappear
    Dec 14 09:01:17.675: INFO: Pod pod-configmaps-9d59cd75-de42-46ed-b136-f783c7f2be08 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:01:17.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9740" for this suite. 12/14/22 09:01:17.723
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:17.75
Dec 14 09:01:17.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:01:17.751
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:17.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:17.877
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Dec 14 09:01:17.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/14/22 09:01:23.054
Dec 14 09:01:23.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
Dec 14 09:01:23.949: INFO: stderr: ""
Dec 14 09:01:23.949: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 14 09:01:23.949: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 delete e2e-test-crd-publish-openapi-2472-crds test-foo'
Dec 14 09:01:24.171: INFO: stderr: ""
Dec 14 09:01:24.171: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 14 09:01:24.171: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
Dec 14 09:01:24.535: INFO: stderr: ""
Dec 14 09:01:24.535: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 14 09:01:24.535: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 delete e2e-test-crd-publish-openapi-2472-crds test-foo'
Dec 14 09:01:24.713: INFO: stderr: ""
Dec 14 09:01:24.713: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/14/22 09:01:24.713
Dec 14 09:01:24.713: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
Dec 14 09:01:25.503: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/14/22 09:01:25.503
Dec 14 09:01:25.503: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
Dec 14 09:01:25.822: INFO: rc: 1
Dec 14 09:01:25.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
Dec 14 09:01:26.174: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/14/22 09:01:26.175
Dec 14 09:01:26.175: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
Dec 14 09:01:26.541: INFO: rc: 1
Dec 14 09:01:26.541: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
Dec 14 09:01:26.920: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 12/14/22 09:01:26.92
Dec 14 09:01:26.920: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds'
Dec 14 09:01:27.228: INFO: stderr: ""
Dec 14 09:01:27.228: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 12/14/22 09:01:27.229
Dec 14 09:01:27.229: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.metadata'
Dec 14 09:01:27.557: INFO: stderr: ""
Dec 14 09:01:27.557: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 14 09:01:27.557: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec'
Dec 14 09:01:27.844: INFO: stderr: ""
Dec 14 09:01:27.844: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 14 09:01:27.844: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec.bars'
Dec 14 09:01:28.151: INFO: stderr: ""
Dec 14 09:01:28.151: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/14/22 09:01:28.151
Dec 14 09:01:28.152: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec.bars2'
Dec 14 09:01:28.466: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:01:31.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9509" for this suite. 12/14/22 09:01:32.03
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":149,"skipped":2758,"failed":0}
------------------------------
• [14.308 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:17.75
    Dec 14 09:01:17.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:01:17.751
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:17.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:17.877
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Dec 14 09:01:17.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/14/22 09:01:23.054
    Dec 14 09:01:23.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
    Dec 14 09:01:23.949: INFO: stderr: ""
    Dec 14 09:01:23.949: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec 14 09:01:23.949: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 delete e2e-test-crd-publish-openapi-2472-crds test-foo'
    Dec 14 09:01:24.171: INFO: stderr: ""
    Dec 14 09:01:24.171: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Dec 14 09:01:24.171: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
    Dec 14 09:01:24.535: INFO: stderr: ""
    Dec 14 09:01:24.535: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec 14 09:01:24.535: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 delete e2e-test-crd-publish-openapi-2472-crds test-foo'
    Dec 14 09:01:24.713: INFO: stderr: ""
    Dec 14 09:01:24.713: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/14/22 09:01:24.713
    Dec 14 09:01:24.713: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
    Dec 14 09:01:25.503: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/14/22 09:01:25.503
    Dec 14 09:01:25.503: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
    Dec 14 09:01:25.822: INFO: rc: 1
    Dec 14 09:01:25.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
    Dec 14 09:01:26.174: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/14/22 09:01:26.175
    Dec 14 09:01:26.175: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 create -f -'
    Dec 14 09:01:26.541: INFO: rc: 1
    Dec 14 09:01:26.541: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 --namespace=crd-publish-openapi-9509 apply -f -'
    Dec 14 09:01:26.920: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 12/14/22 09:01:26.92
    Dec 14 09:01:26.920: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds'
    Dec 14 09:01:27.228: INFO: stderr: ""
    Dec 14 09:01:27.228: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 12/14/22 09:01:27.229
    Dec 14 09:01:27.229: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.metadata'
    Dec 14 09:01:27.557: INFO: stderr: ""
    Dec 14 09:01:27.557: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Dec 14 09:01:27.557: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec'
    Dec 14 09:01:27.844: INFO: stderr: ""
    Dec 14 09:01:27.844: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Dec 14 09:01:27.844: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec.bars'
    Dec 14 09:01:28.151: INFO: stderr: ""
    Dec 14 09:01:28.151: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/14/22 09:01:28.151
    Dec 14 09:01:28.152: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9509 explain e2e-test-crd-publish-openapi-2472-crds.spec.bars2'
    Dec 14 09:01:28.466: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:01:31.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9509" for this suite. 12/14/22 09:01:32.03
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:32.058
Dec 14 09:01:32.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 09:01:32.059
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:32.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:32.187
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Dec 14 09:01:32.269: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040" in namespace "security-context-test-7469" to be "Succeeded or Failed"
Dec 14 09:01:32.295: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Pending", Reason="", readiness=false. Elapsed: 25.837855ms
Dec 14 09:01:34.324: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054801117s
Dec 14 09:01:36.323: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054185888s
Dec 14 09:01:36.323: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040" satisfied condition "Succeeded or Failed"
Dec 14 09:01:36.360: INFO: Got logs for pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 09:01:36.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7469" for this suite. 12/14/22 09:01:36.411
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":150,"skipped":2763,"failed":0}
------------------------------
• [4.381 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:32.058
    Dec 14 09:01:32.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 09:01:32.059
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:32.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:32.187
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Dec 14 09:01:32.269: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040" in namespace "security-context-test-7469" to be "Succeeded or Failed"
    Dec 14 09:01:32.295: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Pending", Reason="", readiness=false. Elapsed: 25.837855ms
    Dec 14 09:01:34.324: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054801117s
    Dec 14 09:01:36.323: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054185888s
    Dec 14 09:01:36.323: INFO: Pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:36.360: INFO: Got logs for pod "busybox-privileged-false-3f0afc32-8983-4a5a-a76c-60750b1a0040": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 09:01:36.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7469" for this suite. 12/14/22 09:01:36.411
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:36.44
Dec 14 09:01:36.440: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:01:36.441
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:36.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:36.569
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-50260204-8c24-49dc-acce-9f4da46fd0b3 12/14/22 09:01:36.62
STEP: Creating a pod to test consume configMaps 12/14/22 09:01:36.646
Dec 14 09:01:36.678: INFO: Waiting up to 5m0s for pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5" in namespace "configmap-772" to be "Succeeded or Failed"
Dec 14 09:01:36.705: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.845694ms
Dec 14 09:01:38.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057296824s
Dec 14 09:01:40.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056783488s
STEP: Saw pod success 12/14/22 09:01:40.735
Dec 14 09:01:40.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5" satisfied condition "Succeeded or Failed"
Dec 14 09:01:40.761: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:01:40.796
Dec 14 09:01:40.831: INFO: Waiting for pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 to disappear
Dec 14 09:01:40.858: INFO: Pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:01:40.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-772" for this suite. 12/14/22 09:01:40.909
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":151,"skipped":2775,"failed":0}
------------------------------
• [4.497 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:36.44
    Dec 14 09:01:36.440: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:01:36.441
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:36.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:36.569
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-50260204-8c24-49dc-acce-9f4da46fd0b3 12/14/22 09:01:36.62
    STEP: Creating a pod to test consume configMaps 12/14/22 09:01:36.646
    Dec 14 09:01:36.678: INFO: Waiting up to 5m0s for pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5" in namespace "configmap-772" to be "Succeeded or Failed"
    Dec 14 09:01:36.705: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.845694ms
    Dec 14 09:01:38.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057296824s
    Dec 14 09:01:40.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056783488s
    STEP: Saw pod success 12/14/22 09:01:40.735
    Dec 14 09:01:40.735: INFO: Pod "pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:40.761: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:01:40.796
    Dec 14 09:01:40.831: INFO: Waiting for pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 to disappear
    Dec 14 09:01:40.858: INFO: Pod pod-configmaps-b170e93b-dd75-4373-b511-0d3cdc492ae5 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:01:40.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-772" for this suite. 12/14/22 09:01:40.909
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:40.938
Dec 14 09:01:40.938: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:01:40.939
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:41.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:41.074
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 12/14/22 09:01:41.124
STEP: Ensuring a job is scheduled 12/14/22 09:01:41.154
STEP: Ensuring exactly one is scheduled 12/14/22 09:02:01.184
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:02:01.246
STEP: Ensuring no more jobs are scheduled 12/14/22 09:02:01.272
STEP: Removing cronjob 12/14/22 09:07:01.325
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:07:01.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8923" for this suite. 12/14/22 09:07:01.403
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":152,"skipped":2776,"failed":0}
------------------------------
• [SLOW TEST] [320.494 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:40.938
    Dec 14 09:01:40.938: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:01:40.939
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:41.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:41.074
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 12/14/22 09:01:41.124
    STEP: Ensuring a job is scheduled 12/14/22 09:01:41.154
    STEP: Ensuring exactly one is scheduled 12/14/22 09:02:01.184
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:02:01.246
    STEP: Ensuring no more jobs are scheduled 12/14/22 09:02:01.272
    STEP: Removing cronjob 12/14/22 09:07:01.325
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:07:01.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8923" for this suite. 12/14/22 09:07:01.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:01.433
Dec 14 09:07:01.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:07:01.434
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:01.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:01.563
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 12/14/22 09:07:01.612
Dec 14 09:07:01.659: INFO: Waiting up to 5m0s for pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10" in namespace "downward-api-8035" to be "Succeeded or Failed"
Dec 14 09:07:01.684: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Pending", Reason="", readiness=false. Elapsed: 25.694572ms
Dec 14 09:07:03.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052436617s
Dec 14 09:07:05.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052538996s
STEP: Saw pod success 12/14/22 09:07:05.711
Dec 14 09:07:05.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10" satisfied condition "Succeeded or Failed"
Dec 14 09:07:05.737: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:07:05.773
Dec 14 09:07:05.807: INFO: Waiting for pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 to disappear
Dec 14 09:07:05.833: INFO: Pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 09:07:05.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8035" for this suite. 12/14/22 09:07:05.883
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":153,"skipped":2796,"failed":0}
------------------------------
• [4.477 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:01.433
    Dec 14 09:07:01.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:07:01.434
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:01.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:01.563
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 12/14/22 09:07:01.612
    Dec 14 09:07:01.659: INFO: Waiting up to 5m0s for pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10" in namespace "downward-api-8035" to be "Succeeded or Failed"
    Dec 14 09:07:01.684: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Pending", Reason="", readiness=false. Elapsed: 25.694572ms
    Dec 14 09:07:03.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052436617s
    Dec 14 09:07:05.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052538996s
    STEP: Saw pod success 12/14/22 09:07:05.711
    Dec 14 09:07:05.711: INFO: Pod "downward-api-9054977b-fd29-4049-a836-b147c2e73a10" satisfied condition "Succeeded or Failed"
    Dec 14 09:07:05.737: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:07:05.773
    Dec 14 09:07:05.807: INFO: Waiting for pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 to disappear
    Dec 14 09:07:05.833: INFO: Pod downward-api-9054977b-fd29-4049-a836-b147c2e73a10 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 09:07:05.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8035" for this suite. 12/14/22 09:07:05.883
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:05.911
Dec 14 09:07:05.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:07:05.912
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:05.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:06.04
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:07:10.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5602" for this suite. 12/14/22 09:07:10.229
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":154,"skipped":2802,"failed":0}
------------------------------
• [4.346 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:05.911
    Dec 14 09:07:05.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:07:05.912
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:05.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:06.04
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:07:10.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5602" for this suite. 12/14/22 09:07:10.229
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:10.261
Dec 14 09:07:10.261: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:07:10.262
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:10.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:10.392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:07:10.442
Dec 14 09:07:10.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 14 09:07:10.643: INFO: stderr: ""
Dec 14 09:07:10.644: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 12/14/22 09:07:10.644
STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:07:15.696
Dec 14 09:07:15.696: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 get pod e2e-test-httpd-pod -o json'
Dec 14 09:07:16.001: INFO: stderr: ""
Dec 14 09:07:16.001: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"76aca611f6bf859643eb2a8f2c04daa0c08970d0eacad337e0220ae2604567d1\",\n            \"cni.projectcalico.org/podIP\": \"100.64.0.79/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.0.79/32\"\n        },\n        \"creationTimestamp\": \"2022-12-14T09:07:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6354\",\n        \"resourceVersion\": \"31284\",\n        \"uid\": \"b228a6a0-702f-4a1a-b02c-2fdf978df519\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-f7hfn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-f7hfn\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://bbd2f1a17419d58591708d3dae9db3df46abba54c221563a861b4807272351f3\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-14T09:07:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.0.79\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.0.79\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-14T09:07:10Z\"\n    }\n}\n"
STEP: replace the image in the pod 12/14/22 09:07:16.001
Dec 14 09:07:16.001: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 replace -f -'
Dec 14 09:07:16.777: INFO: stderr: ""
Dec 14 09:07:16.777: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/14/22 09:07:16.777
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Dec 14 09:07:16.804: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 delete pods e2e-test-httpd-pod'
Dec 14 09:07:19.109: INFO: stderr: ""
Dec 14 09:07:19.109: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:07:19.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6354" for this suite. 12/14/22 09:07:19.163
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":155,"skipped":2879,"failed":0}
------------------------------
• [8.929 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:10.261
    Dec 14 09:07:10.261: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:07:10.262
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:10.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:10.392
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:07:10.442
    Dec 14 09:07:10.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec 14 09:07:10.643: INFO: stderr: ""
    Dec 14 09:07:10.644: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 12/14/22 09:07:10.644
    STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:07:15.696
    Dec 14 09:07:15.696: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 get pod e2e-test-httpd-pod -o json'
    Dec 14 09:07:16.001: INFO: stderr: ""
    Dec 14 09:07:16.001: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"76aca611f6bf859643eb2a8f2c04daa0c08970d0eacad337e0220ae2604567d1\",\n            \"cni.projectcalico.org/podIP\": \"100.64.0.79/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.0.79/32\"\n        },\n        \"creationTimestamp\": \"2022-12-14T09:07:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6354\",\n        \"resourceVersion\": \"31284\",\n        \"uid\": \"b228a6a0-702f-4a1a-b02c-2fdf978df519\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-f7hfn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-f7hfn\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://bbd2f1a17419d58591708d3dae9db3df46abba54c221563a861b4807272351f3\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-14T09:07:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.0.79\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.0.79\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-14T09:07:10Z\"\n    }\n}\n"
    STEP: replace the image in the pod 12/14/22 09:07:16.001
    Dec 14 09:07:16.001: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 replace -f -'
    Dec 14 09:07:16.777: INFO: stderr: ""
    Dec 14 09:07:16.777: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/14/22 09:07:16.777
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Dec 14 09:07:16.804: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6354 delete pods e2e-test-httpd-pod'
    Dec 14 09:07:19.109: INFO: stderr: ""
    Dec 14 09:07:19.109: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:07:19.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6354" for this suite. 12/14/22 09:07:19.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:19.191
Dec 14 09:07:19.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:07:19.192
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:19.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:19.32
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-b6f59d10-1091-4834-96bb-a9a283107652 12/14/22 09:07:19.369
STEP: Creating a pod to test consume configMaps 12/14/22 09:07:19.396
Dec 14 09:07:19.428: INFO: Waiting up to 5m0s for pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05" in namespace "configmap-4495" to be "Succeeded or Failed"
Dec 14 09:07:19.454: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Pending", Reason="", readiness=false. Elapsed: 25.795746ms
Dec 14 09:07:21.481: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052385981s
Dec 14 09:07:23.485: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05666268s
STEP: Saw pod success 12/14/22 09:07:23.485
Dec 14 09:07:23.485: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05" satisfied condition "Succeeded or Failed"
Dec 14 09:07:23.511: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:07:23.545
Dec 14 09:07:23.581: INFO: Waiting for pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 to disappear
Dec 14 09:07:23.606: INFO: Pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:07:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4495" for this suite. 12/14/22 09:07:23.658
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":156,"skipped":2891,"failed":0}
------------------------------
• [4.496 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:19.191
    Dec 14 09:07:19.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:07:19.192
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:19.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:19.32
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-b6f59d10-1091-4834-96bb-a9a283107652 12/14/22 09:07:19.369
    STEP: Creating a pod to test consume configMaps 12/14/22 09:07:19.396
    Dec 14 09:07:19.428: INFO: Waiting up to 5m0s for pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05" in namespace "configmap-4495" to be "Succeeded or Failed"
    Dec 14 09:07:19.454: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Pending", Reason="", readiness=false. Elapsed: 25.795746ms
    Dec 14 09:07:21.481: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052385981s
    Dec 14 09:07:23.485: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05666268s
    STEP: Saw pod success 12/14/22 09:07:23.485
    Dec 14 09:07:23.485: INFO: Pod "pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05" satisfied condition "Succeeded or Failed"
    Dec 14 09:07:23.511: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:07:23.545
    Dec 14 09:07:23.581: INFO: Waiting for pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 to disappear
    Dec 14 09:07:23.606: INFO: Pod pod-configmaps-364508e3-50e5-497b-bb74-f9dae2adba05 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:07:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4495" for this suite. 12/14/22 09:07:23.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:23.687
Dec 14 09:07:23.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ephemeral-containers-test 12/14/22 09:07:23.688
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:23.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:23.817
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 12/14/22 09:07:23.866
Dec 14 09:07:23.897: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-8412" to be "running and ready"
Dec 14 09:07:23.923: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.314783ms
Dec 14 09:07:23.923: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:07:25.950: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05285873s
Dec 14 09:07:25.950: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Dec 14 09:07:25.950: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 12/14/22 09:07:25.977
Dec 14 09:07:26.015: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-8412" to be "container debugger running"
Dec 14 09:07:26.041: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 26.351476ms
Dec 14 09:07:28.070: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.055173406s
Dec 14 09:07:30.069: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.054547322s
Dec 14 09:07:30.069: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 12/14/22 09:07:30.069
Dec 14 09:07:30.070: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8412 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:07:30.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:07:30.070: INFO: ExecWithOptions: Clientset creation
Dec 14 09:07:30.070: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/ephemeral-containers-test-8412/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Dec 14 09:07:30.547: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:07:30.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-8412" for this suite. 12/14/22 09:07:30.683
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":157,"skipped":2902,"failed":0}
------------------------------
• [7.023 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:23.687
    Dec 14 09:07:23.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ephemeral-containers-test 12/14/22 09:07:23.688
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:23.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:23.817
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 12/14/22 09:07:23.866
    Dec 14 09:07:23.897: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-8412" to be "running and ready"
    Dec 14 09:07:23.923: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.314783ms
    Dec 14 09:07:23.923: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:07:25.950: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05285873s
    Dec 14 09:07:25.950: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Dec 14 09:07:25.950: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 12/14/22 09:07:25.977
    Dec 14 09:07:26.015: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-8412" to be "container debugger running"
    Dec 14 09:07:26.041: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 26.351476ms
    Dec 14 09:07:28.070: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.055173406s
    Dec 14 09:07:30.069: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.054547322s
    Dec 14 09:07:30.069: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 12/14/22 09:07:30.069
    Dec 14 09:07:30.070: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8412 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:07:30.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:07:30.070: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:07:30.070: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/ephemeral-containers-test-8412/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Dec 14 09:07:30.547: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:07:30.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-8412" for this suite. 12/14/22 09:07:30.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:30.711
Dec 14 09:07:30.711: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:07:30.712
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:30.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:30.839
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:07:30.944
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:07:31.342
STEP: Deploying the webhook pod 12/14/22 09:07:31.371
STEP: Wait for the deployment to be ready 12/14/22 09:07:31.427
Dec 14 09:07:31.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:07:33.56
STEP: Verifying the service has paired with the endpoint 12/14/22 09:07:33.596
Dec 14 09:07:34.597: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 09:07:34.624
STEP: create a pod 12/14/22 09:07:34.792
Dec 14 09:07:34.823: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4616" to be "running"
Dec 14 09:07:34.849: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.269951ms
Dec 14 09:07:36.877: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.053994043s
Dec 14 09:07:36.877: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 12/14/22 09:07:36.877
Dec 14 09:07:36.877: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=webhook-4616 attach --namespace=webhook-4616 to-be-attached-pod -i -c=container1'
Dec 14 09:07:37.215: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:07:37.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4616" for this suite. 12/14/22 09:07:37.297
STEP: Destroying namespace "webhook-4616-markers" for this suite. 12/14/22 09:07:37.325
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":158,"skipped":2916,"failed":0}
------------------------------
• [6.778 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:30.711
    Dec 14 09:07:30.711: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:07:30.712
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:30.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:30.839
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:07:30.944
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:07:31.342
    STEP: Deploying the webhook pod 12/14/22 09:07:31.371
    STEP: Wait for the deployment to be ready 12/14/22 09:07:31.427
    Dec 14 09:07:31.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:07:33.56
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:07:33.596
    Dec 14 09:07:34.597: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 09:07:34.624
    STEP: create a pod 12/14/22 09:07:34.792
    Dec 14 09:07:34.823: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4616" to be "running"
    Dec 14 09:07:34.849: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.269951ms
    Dec 14 09:07:36.877: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.053994043s
    Dec 14 09:07:36.877: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 12/14/22 09:07:36.877
    Dec 14 09:07:36.877: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=webhook-4616 attach --namespace=webhook-4616 to-be-attached-pod -i -c=container1'
    Dec 14 09:07:37.215: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:07:37.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4616" for this suite. 12/14/22 09:07:37.297
    STEP: Destroying namespace "webhook-4616-markers" for this suite. 12/14/22 09:07:37.325
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:37.49
Dec 14 09:07:37.490: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:07:37.491
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:37.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:37.623
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 12/14/22 09:07:37.7
STEP: waiting for RC to be added 12/14/22 09:07:37.727
STEP: waiting for available Replicas 12/14/22 09:07:37.727
STEP: patching ReplicationController 12/14/22 09:07:39.142
STEP: waiting for RC to be modified 12/14/22 09:07:39.171
STEP: patching ReplicationController status 12/14/22 09:07:39.171
STEP: waiting for RC to be modified 12/14/22 09:07:39.199
STEP: waiting for available Replicas 12/14/22 09:07:39.199
STEP: fetching ReplicationController status 12/14/22 09:07:39.21
STEP: patching ReplicationController scale 12/14/22 09:07:39.237
STEP: waiting for RC to be modified 12/14/22 09:07:39.264
STEP: waiting for ReplicationController's scale to be the max amount 12/14/22 09:07:39.265
STEP: fetching ReplicationController; ensuring that it's patched 12/14/22 09:07:40.778
STEP: updating ReplicationController status 12/14/22 09:07:40.807
STEP: waiting for RC to be modified 12/14/22 09:07:40.835
STEP: listing all ReplicationControllers 12/14/22 09:07:40.835
STEP: checking that ReplicationController has expected values 12/14/22 09:07:40.861
STEP: deleting ReplicationControllers by collection 12/14/22 09:07:40.861
STEP: waiting for ReplicationController to have a DELETED watchEvent 12/14/22 09:07:40.891
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:07:40.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-312" for this suite. 12/14/22 09:07:41.004
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":159,"skipped":2955,"failed":0}
------------------------------
• [3.543 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:37.49
    Dec 14 09:07:37.490: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:07:37.491
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:37.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:37.623
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 12/14/22 09:07:37.7
    STEP: waiting for RC to be added 12/14/22 09:07:37.727
    STEP: waiting for available Replicas 12/14/22 09:07:37.727
    STEP: patching ReplicationController 12/14/22 09:07:39.142
    STEP: waiting for RC to be modified 12/14/22 09:07:39.171
    STEP: patching ReplicationController status 12/14/22 09:07:39.171
    STEP: waiting for RC to be modified 12/14/22 09:07:39.199
    STEP: waiting for available Replicas 12/14/22 09:07:39.199
    STEP: fetching ReplicationController status 12/14/22 09:07:39.21
    STEP: patching ReplicationController scale 12/14/22 09:07:39.237
    STEP: waiting for RC to be modified 12/14/22 09:07:39.264
    STEP: waiting for ReplicationController's scale to be the max amount 12/14/22 09:07:39.265
    STEP: fetching ReplicationController; ensuring that it's patched 12/14/22 09:07:40.778
    STEP: updating ReplicationController status 12/14/22 09:07:40.807
    STEP: waiting for RC to be modified 12/14/22 09:07:40.835
    STEP: listing all ReplicationControllers 12/14/22 09:07:40.835
    STEP: checking that ReplicationController has expected values 12/14/22 09:07:40.861
    STEP: deleting ReplicationControllers by collection 12/14/22 09:07:40.861
    STEP: waiting for ReplicationController to have a DELETED watchEvent 12/14/22 09:07:40.891
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:07:40.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-312" for this suite. 12/14/22 09:07:41.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:41.034
Dec 14 09:07:41.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:07:41.035
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:41.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:41.164
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 12/14/22 09:07:41.213
STEP: Creating a ResourceQuota 12/14/22 09:07:46.239
STEP: Ensuring resource quota status is calculated 12/14/22 09:07:46.266
STEP: Creating a ReplicaSet 12/14/22 09:07:48.296
STEP: Ensuring resource quota status captures replicaset creation 12/14/22 09:07:48.328
STEP: Deleting a ReplicaSet 12/14/22 09:07:50.356
STEP: Ensuring resource quota status released usage 12/14/22 09:07:50.386
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:07:52.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4556" for this suite. 12/14/22 09:07:52.464
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":160,"skipped":2967,"failed":0}
------------------------------
• [11.458 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:41.034
    Dec 14 09:07:41.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:07:41.035
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:41.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:41.164
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 12/14/22 09:07:41.213
    STEP: Creating a ResourceQuota 12/14/22 09:07:46.239
    STEP: Ensuring resource quota status is calculated 12/14/22 09:07:46.266
    STEP: Creating a ReplicaSet 12/14/22 09:07:48.296
    STEP: Ensuring resource quota status captures replicaset creation 12/14/22 09:07:48.328
    STEP: Deleting a ReplicaSet 12/14/22 09:07:50.356
    STEP: Ensuring resource quota status released usage 12/14/22 09:07:50.386
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:07:52.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4556" for this suite. 12/14/22 09:07:52.464
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:52.493
Dec 14 09:07:52.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:07:52.493
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:52.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:52.621
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 12/14/22 09:07:52.671
Dec 14 09:07:52.703: INFO: Waiting up to 5m0s for pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9" in namespace "emptydir-6837" to be "Succeeded or Failed"
Dec 14 09:07:52.732: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Pending", Reason="", readiness=false. Elapsed: 29.095899ms
Dec 14 09:07:54.759: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056314249s
Dec 14 09:07:56.760: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056660881s
STEP: Saw pod success 12/14/22 09:07:56.76
Dec 14 09:07:56.760: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9" satisfied condition "Succeeded or Failed"
Dec 14 09:07:56.787: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 container test-container: <nil>
STEP: delete the pod 12/14/22 09:07:56.862
Dec 14 09:07:56.894: INFO: Waiting for pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 to disappear
Dec 14 09:07:56.920: INFO: Pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:07:56.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6837" for this suite. 12/14/22 09:07:56.971
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":161,"skipped":2978,"failed":0}
------------------------------
• [4.506 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:52.493
    Dec 14 09:07:52.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:07:52.493
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:52.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:52.621
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 12/14/22 09:07:52.671
    Dec 14 09:07:52.703: INFO: Waiting up to 5m0s for pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9" in namespace "emptydir-6837" to be "Succeeded or Failed"
    Dec 14 09:07:52.732: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Pending", Reason="", readiness=false. Elapsed: 29.095899ms
    Dec 14 09:07:54.759: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056314249s
    Dec 14 09:07:56.760: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056660881s
    STEP: Saw pod success 12/14/22 09:07:56.76
    Dec 14 09:07:56.760: INFO: Pod "pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9" satisfied condition "Succeeded or Failed"
    Dec 14 09:07:56.787: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:07:56.862
    Dec 14 09:07:56.894: INFO: Waiting for pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 to disappear
    Dec 14 09:07:56.920: INFO: Pod pod-bdc1edf3-f0e0-498b-b5e7-6b0aa9a82ee9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:07:56.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6837" for this suite. 12/14/22 09:07:56.971
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:57.001
Dec 14 09:07:57.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:07:57.002
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:57.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:57.13
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:07:57.234
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:07:57.81
STEP: Deploying the webhook pod 12/14/22 09:07:57.837
STEP: Wait for the deployment to be ready 12/14/22 09:07:57.89
Dec 14 09:07:57.976: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:08:00.003
STEP: Verifying the service has paired with the endpoint 12/14/22 09:08:00.039
Dec 14 09:08:01.039: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 12/14/22 09:08:01.066
STEP: Creating a custom resource definition that should be denied by the webhook 12/14/22 09:08:01.206
Dec 14 09:08:01.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:08:01.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8117" for this suite. 12/14/22 09:08:01.417
STEP: Destroying namespace "webhook-8117-markers" for this suite. 12/14/22 09:08:01.444
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":162,"skipped":3011,"failed":0}
------------------------------
• [4.598 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:57.001
    Dec 14 09:07:57.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:07:57.002
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:57.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:57.13
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:07:57.234
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:07:57.81
    STEP: Deploying the webhook pod 12/14/22 09:07:57.837
    STEP: Wait for the deployment to be ready 12/14/22 09:07:57.89
    Dec 14 09:07:57.976: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:08:00.003
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:08:00.039
    Dec 14 09:08:01.039: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 12/14/22 09:08:01.066
    STEP: Creating a custom resource definition that should be denied by the webhook 12/14/22 09:08:01.206
    Dec 14 09:08:01.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:08:01.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8117" for this suite. 12/14/22 09:08:01.417
    STEP: Destroying namespace "webhook-8117-markers" for this suite. 12/14/22 09:08:01.444
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:01.599
Dec 14 09:08:01.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:08:01.6
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:01.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:01.736
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 12/14/22 09:08:01.786
STEP: get a list of Events with a label in the current namespace 12/14/22 09:08:01.867
STEP: delete a list of events 12/14/22 09:08:01.894
Dec 14 09:08:01.894: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/14/22 09:08:01.928
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec 14 09:08:01.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7017" for this suite. 12/14/22 09:08:01.983
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":163,"skipped":3020,"failed":0}
------------------------------
• [0.411 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:01.599
    Dec 14 09:08:01.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:08:01.6
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:01.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:01.736
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 12/14/22 09:08:01.786
    STEP: get a list of Events with a label in the current namespace 12/14/22 09:08:01.867
    STEP: delete a list of events 12/14/22 09:08:01.894
    Dec 14 09:08:01.894: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/14/22 09:08:01.928
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec 14 09:08:01.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-7017" for this suite. 12/14/22 09:08:01.983
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:02.011
Dec 14 09:08:02.011: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:08:02.011
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:02.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:02.14
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 12/14/22 09:08:02.189
Dec 14 09:08:02.222: INFO: Waiting up to 5m0s for pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc" in namespace "containers-7127" to be "Succeeded or Failed"
Dec 14 09:08:02.247: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Pending", Reason="", readiness=false. Elapsed: 25.746264ms
Dec 14 09:08:04.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053962066s
Dec 14 09:08:06.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053840791s
STEP: Saw pod success 12/14/22 09:08:06.276
Dec 14 09:08:06.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc" satisfied condition "Succeeded or Failed"
Dec 14 09:08:06.305: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:08:06.34
Dec 14 09:08:06.373: INFO: Waiting for pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc to disappear
Dec 14 09:08:06.399: INFO: Pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:08:06.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7127" for this suite. 12/14/22 09:08:06.45
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":164,"skipped":3020,"failed":0}
------------------------------
• [4.467 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:02.011
    Dec 14 09:08:02.011: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:08:02.011
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:02.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:02.14
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 12/14/22 09:08:02.189
    Dec 14 09:08:02.222: INFO: Waiting up to 5m0s for pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc" in namespace "containers-7127" to be "Succeeded or Failed"
    Dec 14 09:08:02.247: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Pending", Reason="", readiness=false. Elapsed: 25.746264ms
    Dec 14 09:08:04.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053962066s
    Dec 14 09:08:06.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053840791s
    STEP: Saw pod success 12/14/22 09:08:06.276
    Dec 14 09:08:06.276: INFO: Pod "client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:06.305: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:08:06.34
    Dec 14 09:08:06.373: INFO: Waiting for pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc to disappear
    Dec 14 09:08:06.399: INFO: Pod client-containers-929adbdb-cf65-45ec-81d7-d25593a2dbcc no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:08:06.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7127" for this suite. 12/14/22 09:08:06.45
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:06.478
Dec 14 09:08:06.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:08:06.479
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:06.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:06.606
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/14/22 09:08:06.655
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:08:07.044
STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:08:07.072
STEP: Wait for the deployment to be ready 12/14/22 09:08:07.125
Dec 14 09:08:07.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:08:09.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:08:11.237
STEP: Verifying the service has paired with the endpoint 12/14/22 09:08:11.276
Dec 14 09:08:12.276: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Dec 14 09:08:12.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource 12/14/22 09:08:14.679
STEP: v2 custom resource should be converted 12/14/22 09:08:14.706
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:08:14.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6334" for this suite. 12/14/22 09:08:14.865
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":165,"skipped":3022,"failed":0}
------------------------------
• [8.558 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:06.478
    Dec 14 09:08:06.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:08:06.479
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:06.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:06.606
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/14/22 09:08:06.655
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:08:07.044
    STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:08:07.072
    STEP: Wait for the deployment to be ready 12/14/22 09:08:07.125
    Dec 14 09:08:07.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:08:09.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 8, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:08:11.237
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:08:11.276
    Dec 14 09:08:12.276: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Dec 14 09:08:12.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating a v1 custom resource 12/14/22 09:08:14.679
    STEP: v2 custom resource should be converted 12/14/22 09:08:14.706
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:08:14.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6334" for this suite. 12/14/22 09:08:14.865
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:15.037
Dec 14 09:08:15.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:08:15.038
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:15.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:15.167
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-3757 12/14/22 09:08:15.232
STEP: creating replication controller nodeport-test in namespace services-3757 12/14/22 09:08:15.277
I1214 09:08:15.305832    6274 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3757, replica count: 2
I1214 09:08:18.357292    6274 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:08:18.357: INFO: Creating new exec pod
Dec 14 09:08:18.387: INFO: Waiting up to 5m0s for pod "execpodp2tt6" in namespace "services-3757" to be "running"
Dec 14 09:08:18.413: INFO: Pod "execpodp2tt6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.705565ms
Dec 14 09:08:20.441: INFO: Pod "execpodp2tt6": Phase="Running", Reason="", readiness=true. Elapsed: 2.053990829s
Dec 14 09:08:20.441: INFO: Pod "execpodp2tt6" satisfied condition "running"
Dec 14 09:08:21.492: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:22.162: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:22.162: INFO: stdout: ""
Dec 14 09:08:23.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:23.735: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:23.736: INFO: stdout: ""
Dec 14 09:08:24.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:24.768: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:24.768: INFO: stdout: ""
Dec 14 09:08:25.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:25.798: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:25.798: INFO: stdout: ""
Dec 14 09:08:26.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:26.809: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:26.809: INFO: stdout: ""
Dec 14 09:08:27.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 09:08:27.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:27.757: INFO: stdout: "nodeport-test-9msm4"
Dec 14 09:08:27.758: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.72.56 80'
Dec 14 09:08:28.347: INFO: stderr: "+ nc -v -t -w 2 100.108.72.56 80\nConnection to 100.108.72.56 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 14 09:08:28.348: INFO: stdout: "nodeport-test-t8z4b"
Dec 14 09:08:28.348: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32222'
Dec 14 09:08:28.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32222\nConnection to 10.250.0.5 32222 port [tcp/*] succeeded!\n"
Dec 14 09:08:28.927: INFO: stdout: "nodeport-test-9msm4"
Dec 14 09:08:28.927: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
Dec 14 09:08:29.572: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32222\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
Dec 14 09:08:29.572: INFO: stdout: ""
Dec 14 09:08:30.572: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
Dec 14 09:08:31.154: INFO: stderr: "+ + nc -v -t -w 2 10.250.0.4 32222\necho hostName\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
Dec 14 09:08:31.154: INFO: stdout: ""
Dec 14 09:08:31.572: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
Dec 14 09:08:32.202: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32222\n+ echo hostName\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
Dec 14 09:08:32.202: INFO: stdout: ""
Dec 14 09:08:32.573: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
Dec 14 09:08:33.210: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32222\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
Dec 14 09:08:33.210: INFO: stdout: "nodeport-test-t8z4b"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:08:33.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3757" for this suite. 12/14/22 09:08:33.261
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":166,"skipped":3037,"failed":0}
------------------------------
• [18.252 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:15.037
    Dec 14 09:08:15.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:08:15.038
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:15.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:15.167
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-3757 12/14/22 09:08:15.232
    STEP: creating replication controller nodeport-test in namespace services-3757 12/14/22 09:08:15.277
    I1214 09:08:15.305832    6274 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3757, replica count: 2
    I1214 09:08:18.357292    6274 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:08:18.357: INFO: Creating new exec pod
    Dec 14 09:08:18.387: INFO: Waiting up to 5m0s for pod "execpodp2tt6" in namespace "services-3757" to be "running"
    Dec 14 09:08:18.413: INFO: Pod "execpodp2tt6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.705565ms
    Dec 14 09:08:20.441: INFO: Pod "execpodp2tt6": Phase="Running", Reason="", readiness=true. Elapsed: 2.053990829s
    Dec 14 09:08:20.441: INFO: Pod "execpodp2tt6" satisfied condition "running"
    Dec 14 09:08:21.492: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:22.162: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:22.162: INFO: stdout: ""
    Dec 14 09:08:23.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:23.735: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:23.736: INFO: stdout: ""
    Dec 14 09:08:24.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:24.768: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:24.768: INFO: stdout: ""
    Dec 14 09:08:25.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:25.798: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:25.798: INFO: stdout: ""
    Dec 14 09:08:26.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:26.809: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:26.809: INFO: stdout: ""
    Dec 14 09:08:27.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 09:08:27.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:27.757: INFO: stdout: "nodeport-test-9msm4"
    Dec 14 09:08:27.758: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.72.56 80'
    Dec 14 09:08:28.347: INFO: stderr: "+ nc -v -t -w 2 100.108.72.56 80\nConnection to 100.108.72.56 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Dec 14 09:08:28.348: INFO: stdout: "nodeport-test-t8z4b"
    Dec 14 09:08:28.348: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32222'
    Dec 14 09:08:28.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32222\nConnection to 10.250.0.5 32222 port [tcp/*] succeeded!\n"
    Dec 14 09:08:28.927: INFO: stdout: "nodeport-test-9msm4"
    Dec 14 09:08:28.927: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
    Dec 14 09:08:29.572: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32222\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
    Dec 14 09:08:29.572: INFO: stdout: ""
    Dec 14 09:08:30.572: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
    Dec 14 09:08:31.154: INFO: stderr: "+ + nc -v -t -w 2 10.250.0.4 32222\necho hostName\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
    Dec 14 09:08:31.154: INFO: stdout: ""
    Dec 14 09:08:31.572: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
    Dec 14 09:08:32.202: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32222\n+ echo hostName\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
    Dec 14 09:08:32.202: INFO: stdout: ""
    Dec 14 09:08:32.573: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3757 exec execpodp2tt6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32222'
    Dec 14 09:08:33.210: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 32222\nConnection to 10.250.0.4 32222 port [tcp/*] succeeded!\n"
    Dec 14 09:08:33.210: INFO: stdout: "nodeport-test-t8z4b"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:08:33.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3757" for this suite. 12/14/22 09:08:33.261
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:33.289
Dec 14 09:08:33.289: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:08:33.29
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:33.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:33.418
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:08:33.497
Dec 14 09:08:33.531: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8109" to be "running and ready"
Dec 14 09:08:33.561: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 30.430448ms
Dec 14 09:08:33.561: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:08:35.589: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.05832026s
Dec 14 09:08:35.589: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:08:35.589: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 12/14/22 09:08:35.615
Dec 14 09:08:35.646: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-8109" to be "running and ready"
Dec 14 09:08:35.673: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 26.742861ms
Dec 14 09:08:35.673: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:08:37.701: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.054265096s
Dec 14 09:08:37.701: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Dec 14 09:08:37.701: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/14/22 09:08:37.729
STEP: delete the pod with lifecycle hook 12/14/22 09:08:37.762
Dec 14 09:08:37.793: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:08:37.819: INFO: Pod pod-with-poststart-http-hook still exists
Dec 14 09:08:39.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:08:39.847: INFO: Pod pod-with-poststart-http-hook still exists
Dec 14 09:08:41.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:08:41.847: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:08:41.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8109" for this suite. 12/14/22 09:08:41.898
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":167,"skipped":3050,"failed":0}
------------------------------
• [8.636 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:33.289
    Dec 14 09:08:33.289: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:08:33.29
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:33.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:33.418
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:08:33.497
    Dec 14 09:08:33.531: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8109" to be "running and ready"
    Dec 14 09:08:33.561: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 30.430448ms
    Dec 14 09:08:33.561: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:08:35.589: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.05832026s
    Dec 14 09:08:35.589: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:08:35.589: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 12/14/22 09:08:35.615
    Dec 14 09:08:35.646: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-8109" to be "running and ready"
    Dec 14 09:08:35.673: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 26.742861ms
    Dec 14 09:08:35.673: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:08:37.701: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.054265096s
    Dec 14 09:08:37.701: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Dec 14 09:08:37.701: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/14/22 09:08:37.729
    STEP: delete the pod with lifecycle hook 12/14/22 09:08:37.762
    Dec 14 09:08:37.793: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:08:37.819: INFO: Pod pod-with-poststart-http-hook still exists
    Dec 14 09:08:39.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:08:39.847: INFO: Pod pod-with-poststart-http-hook still exists
    Dec 14 09:08:41.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:08:41.847: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:08:41.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8109" for this suite. 12/14/22 09:08:41.898
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:41.928
Dec 14 09:08:41.928: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:08:41.929
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:42.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:42.059
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 12/14/22 09:08:42.109
STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:08:42.136
STEP: delete the deployment 12/14/22 09:08:42.163
STEP: wait for all rs to be garbage collected 12/14/22 09:08:42.193
STEP: Gathering metrics 12/14/22 09:08:42.275
W1214 09:08:42.333379    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:08:42.333: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:08:42.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7086" for this suite. 12/14/22 09:08:42.361
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":168,"skipped":3113,"failed":0}
------------------------------
• [0.461 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:41.928
    Dec 14 09:08:41.928: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:08:41.929
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:42.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:42.059
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 12/14/22 09:08:42.109
    STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:08:42.136
    STEP: delete the deployment 12/14/22 09:08:42.163
    STEP: wait for all rs to be garbage collected 12/14/22 09:08:42.193
    STEP: Gathering metrics 12/14/22 09:08:42.275
    W1214 09:08:42.333379    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:08:42.333: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:08:42.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7086" for this suite. 12/14/22 09:08:42.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:42.405
Dec 14 09:08:42.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:08:42.407
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:42.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:42.536
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 12/14/22 09:08:42.586
Dec 14 09:08:42.618: INFO: Waiting up to 5m0s for pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9" in namespace "containers-770" to be "Succeeded or Failed"
Dec 14 09:08:42.644: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 25.884335ms
Dec 14 09:08:44.679: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061367242s
Dec 14 09:08:46.672: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053833119s
STEP: Saw pod success 12/14/22 09:08:46.672
Dec 14 09:08:46.672: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9" satisfied condition "Succeeded or Failed"
Dec 14 09:08:46.700: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:08:46.734
Dec 14 09:08:46.771: INFO: Waiting for pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 to disappear
Dec 14 09:08:46.798: INFO: Pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:08:46.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-770" for this suite. 12/14/22 09:08:46.85
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":169,"skipped":3140,"failed":0}
------------------------------
• [4.474 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:42.405
    Dec 14 09:08:42.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:08:42.407
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:42.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:42.536
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 12/14/22 09:08:42.586
    Dec 14 09:08:42.618: INFO: Waiting up to 5m0s for pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9" in namespace "containers-770" to be "Succeeded or Failed"
    Dec 14 09:08:42.644: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 25.884335ms
    Dec 14 09:08:44.679: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061367242s
    Dec 14 09:08:46.672: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053833119s
    STEP: Saw pod success 12/14/22 09:08:46.672
    Dec 14 09:08:46.672: INFO: Pod "client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:46.700: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:08:46.734
    Dec 14 09:08:46.771: INFO: Waiting for pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 to disappear
    Dec 14 09:08:46.798: INFO: Pod client-containers-8d908194-cdcd-4775-b353-d73ec046d9b9 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:08:46.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-770" for this suite. 12/14/22 09:08:46.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:46.88
Dec 14 09:08:46.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:08:46.882
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:46.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:47.009
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 12/14/22 09:08:47.058
Dec 14 09:08:47.089: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7421" to be "running and ready"
Dec 14 09:08:47.115: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 26.118025ms
Dec 14 09:08:47.115: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:08:49.146: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.056301012s
Dec 14 09:08:49.146: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Dec 14 09:08:49.146: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 12/14/22 09:08:49.173
STEP: Then the orphan pod is adopted 12/14/22 09:08:49.199
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:08:49.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7421" for this suite. 12/14/22 09:08:49.276
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":170,"skipped":3146,"failed":0}
------------------------------
• [2.423 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:46.88
    Dec 14 09:08:46.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:08:46.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:46.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:47.009
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 12/14/22 09:08:47.058
    Dec 14 09:08:47.089: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7421" to be "running and ready"
    Dec 14 09:08:47.115: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 26.118025ms
    Dec 14 09:08:47.115: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:08:49.146: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.056301012s
    Dec 14 09:08:49.146: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Dec 14 09:08:49.146: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 12/14/22 09:08:49.173
    STEP: Then the orphan pod is adopted 12/14/22 09:08:49.199
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:08:49.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7421" for this suite. 12/14/22 09:08:49.276
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:49.304
Dec 14 09:08:49.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:08:49.305
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:49.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:49.436
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-3853 12/14/22 09:08:49.486
STEP: creating service affinity-clusterip in namespace services-3853 12/14/22 09:08:49.486
STEP: creating replication controller affinity-clusterip in namespace services-3853 12/14/22 09:08:49.525
I1214 09:08:49.552268    6274 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3853, replica count: 3
I1214 09:08:52.603448    6274 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:08:52.660: INFO: Creating new exec pod
Dec 14 09:08:52.691: INFO: Waiting up to 5m0s for pod "execpod-affinity4z6vl" in namespace "services-3853" to be "running"
Dec 14 09:08:52.721: INFO: Pod "execpod-affinity4z6vl": Phase="Pending", Reason="", readiness=false. Elapsed: 29.270141ms
Dec 14 09:08:54.748: INFO: Pod "execpod-affinity4z6vl": Phase="Running", Reason="", readiness=true. Elapsed: 2.056785407s
Dec 14 09:08:54.748: INFO: Pod "execpod-affinity4z6vl" satisfied condition "running"
Dec 14 09:08:55.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Dec 14 09:08:56.415: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:56.415: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:08:56.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.243.189 80'
Dec 14 09:08:56.888: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.243.189 80\nConnection to 100.111.243.189 80 port [tcp/http] succeeded!\n"
Dec 14 09:08:56.889: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:08:56.889: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.111.243.189:80/ ; done'
Dec 14 09:08:57.621: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n"
Dec 14 09:08:57.621: INFO: stdout: "\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx"
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
Dec 14 09:08:57.621: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-3853, will wait for the garbage collector to delete the pods 12/14/22 09:08:57.663
Dec 14 09:08:57.775: INFO: Deleting ReplicationController affinity-clusterip took: 27.671502ms
Dec 14 09:08:57.876: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.965086ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:09:00.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3853" for this suite. 12/14/22 09:09:00.176
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":171,"skipped":3154,"failed":0}
------------------------------
• [10.899 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:49.304
    Dec 14 09:08:49.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:08:49.305
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:49.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:49.436
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-3853 12/14/22 09:08:49.486
    STEP: creating service affinity-clusterip in namespace services-3853 12/14/22 09:08:49.486
    STEP: creating replication controller affinity-clusterip in namespace services-3853 12/14/22 09:08:49.525
    I1214 09:08:49.552268    6274 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3853, replica count: 3
    I1214 09:08:52.603448    6274 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:08:52.660: INFO: Creating new exec pod
    Dec 14 09:08:52.691: INFO: Waiting up to 5m0s for pod "execpod-affinity4z6vl" in namespace "services-3853" to be "running"
    Dec 14 09:08:52.721: INFO: Pod "execpod-affinity4z6vl": Phase="Pending", Reason="", readiness=false. Elapsed: 29.270141ms
    Dec 14 09:08:54.748: INFO: Pod "execpod-affinity4z6vl": Phase="Running", Reason="", readiness=true. Elapsed: 2.056785407s
    Dec 14 09:08:54.748: INFO: Pod "execpod-affinity4z6vl" satisfied condition "running"
    Dec 14 09:08:55.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Dec 14 09:08:56.415: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:56.415: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:08:56.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.243.189 80'
    Dec 14 09:08:56.888: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.243.189 80\nConnection to 100.111.243.189 80 port [tcp/http] succeeded!\n"
    Dec 14 09:08:56.889: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:08:56.889: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3853 exec execpod-affinity4z6vl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.111.243.189:80/ ; done'
    Dec 14 09:08:57.621: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.111.243.189:80/\n"
    Dec 14 09:08:57.621: INFO: stdout: "\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx\naffinity-clusterip-rmgvx"
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Received response from host: affinity-clusterip-rmgvx
    Dec 14 09:08:57.621: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-3853, will wait for the garbage collector to delete the pods 12/14/22 09:08:57.663
    Dec 14 09:08:57.775: INFO: Deleting ReplicationController affinity-clusterip took: 27.671502ms
    Dec 14 09:08:57.876: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.965086ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:09:00.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3853" for this suite. 12/14/22 09:09:00.176
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:00.204
Dec 14 09:09:00.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:09:00.205
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:00.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:00.334
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 12/14/22 09:09:00.384
Dec 14 09:09:00.416: INFO: Waiting up to 5m0s for pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a" in namespace "pods-7599" to be "running and ready"
Dec 14 09:09:00.441: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.517736ms
Dec 14 09:09:00.441: INFO: The phase of Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:09:02.470: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053990277s
Dec 14 09:09:02.470: INFO: The phase of Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a is Running (Ready = true)
Dec 14 09:09:02.470: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a" satisfied condition "running and ready"
Dec 14 09:09:02.524: INFO: Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a has hostIP: 10.250.0.5
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:09:02.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7599" for this suite. 12/14/22 09:09:02.575
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":172,"skipped":3162,"failed":0}
------------------------------
• [2.399 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:00.204
    Dec 14 09:09:00.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:09:00.205
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:00.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:00.334
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 12/14/22 09:09:00.384
    Dec 14 09:09:00.416: INFO: Waiting up to 5m0s for pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a" in namespace "pods-7599" to be "running and ready"
    Dec 14 09:09:00.441: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.517736ms
    Dec 14 09:09:00.441: INFO: The phase of Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:09:02.470: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053990277s
    Dec 14 09:09:02.470: INFO: The phase of Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a is Running (Ready = true)
    Dec 14 09:09:02.470: INFO: Pod "pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a" satisfied condition "running and ready"
    Dec 14 09:09:02.524: INFO: Pod pod-hostip-a2223ecc-0d1b-4696-a85e-5293ede6405a has hostIP: 10.250.0.5
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:09:02.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7599" for this suite. 12/14/22 09:09:02.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:02.603
Dec 14 09:09:02.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:09:02.604
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:02.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:02.733
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 in namespace container-probe-1568 12/14/22 09:09:02.783
Dec 14 09:09:02.817: INFO: Waiting up to 5m0s for pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7" in namespace "container-probe-1568" to be "not pending"
Dec 14 09:09:02.843: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.646033ms
Dec 14 09:09:04.870: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.053072619s
Dec 14 09:09:04.870: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7" satisfied condition "not pending"
Dec 14 09:09:04.870: INFO: Started pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 in namespace container-probe-1568
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:09:04.87
Dec 14 09:09:04.896: INFO: Initial restart count of pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 is 0
Dec 14 09:09:25.194: INFO: Restart count of pod container-probe-1568/liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 is now 1 (20.297644793s elapsed)
STEP: deleting the pod 12/14/22 09:09:25.194
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:09:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1568" for this suite. 12/14/22 09:09:25.279
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":173,"skipped":3169,"failed":0}
------------------------------
• [22.703 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:02.603
    Dec 14 09:09:02.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:09:02.604
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:02.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:02.733
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 in namespace container-probe-1568 12/14/22 09:09:02.783
    Dec 14 09:09:02.817: INFO: Waiting up to 5m0s for pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7" in namespace "container-probe-1568" to be "not pending"
    Dec 14 09:09:02.843: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.646033ms
    Dec 14 09:09:04.870: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.053072619s
    Dec 14 09:09:04.870: INFO: Pod "liveness-904b876a-557d-45ab-b4d0-915a36fe23a7" satisfied condition "not pending"
    Dec 14 09:09:04.870: INFO: Started pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 in namespace container-probe-1568
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:09:04.87
    Dec 14 09:09:04.896: INFO: Initial restart count of pod liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 is 0
    Dec 14 09:09:25.194: INFO: Restart count of pod container-probe-1568/liveness-904b876a-557d-45ab-b4d0-915a36fe23a7 is now 1 (20.297644793s elapsed)
    STEP: deleting the pod 12/14/22 09:09:25.194
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:09:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1568" for this suite. 12/14/22 09:09:25.279
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:25.307
Dec 14 09:09:25.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:09:25.307
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:25.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:25.437
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:09:25.543
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:09:25.903
STEP: Deploying the webhook pod 12/14/22 09:09:25.932
STEP: Wait for the deployment to be ready 12/14/22 09:09:25.986
Dec 14 09:09:26.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 9, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:09:28.1
STEP: Verifying the service has paired with the endpoint 12/14/22 09:09:28.136
Dec 14 09:09:29.137: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/14/22 09:09:29.164
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:29.164
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/14/22 09:09:29.326
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/14/22 09:09:30.385
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:30.385
STEP: Having no error when timeout is longer than webhook latency 12/14/22 09:09:31.536
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:31.536
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/14/22 09:09:36.76
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:36.761
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:09:41.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1637" for this suite. 12/14/22 09:09:41.964
STEP: Destroying namespace "webhook-1637-markers" for this suite. 12/14/22 09:09:41.992
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":174,"skipped":3174,"failed":0}
------------------------------
• [16.831 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:25.307
    Dec 14 09:09:25.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:09:25.307
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:25.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:25.437
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:09:25.543
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:09:25.903
    STEP: Deploying the webhook pod 12/14/22 09:09:25.932
    STEP: Wait for the deployment to be ready 12/14/22 09:09:25.986
    Dec 14 09:09:26.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 9, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 9, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:09:28.1
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:09:28.136
    Dec 14 09:09:29.137: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/14/22 09:09:29.164
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:29.164
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/14/22 09:09:29.326
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/14/22 09:09:30.385
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:30.385
    STEP: Having no error when timeout is longer than webhook latency 12/14/22 09:09:31.536
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:31.536
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/14/22 09:09:36.76
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 09:09:36.761
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:09:41.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1637" for this suite. 12/14/22 09:09:41.964
    STEP: Destroying namespace "webhook-1637-markers" for this suite. 12/14/22 09:09:41.992
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:42.138
Dec 14 09:09:42.138: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 09:09:42.139
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:42.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:42.271
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 09:09:42.322: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 09:09:42.378: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 09:09:42.404: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
Dec 14 09:09:42.466: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:09:42.466: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:09:42.466: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:09:42.466: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:09:42.466: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:09:42.466: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:09:42.466: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:09:42.466: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:09:42.466: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:09:42.466: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:09:42.466: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:09:42.466: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:09:42.466: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:09:42.466: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:09:42.466: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:09:42.466: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.466: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:09:42.466: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
Dec 14 09:09:42.500: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 09:09:42.500: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 09:09:42.500: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:09:42.500: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:09:42.500: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:09:42.500: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 09:09:42.500: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:09:42.500: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:09:42.500: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:09:42.500: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:09:42.500: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:09:42.500: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:09:42.500: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:09:42.500: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:09:42.500: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:09:42.500: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:09:42.500: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:09:42.500: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:09:42.500: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:09:42.500: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:09:42.500: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:09:42.500: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 09:09:42.500: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 09:09:42.500: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:09:42.500: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:09:42.569
STEP: verifying the node has the label node shoot--it--tm0ct-io0-worker-1-6f755-vb826 12/14/22 09:09:42.628
Dec 14 09:09:42.692: INFO: Pod addons-nginx-ingress-controller-7fb8f7fc5-tzh7n requesting resource cpu=100m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.692: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 requesting resource cpu=0m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.692: INFO: Pod apiserver-proxy-fdh6d requesting resource cpu=40m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.692: INFO: Pod apiserver-proxy-rkc87 requesting resource cpu=40m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod blackbox-exporter-59447f4c55-gg28g requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod blackbox-exporter-59447f4c55-l4sl8 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod calico-node-nm9fv requesting resource cpu=250m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod calico-node-sxn8l requesting resource cpu=250m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod calico-node-vertical-autoscaler-6597dd8998-z22xv requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod calico-typha-deploy-65c54d4db6-78pzm requesting resource cpu=320m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod calico-typha-vertical-autoscaler-84df655c88-ml548 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod cloud-node-manager-ct9x9 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod cloud-node-manager-d7nl7 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod coredns-7558877f6f-4drgs requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod coredns-7558877f6f-vcqln requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod csi-driver-node-disk-ffbkk requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod csi-driver-node-disk-x2d9h requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod csi-driver-node-file-5rtwn requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod csi-driver-node-file-fqj5x requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod egress-filter-applier-ch9gv requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod egress-filter-applier-f6rpl requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod kube-proxy-worker-1-v1.25.4-9z98n requesting resource cpu=34m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod kube-proxy-worker-1-v1.25.4-n64tv requesting resource cpu=34m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod metrics-server-8688dbf74b-kz62g requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod metrics-server-8688dbf74b-twwq4 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod network-problem-detector-host-99jhg requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod network-problem-detector-host-hs2n4 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod network-problem-detector-pod-ckmps requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod network-problem-detector-pod-rk4t7 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod node-exporter-72h6z requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod node-exporter-tx6hc requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod node-local-dns-d8jbc requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod node-local-dns-kjrz2 requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod node-problem-detector-9q4nh requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod node-problem-detector-p9pfw requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.693: INFO: Pod vpn-shoot-85c474665b-xf7mf requesting resource cpu=100m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod dashboard-metrics-scraper-6d54964d4b-j8l58 requesting resource cpu=0m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.693: INFO: Pod kubernetes-dashboard-86f4dbb8b4-s2nk9 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
STEP: Starting Pods to consume most of the cluster CPU. 12/14/22 09:09:42.693
Dec 14 09:09:42.693: INFO: Creating a pod which consumes cpu=434m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
Dec 14 09:09:42.726: INFO: Creating a pod which consumes cpu=840m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
Dec 14 09:09:42.757: INFO: Waiting up to 5m0s for pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9" in namespace "sched-pred-5961" to be "running"
Dec 14 09:09:42.786: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.869755ms
Dec 14 09:09:44.815: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.057461582s
Dec 14 09:09:44.815: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9" satisfied condition "running"
Dec 14 09:09:44.815: INFO: Waiting up to 5m0s for pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49" in namespace "sched-pred-5961" to be "running"
Dec 14 09:09:44.842: INFO: Pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49": Phase="Running", Reason="", readiness=true. Elapsed: 26.85601ms
Dec 14 09:09:44.842: INFO: Pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 12/14/22 09:09:44.842
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd1003bd6d2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5961/filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49 to shoot--it--tm0ct-io0-worker-1-6f755-hwmlx] 12/14/22 09:09:44.869
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd126d289a9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:09:44.869
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd12cc6869e], Reason = [Created], Message = [Created container filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49] 12/14/22 09:09:44.869
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd131a2e094], Reason = [Started], Message = [Started container filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49] 12/14/22 09:09:44.869
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd0fecc97d7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5961/filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9 to shoot--it--tm0ct-io0-worker-1-6f755-vb826] 12/14/22 09:09:44.87
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd1274c75e4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:09:44.87
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd12d24adca], Reason = [Created], Message = [Created container filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9] 12/14/22 09:09:44.87
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd13325cfe4], Reason = [Started], Message = [Started container filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9] 12/14/22 09:09:44.87
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17309dd1815bf104], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 12/14/22 09:09:44.931
STEP: removing the label node off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:09:45.956
STEP: verifying the node doesn't have the label node 12/14/22 09:09:46.039
STEP: removing the label node off the node shoot--it--tm0ct-io0-worker-1-6f755-vb826 12/14/22 09:09:46.068
STEP: verifying the node doesn't have the label node 12/14/22 09:09:46.135
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:09:46.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5961" for this suite. 12/14/22 09:09:46.188
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":175,"skipped":3178,"failed":0}
------------------------------
• [4.077 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:42.138
    Dec 14 09:09:42.138: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 09:09:42.139
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:42.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:42.271
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 09:09:42.322: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 09:09:42.378: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 09:09:42.404: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
    Dec 14 09:09:42.466: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:09:42.466: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.466: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:09:42.466: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
    Dec 14 09:09:42.500: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:09:42.500: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:09:42.500: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:09:42.500: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 09:09:42.500: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:09:42.500: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:09:42.569
    STEP: verifying the node has the label node shoot--it--tm0ct-io0-worker-1-6f755-vb826 12/14/22 09:09:42.628
    Dec 14 09:09:42.692: INFO: Pod addons-nginx-ingress-controller-7fb8f7fc5-tzh7n requesting resource cpu=100m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.692: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 requesting resource cpu=0m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.692: INFO: Pod apiserver-proxy-fdh6d requesting resource cpu=40m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.692: INFO: Pod apiserver-proxy-rkc87 requesting resource cpu=40m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod blackbox-exporter-59447f4c55-gg28g requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod blackbox-exporter-59447f4c55-l4sl8 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod calico-node-nm9fv requesting resource cpu=250m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod calico-node-sxn8l requesting resource cpu=250m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod calico-node-vertical-autoscaler-6597dd8998-z22xv requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod calico-typha-deploy-65c54d4db6-78pzm requesting resource cpu=320m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod calico-typha-vertical-autoscaler-84df655c88-ml548 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod cloud-node-manager-ct9x9 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod cloud-node-manager-d7nl7 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod coredns-7558877f6f-4drgs requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod coredns-7558877f6f-vcqln requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod csi-driver-node-disk-ffbkk requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod csi-driver-node-disk-x2d9h requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod csi-driver-node-file-5rtwn requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod csi-driver-node-file-fqj5x requesting resource cpu=42m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod egress-filter-applier-ch9gv requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod egress-filter-applier-f6rpl requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod kube-proxy-worker-1-v1.25.4-9z98n requesting resource cpu=34m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod kube-proxy-worker-1-v1.25.4-n64tv requesting resource cpu=34m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod metrics-server-8688dbf74b-kz62g requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod metrics-server-8688dbf74b-twwq4 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod network-problem-detector-host-99jhg requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod network-problem-detector-host-hs2n4 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod network-problem-detector-pod-ckmps requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod network-problem-detector-pod-rk4t7 requesting resource cpu=10m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod node-exporter-72h6z requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod node-exporter-tx6hc requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod node-local-dns-d8jbc requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod node-local-dns-kjrz2 requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod node-problem-detector-9q4nh requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod node-problem-detector-p9pfw requesting resource cpu=11m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.693: INFO: Pod vpn-shoot-85c474665b-xf7mf requesting resource cpu=100m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod dashboard-metrics-scraper-6d54964d4b-j8l58 requesting resource cpu=0m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.693: INFO: Pod kubernetes-dashboard-86f4dbb8b4-s2nk9 requesting resource cpu=50m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    STEP: Starting Pods to consume most of the cluster CPU. 12/14/22 09:09:42.693
    Dec 14 09:09:42.693: INFO: Creating a pod which consumes cpu=434m on Node shoot--it--tm0ct-io0-worker-1-6f755-vb826
    Dec 14 09:09:42.726: INFO: Creating a pod which consumes cpu=840m on Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    Dec 14 09:09:42.757: INFO: Waiting up to 5m0s for pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9" in namespace "sched-pred-5961" to be "running"
    Dec 14 09:09:42.786: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.869755ms
    Dec 14 09:09:44.815: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.057461582s
    Dec 14 09:09:44.815: INFO: Pod "filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9" satisfied condition "running"
    Dec 14 09:09:44.815: INFO: Waiting up to 5m0s for pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49" in namespace "sched-pred-5961" to be "running"
    Dec 14 09:09:44.842: INFO: Pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49": Phase="Running", Reason="", readiness=true. Elapsed: 26.85601ms
    Dec 14 09:09:44.842: INFO: Pod "filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 12/14/22 09:09:44.842
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd1003bd6d2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5961/filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49 to shoot--it--tm0ct-io0-worker-1-6f755-hwmlx] 12/14/22 09:09:44.869
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd126d289a9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:09:44.869
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd12cc6869e], Reason = [Created], Message = [Created container filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49] 12/14/22 09:09:44.869
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49.17309dd131a2e094], Reason = [Started], Message = [Started container filler-pod-13b7678d-d517-4c90-bffe-33de5ffffe49] 12/14/22 09:09:44.869
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd0fecc97d7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5961/filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9 to shoot--it--tm0ct-io0-worker-1-6f755-vb826] 12/14/22 09:09:44.87
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd1274c75e4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:09:44.87
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd12d24adca], Reason = [Created], Message = [Created container filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9] 12/14/22 09:09:44.87
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9.17309dd13325cfe4], Reason = [Started], Message = [Started container filler-pod-9856e657-2767-4f9f-8830-ef6887f806c9] 12/14/22 09:09:44.87
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17309dd1815bf104], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 12/14/22 09:09:44.931
    STEP: removing the label node off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:09:45.956
    STEP: verifying the node doesn't have the label node 12/14/22 09:09:46.039
    STEP: removing the label node off the node shoot--it--tm0ct-io0-worker-1-6f755-vb826 12/14/22 09:09:46.068
    STEP: verifying the node doesn't have the label node 12/14/22 09:09:46.135
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:09:46.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5961" for this suite. 12/14/22 09:09:46.188
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:46.218
Dec 14 09:09:46.218: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:09:46.219
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:46.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:46.352
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/14/22 09:09:46.437
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/14/22 09:10:04.958
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/14/22 09:10:04.989
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/14/22 09:10:05.042
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/14/22 09:10:05.042
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/14/22 09:10:05.131
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/14/22 09:10:08.237
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/14/22 09:10:10.324
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/14/22 09:10:10.378
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/14/22 09:10:10.378
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/14/22 09:10:10.473
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/14/22 09:10:10.499
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/14/22 09:10:13.609
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/14/22 09:10:13.662
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/14/22 09:10:13.662
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:10:13.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5479" for this suite. 12/14/22 09:10:13.851
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":176,"skipped":3236,"failed":0}
------------------------------
• [27.663 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:46.218
    Dec 14 09:09:46.218: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:09:46.219
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:46.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:46.352
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/14/22 09:09:46.437
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/14/22 09:10:04.958
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/14/22 09:10:04.989
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/14/22 09:10:05.042
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/14/22 09:10:05.042
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/14/22 09:10:05.131
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/14/22 09:10:08.237
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/14/22 09:10:10.324
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/14/22 09:10:10.378
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/14/22 09:10:10.378
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/14/22 09:10:10.473
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/14/22 09:10:10.499
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/14/22 09:10:13.609
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/14/22 09:10:13.662
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/14/22 09:10:13.662
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:10:13.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5479" for this suite. 12/14/22 09:10:13.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:13.882
Dec 14 09:10:13.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:10:13.882
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:13.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:14.036
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-1e8ed4cd-b788-442b-83f9-b083d2ea22e8 12/14/22 09:10:14.086
STEP: Creating a pod to test consume secrets 12/14/22 09:10:14.112
Dec 14 09:10:14.146: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506" in namespace "projected-6525" to be "Succeeded or Failed"
Dec 14 09:10:14.172: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Pending", Reason="", readiness=false. Elapsed: 26.385793ms
Dec 14 09:10:16.199: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053165992s
Dec 14 09:10:18.199: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053383319s
STEP: Saw pod success 12/14/22 09:10:18.199
Dec 14 09:10:18.200: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506" satisfied condition "Succeeded or Failed"
Dec 14 09:10:18.225: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:10:18.302
Dec 14 09:10:18.336: INFO: Waiting for pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 to disappear
Dec 14 09:10:18.362: INFO: Pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:10:18.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6525" for this suite. 12/14/22 09:10:18.412
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":177,"skipped":3241,"failed":0}
------------------------------
• [4.559 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:13.882
    Dec 14 09:10:13.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:10:13.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:13.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:14.036
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-1e8ed4cd-b788-442b-83f9-b083d2ea22e8 12/14/22 09:10:14.086
    STEP: Creating a pod to test consume secrets 12/14/22 09:10:14.112
    Dec 14 09:10:14.146: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506" in namespace "projected-6525" to be "Succeeded or Failed"
    Dec 14 09:10:14.172: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Pending", Reason="", readiness=false. Elapsed: 26.385793ms
    Dec 14 09:10:16.199: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053165992s
    Dec 14 09:10:18.199: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053383319s
    STEP: Saw pod success 12/14/22 09:10:18.199
    Dec 14 09:10:18.200: INFO: Pod "pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506" satisfied condition "Succeeded or Failed"
    Dec 14 09:10:18.225: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:10:18.302
    Dec 14 09:10:18.336: INFO: Waiting for pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 to disappear
    Dec 14 09:10:18.362: INFO: Pod pod-projected-secrets-791651a6-e7d5-4eeb-a2df-878886c5d506 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:10:18.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6525" for this suite. 12/14/22 09:10:18.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:18.444
Dec 14 09:10:18.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:10:18.445
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:18.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:18.573
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:10:18.622
Dec 14 09:10:18.654: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f" in namespace "downward-api-8361" to be "Succeeded or Failed"
Dec 14 09:10:18.679: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.491615ms
Dec 14 09:10:20.709: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055052731s
Dec 14 09:10:22.706: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052875638s
STEP: Saw pod success 12/14/22 09:10:22.707
Dec 14 09:10:22.707: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f" satisfied condition "Succeeded or Failed"
Dec 14 09:10:22.735: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f container client-container: <nil>
STEP: delete the pod 12/14/22 09:10:22.769
Dec 14 09:10:22.803: INFO: Waiting for pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f to disappear
Dec 14 09:10:22.829: INFO: Pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:10:22.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8361" for this suite. 12/14/22 09:10:22.88
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":178,"skipped":3321,"failed":0}
------------------------------
• [4.463 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:18.444
    Dec 14 09:10:18.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:10:18.445
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:18.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:18.573
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:10:18.622
    Dec 14 09:10:18.654: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f" in namespace "downward-api-8361" to be "Succeeded or Failed"
    Dec 14 09:10:18.679: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.491615ms
    Dec 14 09:10:20.709: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055052731s
    Dec 14 09:10:22.706: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052875638s
    STEP: Saw pod success 12/14/22 09:10:22.707
    Dec 14 09:10:22.707: INFO: Pod "downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f" satisfied condition "Succeeded or Failed"
    Dec 14 09:10:22.735: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f container client-container: <nil>
    STEP: delete the pod 12/14/22 09:10:22.769
    Dec 14 09:10:22.803: INFO: Waiting for pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f to disappear
    Dec 14 09:10:22.829: INFO: Pod downwardapi-volume-b1f6aae3-4f66-46fd-a755-06d14cee4b9f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:10:22.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8361" for this suite. 12/14/22 09:10:22.88
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:22.908
Dec 14 09:10:22.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:10:22.908
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:22.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:23.036
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 12/14/22 09:10:23.086
STEP: Ensuring job reaches completions 12/14/22 09:10:23.114
STEP: Ensuring pods with index for job exist 12/14/22 09:10:31.142
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:10:31.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9556" for this suite. 12/14/22 09:10:31.244
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":179,"skipped":3324,"failed":0}
------------------------------
• [8.363 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:22.908
    Dec 14 09:10:22.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:10:22.908
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:22.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:23.036
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 12/14/22 09:10:23.086
    STEP: Ensuring job reaches completions 12/14/22 09:10:23.114
    STEP: Ensuring pods with index for job exist 12/14/22 09:10:31.142
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:10:31.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9556" for this suite. 12/14/22 09:10:31.244
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:31.271
Dec 14 09:10:31.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 09:10:31.272
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:31.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:31.401
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 12/14/22 09:10:31.451
Dec 14 09:10:31.451: INFO: PodSpec: initContainers in spec.initContainers
Dec 14 09:11:14.772: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c27d31e8-85bf-46a3-a44b-22d27d17bbe1", GenerateName:"", Namespace:"init-container-6820", SelfLink:"", UID:"953f48fd-954f-444a-aac3-5f391ff80309", ResourceVersion:"33708", Generation:0, CreationTimestamp:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"451665607"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"b445f79a95b27188d84afed4049e24d51cea486f42606d31de4df8a8d95fe34f", "cni.projectcalico.org/podIP":"100.64.0.112/32", "cni.projectcalico.org/podIPs":"100.64.0.112/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f170), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f1a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 11, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f1d0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-wkv87", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00237ece0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003930cb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0004dc3f0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003930d30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003930d50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003930d58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003930d5c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00111ada0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.5", PodIP:"100.64.0.112", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.0.112"}}, StartTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004dc540)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004dc620)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://897f9a32028fe8fe0895c61b47330180e32a5e59e4d2f5421a8eea03f69da78a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00237ed60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00237ed40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003930ddf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:11:14.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6820" for this suite. 12/14/22 09:11:14.822
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":180,"skipped":3333,"failed":0}
------------------------------
• [43.580 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:31.271
    Dec 14 09:10:31.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 09:10:31.272
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:31.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:31.401
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 12/14/22 09:10:31.451
    Dec 14 09:10:31.451: INFO: PodSpec: initContainers in spec.initContainers
    Dec 14 09:11:14.772: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c27d31e8-85bf-46a3-a44b-22d27d17bbe1", GenerateName:"", Namespace:"init-container-6820", SelfLink:"", UID:"953f48fd-954f-444a-aac3-5f391ff80309", ResourceVersion:"33708", Generation:0, CreationTimestamp:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"451665607"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"b445f79a95b27188d84afed4049e24d51cea486f42606d31de4df8a8d95fe34f", "cni.projectcalico.org/podIP":"100.64.0.112/32", "cni.projectcalico.org/podIPs":"100.64.0.112/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f170), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f1a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 11, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c6f1d0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-wkv87", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00237ece0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-wkv87", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003930cb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0004dc3f0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003930d30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003930d50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003930d58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003930d5c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00111ada0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.5", PodIP:"100.64.0.112", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.0.112"}}, StartTime:time.Date(2022, time.December, 14, 9, 10, 31, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004dc540)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004dc620)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://897f9a32028fe8fe0895c61b47330180e32a5e59e4d2f5421a8eea03f69da78a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00237ed60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00237ed40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003930ddf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:11:14.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6820" for this suite. 12/14/22 09:11:14.822
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:14.852
Dec 14 09:11:14.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:11:14.853
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:14.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:14.984
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Dec 14 09:11:15.061: INFO: Got root ca configmap in namespace "svcaccounts-2106"
Dec 14 09:11:15.088: INFO: Deleted root ca configmap in namespace "svcaccounts-2106"
STEP: waiting for a new root ca configmap created 12/14/22 09:11:15.589
Dec 14 09:11:15.616: INFO: Recreated root ca configmap in namespace "svcaccounts-2106"
Dec 14 09:11:15.642: INFO: Updated root ca configmap in namespace "svcaccounts-2106"
STEP: waiting for the root ca configmap reconciled 12/14/22 09:11:16.143
Dec 14 09:11:16.170: INFO: Reconciled root ca configmap in namespace "svcaccounts-2106"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:11:16.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2106" for this suite. 12/14/22 09:11:16.222
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":181,"skipped":3333,"failed":0}
------------------------------
• [1.398 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:14.852
    Dec 14 09:11:14.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:11:14.853
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:14.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:14.984
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Dec 14 09:11:15.061: INFO: Got root ca configmap in namespace "svcaccounts-2106"
    Dec 14 09:11:15.088: INFO: Deleted root ca configmap in namespace "svcaccounts-2106"
    STEP: waiting for a new root ca configmap created 12/14/22 09:11:15.589
    Dec 14 09:11:15.616: INFO: Recreated root ca configmap in namespace "svcaccounts-2106"
    Dec 14 09:11:15.642: INFO: Updated root ca configmap in namespace "svcaccounts-2106"
    STEP: waiting for the root ca configmap reconciled 12/14/22 09:11:16.143
    Dec 14 09:11:16.170: INFO: Reconciled root ca configmap in namespace "svcaccounts-2106"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:11:16.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2106" for this suite. 12/14/22 09:11:16.222
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:16.251
Dec 14 09:11:16.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:11:16.252
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:16.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:16.384
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:11:16.461
Dec 14 09:11:16.494: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8713" to be "running and ready"
Dec 14 09:11:16.520: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.710335ms
Dec 14 09:11:16.520: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:11:18.547: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.053071378s
Dec 14 09:11:18.547: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:11:18.547: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 12/14/22 09:11:18.574
Dec 14 09:11:18.604: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8713" to be "running and ready"
Dec 14 09:11:18.631: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 27.067848ms
Dec 14 09:11:18.631: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:11:20.659: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.05508542s
Dec 14 09:11:20.659: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Dec 14 09:11:20.659: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/14/22 09:11:20.686
STEP: delete the pod with lifecycle hook 12/14/22 09:11:20.718
Dec 14 09:11:20.747: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 14 09:11:20.773: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 14 09:11:22.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 14 09:11:22.802: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 14 09:11:24.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 14 09:11:24.802: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:11:24.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8713" for this suite. 12/14/22 09:11:24.853
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":182,"skipped":3335,"failed":0}
------------------------------
• [8.630 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:16.251
    Dec 14 09:11:16.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:11:16.252
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:16.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:16.384
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:11:16.461
    Dec 14 09:11:16.494: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8713" to be "running and ready"
    Dec 14 09:11:16.520: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.710335ms
    Dec 14 09:11:16.520: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:11:18.547: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.053071378s
    Dec 14 09:11:18.547: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:11:18.547: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 12/14/22 09:11:18.574
    Dec 14 09:11:18.604: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8713" to be "running and ready"
    Dec 14 09:11:18.631: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 27.067848ms
    Dec 14 09:11:18.631: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:11:20.659: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.05508542s
    Dec 14 09:11:20.659: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Dec 14 09:11:20.659: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/14/22 09:11:20.686
    STEP: delete the pod with lifecycle hook 12/14/22 09:11:20.718
    Dec 14 09:11:20.747: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec 14 09:11:20.773: INFO: Pod pod-with-poststart-exec-hook still exists
    Dec 14 09:11:22.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec 14 09:11:22.802: INFO: Pod pod-with-poststart-exec-hook still exists
    Dec 14 09:11:24.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec 14 09:11:24.802: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:11:24.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8713" for this suite. 12/14/22 09:11:24.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:24.881
Dec 14 09:11:24.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:11:24.882
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:24.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:25.009
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/14/22 09:11:25.059
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/14/22 09:11:25.059
STEP: creating a pod to probe DNS 12/14/22 09:11:25.059
STEP: submitting the pod to kubernetes 12/14/22 09:11:25.059
Dec 14 09:11:25.093: INFO: Waiting up to 15m0s for pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a" in namespace "dns-999" to be "running"
Dec 14 09:11:25.119: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.908117ms
Dec 14 09:11:27.147: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053975702s
Dec 14 09:11:27.147: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:11:27.147
STEP: looking for the results for each expected name from probers 12/14/22 09:11:27.173
Dec 14 09:11:27.411: INFO: DNS probes using dns-999/dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a succeeded

STEP: deleting the pod 12/14/22 09:11:27.411
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:11:27.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-999" for this suite. 12/14/22 09:11:27.5
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":183,"skipped":3346,"failed":0}
------------------------------
• [2.646 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:24.881
    Dec 14 09:11:24.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:11:24.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:24.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:25.009
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/14/22 09:11:25.059
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/14/22 09:11:25.059
    STEP: creating a pod to probe DNS 12/14/22 09:11:25.059
    STEP: submitting the pod to kubernetes 12/14/22 09:11:25.059
    Dec 14 09:11:25.093: INFO: Waiting up to 15m0s for pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a" in namespace "dns-999" to be "running"
    Dec 14 09:11:25.119: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.908117ms
    Dec 14 09:11:27.147: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053975702s
    Dec 14 09:11:27.147: INFO: Pod "dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:11:27.147
    STEP: looking for the results for each expected name from probers 12/14/22 09:11:27.173
    Dec 14 09:11:27.411: INFO: DNS probes using dns-999/dns-test-c22de68d-e928-4f85-80e6-1679db6bec4a succeeded

    STEP: deleting the pod 12/14/22 09:11:27.411
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:11:27.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-999" for this suite. 12/14/22 09:11:27.5
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:27.529
Dec 14 09:11:27.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:11:27.529
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:27.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:27.661
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-fe812ff9-1c08-4d2a-8024-e7043a024411 12/14/22 09:11:27.711
STEP: Creating a pod to test consume secrets 12/14/22 09:11:27.738
Dec 14 09:11:27.770: INFO: Waiting up to 5m0s for pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3" in namespace "secrets-5134" to be "Succeeded or Failed"
Dec 14 09:11:27.800: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 29.897351ms
Dec 14 09:11:29.828: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Running", Reason="", readiness=false. Elapsed: 2.058167637s
Dec 14 09:11:31.827: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Running", Reason="", readiness=false. Elapsed: 4.056648983s
Dec 14 09:11:33.829: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059083883s
STEP: Saw pod success 12/14/22 09:11:33.829
Dec 14 09:11:33.829: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3" satisfied condition "Succeeded or Failed"
Dec 14 09:11:33.856: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:11:33.893
Dec 14 09:11:33.929: INFO: Waiting for pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 to disappear
Dec 14 09:11:33.955: INFO: Pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:11:33.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5134" for this suite. 12/14/22 09:11:34.006
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":184,"skipped":3373,"failed":0}
------------------------------
• [6.505 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:27.529
    Dec 14 09:11:27.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:11:27.529
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:27.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:27.661
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-fe812ff9-1c08-4d2a-8024-e7043a024411 12/14/22 09:11:27.711
    STEP: Creating a pod to test consume secrets 12/14/22 09:11:27.738
    Dec 14 09:11:27.770: INFO: Waiting up to 5m0s for pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3" in namespace "secrets-5134" to be "Succeeded or Failed"
    Dec 14 09:11:27.800: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 29.897351ms
    Dec 14 09:11:29.828: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Running", Reason="", readiness=false. Elapsed: 2.058167637s
    Dec 14 09:11:31.827: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Running", Reason="", readiness=false. Elapsed: 4.056648983s
    Dec 14 09:11:33.829: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059083883s
    STEP: Saw pod success 12/14/22 09:11:33.829
    Dec 14 09:11:33.829: INFO: Pod "pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3" satisfied condition "Succeeded or Failed"
    Dec 14 09:11:33.856: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:11:33.893
    Dec 14 09:11:33.929: INFO: Waiting for pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 to disappear
    Dec 14 09:11:33.955: INFO: Pod pod-secrets-126034d9-e48c-48c2-8288-a13916848fb3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:11:33.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5134" for this suite. 12/14/22 09:11:34.006
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:34.034
Dec 14 09:11:34.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:11:34.035
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:34.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:34.164
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Dec 14 09:11:34.213: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4583 version'
Dec 14 09:11:34.386: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Dec 14 09:11:34.386: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:11:34.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4583" for this suite. 12/14/22 09:11:34.414
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":185,"skipped":3384,"failed":0}
------------------------------
• [0.407 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:34.034
    Dec 14 09:11:34.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:11:34.035
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:34.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:34.164
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Dec 14 09:11:34.213: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4583 version'
    Dec 14 09:11:34.386: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Dec 14 09:11:34.386: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:11:34.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4583" for this suite. 12/14/22 09:11:34.414
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:34.442
Dec 14 09:11:34.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:11:34.443
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:34.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:34.57
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-ea8260a1-4b2f-48aa-bc2b-be746752b2a3 12/14/22 09:11:34.624
STEP: Creating a pod to test consume configMaps 12/14/22 09:11:34.651
Dec 14 09:11:34.684: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65" in namespace "projected-8714" to be "Succeeded or Failed"
Dec 14 09:11:34.710: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Pending", Reason="", readiness=false. Elapsed: 26.040896ms
Dec 14 09:11:36.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053316546s
Dec 14 09:11:38.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052618117s
STEP: Saw pod success 12/14/22 09:11:38.737
Dec 14 09:11:38.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65" satisfied condition "Succeeded or Failed"
Dec 14 09:11:38.763: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:11:38.799
Dec 14 09:11:38.836: INFO: Waiting for pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 to disappear
Dec 14 09:11:38.862: INFO: Pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:11:38.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8714" for this suite. 12/14/22 09:11:38.914
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":186,"skipped":3385,"failed":0}
------------------------------
• [4.500 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:34.442
    Dec 14 09:11:34.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:11:34.443
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:34.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:34.57
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-ea8260a1-4b2f-48aa-bc2b-be746752b2a3 12/14/22 09:11:34.624
    STEP: Creating a pod to test consume configMaps 12/14/22 09:11:34.651
    Dec 14 09:11:34.684: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65" in namespace "projected-8714" to be "Succeeded or Failed"
    Dec 14 09:11:34.710: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Pending", Reason="", readiness=false. Elapsed: 26.040896ms
    Dec 14 09:11:36.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053316546s
    Dec 14 09:11:38.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052618117s
    STEP: Saw pod success 12/14/22 09:11:38.737
    Dec 14 09:11:38.737: INFO: Pod "pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65" satisfied condition "Succeeded or Failed"
    Dec 14 09:11:38.763: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:11:38.799
    Dec 14 09:11:38.836: INFO: Waiting for pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 to disappear
    Dec 14 09:11:38.862: INFO: Pod pod-projected-configmaps-e39dcbaf-03d4-4b4f-8ad5-b4b2644def65 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:11:38.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8714" for this suite. 12/14/22 09:11:38.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:38.943
Dec 14 09:11:38.943: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:11:38.944
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:39.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:39.074
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 12/14/22 09:11:39.125
Dec 14 09:11:39.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 create -f -'
Dec 14 09:11:40.280: INFO: stderr: ""
Dec 14 09:11:40.280: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:11:40.28
Dec 14 09:11:40.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:11:40.471: INFO: stderr: ""
Dec 14 09:11:40.471: INFO: stdout: "update-demo-nautilus-628pl update-demo-nautilus-sjnhs "
Dec 14 09:11:40.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:11:40.619: INFO: stderr: ""
Dec 14 09:11:40.619: INFO: stdout: ""
Dec 14 09:11:40.619: INFO: update-demo-nautilus-628pl is created but not running
Dec 14 09:11:45.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:11:45.798: INFO: stderr: ""
Dec 14 09:11:45.798: INFO: stdout: "update-demo-nautilus-628pl update-demo-nautilus-sjnhs "
Dec 14 09:11:45.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:11:45.967: INFO: stderr: ""
Dec 14 09:11:45.967: INFO: stdout: "true"
Dec 14 09:11:45.967: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:11:46.117: INFO: stderr: ""
Dec 14 09:11:46.117: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:11:46.117: INFO: validating pod update-demo-nautilus-628pl
Dec 14 09:11:46.180: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:11:46.180: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:11:46.180: INFO: update-demo-nautilus-628pl is verified up and running
Dec 14 09:11:46.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-sjnhs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:11:46.375: INFO: stderr: ""
Dec 14 09:11:46.375: INFO: stdout: "true"
Dec 14 09:11:46.375: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-sjnhs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:11:46.523: INFO: stderr: ""
Dec 14 09:11:46.523: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:11:46.523: INFO: validating pod update-demo-nautilus-sjnhs
Dec 14 09:11:46.645: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:11:46.646: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:11:46.646: INFO: update-demo-nautilus-sjnhs is verified up and running
STEP: using delete to clean up resources 12/14/22 09:11:46.646
Dec 14 09:11:46.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 delete --grace-period=0 --force -f -'
Dec 14 09:11:46.843: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:11:46.843: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 14 09:11:46.843: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get rc,svc -l name=update-demo --no-headers'
Dec 14 09:11:47.063: INFO: stderr: "No resources found in kubectl-5848 namespace.\n"
Dec 14 09:11:47.063: INFO: stdout: ""
Dec 14 09:11:47.064: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 09:11:47.226: INFO: stderr: ""
Dec 14 09:11:47.226: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:11:47.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5848" for this suite. 12/14/22 09:11:47.281
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":187,"skipped":3398,"failed":0}
------------------------------
• [8.368 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:38.943
    Dec 14 09:11:38.943: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:11:38.944
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:39.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:39.074
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 12/14/22 09:11:39.125
    Dec 14 09:11:39.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 create -f -'
    Dec 14 09:11:40.280: INFO: stderr: ""
    Dec 14 09:11:40.280: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:11:40.28
    Dec 14 09:11:40.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:11:40.471: INFO: stderr: ""
    Dec 14 09:11:40.471: INFO: stdout: "update-demo-nautilus-628pl update-demo-nautilus-sjnhs "
    Dec 14 09:11:40.471: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:11:40.619: INFO: stderr: ""
    Dec 14 09:11:40.619: INFO: stdout: ""
    Dec 14 09:11:40.619: INFO: update-demo-nautilus-628pl is created but not running
    Dec 14 09:11:45.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:11:45.798: INFO: stderr: ""
    Dec 14 09:11:45.798: INFO: stdout: "update-demo-nautilus-628pl update-demo-nautilus-sjnhs "
    Dec 14 09:11:45.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:11:45.967: INFO: stderr: ""
    Dec 14 09:11:45.967: INFO: stdout: "true"
    Dec 14 09:11:45.967: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-628pl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:11:46.117: INFO: stderr: ""
    Dec 14 09:11:46.117: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:11:46.117: INFO: validating pod update-demo-nautilus-628pl
    Dec 14 09:11:46.180: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:11:46.180: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:11:46.180: INFO: update-demo-nautilus-628pl is verified up and running
    Dec 14 09:11:46.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-sjnhs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:11:46.375: INFO: stderr: ""
    Dec 14 09:11:46.375: INFO: stdout: "true"
    Dec 14 09:11:46.375: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods update-demo-nautilus-sjnhs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:11:46.523: INFO: stderr: ""
    Dec 14 09:11:46.523: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:11:46.523: INFO: validating pod update-demo-nautilus-sjnhs
    Dec 14 09:11:46.645: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:11:46.646: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:11:46.646: INFO: update-demo-nautilus-sjnhs is verified up and running
    STEP: using delete to clean up resources 12/14/22 09:11:46.646
    Dec 14 09:11:46.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 delete --grace-period=0 --force -f -'
    Dec 14 09:11:46.843: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:11:46.843: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec 14 09:11:46.843: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get rc,svc -l name=update-demo --no-headers'
    Dec 14 09:11:47.063: INFO: stderr: "No resources found in kubectl-5848 namespace.\n"
    Dec 14 09:11:47.063: INFO: stdout: ""
    Dec 14 09:11:47.064: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5848 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 09:11:47.226: INFO: stderr: ""
    Dec 14 09:11:47.226: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:11:47.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5848" for this suite. 12/14/22 09:11:47.281
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:47.311
Dec 14 09:11:47.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:11:47.312
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:47.39
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:47.439
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:11:47.545
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:48.309
STEP: Deploying the webhook pod 12/14/22 09:11:48.338
STEP: Wait for the deployment to be ready 12/14/22 09:11:48.392
Dec 14 09:11:48.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:11:50.505
STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:50.543
Dec 14 09:11:51.544: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 12/14/22 09:11:51.57
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/14/22 09:11:51.595
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 09:11:51.595
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:11:51.595
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:11:51.62
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:11:51.62
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:11:51.645
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:11:51.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7735" for this suite. 12/14/22 09:11:51.7
STEP: Destroying namespace "webhook-7735-markers" for this suite. 12/14/22 09:11:51.727
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":188,"skipped":3401,"failed":0}
------------------------------
• [4.578 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:47.311
    Dec 14 09:11:47.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:11:47.312
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:47.39
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:47.439
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:11:47.545
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:48.309
    STEP: Deploying the webhook pod 12/14/22 09:11:48.338
    STEP: Wait for the deployment to be ready 12/14/22 09:11:48.392
    Dec 14 09:11:48.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:11:50.505
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:50.543
    Dec 14 09:11:51.544: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 12/14/22 09:11:51.57
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/14/22 09:11:51.595
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 09:11:51.595
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:11:51.595
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:11:51.62
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:11:51.62
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:11:51.645
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:11:51.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7735" for this suite. 12/14/22 09:11:51.7
    STEP: Destroying namespace "webhook-7735-markers" for this suite. 12/14/22 09:11:51.727
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:51.892
Dec 14 09:11:51.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:11:51.893
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:51.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:52.02
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-5e977295-1693-4c83-9bbd-ace22b2c71dd 12/14/22 09:11:52.178
STEP: Creating a pod to test consume secrets 12/14/22 09:11:52.204
Dec 14 09:11:52.237: INFO: Waiting up to 5m0s for pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a" in namespace "secrets-7573" to be "Succeeded or Failed"
Dec 14 09:11:52.264: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Pending", Reason="", readiness=false. Elapsed: 27.086464ms
Dec 14 09:11:54.291: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054631768s
Dec 14 09:11:56.291: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054874663s
STEP: Saw pod success 12/14/22 09:11:56.292
Dec 14 09:11:56.292: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a" satisfied condition "Succeeded or Failed"
Dec 14 09:11:56.319: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:11:56.402
Dec 14 09:11:56.436: INFO: Waiting for pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a to disappear
Dec 14 09:11:56.463: INFO: Pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:11:56.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7573" for this suite. 12/14/22 09:11:56.513
STEP: Destroying namespace "secret-namespace-8934" for this suite. 12/14/22 09:11:56.541
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":189,"skipped":3495,"failed":0}
------------------------------
• [4.677 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:51.892
    Dec 14 09:11:51.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:11:51.893
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:51.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:52.02
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-5e977295-1693-4c83-9bbd-ace22b2c71dd 12/14/22 09:11:52.178
    STEP: Creating a pod to test consume secrets 12/14/22 09:11:52.204
    Dec 14 09:11:52.237: INFO: Waiting up to 5m0s for pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a" in namespace "secrets-7573" to be "Succeeded or Failed"
    Dec 14 09:11:52.264: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Pending", Reason="", readiness=false. Elapsed: 27.086464ms
    Dec 14 09:11:54.291: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054631768s
    Dec 14 09:11:56.291: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054874663s
    STEP: Saw pod success 12/14/22 09:11:56.292
    Dec 14 09:11:56.292: INFO: Pod "pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a" satisfied condition "Succeeded or Failed"
    Dec 14 09:11:56.319: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:11:56.402
    Dec 14 09:11:56.436: INFO: Waiting for pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a to disappear
    Dec 14 09:11:56.463: INFO: Pod pod-secrets-6f7c7836-2ee7-4802-aede-5b5e62b6de2a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:11:56.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7573" for this suite. 12/14/22 09:11:56.513
    STEP: Destroying namespace "secret-namespace-8934" for this suite. 12/14/22 09:11:56.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:56.569
Dec 14 09:11:56.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:11:56.57
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:56.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:56.7
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 12/14/22 09:11:56.75
STEP: watching for the ServiceAccount to be added 12/14/22 09:11:56.802
STEP: patching the ServiceAccount 12/14/22 09:11:56.827
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/14/22 09:11:56.855
STEP: deleting the ServiceAccount 12/14/22 09:11:56.883
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:11:56.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9649" for this suite. 12/14/22 09:11:56.946
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":190,"skipped":3503,"failed":0}
------------------------------
• [0.422 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:56.569
    Dec 14 09:11:56.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:11:56.57
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:56.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:56.7
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 12/14/22 09:11:56.75
    STEP: watching for the ServiceAccount to be added 12/14/22 09:11:56.802
    STEP: patching the ServiceAccount 12/14/22 09:11:56.827
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/14/22 09:11:56.855
    STEP: deleting the ServiceAccount 12/14/22 09:11:56.883
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:11:56.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9649" for this suite. 12/14/22 09:11:56.946
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:56.991
Dec 14 09:11:56.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:11:56.992
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:57.069
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:57.119
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:11:57.226
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:57.73
STEP: Deploying the webhook pod 12/14/22 09:11:57.757
STEP: Wait for the deployment to be ready 12/14/22 09:11:57.817
Dec 14 09:11:57.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:11:59.927
STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:59.963
Dec 14 09:12:00.963: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/14/22 09:12:00.99
STEP: create a namespace for the webhook 12/14/22 09:12:01.154
STEP: create a configmap should be unconditionally rejected by the webhook 12/14/22 09:12:01.183
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:12:01.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5709" for this suite. 12/14/22 09:12:01.374
STEP: Destroying namespace "webhook-5709-markers" for this suite. 12/14/22 09:12:01.403
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":191,"skipped":3503,"failed":0}
------------------------------
• [4.582 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:56.991
    Dec 14 09:11:56.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:11:56.992
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:57.069
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:57.119
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:11:57.226
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:57.73
    STEP: Deploying the webhook pod 12/14/22 09:11:57.757
    STEP: Wait for the deployment to be ready 12/14/22 09:11:57.817
    Dec 14 09:11:57.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:11:59.927
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:59.963
    Dec 14 09:12:00.963: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/14/22 09:12:00.99
    STEP: create a namespace for the webhook 12/14/22 09:12:01.154
    STEP: create a configmap should be unconditionally rejected by the webhook 12/14/22 09:12:01.183
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:12:01.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5709" for this suite. 12/14/22 09:12:01.374
    STEP: Destroying namespace "webhook-5709-markers" for this suite. 12/14/22 09:12:01.403
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:01.579
Dec 14 09:12:01.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:12:01.58
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:01.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:01.707
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 12/14/22 09:12:01.757
Dec 14 09:12:01.757: INFO: namespace kubectl-5858
Dec 14 09:12:01.757: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 create -f -'
Dec 14 09:12:02.734: INFO: stderr: ""
Dec 14 09:12:02.734: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 09:12:02.734
Dec 14 09:12:03.762: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:12:03.762: INFO: Found 0 / 1
Dec 14 09:12:04.762: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:12:04.762: INFO: Found 1 / 1
Dec 14 09:12:04.762: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 14 09:12:04.789: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:12:04.789: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 09:12:04.789: INFO: wait on agnhost-primary startup in kubectl-5858 
Dec 14 09:12:04.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 logs agnhost-primary-7wmww agnhost-primary'
Dec 14 09:12:04.994: INFO: stderr: ""
Dec 14 09:12:04.994: INFO: stdout: "Paused\n"
STEP: exposing RC 12/14/22 09:12:04.994
Dec 14 09:12:04.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Dec 14 09:12:05.204: INFO: stderr: ""
Dec 14 09:12:05.204: INFO: stdout: "service/rm2 exposed\n"
Dec 14 09:12:05.230: INFO: Service rm2 in namespace kubectl-5858 found.
STEP: exposing service 12/14/22 09:12:07.283
Dec 14 09:12:07.283: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Dec 14 09:12:07.484: INFO: stderr: ""
Dec 14 09:12:07.484: INFO: stdout: "service/rm3 exposed\n"
Dec 14 09:12:07.510: INFO: Service rm3 in namespace kubectl-5858 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:12:09.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5858" for this suite. 12/14/22 09:12:09.614
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":192,"skipped":3608,"failed":0}
------------------------------
• [8.063 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:01.579
    Dec 14 09:12:01.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:12:01.58
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:01.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:01.707
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 12/14/22 09:12:01.757
    Dec 14 09:12:01.757: INFO: namespace kubectl-5858
    Dec 14 09:12:01.757: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 create -f -'
    Dec 14 09:12:02.734: INFO: stderr: ""
    Dec 14 09:12:02.734: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 09:12:02.734
    Dec 14 09:12:03.762: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:12:03.762: INFO: Found 0 / 1
    Dec 14 09:12:04.762: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:12:04.762: INFO: Found 1 / 1
    Dec 14 09:12:04.762: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec 14 09:12:04.789: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:12:04.789: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 09:12:04.789: INFO: wait on agnhost-primary startup in kubectl-5858 
    Dec 14 09:12:04.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 logs agnhost-primary-7wmww agnhost-primary'
    Dec 14 09:12:04.994: INFO: stderr: ""
    Dec 14 09:12:04.994: INFO: stdout: "Paused\n"
    STEP: exposing RC 12/14/22 09:12:04.994
    Dec 14 09:12:04.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Dec 14 09:12:05.204: INFO: stderr: ""
    Dec 14 09:12:05.204: INFO: stdout: "service/rm2 exposed\n"
    Dec 14 09:12:05.230: INFO: Service rm2 in namespace kubectl-5858 found.
    STEP: exposing service 12/14/22 09:12:07.283
    Dec 14 09:12:07.283: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5858 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Dec 14 09:12:07.484: INFO: stderr: ""
    Dec 14 09:12:07.484: INFO: stdout: "service/rm3 exposed\n"
    Dec 14 09:12:07.510: INFO: Service rm3 in namespace kubectl-5858 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:12:09.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5858" for this suite. 12/14/22 09:12:09.614
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:09.642
Dec 14 09:12:09.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator 12/14/22 09:12:09.643
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:09.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:09.773
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Dec 14 09:12:09.822: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 12/14/22 09:12:09.823
Dec 14 09:12:10.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:12.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:14.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:16.687: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:18.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:20.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:22.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:24.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:26.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:28.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:30.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:32.685: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:12:34.998: INFO: Waited 287.229504ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 12/14/22 09:12:35.694
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/14/22 09:12:35.723
STEP: List APIServices 12/14/22 09:12:35.749
Dec 14 09:12:35.779: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Dec 14 09:12:36.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9589" for this suite. 12/14/22 09:12:36.463
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":193,"skipped":3612,"failed":0}
------------------------------
• [26.848 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:09.642
    Dec 14 09:12:09.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename aggregator 12/14/22 09:12:09.643
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:09.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:09.773
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Dec 14 09:12:09.822: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 12/14/22 09:12:09.823
    Dec 14 09:12:10.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:12.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:14.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:16.687: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:18.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:20.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:22.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:24.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:26.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:28.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:30.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:32.685: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 12, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:12:34.998: INFO: Waited 287.229504ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 12/14/22 09:12:35.694
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/14/22 09:12:35.723
    STEP: List APIServices 12/14/22 09:12:35.749
    Dec 14 09:12:35.779: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Dec 14 09:12:36.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-9589" for this suite. 12/14/22 09:12:36.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:36.491
Dec 14 09:12:36.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:12:36.492
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:36.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:36.62
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-cdc15446-9506-405d-8e0b-bed7a0b2f152 12/14/22 09:12:36.67
STEP: Creating a pod to test consume secrets 12/14/22 09:12:36.698
Dec 14 09:12:36.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2" in namespace "projected-8173" to be "Succeeded or Failed"
Dec 14 09:12:36.759: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.620237ms
Dec 14 09:12:38.789: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057220283s
Dec 14 09:12:40.787: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055858262s
STEP: Saw pod success 12/14/22 09:12:40.787
Dec 14 09:12:40.787: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2" satisfied condition "Succeeded or Failed"
Dec 14 09:12:40.813: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:12:40.851
Dec 14 09:12:40.893: INFO: Waiting for pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 to disappear
Dec 14 09:12:40.919: INFO: Pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:12:40.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8173" for this suite. 12/14/22 09:12:40.971
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":194,"skipped":3626,"failed":0}
------------------------------
• [4.507 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:36.491
    Dec 14 09:12:36.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:12:36.492
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:36.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:36.62
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-cdc15446-9506-405d-8e0b-bed7a0b2f152 12/14/22 09:12:36.67
    STEP: Creating a pod to test consume secrets 12/14/22 09:12:36.698
    Dec 14 09:12:36.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2" in namespace "projected-8173" to be "Succeeded or Failed"
    Dec 14 09:12:36.759: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.620237ms
    Dec 14 09:12:38.789: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057220283s
    Dec 14 09:12:40.787: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055858262s
    STEP: Saw pod success 12/14/22 09:12:40.787
    Dec 14 09:12:40.787: INFO: Pod "pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2" satisfied condition "Succeeded or Failed"
    Dec 14 09:12:40.813: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:12:40.851
    Dec 14 09:12:40.893: INFO: Waiting for pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 to disappear
    Dec 14 09:12:40.919: INFO: Pod pod-projected-secrets-44e97361-8841-4869-adfc-3bce9e1389f2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:12:40.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8173" for this suite. 12/14/22 09:12:40.971
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:40.999
Dec 14 09:12:40.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:12:41
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:41.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:41.128
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 12/14/22 09:12:41.178
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local;sleep 1; done
 12/14/22 09:12:41.205
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local;sleep 1; done
 12/14/22 09:12:41.205
STEP: creating a pod to probe DNS 12/14/22 09:12:41.205
STEP: submitting the pod to kubernetes 12/14/22 09:12:41.205
Dec 14 09:12:41.241: INFO: Waiting up to 15m0s for pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242" in namespace "dns-9317" to be "running"
Dec 14 09:12:41.267: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242": Phase="Pending", Reason="", readiness=false. Elapsed: 25.563493ms
Dec 14 09:12:43.295: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242": Phase="Running", Reason="", readiness=true. Elapsed: 2.053738185s
Dec 14 09:12:43.295: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:12:43.295
STEP: looking for the results for each expected name from probers 12/14/22 09:12:43.322
Dec 14 09:12:43.454: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.500: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.531: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.565: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.599: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.632: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.663: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.693: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:43.693: INFO: Lookups using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local]

Dec 14 09:12:48.728: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.772: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.804: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.835: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.865: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.898: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.928: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.961: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
Dec 14 09:12:48.961: INFO: Lookups using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local]

Dec 14 09:12:53.955: INFO: DNS probes using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 succeeded

STEP: deleting the pod 12/14/22 09:12:53.955
STEP: deleting the test headless service 12/14/22 09:12:53.993
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:12:54.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9317" for this suite. 12/14/22 09:12:54.078
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":195,"skipped":3631,"failed":0}
------------------------------
• [13.105 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:40.999
    Dec 14 09:12:40.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:12:41
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:41.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:41.128
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 12/14/22 09:12:41.178
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local;sleep 1; done
     12/14/22 09:12:41.205
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local;sleep 1; done
     12/14/22 09:12:41.205
    STEP: creating a pod to probe DNS 12/14/22 09:12:41.205
    STEP: submitting the pod to kubernetes 12/14/22 09:12:41.205
    Dec 14 09:12:41.241: INFO: Waiting up to 15m0s for pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242" in namespace "dns-9317" to be "running"
    Dec 14 09:12:41.267: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242": Phase="Pending", Reason="", readiness=false. Elapsed: 25.563493ms
    Dec 14 09:12:43.295: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242": Phase="Running", Reason="", readiness=true. Elapsed: 2.053738185s
    Dec 14 09:12:43.295: INFO: Pod "dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:12:43.295
    STEP: looking for the results for each expected name from probers 12/14/22 09:12:43.322
    Dec 14 09:12:43.454: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.500: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.531: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.565: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.599: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.632: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.663: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.693: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:43.693: INFO: Lookups using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local]

    Dec 14 09:12:48.728: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.772: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.804: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.835: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.865: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.898: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.928: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.961: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local from pod dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242: the server could not find the requested resource (get pods dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242)
    Dec 14 09:12:48.961: INFO: Lookups using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9317.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9317.svc.cluster.local jessie_udp@dns-test-service-2.dns-9317.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9317.svc.cluster.local]

    Dec 14 09:12:53.955: INFO: DNS probes using dns-9317/dns-test-222fdcd3-575b-49b6-9ebd-39d7028b6242 succeeded

    STEP: deleting the pod 12/14/22 09:12:53.955
    STEP: deleting the test headless service 12/14/22 09:12:53.993
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:12:54.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9317" for this suite. 12/14/22 09:12:54.078
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:54.105
Dec 14 09:12:54.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:12:54.105
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:54.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:54.232
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 12/14/22 09:12:54.281
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 12/14/22 09:12:54.307
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 12/14/22 09:12:54.308
STEP: creating a pod to probe DNS 12/14/22 09:12:54.308
STEP: submitting the pod to kubernetes 12/14/22 09:12:54.308
Dec 14 09:12:54.341: INFO: Waiting up to 15m0s for pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d" in namespace "dns-3920" to be "running"
Dec 14 09:12:54.367: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02492ms
Dec 14 09:12:56.395: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d": Phase="Running", Reason="", readiness=true. Elapsed: 2.053998003s
Dec 14 09:12:56.395: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:12:56.395
STEP: looking for the results for each expected name from probers 12/14/22 09:12:56.424
Dec 14 09:12:56.673: INFO: DNS probes using dns-3920/dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d succeeded

STEP: deleting the pod 12/14/22 09:12:56.673
STEP: deleting the test headless service 12/14/22 09:12:56.711
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:12:56.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3920" for this suite. 12/14/22 09:12:56.812
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":196,"skipped":3635,"failed":0}
------------------------------
• [2.734 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:54.105
    Dec 14 09:12:54.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:12:54.105
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:54.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:54.232
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 12/14/22 09:12:54.281
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     12/14/22 09:12:54.307
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3920.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     12/14/22 09:12:54.308
    STEP: creating a pod to probe DNS 12/14/22 09:12:54.308
    STEP: submitting the pod to kubernetes 12/14/22 09:12:54.308
    Dec 14 09:12:54.341: INFO: Waiting up to 15m0s for pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d" in namespace "dns-3920" to be "running"
    Dec 14 09:12:54.367: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02492ms
    Dec 14 09:12:56.395: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d": Phase="Running", Reason="", readiness=true. Elapsed: 2.053998003s
    Dec 14 09:12:56.395: INFO: Pod "dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:12:56.395
    STEP: looking for the results for each expected name from probers 12/14/22 09:12:56.424
    Dec 14 09:12:56.673: INFO: DNS probes using dns-3920/dns-test-07a3e5e8-e260-4c36-8af9-e6de1ec3417d succeeded

    STEP: deleting the pod 12/14/22 09:12:56.673
    STEP: deleting the test headless service 12/14/22 09:12:56.711
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:12:56.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3920" for this suite. 12/14/22 09:12:56.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:56.841
Dec 14 09:12:56.841: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:12:56.842
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:56.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:56.975
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 in namespace container-probe-6638 12/14/22 09:12:57.025
Dec 14 09:12:57.057: INFO: Waiting up to 5m0s for pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8" in namespace "container-probe-6638" to be "not pending"
Dec 14 09:12:57.084: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.144381ms
Dec 14 09:12:59.119: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8": Phase="Running", Reason="", readiness=true. Elapsed: 2.061739937s
Dec 14 09:12:59.119: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8" satisfied condition "not pending"
Dec 14 09:12:59.119: INFO: Started pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 in namespace container-probe-6638
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:12:59.119
Dec 14 09:12:59.145: INFO: Initial restart count of pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is 0
Dec 14 09:13:19.457: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 1 (20.311497047s elapsed)
Dec 14 09:13:39.731: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 2 (40.585779829s elapsed)
Dec 14 09:14:00.009: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 3 (1m0.863513907s elapsed)
Dec 14 09:14:18.259: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 4 (1m19.11347331s elapsed)
Dec 14 09:15:25.176: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 5 (2m26.030119286s elapsed)
STEP: deleting the pod 12/14/22 09:15:25.176
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:15:25.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6638" for this suite. 12/14/22 09:15:25.261
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":197,"skipped":3642,"failed":0}
------------------------------
• [148.449 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:56.841
    Dec 14 09:12:56.841: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:12:56.842
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:56.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:56.975
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 in namespace container-probe-6638 12/14/22 09:12:57.025
    Dec 14 09:12:57.057: INFO: Waiting up to 5m0s for pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8" in namespace "container-probe-6638" to be "not pending"
    Dec 14 09:12:57.084: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.144381ms
    Dec 14 09:12:59.119: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8": Phase="Running", Reason="", readiness=true. Elapsed: 2.061739937s
    Dec 14 09:12:59.119: INFO: Pod "liveness-052ae40d-1e25-44cb-bc3b-837c455485a8" satisfied condition "not pending"
    Dec 14 09:12:59.119: INFO: Started pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 in namespace container-probe-6638
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:12:59.119
    Dec 14 09:12:59.145: INFO: Initial restart count of pod liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is 0
    Dec 14 09:13:19.457: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 1 (20.311497047s elapsed)
    Dec 14 09:13:39.731: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 2 (40.585779829s elapsed)
    Dec 14 09:14:00.009: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 3 (1m0.863513907s elapsed)
    Dec 14 09:14:18.259: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 4 (1m19.11347331s elapsed)
    Dec 14 09:15:25.176: INFO: Restart count of pod container-probe-6638/liveness-052ae40d-1e25-44cb-bc3b-837c455485a8 is now 5 (2m26.030119286s elapsed)
    STEP: deleting the pod 12/14/22 09:15:25.176
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:15:25.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6638" for this suite. 12/14/22 09:15:25.261
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:15:25.29
Dec 14 09:15:25.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:15:25.291
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:15:25.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:15:25.42
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 12/14/22 09:15:25.469
STEP: Ensuring more than one job is running at a time 12/14/22 09:15:25.497
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/14/22 09:17:01.527
STEP: Removing cronjob 12/14/22 09:17:01.554
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:17:01.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1123" for this suite. 12/14/22 09:17:01.633
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":198,"skipped":3644,"failed":0}
------------------------------
• [96.373 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:15:25.29
    Dec 14 09:15:25.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:15:25.291
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:15:25.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:15:25.42
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 12/14/22 09:15:25.469
    STEP: Ensuring more than one job is running at a time 12/14/22 09:15:25.497
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/14/22 09:17:01.527
    STEP: Removing cronjob 12/14/22 09:17:01.554
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:17:01.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1123" for this suite. 12/14/22 09:17:01.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:01.664
Dec 14 09:17:01.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:17:01.666
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:01.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:01.795
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Dec 14 09:17:01.880: INFO: Waiting up to 2m0s for pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" in namespace "var-expansion-4811" to be "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:17:01.906: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81": Phase="Pending", Reason="", readiness=false. Elapsed: 25.879677ms
Dec 14 09:17:03.933: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053383166s
Dec 14 09:17:03.934: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:17:03.934: INFO: Deleting pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" in namespace "var-expansion-4811"
Dec 14 09:17:03.961: INFO: Wait up to 5m0s for pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:17:06.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4811" for this suite. 12/14/22 09:17:06.067
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":199,"skipped":3658,"failed":0}
------------------------------
• [4.430 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:01.664
    Dec 14 09:17:01.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:17:01.666
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:01.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:01.795
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Dec 14 09:17:01.880: INFO: Waiting up to 2m0s for pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" in namespace "var-expansion-4811" to be "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:17:01.906: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81": Phase="Pending", Reason="", readiness=false. Elapsed: 25.879677ms
    Dec 14 09:17:03.933: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053383166s
    Dec 14 09:17:03.934: INFO: Pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:17:03.934: INFO: Deleting pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" in namespace "var-expansion-4811"
    Dec 14 09:17:03.961: INFO: Wait up to 5m0s for pod "var-expansion-5b28c551-137b-4c68-94af-e7ebe260bf81" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:17:06.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4811" for this suite. 12/14/22 09:17:06.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:06.097
Dec 14 09:17:06.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:17:06.098
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.231
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:17:06.281
Dec 14 09:17:06.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f" in namespace "downward-api-7350" to be "Succeeded or Failed"
Dec 14 09:17:06.339: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.538179ms
Dec 14 09:17:08.366: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052598039s
Dec 14 09:17:10.366: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053056076s
STEP: Saw pod success 12/14/22 09:17:10.366
Dec 14 09:17:10.367: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f" satisfied condition "Succeeded or Failed"
Dec 14 09:17:10.393: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f container client-container: <nil>
STEP: delete the pod 12/14/22 09:17:10.466
Dec 14 09:17:10.502: INFO: Waiting for pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f to disappear
Dec 14 09:17:10.529: INFO: Pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:17:10.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7350" for this suite. 12/14/22 09:17:10.587
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":200,"skipped":3711,"failed":0}
------------------------------
• [4.517 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:06.097
    Dec 14 09:17:06.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:17:06.098
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.231
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:17:06.281
    Dec 14 09:17:06.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f" in namespace "downward-api-7350" to be "Succeeded or Failed"
    Dec 14 09:17:06.339: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.538179ms
    Dec 14 09:17:08.366: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052598039s
    Dec 14 09:17:10.366: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053056076s
    STEP: Saw pod success 12/14/22 09:17:10.366
    Dec 14 09:17:10.367: INFO: Pod "downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f" satisfied condition "Succeeded or Failed"
    Dec 14 09:17:10.393: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f container client-container: <nil>
    STEP: delete the pod 12/14/22 09:17:10.466
    Dec 14 09:17:10.502: INFO: Waiting for pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f to disappear
    Dec 14 09:17:10.529: INFO: Pod downwardapi-volume-99313e9b-a85f-4ab3-9437-695085e36c6f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:17:10.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7350" for this suite. 12/14/22 09:17:10.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:10.615
Dec 14 09:17:10.615: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:17:10.616
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:10.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:10.743
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 12/14/22 09:17:10.794
STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.82
STEP: updating the pdb 12/14/22 09:17:10.846
STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.902
STEP: patching the pdb 12/14/22 09:17:10.928
STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.983
STEP: Waiting for the pdb to be deleted 12/14/22 09:17:11.036
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:17:11.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3187" for this suite. 12/14/22 09:17:11.091
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":201,"skipped":3729,"failed":0}
------------------------------
• [0.507 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:10.615
    Dec 14 09:17:10.615: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:17:10.616
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:10.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:10.743
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 12/14/22 09:17:10.794
    STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.82
    STEP: updating the pdb 12/14/22 09:17:10.846
    STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.902
    STEP: patching the pdb 12/14/22 09:17:10.928
    STEP: Waiting for the pdb to be processed 12/14/22 09:17:10.983
    STEP: Waiting for the pdb to be deleted 12/14/22 09:17:11.036
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:17:11.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3187" for this suite. 12/14/22 09:17:11.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:11.124
Dec 14 09:17:11.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:17:11.125
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:11.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:11.254
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  12/14/22 09:17:11.304
Dec 14 09:17:11.341: INFO: Waiting up to 5m0s for pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0" in namespace "svcaccounts-3110" to be "Succeeded or Failed"
Dec 14 09:17:11.367: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.135763ms
Dec 14 09:17:13.400: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059617638s
Dec 14 09:17:15.395: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054652909s
STEP: Saw pod success 12/14/22 09:17:15.395
Dec 14 09:17:15.395: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0" satisfied condition "Succeeded or Failed"
Dec 14 09:17:15.422: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:17:15.455
Dec 14 09:17:15.489: INFO: Waiting for pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 to disappear
Dec 14 09:17:15.515: INFO: Pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:17:15.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3110" for this suite. 12/14/22 09:17:15.565
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":202,"skipped":3767,"failed":0}
------------------------------
• [4.469 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:11.124
    Dec 14 09:17:11.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:17:11.125
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:11.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:11.254
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  12/14/22 09:17:11.304
    Dec 14 09:17:11.341: INFO: Waiting up to 5m0s for pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0" in namespace "svcaccounts-3110" to be "Succeeded or Failed"
    Dec 14 09:17:11.367: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.135763ms
    Dec 14 09:17:13.400: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059617638s
    Dec 14 09:17:15.395: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054652909s
    STEP: Saw pod success 12/14/22 09:17:15.395
    Dec 14 09:17:15.395: INFO: Pod "test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0" satisfied condition "Succeeded or Failed"
    Dec 14 09:17:15.422: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:17:15.455
    Dec 14 09:17:15.489: INFO: Waiting for pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 to disappear
    Dec 14 09:17:15.515: INFO: Pod test-pod-5351a3d7-7bb6-4d9a-8ff8-64df88776bf0 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:17:15.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3110" for this suite. 12/14/22 09:17:15.565
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:15.594
Dec 14 09:17:15.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 09:17:15.595
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:15.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:15.723
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 09:17:15.775: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 09:17:15.829: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 09:17:15.856: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
Dec 14 09:17:15.916: INFO: concurrent-27850156-xs9c9 from cronjob-1123 started at 2022-12-14 09:16:00 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container c ready: true, restart count 0
Dec 14 09:17:15.916: INFO: concurrent-27850157-x8nrc from cronjob-1123 started at 2022-12-14 09:17:00 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container c ready: true, restart count 0
Dec 14 09:17:15.916: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:17:15.916: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:17:15.916: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:17:15.916: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:17:15.916: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:17:15.916: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:17:15.916: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:17:15.916: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:17:15.916: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:17:15.916: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:17:15.916: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:17:15.916: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:17:15.916: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:17:15.916: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:17:15.916: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:17:15.916: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.916: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:17:15.916: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
Dec 14 09:17:15.952: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 09:17:15.952: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 09:17:15.952: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:17:15.952: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:17:15.952: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:17:15.952: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 09:17:15.952: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:17:15.952: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:17:15.952: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:17:15.952: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:17:15.952: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:17:15.952: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:17:15.952: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:17:15.952: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:17:15.952: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:17:15.952: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:17:15.952: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:17:15.952: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:17:15.952: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:17:15.952: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:17:15.952: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:17:15.952: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 09:17:15.952: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 09:17:15.952: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:17:15.952: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 09:17:15.952
Dec 14 09:17:15.983: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5753" to be "running"
Dec 14 09:17:16.014: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 30.604485ms
Dec 14 09:17:18.042: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.05875509s
Dec 14 09:17:18.042: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 09:17:18.068
STEP: Trying to apply a random label on the found node. 12/14/22 09:17:18.103
STEP: verifying the node has the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e 42 12/14/22 09:17:18.164
STEP: Trying to relaunch the pod, now with labels. 12/14/22 09:17:18.19
Dec 14 09:17:18.224: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5753" to be "not pending"
Dec 14 09:17:18.250: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 25.996272ms
Dec 14 09:17:20.278: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.054039379s
Dec 14 09:17:20.278: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:17:20.304
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e 12/14/22 09:17:20.409
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:17:20.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5753" for this suite. 12/14/22 09:17:20.463
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":203,"skipped":3778,"failed":0}
------------------------------
• [4.897 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:15.594
    Dec 14 09:17:15.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 09:17:15.595
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:15.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:15.723
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 09:17:15.775: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 09:17:15.829: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 09:17:15.856: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
    Dec 14 09:17:15.916: INFO: concurrent-27850156-xs9c9 from cronjob-1123 started at 2022-12-14 09:16:00 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container c ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: concurrent-27850157-x8nrc from cronjob-1123 started at 2022-12-14 09:17:00 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container c ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:17:15.916: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.916: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:17:15.916: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
    Dec 14 09:17:15.952: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:17:15.952: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:17:15.952: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:17:15.952: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 09:17:15.952: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:17:15.952: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 09:17:15.952
    Dec 14 09:17:15.983: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5753" to be "running"
    Dec 14 09:17:16.014: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 30.604485ms
    Dec 14 09:17:18.042: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.05875509s
    Dec 14 09:17:18.042: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 09:17:18.068
    STEP: Trying to apply a random label on the found node. 12/14/22 09:17:18.103
    STEP: verifying the node has the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e 42 12/14/22 09:17:18.164
    STEP: Trying to relaunch the pod, now with labels. 12/14/22 09:17:18.19
    Dec 14 09:17:18.224: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5753" to be "not pending"
    Dec 14 09:17:18.250: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 25.996272ms
    Dec 14 09:17:20.278: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.054039379s
    Dec 14 09:17:20.278: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 09:17:20.304
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-ff340b13-c61d-4bc0-99c8-96bfc9f3381e 12/14/22 09:17:20.409
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:17:20.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5753" for this suite. 12/14/22 09:17:20.463
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:20.492
Dec 14 09:17:20.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:17:20.493
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:20.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:20.622
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-758d146a-6b63-4efe-a25f-15a21d87fb3a 12/14/22 09:17:20.671
STEP: Creating a pod to test consume secrets 12/14/22 09:17:20.697
Dec 14 09:17:20.730: INFO: Waiting up to 5m0s for pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587" in namespace "secrets-3503" to be "Succeeded or Failed"
Dec 14 09:17:20.758: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Pending", Reason="", readiness=false. Elapsed: 28.232477ms
Dec 14 09:17:22.785: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Running", Reason="", readiness=false. Elapsed: 2.055579912s
Dec 14 09:17:24.787: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056971742s
STEP: Saw pod success 12/14/22 09:17:24.787
Dec 14 09:17:24.787: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587" satisfied condition "Succeeded or Failed"
Dec 14 09:17:24.815: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:17:24.85
Dec 14 09:17:24.887: INFO: Waiting for pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 to disappear
Dec 14 09:17:24.914: INFO: Pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:17:24.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3503" for this suite. 12/14/22 09:17:24.967
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":204,"skipped":3798,"failed":0}
------------------------------
• [4.505 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:20.492
    Dec 14 09:17:20.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:17:20.493
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:20.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:20.622
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-758d146a-6b63-4efe-a25f-15a21d87fb3a 12/14/22 09:17:20.671
    STEP: Creating a pod to test consume secrets 12/14/22 09:17:20.697
    Dec 14 09:17:20.730: INFO: Waiting up to 5m0s for pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587" in namespace "secrets-3503" to be "Succeeded or Failed"
    Dec 14 09:17:20.758: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Pending", Reason="", readiness=false. Elapsed: 28.232477ms
    Dec 14 09:17:22.785: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Running", Reason="", readiness=false. Elapsed: 2.055579912s
    Dec 14 09:17:24.787: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056971742s
    STEP: Saw pod success 12/14/22 09:17:24.787
    Dec 14 09:17:24.787: INFO: Pod "pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587" satisfied condition "Succeeded or Failed"
    Dec 14 09:17:24.815: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:17:24.85
    Dec 14 09:17:24.887: INFO: Waiting for pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 to disappear
    Dec 14 09:17:24.914: INFO: Pod pod-secrets-31b35e31-2f1b-4189-95cd-a8a5d9188587 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:17:24.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3503" for this suite. 12/14/22 09:17:24.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:24.997
Dec 14 09:17:24.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:17:24.998
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:25.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:25.134
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 12/14/22 09:17:25.189
STEP: modifying the configmap once 12/14/22 09:17:25.219
STEP: modifying the configmap a second time 12/14/22 09:17:25.28
STEP: deleting the configmap 12/14/22 09:17:25.336
STEP: creating a watch on configmaps from the resource version returned by the first update 12/14/22 09:17:25.364
STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/14/22 09:17:25.393
Dec 14 09:17:25.393: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3933  79284265-b1f9-46cc-83a5-d586ae185974 36658 0 2022-12-14 09:17:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:17:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:17:25.394: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3933  79284265-b1f9-46cc-83a5-d586ae185974 36659 0 2022-12-14 09:17:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:17:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:17:25.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3933" for this suite. 12/14/22 09:17:25.423
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":205,"skipped":3811,"failed":0}
------------------------------
• [0.454 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:24.997
    Dec 14 09:17:24.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:17:24.998
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:25.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:25.134
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 12/14/22 09:17:25.189
    STEP: modifying the configmap once 12/14/22 09:17:25.219
    STEP: modifying the configmap a second time 12/14/22 09:17:25.28
    STEP: deleting the configmap 12/14/22 09:17:25.336
    STEP: creating a watch on configmaps from the resource version returned by the first update 12/14/22 09:17:25.364
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/14/22 09:17:25.393
    Dec 14 09:17:25.393: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3933  79284265-b1f9-46cc-83a5-d586ae185974 36658 0 2022-12-14 09:17:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:17:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:17:25.394: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3933  79284265-b1f9-46cc-83a5-d586ae185974 36659 0 2022-12-14 09:17:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:17:25 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:17:25.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3933" for this suite. 12/14/22 09:17:25.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:25.453
Dec 14 09:17:25.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:17:25.453
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:25.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:25.588
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/14/22 09:17:25.641
Dec 14 09:17:25.641: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:17:30.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:17:46.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9574" for this suite. 12/14/22 09:17:46.801
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":206,"skipped":3821,"failed":0}
------------------------------
• [21.376 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:25.453
    Dec 14 09:17:25.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:17:25.453
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:25.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:25.588
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/14/22 09:17:25.641
    Dec 14 09:17:25.641: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:17:30.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:17:46.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9574" for this suite. 12/14/22 09:17:46.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:46.83
Dec 14 09:17:46.830: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:17:46.831
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:46.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:46.961
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 12/14/22 09:17:47.009
STEP: Ensuring a job is scheduled 12/14/22 09:17:47.036
STEP: Ensuring exactly one is scheduled 12/14/22 09:18:01.062
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:18:01.087
STEP: Ensuring the job is replaced with a new one 12/14/22 09:18:01.114
STEP: Removing cronjob 12/14/22 09:19:01.141
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:19:01.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9561" for this suite. 12/14/22 09:19:01.234
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":207,"skipped":3848,"failed":0}
------------------------------
• [74.437 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:46.83
    Dec 14 09:17:46.830: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:17:46.831
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:46.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:46.961
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 12/14/22 09:17:47.009
    STEP: Ensuring a job is scheduled 12/14/22 09:17:47.036
    STEP: Ensuring exactly one is scheduled 12/14/22 09:18:01.062
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:18:01.087
    STEP: Ensuring the job is replaced with a new one 12/14/22 09:18:01.114
    STEP: Removing cronjob 12/14/22 09:19:01.141
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:19:01.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9561" for this suite. 12/14/22 09:19:01.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:19:01.268
Dec 14 09:19:01.268: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:19:01.269
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:01.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:01.391
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 12/14/22 09:19:01.438
Dec 14 09:19:01.481: INFO: Waiting up to 5m0s for pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40" in namespace "downward-api-653" to be "Succeeded or Failed"
Dec 14 09:19:01.506: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Pending", Reason="", readiness=false. Elapsed: 25.081963ms
Dec 14 09:19:03.534: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052746442s
Dec 14 09:19:05.532: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051432161s
STEP: Saw pod success 12/14/22 09:19:05.532
Dec 14 09:19:05.533: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40" satisfied condition "Succeeded or Failed"
Dec 14 09:19:05.558: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:19:05.595
Dec 14 09:19:05.634: INFO: Waiting for pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 to disappear
Dec 14 09:19:05.659: INFO: Pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 09:19:05.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-653" for this suite. 12/14/22 09:19:05.708
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":208,"skipped":3870,"failed":0}
------------------------------
• [4.471 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:19:01.268
    Dec 14 09:19:01.268: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:19:01.269
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:01.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:01.391
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 12/14/22 09:19:01.438
    Dec 14 09:19:01.481: INFO: Waiting up to 5m0s for pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40" in namespace "downward-api-653" to be "Succeeded or Failed"
    Dec 14 09:19:01.506: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Pending", Reason="", readiness=false. Elapsed: 25.081963ms
    Dec 14 09:19:03.534: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052746442s
    Dec 14 09:19:05.532: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051432161s
    STEP: Saw pod success 12/14/22 09:19:05.532
    Dec 14 09:19:05.533: INFO: Pod "downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40" satisfied condition "Succeeded or Failed"
    Dec 14 09:19:05.558: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:19:05.595
    Dec 14 09:19:05.634: INFO: Waiting for pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 to disappear
    Dec 14 09:19:05.659: INFO: Pod downward-api-c3df7062-6cd0-4ef6-9946-b8da9ff89a40 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 09:19:05.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-653" for this suite. 12/14/22 09:19:05.708
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:19:05.74
Dec 14 09:19:05.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:19:05.741
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:05.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:05.863
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5443 12/14/22 09:19:05.911
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-5443 12/14/22 09:19:05.936
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5443 12/14/22 09:19:05.964
Dec 14 09:19:05.989: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec 14 09:19:16.018: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/14/22 09:19:16.019
Dec 14 09:19:16.045: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:19:16.762: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:19:16.762: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:19:16.762: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:19:16.789: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 14 09:19:26.817: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:19:26.817: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:19:26.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999592s
Dec 14 09:19:27.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.972097701s
Dec 14 09:19:28.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.944257252s
Dec 14 09:19:30.003: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.916974707s
Dec 14 09:19:31.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.889870094s
Dec 14 09:19:32.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.863132349s
Dec 14 09:19:33.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.834067114s
Dec 14 09:19:34.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.806844825s
Dec 14 09:19:35.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.779272767s
Dec 14 09:19:36.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 751.2077ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5443 12/14/22 09:19:37.17
Dec 14 09:19:37.198: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:19:37.812: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:19:37.812: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:19:37.812: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:19:37.812: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:19:38.493: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 14 09:19:38.493: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:19:38.493: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:19:38.493: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:19:39.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 14 09:19:39.136: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:19:39.136: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:19:39.162: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:19:39.162: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:19:39.162: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 12/14/22 09:19:39.162
Dec 14 09:19:39.188: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:19:39.817: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:19:39.818: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:19:39.818: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:19:39.818: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:19:40.361: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:19:40.361: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:19:40.361: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:19:40.361: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:19:41.025: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:19:41.025: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:19:41.025: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:19:41.025: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:19:41.050: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 14 09:19:51.104: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:19:51.104: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:19:51.104: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:19:51.182: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Dec 14 09:19:51.182: INFO: ss-0  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:05 +0000 UTC  }]
Dec 14 09:19:51.182: INFO: ss-1  shoot--it--tm0ct-io0-worker-1-6f755-vb826  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
Dec 14 09:19:51.182: INFO: ss-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
Dec 14 09:19:51.182: INFO: 
Dec 14 09:19:51.182: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 14 09:19:52.209: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Dec 14 09:19:52.209: INFO: ss-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
Dec 14 09:19:52.209: INFO: 
Dec 14 09:19:52.209: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 14 09:19:53.239: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.945178206s
Dec 14 09:19:54.265: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.915600699s
Dec 14 09:19:55.291: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.889221913s
Dec 14 09:19:56.317: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.863528359s
Dec 14 09:19:57.343: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.837202s
Dec 14 09:19:58.369: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.812243864s
Dec 14 09:19:59.395: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.785225717s
Dec 14 09:20:00.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 759.985138ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5443 12/14/22 09:20:01.422
Dec 14 09:20:01.448: INFO: Scaling statefulset ss to 0
Dec 14 09:20:01.527: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:20:01.552: INFO: Deleting all statefulset in ns statefulset-5443
Dec 14 09:20:01.578: INFO: Scaling statefulset ss to 0
Dec 14 09:20:01.654: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:20:01.679: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:20:01.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5443" for this suite. 12/14/22 09:20:01.803
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":209,"skipped":3899,"failed":0}
------------------------------
• [56.089 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:19:05.74
    Dec 14 09:19:05.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:19:05.741
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:05.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:05.863
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5443 12/14/22 09:19:05.911
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-5443 12/14/22 09:19:05.936
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5443 12/14/22 09:19:05.964
    Dec 14 09:19:05.989: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Dec 14 09:19:16.018: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/14/22 09:19:16.019
    Dec 14 09:19:16.045: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:19:16.762: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:19:16.762: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:19:16.762: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:19:16.789: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec 14 09:19:26.817: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:19:26.817: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:19:26.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999592s
    Dec 14 09:19:27.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.972097701s
    Dec 14 09:19:28.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.944257252s
    Dec 14 09:19:30.003: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.916974707s
    Dec 14 09:19:31.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.889870094s
    Dec 14 09:19:32.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.863132349s
    Dec 14 09:19:33.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.834067114s
    Dec 14 09:19:34.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.806844825s
    Dec 14 09:19:35.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.779272767s
    Dec 14 09:19:36.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 751.2077ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5443 12/14/22 09:19:37.17
    Dec 14 09:19:37.198: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:19:37.812: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:19:37.812: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:19:37.812: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:19:37.812: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:19:38.493: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec 14 09:19:38.493: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:19:38.493: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:19:38.493: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:19:39.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec 14 09:19:39.136: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:19:39.136: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:19:39.162: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:19:39.162: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:19:39.162: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 12/14/22 09:19:39.162
    Dec 14 09:19:39.188: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:19:39.817: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:19:39.818: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:19:39.818: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:19:39.818: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:19:40.361: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:19:40.361: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:19:40.361: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:19:40.361: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-5443 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:19:41.025: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:19:41.025: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:19:41.025: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:19:41.025: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:19:41.050: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Dec 14 09:19:51.104: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:19:51.104: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:19:51.104: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:19:51.182: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
    Dec 14 09:19:51.182: INFO: ss-0  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:05 +0000 UTC  }]
    Dec 14 09:19:51.182: INFO: ss-1  shoot--it--tm0ct-io0-worker-1-6f755-vb826  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
    Dec 14 09:19:51.182: INFO: ss-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
    Dec 14 09:19:51.182: INFO: 
    Dec 14 09:19:51.182: INFO: StatefulSet ss has not reached scale 0, at 3
    Dec 14 09:19:52.209: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
    Dec 14 09:19:52.209: INFO: ss-2  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:19:26 +0000 UTC  }]
    Dec 14 09:19:52.209: INFO: 
    Dec 14 09:19:52.209: INFO: StatefulSet ss has not reached scale 0, at 1
    Dec 14 09:19:53.239: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.945178206s
    Dec 14 09:19:54.265: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.915600699s
    Dec 14 09:19:55.291: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.889221913s
    Dec 14 09:19:56.317: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.863528359s
    Dec 14 09:19:57.343: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.837202s
    Dec 14 09:19:58.369: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.812243864s
    Dec 14 09:19:59.395: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.785225717s
    Dec 14 09:20:00.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 759.985138ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5443 12/14/22 09:20:01.422
    Dec 14 09:20:01.448: INFO: Scaling statefulset ss to 0
    Dec 14 09:20:01.527: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:20:01.552: INFO: Deleting all statefulset in ns statefulset-5443
    Dec 14 09:20:01.578: INFO: Scaling statefulset ss to 0
    Dec 14 09:20:01.654: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:20:01.679: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:20:01.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5443" for this suite. 12/14/22 09:20:01.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:01.831
Dec 14 09:20:01.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:20:01.832
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:01.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:01.957
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 09:20:02.004
Dec 14 09:20:02.036: INFO: Waiting up to 5m0s for pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9" in namespace "emptydir-8662" to be "Succeeded or Failed"
Dec 14 09:20:02.063: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.568636ms
Dec 14 09:20:04.089: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Running", Reason="", readiness=false. Elapsed: 2.052698674s
Dec 14 09:20:06.099: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062846663s
STEP: Saw pod success 12/14/22 09:20:06.099
Dec 14 09:20:06.099: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9" satisfied condition "Succeeded or Failed"
Dec 14 09:20:06.125: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 container test-container: <nil>
STEP: delete the pod 12/14/22 09:20:06.202
Dec 14 09:20:06.240: INFO: Waiting for pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 to disappear
Dec 14 09:20:06.264: INFO: Pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:20:06.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8662" for this suite. 12/14/22 09:20:06.312
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":210,"skipped":3921,"failed":0}
------------------------------
• [4.508 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:01.831
    Dec 14 09:20:01.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:20:01.832
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:01.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:01.957
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 09:20:02.004
    Dec 14 09:20:02.036: INFO: Waiting up to 5m0s for pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9" in namespace "emptydir-8662" to be "Succeeded or Failed"
    Dec 14 09:20:02.063: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.568636ms
    Dec 14 09:20:04.089: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Running", Reason="", readiness=false. Elapsed: 2.052698674s
    Dec 14 09:20:06.099: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062846663s
    STEP: Saw pod success 12/14/22 09:20:06.099
    Dec 14 09:20:06.099: INFO: Pod "pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9" satisfied condition "Succeeded or Failed"
    Dec 14 09:20:06.125: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:20:06.202
    Dec 14 09:20:06.240: INFO: Waiting for pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 to disappear
    Dec 14 09:20:06.264: INFO: Pod pod-ec603bfe-7ed0-4708-a10a-3bcdf0e38dd9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:20:06.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8662" for this suite. 12/14/22 09:20:06.312
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:06.339
Dec 14 09:20:06.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:20:06.34
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.463
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 12/14/22 09:20:06.51
Dec 14 09:20:06.538: INFO: created test-event-1
Dec 14 09:20:06.563: INFO: created test-event-2
Dec 14 09:20:06.588: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 12/14/22 09:20:06.588
STEP: delete collection of events 12/14/22 09:20:06.614
Dec 14 09:20:06.614: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/14/22 09:20:06.65
Dec 14 09:20:06.650: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec 14 09:20:06.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-735" for this suite. 12/14/22 09:20:06.703
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":211,"skipped":3929,"failed":0}
------------------------------
• [0.390 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:06.339
    Dec 14 09:20:06.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:20:06.34
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.463
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 12/14/22 09:20:06.51
    Dec 14 09:20:06.538: INFO: created test-event-1
    Dec 14 09:20:06.563: INFO: created test-event-2
    Dec 14 09:20:06.588: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 12/14/22 09:20:06.588
    STEP: delete collection of events 12/14/22 09:20:06.614
    Dec 14 09:20:06.614: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/14/22 09:20:06.65
    Dec 14 09:20:06.650: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec 14 09:20:06.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-735" for this suite. 12/14/22 09:20:06.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:06.73
Dec 14 09:20:06.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:20:06.731
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.853
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 09:20:06.901
Dec 14 09:20:06.933: INFO: Waiting up to 5m0s for pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07" in namespace "emptydir-230" to be "Succeeded or Failed"
Dec 14 09:20:06.961: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Pending", Reason="", readiness=false. Elapsed: 27.793352ms
Dec 14 09:20:08.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Running", Reason="", readiness=true. Elapsed: 2.054561212s
Dec 14 09:20:10.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Running", Reason="", readiness=false. Elapsed: 4.055382405s
Dec 14 09:20:12.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05458s
STEP: Saw pod success 12/14/22 09:20:12.988
Dec 14 09:20:12.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07" satisfied condition "Succeeded or Failed"
Dec 14 09:20:13.013: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 container test-container: <nil>
STEP: delete the pod 12/14/22 09:20:13.046
Dec 14 09:20:13.091: INFO: Waiting for pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 to disappear
Dec 14 09:20:13.116: INFO: Pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:20:13.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-230" for this suite. 12/14/22 09:20:13.165
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":212,"skipped":3949,"failed":0}
------------------------------
• [6.467 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:06.73
    Dec 14 09:20:06.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:20:06.731
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.853
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 09:20:06.901
    Dec 14 09:20:06.933: INFO: Waiting up to 5m0s for pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07" in namespace "emptydir-230" to be "Succeeded or Failed"
    Dec 14 09:20:06.961: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Pending", Reason="", readiness=false. Elapsed: 27.793352ms
    Dec 14 09:20:08.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Running", Reason="", readiness=true. Elapsed: 2.054561212s
    Dec 14 09:20:10.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Running", Reason="", readiness=false. Elapsed: 4.055382405s
    Dec 14 09:20:12.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05458s
    STEP: Saw pod success 12/14/22 09:20:12.988
    Dec 14 09:20:12.988: INFO: Pod "pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07" satisfied condition "Succeeded or Failed"
    Dec 14 09:20:13.013: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:20:13.046
    Dec 14 09:20:13.091: INFO: Waiting for pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 to disappear
    Dec 14 09:20:13.116: INFO: Pod pod-f1cb18de-dea9-4933-ba6a-a351a7d14f07 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:20:13.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-230" for this suite. 12/14/22 09:20:13.165
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:13.198
Dec 14 09:20:13.198: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:20:13.199
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:13.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:13.32
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:20:13.369
Dec 14 09:20:13.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a" in namespace "downward-api-2716" to be "Succeeded or Failed"
Dec 14 09:20:13.431: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Pending", Reason="", readiness=false. Elapsed: 29.067874ms
Dec 14 09:20:15.459: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057231196s
Dec 14 09:20:17.458: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056319163s
STEP: Saw pod success 12/14/22 09:20:17.462
Dec 14 09:20:17.462: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a" satisfied condition "Succeeded or Failed"
Dec 14 09:20:17.489: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a container client-container: <nil>
STEP: delete the pod 12/14/22 09:20:17.523
Dec 14 09:20:17.560: INFO: Waiting for pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a to disappear
Dec 14 09:20:17.585: INFO: Pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:20:17.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2716" for this suite. 12/14/22 09:20:17.633
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":213,"skipped":3950,"failed":0}
------------------------------
• [4.463 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:13.198
    Dec 14 09:20:13.198: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:20:13.199
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:13.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:13.32
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:20:13.369
    Dec 14 09:20:13.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a" in namespace "downward-api-2716" to be "Succeeded or Failed"
    Dec 14 09:20:13.431: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Pending", Reason="", readiness=false. Elapsed: 29.067874ms
    Dec 14 09:20:15.459: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057231196s
    Dec 14 09:20:17.458: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056319163s
    STEP: Saw pod success 12/14/22 09:20:17.462
    Dec 14 09:20:17.462: INFO: Pod "downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a" satisfied condition "Succeeded or Failed"
    Dec 14 09:20:17.489: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a container client-container: <nil>
    STEP: delete the pod 12/14/22 09:20:17.523
    Dec 14 09:20:17.560: INFO: Waiting for pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a to disappear
    Dec 14 09:20:17.585: INFO: Pod downwardapi-volume-6d410724-deba-4706-a172-0aae071efe6a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:20:17.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2716" for this suite. 12/14/22 09:20:17.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:17.663
Dec 14 09:20:17.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:20:17.664
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:17.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:17.788
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 12/14/22 09:20:17.836
STEP: creating a watch on configmaps with label B 12/14/22 09:20:17.86
STEP: creating a watch on configmaps with label A or B 12/14/22 09:20:17.884
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/14/22 09:20:17.908
Dec 14 09:20:17.935: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38021 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:17.935: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38021 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/14/22 09:20:17.935
Dec 14 09:20:17.986: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38022 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:17.986: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38022 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/14/22 09:20:17.986
Dec 14 09:20:18.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38023 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:18.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38023 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/14/22 09:20:18.038
Dec 14 09:20:18.066: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38024 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:18.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38024 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/14/22 09:20:18.067
Dec 14 09:20:18.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38025 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:18.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38025 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/14/22 09:20:28.097
Dec 14 09:20:28.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38091 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:20:28.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38091 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:20:38.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3512" for this suite. 12/14/22 09:20:38.175
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":214,"skipped":3999,"failed":0}
------------------------------
• [20.540 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:17.663
    Dec 14 09:20:17.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:20:17.664
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:17.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:17.788
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 12/14/22 09:20:17.836
    STEP: creating a watch on configmaps with label B 12/14/22 09:20:17.86
    STEP: creating a watch on configmaps with label A or B 12/14/22 09:20:17.884
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/14/22 09:20:17.908
    Dec 14 09:20:17.935: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38021 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:17.935: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38021 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/14/22 09:20:17.935
    Dec 14 09:20:17.986: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38022 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:17.986: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38022 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/14/22 09:20:17.986
    Dec 14 09:20:18.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38023 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:18.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38023 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/14/22 09:20:18.038
    Dec 14 09:20:18.066: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38024 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:18.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3512  f2ba79be-0ddc-4304-ba67-ced7a0c468b9 38024 0 2022-12-14 09:20:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/14/22 09:20:18.067
    Dec 14 09:20:18.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38025 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:18.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38025 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/14/22 09:20:28.097
    Dec 14 09:20:28.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38091 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:20:28.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3512  9b3581b1-fd6f-469c-af64-9e1837844121 38091 0 2022-12-14 09:20:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:20:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:20:38.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3512" for this suite. 12/14/22 09:20:38.175
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:38.204
Dec 14 09:20:38.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency 12/14/22 09:20:38.204
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:38.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:38.327
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Dec 14 09:20:38.374: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8456 12/14/22 09:20:38.376
I1214 09:20:38.402875    6274 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8456, replica count: 1
I1214 09:20:39.453482    6274 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 09:20:40.458160    6274 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:20:40.594: INFO: Created: latency-svc-66gkd
Dec 14 09:20:40.600: INFO: Got endpoints: latency-svc-66gkd [42.466375ms]
Dec 14 09:20:40.635: INFO: Created: latency-svc-8mfw2
Dec 14 09:20:40.643: INFO: Got endpoints: latency-svc-8mfw2 [42.324587ms]
Dec 14 09:20:40.647: INFO: Created: latency-svc-svplx
Dec 14 09:20:40.654: INFO: Got endpoints: latency-svc-svplx [53.53606ms]
Dec 14 09:20:40.655: INFO: Created: latency-svc-d5s4d
Dec 14 09:20:40.663: INFO: Got endpoints: latency-svc-d5s4d [62.34137ms]
Dec 14 09:20:40.670: INFO: Created: latency-svc-vspzs
Dec 14 09:20:40.675: INFO: Got endpoints: latency-svc-vspzs [74.749562ms]
Dec 14 09:20:40.684: INFO: Created: latency-svc-k2r22
Dec 14 09:20:40.692: INFO: Got endpoints: latency-svc-k2r22 [91.659142ms]
Dec 14 09:20:40.703: INFO: Created: latency-svc-l4plk
Dec 14 09:20:40.707: INFO: Got endpoints: latency-svc-l4plk [106.206813ms]
Dec 14 09:20:40.729: INFO: Created: latency-svc-v5dr9
Dec 14 09:20:40.732: INFO: Got endpoints: latency-svc-v5dr9 [131.736843ms]
Dec 14 09:20:40.744: INFO: Created: latency-svc-6c7qq
Dec 14 09:20:40.753: INFO: Got endpoints: latency-svc-6c7qq [152.435428ms]
Dec 14 09:20:40.761: INFO: Created: latency-svc-mjjjr
Dec 14 09:20:40.773: INFO: Got endpoints: latency-svc-mjjjr [172.681643ms]
Dec 14 09:20:40.776: INFO: Created: latency-svc-9b54l
Dec 14 09:20:40.778: INFO: Got endpoints: latency-svc-9b54l [176.805896ms]
Dec 14 09:20:40.789: INFO: Created: latency-svc-2fkqc
Dec 14 09:20:40.797: INFO: Got endpoints: latency-svc-2fkqc [196.400295ms]
Dec 14 09:20:40.806: INFO: Created: latency-svc-2nlxq
Dec 14 09:20:40.810: INFO: Got endpoints: latency-svc-2nlxq [208.86483ms]
Dec 14 09:20:40.814: INFO: Created: latency-svc-wxh46
Dec 14 09:20:40.817: INFO: Got endpoints: latency-svc-wxh46 [216.246788ms]
Dec 14 09:20:40.825: INFO: Created: latency-svc-kxffx
Dec 14 09:20:40.827: INFO: Got endpoints: latency-svc-kxffx [226.185853ms]
Dec 14 09:20:40.845: INFO: Created: latency-svc-tkct2
Dec 14 09:20:40.853: INFO: Got endpoints: latency-svc-tkct2 [252.112359ms]
Dec 14 09:20:40.859: INFO: Created: latency-svc-cg9qb
Dec 14 09:20:40.862: INFO: Got endpoints: latency-svc-cg9qb [218.582329ms]
Dec 14 09:20:40.869: INFO: Created: latency-svc-lk25m
Dec 14 09:20:40.872: INFO: Got endpoints: latency-svc-lk25m [218.107941ms]
Dec 14 09:20:40.879: INFO: Created: latency-svc-p4nfk
Dec 14 09:20:40.891: INFO: Created: latency-svc-bhhdk
Dec 14 09:20:40.891: INFO: Got endpoints: latency-svc-p4nfk [228.225772ms]
Dec 14 09:20:40.898: INFO: Got endpoints: latency-svc-bhhdk [222.796492ms]
Dec 14 09:20:40.906: INFO: Created: latency-svc-p878v
Dec 14 09:20:40.913: INFO: Got endpoints: latency-svc-p878v [221.34527ms]
Dec 14 09:20:40.914: INFO: Created: latency-svc-frk2v
Dec 14 09:20:40.919: INFO: Got endpoints: latency-svc-frk2v [211.565458ms]
Dec 14 09:20:40.924: INFO: Created: latency-svc-pdvqm
Dec 14 09:20:40.926: INFO: Got endpoints: latency-svc-pdvqm [193.481689ms]
Dec 14 09:20:40.935: INFO: Created: latency-svc-4mc7q
Dec 14 09:20:40.940: INFO: Got endpoints: latency-svc-4mc7q [187.251243ms]
Dec 14 09:20:40.954: INFO: Created: latency-svc-pb5fg
Dec 14 09:20:40.962: INFO: Got endpoints: latency-svc-pb5fg [188.208437ms]
Dec 14 09:20:40.967: INFO: Created: latency-svc-mmw8q
Dec 14 09:20:40.969: INFO: Got endpoints: latency-svc-mmw8q [191.473707ms]
Dec 14 09:20:40.976: INFO: Created: latency-svc-8cr8t
Dec 14 09:20:40.980: INFO: Got endpoints: latency-svc-8cr8t [183.022914ms]
Dec 14 09:20:40.985: INFO: Created: latency-svc-jjlmf
Dec 14 09:20:40.991: INFO: Got endpoints: latency-svc-jjlmf [181.11053ms]
Dec 14 09:20:40.996: INFO: Created: latency-svc-w7t9s
Dec 14 09:20:41.002: INFO: Got endpoints: latency-svc-w7t9s [184.876099ms]
Dec 14 09:20:41.012: INFO: Created: latency-svc-pvzvs
Dec 14 09:20:41.018: INFO: Got endpoints: latency-svc-pvzvs [190.540563ms]
Dec 14 09:20:41.022: INFO: Created: latency-svc-l525v
Dec 14 09:20:41.031: INFO: Got endpoints: latency-svc-l525v [178.293856ms]
Dec 14 09:20:41.036: INFO: Created: latency-svc-wvfvh
Dec 14 09:20:41.047: INFO: Got endpoints: latency-svc-wvfvh [185.207028ms]
Dec 14 09:20:41.052: INFO: Created: latency-svc-b42tq
Dec 14 09:20:41.069: INFO: Got endpoints: latency-svc-b42tq [197.208714ms]
Dec 14 09:20:41.071: INFO: Created: latency-svc-hl5td
Dec 14 09:20:41.081: INFO: Got endpoints: latency-svc-hl5td [189.659214ms]
Dec 14 09:20:41.085: INFO: Created: latency-svc-bsblk
Dec 14 09:20:41.089: INFO: Got endpoints: latency-svc-bsblk [190.568918ms]
Dec 14 09:20:41.102: INFO: Created: latency-svc-npd98
Dec 14 09:20:41.105: INFO: Got endpoints: latency-svc-npd98 [191.402272ms]
Dec 14 09:20:41.115: INFO: Created: latency-svc-bpqkk
Dec 14 09:20:41.117: INFO: Got endpoints: latency-svc-bpqkk [198.860652ms]
Dec 14 09:20:41.125: INFO: Created: latency-svc-c9zbf
Dec 14 09:20:41.128: INFO: Got endpoints: latency-svc-c9zbf [202.460542ms]
Dec 14 09:20:41.133: INFO: Created: latency-svc-7m9kh
Dec 14 09:20:41.135: INFO: Got endpoints: latency-svc-7m9kh [194.863544ms]
Dec 14 09:20:41.147: INFO: Created: latency-svc-lzr8t
Dec 14 09:20:41.149: INFO: Got endpoints: latency-svc-lzr8t [187.533141ms]
Dec 14 09:20:41.157: INFO: Created: latency-svc-dw896
Dec 14 09:20:41.162: INFO: Got endpoints: latency-svc-dw896 [193.009043ms]
Dec 14 09:20:41.178: INFO: Created: latency-svc-dh2jl
Dec 14 09:20:41.185: INFO: Created: latency-svc-w5h5t
Dec 14 09:20:41.193: INFO: Created: latency-svc-zhqbk
Dec 14 09:20:41.197: INFO: Got endpoints: latency-svc-dh2jl [216.272719ms]
Dec 14 09:20:41.204: INFO: Created: latency-svc-wzkkj
Dec 14 09:20:41.214: INFO: Created: latency-svc-24mf4
Dec 14 09:20:41.222: INFO: Created: latency-svc-6vx78
Dec 14 09:20:41.231: INFO: Created: latency-svc-7lwmt
Dec 14 09:20:41.247: INFO: Got endpoints: latency-svc-w5h5t [256.580347ms]
Dec 14 09:20:41.252: INFO: Created: latency-svc-qf9hn
Dec 14 09:20:41.266: INFO: Created: latency-svc-nkszx
Dec 14 09:20:41.286: INFO: Created: latency-svc-db2rb
Dec 14 09:20:41.297: INFO: Created: latency-svc-pbzv7
Dec 14 09:20:41.299: INFO: Got endpoints: latency-svc-zhqbk [297.021347ms]
Dec 14 09:20:41.316: INFO: Created: latency-svc-jxp2g
Dec 14 09:20:41.321: INFO: Created: latency-svc-x6lmh
Dec 14 09:20:41.338: INFO: Created: latency-svc-8wwts
Dec 14 09:20:41.351: INFO: Created: latency-svc-lgw2t
Dec 14 09:20:41.351: INFO: Got endpoints: latency-svc-wzkkj [333.313ms]
Dec 14 09:20:41.363: INFO: Created: latency-svc-6pgx7
Dec 14 09:20:41.371: INFO: Created: latency-svc-j77tx
Dec 14 09:20:41.383: INFO: Created: latency-svc-c6j7m
Dec 14 09:20:41.399: INFO: Got endpoints: latency-svc-24mf4 [367.836925ms]
Dec 14 09:20:41.401: INFO: Created: latency-svc-shkbb
Dec 14 09:20:41.445: INFO: Created: latency-svc-rdt5z
Dec 14 09:20:41.452: INFO: Got endpoints: latency-svc-6vx78 [405.139254ms]
Dec 14 09:20:41.485: INFO: Created: latency-svc-k7cn6
Dec 14 09:20:41.508: INFO: Got endpoints: latency-svc-7lwmt [438.848686ms]
Dec 14 09:20:41.543: INFO: Created: latency-svc-9vkwc
Dec 14 09:20:41.547: INFO: Got endpoints: latency-svc-qf9hn [466.437076ms]
Dec 14 09:20:41.583: INFO: Created: latency-svc-lsw7r
Dec 14 09:20:41.598: INFO: Got endpoints: latency-svc-nkszx [509.073332ms]
Dec 14 09:20:41.632: INFO: Created: latency-svc-fw9z7
Dec 14 09:20:41.652: INFO: Got endpoints: latency-svc-db2rb [546.650989ms]
Dec 14 09:20:41.685: INFO: Created: latency-svc-kxmzk
Dec 14 09:20:41.701: INFO: Got endpoints: latency-svc-pbzv7 [583.097703ms]
Dec 14 09:20:41.735: INFO: Created: latency-svc-22rzp
Dec 14 09:20:41.748: INFO: Got endpoints: latency-svc-jxp2g [619.4972ms]
Dec 14 09:20:41.783: INFO: Created: latency-svc-8fs6z
Dec 14 09:20:41.798: INFO: Got endpoints: latency-svc-x6lmh [662.77799ms]
Dec 14 09:20:41.835: INFO: Created: latency-svc-d6jrp
Dec 14 09:20:41.848: INFO: Got endpoints: latency-svc-8wwts [698.318335ms]
Dec 14 09:20:41.881: INFO: Created: latency-svc-fwrgw
Dec 14 09:20:41.902: INFO: Got endpoints: latency-svc-lgw2t [740.168338ms]
Dec 14 09:20:41.943: INFO: Created: latency-svc-4fzfc
Dec 14 09:20:41.950: INFO: Got endpoints: latency-svc-6pgx7 [753.265157ms]
Dec 14 09:20:41.985: INFO: Created: latency-svc-gb6ps
Dec 14 09:20:42.001: INFO: Got endpoints: latency-svc-j77tx [753.455861ms]
Dec 14 09:20:42.046: INFO: Created: latency-svc-z5hsq
Dec 14 09:20:42.049: INFO: Got endpoints: latency-svc-c6j7m [749.654395ms]
Dec 14 09:20:42.085: INFO: Created: latency-svc-r5lvb
Dec 14 09:20:42.104: INFO: Got endpoints: latency-svc-shkbb [753.155424ms]
Dec 14 09:20:42.138: INFO: Created: latency-svc-52bbv
Dec 14 09:20:42.155: INFO: Got endpoints: latency-svc-rdt5z [755.33724ms]
Dec 14 09:20:42.192: INFO: Created: latency-svc-js42p
Dec 14 09:20:42.198: INFO: Got endpoints: latency-svc-k7cn6 [745.675011ms]
Dec 14 09:20:42.237: INFO: Created: latency-svc-xzr7v
Dec 14 09:20:42.248: INFO: Got endpoints: latency-svc-9vkwc [739.621757ms]
Dec 14 09:20:42.291: INFO: Created: latency-svc-rs48z
Dec 14 09:20:42.298: INFO: Got endpoints: latency-svc-lsw7r [750.857357ms]
Dec 14 09:20:42.331: INFO: Created: latency-svc-sfzkx
Dec 14 09:20:42.352: INFO: Got endpoints: latency-svc-fw9z7 [753.956593ms]
Dec 14 09:20:42.388: INFO: Created: latency-svc-r7tww
Dec 14 09:20:42.402: INFO: Got endpoints: latency-svc-kxmzk [750.154281ms]
Dec 14 09:20:42.436: INFO: Created: latency-svc-d4klg
Dec 14 09:20:42.451: INFO: Got endpoints: latency-svc-22rzp [750.151632ms]
Dec 14 09:20:42.491: INFO: Created: latency-svc-trqvr
Dec 14 09:20:42.498: INFO: Got endpoints: latency-svc-8fs6z [749.940765ms]
Dec 14 09:20:42.533: INFO: Created: latency-svc-q8pf2
Dec 14 09:20:42.548: INFO: Got endpoints: latency-svc-d6jrp [749.927587ms]
Dec 14 09:20:42.583: INFO: Created: latency-svc-9ptsw
Dec 14 09:20:42.598: INFO: Got endpoints: latency-svc-fwrgw [750.662349ms]
Dec 14 09:20:42.633: INFO: Created: latency-svc-nkqjc
Dec 14 09:20:42.653: INFO: Got endpoints: latency-svc-4fzfc [750.311168ms]
Dec 14 09:20:42.688: INFO: Created: latency-svc-q7ttl
Dec 14 09:20:42.713: INFO: Got endpoints: latency-svc-gb6ps [763.402488ms]
Dec 14 09:20:42.759: INFO: Got endpoints: latency-svc-z5hsq [757.640963ms]
Dec 14 09:20:42.759: INFO: Created: latency-svc-lbr6p
Dec 14 09:20:42.797: INFO: Created: latency-svc-2zzlb
Dec 14 09:20:42.803: INFO: Got endpoints: latency-svc-r5lvb [754.648007ms]
Dec 14 09:20:42.837: INFO: Created: latency-svc-hnjrb
Dec 14 09:20:42.848: INFO: Got endpoints: latency-svc-52bbv [743.570152ms]
Dec 14 09:20:42.886: INFO: Created: latency-svc-mpgt2
Dec 14 09:20:42.899: INFO: Got endpoints: latency-svc-js42p [744.220991ms]
Dec 14 09:20:42.934: INFO: Created: latency-svc-8rpqn
Dec 14 09:20:42.948: INFO: Got endpoints: latency-svc-xzr7v [750.268423ms]
Dec 14 09:20:42.981: INFO: Created: latency-svc-k22m8
Dec 14 09:20:43.001: INFO: Got endpoints: latency-svc-rs48z [753.014573ms]
Dec 14 09:20:43.039: INFO: Created: latency-svc-rgp95
Dec 14 09:20:43.048: INFO: Got endpoints: latency-svc-sfzkx [749.660808ms]
Dec 14 09:20:43.083: INFO: Created: latency-svc-vsx26
Dec 14 09:20:43.100: INFO: Got endpoints: latency-svc-r7tww [748.387027ms]
Dec 14 09:20:43.141: INFO: Created: latency-svc-28xtv
Dec 14 09:20:43.148: INFO: Got endpoints: latency-svc-d4klg [745.771069ms]
Dec 14 09:20:43.182: INFO: Created: latency-svc-mmvft
Dec 14 09:20:43.198: INFO: Got endpoints: latency-svc-trqvr [746.688686ms]
Dec 14 09:20:43.232: INFO: Created: latency-svc-54g5l
Dec 14 09:20:43.252: INFO: Got endpoints: latency-svc-q8pf2 [753.509566ms]
Dec 14 09:20:43.285: INFO: Created: latency-svc-4k6v5
Dec 14 09:20:43.297: INFO: Got endpoints: latency-svc-9ptsw [749.130171ms]
Dec 14 09:20:43.337: INFO: Created: latency-svc-2p2pt
Dec 14 09:20:43.355: INFO: Got endpoints: latency-svc-nkqjc [756.876291ms]
Dec 14 09:20:43.398: INFO: Created: latency-svc-sxrmn
Dec 14 09:20:43.399: INFO: Got endpoints: latency-svc-q7ttl [746.550837ms]
Dec 14 09:20:43.436: INFO: Created: latency-svc-dpjpt
Dec 14 09:20:43.448: INFO: Got endpoints: latency-svc-lbr6p [734.127598ms]
Dec 14 09:20:43.485: INFO: Created: latency-svc-kmf72
Dec 14 09:20:43.502: INFO: Got endpoints: latency-svc-2zzlb [743.760698ms]
Dec 14 09:20:43.537: INFO: Created: latency-svc-mzfxw
Dec 14 09:20:43.549: INFO: Got endpoints: latency-svc-hnjrb [745.428395ms]
Dec 14 09:20:43.595: INFO: Created: latency-svc-22mhh
Dec 14 09:20:43.602: INFO: Got endpoints: latency-svc-mpgt2 [754.277496ms]
Dec 14 09:20:43.643: INFO: Created: latency-svc-pgl6q
Dec 14 09:20:43.648: INFO: Got endpoints: latency-svc-8rpqn [748.910276ms]
Dec 14 09:20:43.688: INFO: Created: latency-svc-h2k9g
Dec 14 09:20:43.698: INFO: Got endpoints: latency-svc-k22m8 [749.799871ms]
Dec 14 09:20:43.733: INFO: Created: latency-svc-f66jr
Dec 14 09:20:43.748: INFO: Got endpoints: latency-svc-rgp95 [746.916649ms]
Dec 14 09:20:43.783: INFO: Created: latency-svc-zwtwp
Dec 14 09:20:43.800: INFO: Got endpoints: latency-svc-vsx26 [752.109304ms]
Dec 14 09:20:43.836: INFO: Created: latency-svc-xclc8
Dec 14 09:20:43.852: INFO: Got endpoints: latency-svc-28xtv [751.579028ms]
Dec 14 09:20:43.886: INFO: Created: latency-svc-lq547
Dec 14 09:20:43.902: INFO: Got endpoints: latency-svc-mmvft [754.718989ms]
Dec 14 09:20:43.948: INFO: Created: latency-svc-47fzv
Dec 14 09:20:43.949: INFO: Got endpoints: latency-svc-54g5l [751.627542ms]
Dec 14 09:20:43.984: INFO: Created: latency-svc-28lqw
Dec 14 09:20:44.001: INFO: Got endpoints: latency-svc-4k6v5 [749.402436ms]
Dec 14 09:20:44.037: INFO: Created: latency-svc-rpjhl
Dec 14 09:20:44.048: INFO: Got endpoints: latency-svc-2p2pt [750.399567ms]
Dec 14 09:20:44.081: INFO: Created: latency-svc-v9bqc
Dec 14 09:20:44.098: INFO: Got endpoints: latency-svc-sxrmn [742.713515ms]
Dec 14 09:20:44.135: INFO: Created: latency-svc-t8d6t
Dec 14 09:20:44.153: INFO: Got endpoints: latency-svc-dpjpt [753.115975ms]
Dec 14 09:20:44.189: INFO: Created: latency-svc-lj7nb
Dec 14 09:20:44.206: INFO: Got endpoints: latency-svc-kmf72 [758.504448ms]
Dec 14 09:20:44.244: INFO: Created: latency-svc-9pfhx
Dec 14 09:20:44.248: INFO: Got endpoints: latency-svc-mzfxw [745.778102ms]
Dec 14 09:20:44.282: INFO: Created: latency-svc-5blkt
Dec 14 09:20:44.298: INFO: Got endpoints: latency-svc-22mhh [748.627463ms]
Dec 14 09:20:44.338: INFO: Created: latency-svc-blt2p
Dec 14 09:20:44.349: INFO: Got endpoints: latency-svc-pgl6q [746.773118ms]
Dec 14 09:20:44.385: INFO: Created: latency-svc-sdk4l
Dec 14 09:20:44.402: INFO: Got endpoints: latency-svc-h2k9g [754.391819ms]
Dec 14 09:20:44.438: INFO: Created: latency-svc-d8xgp
Dec 14 09:20:44.448: INFO: Got endpoints: latency-svc-f66jr [749.886211ms]
Dec 14 09:20:44.482: INFO: Created: latency-svc-ls7gg
Dec 14 09:20:44.500: INFO: Got endpoints: latency-svc-zwtwp [752.253415ms]
Dec 14 09:20:44.535: INFO: Created: latency-svc-c5nct
Dec 14 09:20:44.557: INFO: Got endpoints: latency-svc-xclc8 [756.480041ms]
Dec 14 09:20:44.590: INFO: Created: latency-svc-clf9b
Dec 14 09:20:44.598: INFO: Got endpoints: latency-svc-lq547 [746.222544ms]
Dec 14 09:20:44.634: INFO: Created: latency-svc-5mm8f
Dec 14 09:20:44.652: INFO: Got endpoints: latency-svc-47fzv [749.286653ms]
Dec 14 09:20:44.699: INFO: Got endpoints: latency-svc-28lqw [749.629958ms]
Dec 14 09:20:44.699: INFO: Created: latency-svc-k9c9v
Dec 14 09:20:44.736: INFO: Created: latency-svc-wqmvh
Dec 14 09:20:44.748: INFO: Got endpoints: latency-svc-rpjhl [747.284788ms]
Dec 14 09:20:44.785: INFO: Created: latency-svc-587h5
Dec 14 09:20:44.801: INFO: Got endpoints: latency-svc-v9bqc [753.482342ms]
Dec 14 09:20:44.837: INFO: Created: latency-svc-s7blz
Dec 14 09:20:44.848: INFO: Got endpoints: latency-svc-t8d6t [750.073229ms]
Dec 14 09:20:44.885: INFO: Created: latency-svc-tk6gl
Dec 14 09:20:44.899: INFO: Got endpoints: latency-svc-lj7nb [746.381394ms]
Dec 14 09:20:44.934: INFO: Created: latency-svc-twcl6
Dec 14 09:20:44.948: INFO: Got endpoints: latency-svc-9pfhx [741.981456ms]
Dec 14 09:20:44.985: INFO: Created: latency-svc-8b9zm
Dec 14 09:20:44.998: INFO: Got endpoints: latency-svc-5blkt [749.360196ms]
Dec 14 09:20:45.033: INFO: Created: latency-svc-rzmts
Dec 14 09:20:45.048: INFO: Got endpoints: latency-svc-blt2p [750.250394ms]
Dec 14 09:20:45.091: INFO: Created: latency-svc-x6fgj
Dec 14 09:20:45.101: INFO: Got endpoints: latency-svc-sdk4l [751.743142ms]
Dec 14 09:20:45.134: INFO: Created: latency-svc-mjnb5
Dec 14 09:20:45.150: INFO: Got endpoints: latency-svc-d8xgp [747.791358ms]
Dec 14 09:20:45.188: INFO: Created: latency-svc-bmws2
Dec 14 09:20:45.198: INFO: Got endpoints: latency-svc-ls7gg [749.791282ms]
Dec 14 09:20:45.235: INFO: Created: latency-svc-k6pgg
Dec 14 09:20:45.254: INFO: Got endpoints: latency-svc-c5nct [753.511708ms]
Dec 14 09:20:45.287: INFO: Created: latency-svc-snsz8
Dec 14 09:20:45.304: INFO: Got endpoints: latency-svc-clf9b [747.258056ms]
Dec 14 09:20:45.348: INFO: Created: latency-svc-wtqls
Dec 14 09:20:45.353: INFO: Got endpoints: latency-svc-5mm8f [754.617052ms]
Dec 14 09:20:45.393: INFO: Created: latency-svc-f8lmd
Dec 14 09:20:45.398: INFO: Got endpoints: latency-svc-k9c9v [746.649471ms]
Dec 14 09:20:45.433: INFO: Created: latency-svc-kgvtg
Dec 14 09:20:45.452: INFO: Got endpoints: latency-svc-wqmvh [753.072181ms]
Dec 14 09:20:45.486: INFO: Created: latency-svc-n5bdv
Dec 14 09:20:45.501: INFO: Got endpoints: latency-svc-587h5 [752.353751ms]
Dec 14 09:20:45.535: INFO: Created: latency-svc-trz8x
Dec 14 09:20:45.551: INFO: Got endpoints: latency-svc-s7blz [749.214198ms]
Dec 14 09:20:45.585: INFO: Created: latency-svc-6qjx2
Dec 14 09:20:45.598: INFO: Got endpoints: latency-svc-tk6gl [749.954903ms]
Dec 14 09:20:45.632: INFO: Created: latency-svc-fjknf
Dec 14 09:20:45.651: INFO: Got endpoints: latency-svc-twcl6 [751.696725ms]
Dec 14 09:20:45.686: INFO: Created: latency-svc-6x8fb
Dec 14 09:20:45.699: INFO: Got endpoints: latency-svc-8b9zm [750.711722ms]
Dec 14 09:20:45.740: INFO: Created: latency-svc-vr9vd
Dec 14 09:20:45.748: INFO: Got endpoints: latency-svc-rzmts [750.201127ms]
Dec 14 09:20:45.781: INFO: Created: latency-svc-8v4vc
Dec 14 09:20:45.798: INFO: Got endpoints: latency-svc-x6fgj [750.117165ms]
Dec 14 09:20:45.839: INFO: Created: latency-svc-4mwj5
Dec 14 09:20:45.849: INFO: Got endpoints: latency-svc-mjnb5 [748.573359ms]
Dec 14 09:20:45.884: INFO: Created: latency-svc-rjvww
Dec 14 09:20:45.898: INFO: Got endpoints: latency-svc-bmws2 [747.759988ms]
Dec 14 09:20:45.938: INFO: Created: latency-svc-7sjnd
Dec 14 09:20:45.956: INFO: Got endpoints: latency-svc-k6pgg [758.178727ms]
Dec 14 09:20:45.995: INFO: Created: latency-svc-th8lv
Dec 14 09:20:45.997: INFO: Got endpoints: latency-svc-snsz8 [743.100822ms]
Dec 14 09:20:46.031: INFO: Created: latency-svc-79lkh
Dec 14 09:20:46.049: INFO: Got endpoints: latency-svc-wtqls [744.497091ms]
Dec 14 09:20:46.082: INFO: Created: latency-svc-cwblf
Dec 14 09:20:46.098: INFO: Got endpoints: latency-svc-f8lmd [745.226752ms]
Dec 14 09:20:46.134: INFO: Created: latency-svc-xj4ql
Dec 14 09:20:46.147: INFO: Got endpoints: latency-svc-kgvtg [748.961382ms]
Dec 14 09:20:46.182: INFO: Created: latency-svc-rhfpt
Dec 14 09:20:46.198: INFO: Got endpoints: latency-svc-n5bdv [746.304187ms]
Dec 14 09:20:46.233: INFO: Created: latency-svc-gp9kj
Dec 14 09:20:46.251: INFO: Got endpoints: latency-svc-trz8x [749.95848ms]
Dec 14 09:20:46.289: INFO: Created: latency-svc-v96l7
Dec 14 09:20:46.302: INFO: Got endpoints: latency-svc-6qjx2 [751.079359ms]
Dec 14 09:20:46.337: INFO: Created: latency-svc-z4grg
Dec 14 09:20:46.360: INFO: Got endpoints: latency-svc-fjknf [761.236941ms]
Dec 14 09:20:46.400: INFO: Created: latency-svc-8p97h
Dec 14 09:20:46.400: INFO: Got endpoints: latency-svc-6x8fb [749.166543ms]
Dec 14 09:20:46.437: INFO: Created: latency-svc-cgz4t
Dec 14 09:20:46.448: INFO: Got endpoints: latency-svc-vr9vd [748.82817ms]
Dec 14 09:20:46.482: INFO: Created: latency-svc-f4vq4
Dec 14 09:20:46.500: INFO: Got endpoints: latency-svc-8v4vc [752.527334ms]
Dec 14 09:20:46.535: INFO: Created: latency-svc-25qzk
Dec 14 09:20:46.548: INFO: Got endpoints: latency-svc-4mwj5 [749.863227ms]
Dec 14 09:20:46.584: INFO: Created: latency-svc-zp5d6
Dec 14 09:20:46.609: INFO: Got endpoints: latency-svc-rjvww [759.710793ms]
Dec 14 09:20:46.646: INFO: Created: latency-svc-bkjxh
Dec 14 09:20:46.651: INFO: Got endpoints: latency-svc-7sjnd [753.289783ms]
Dec 14 09:20:46.688: INFO: Created: latency-svc-hszk7
Dec 14 09:20:46.701: INFO: Got endpoints: latency-svc-th8lv [744.768069ms]
Dec 14 09:20:46.741: INFO: Created: latency-svc-6bwzp
Dec 14 09:20:46.747: INFO: Got endpoints: latency-svc-79lkh [750.24848ms]
Dec 14 09:20:46.790: INFO: Created: latency-svc-8gzf5
Dec 14 09:20:46.798: INFO: Got endpoints: latency-svc-cwblf [749.699518ms]
Dec 14 09:20:46.840: INFO: Created: latency-svc-2gcmz
Dec 14 09:20:46.848: INFO: Got endpoints: latency-svc-xj4ql [749.061012ms]
Dec 14 09:20:46.881: INFO: Created: latency-svc-n8qck
Dec 14 09:20:46.898: INFO: Got endpoints: latency-svc-rhfpt [750.699436ms]
Dec 14 09:20:46.944: INFO: Created: latency-svc-bfrxl
Dec 14 09:20:46.947: INFO: Got endpoints: latency-svc-gp9kj [748.992157ms]
Dec 14 09:20:46.984: INFO: Created: latency-svc-mc48z
Dec 14 09:20:47.003: INFO: Got endpoints: latency-svc-v96l7 [751.959208ms]
Dec 14 09:20:47.037: INFO: Created: latency-svc-tcg72
Dec 14 09:20:47.051: INFO: Got endpoints: latency-svc-z4grg [749.011376ms]
Dec 14 09:20:47.084: INFO: Created: latency-svc-9dbxz
Dec 14 09:20:47.099: INFO: Got endpoints: latency-svc-8p97h [739.311245ms]
Dec 14 09:20:47.134: INFO: Created: latency-svc-57mvh
Dec 14 09:20:47.151: INFO: Got endpoints: latency-svc-cgz4t [750.549805ms]
Dec 14 09:20:47.184: INFO: Created: latency-svc-7cpqx
Dec 14 09:20:47.199: INFO: Got endpoints: latency-svc-f4vq4 [750.828924ms]
Dec 14 09:20:47.235: INFO: Created: latency-svc-gg2l9
Dec 14 09:20:47.251: INFO: Got endpoints: latency-svc-25qzk [750.047261ms]
Dec 14 09:20:47.288: INFO: Created: latency-svc-bc5rm
Dec 14 09:20:47.298: INFO: Got endpoints: latency-svc-zp5d6 [750.10487ms]
Dec 14 09:20:47.333: INFO: Created: latency-svc-vl689
Dec 14 09:20:47.348: INFO: Got endpoints: latency-svc-bkjxh [739.032525ms]
Dec 14 09:20:47.400: INFO: Created: latency-svc-4zctz
Dec 14 09:20:47.400: INFO: Got endpoints: latency-svc-hszk7 [748.265035ms]
Dec 14 09:20:47.433: INFO: Created: latency-svc-rsqw2
Dec 14 09:20:47.448: INFO: Got endpoints: latency-svc-6bwzp [747.265128ms]
Dec 14 09:20:47.482: INFO: Created: latency-svc-8nnp5
Dec 14 09:20:47.499: INFO: Got endpoints: latency-svc-8gzf5 [751.685415ms]
Dec 14 09:20:47.532: INFO: Created: latency-svc-2fbhj
Dec 14 09:20:47.550: INFO: Got endpoints: latency-svc-2gcmz [751.201249ms]
Dec 14 09:20:47.583: INFO: Created: latency-svc-5lz2j
Dec 14 09:20:47.608: INFO: Got endpoints: latency-svc-n8qck [760.093167ms]
Dec 14 09:20:47.640: INFO: Created: latency-svc-x5hrk
Dec 14 09:20:47.652: INFO: Got endpoints: latency-svc-bfrxl [753.902374ms]
Dec 14 09:20:47.686: INFO: Created: latency-svc-xgsl2
Dec 14 09:20:47.697: INFO: Got endpoints: latency-svc-mc48z [749.86307ms]
Dec 14 09:20:47.732: INFO: Created: latency-svc-4vrb6
Dec 14 09:20:47.748: INFO: Got endpoints: latency-svc-tcg72 [744.667064ms]
Dec 14 09:20:47.781: INFO: Created: latency-svc-ps5qb
Dec 14 09:20:47.798: INFO: Got endpoints: latency-svc-9dbxz [746.941164ms]
Dec 14 09:20:47.831: INFO: Created: latency-svc-zxs79
Dec 14 09:20:47.851: INFO: Got endpoints: latency-svc-57mvh [751.710361ms]
Dec 14 09:20:47.885: INFO: Created: latency-svc-26p5h
Dec 14 09:20:47.901: INFO: Got endpoints: latency-svc-7cpqx [750.810046ms]
Dec 14 09:20:47.941: INFO: Created: latency-svc-v868k
Dec 14 09:20:47.949: INFO: Got endpoints: latency-svc-gg2l9 [749.787298ms]
Dec 14 09:20:47.982: INFO: Created: latency-svc-qphpx
Dec 14 09:20:47.998: INFO: Got endpoints: latency-svc-bc5rm [746.878196ms]
Dec 14 09:20:48.046: INFO: Created: latency-svc-k8zx6
Dec 14 09:20:48.048: INFO: Got endpoints: latency-svc-vl689 [749.964477ms]
Dec 14 09:20:48.086: INFO: Created: latency-svc-tf6xd
Dec 14 09:20:48.097: INFO: Got endpoints: latency-svc-4zctz [749.078685ms]
Dec 14 09:20:48.135: INFO: Created: latency-svc-jchdz
Dec 14 09:20:48.161: INFO: Got endpoints: latency-svc-rsqw2 [760.934198ms]
Dec 14 09:20:48.200: INFO: Got endpoints: latency-svc-8nnp5 [751.638477ms]
Dec 14 09:20:48.200: INFO: Created: latency-svc-zstgn
Dec 14 09:20:48.234: INFO: Created: latency-svc-wd9zw
Dec 14 09:20:48.248: INFO: Got endpoints: latency-svc-2fbhj [748.33542ms]
Dec 14 09:20:48.281: INFO: Created: latency-svc-hn8g6
Dec 14 09:20:48.297: INFO: Got endpoints: latency-svc-5lz2j [747.540335ms]
Dec 14 09:20:48.331: INFO: Created: latency-svc-q698d
Dec 14 09:20:48.348: INFO: Got endpoints: latency-svc-x5hrk [740.696607ms]
Dec 14 09:20:48.386: INFO: Created: latency-svc-jgmbx
Dec 14 09:20:48.401: INFO: Got endpoints: latency-svc-xgsl2 [748.729489ms]
Dec 14 09:20:48.435: INFO: Created: latency-svc-rgnb5
Dec 14 09:20:48.448: INFO: Got endpoints: latency-svc-4vrb6 [750.28304ms]
Dec 14 09:20:48.498: INFO: Got endpoints: latency-svc-ps5qb [750.707889ms]
Dec 14 09:20:48.548: INFO: Got endpoints: latency-svc-zxs79 [749.779591ms]
Dec 14 09:20:48.598: INFO: Got endpoints: latency-svc-26p5h [747.14651ms]
Dec 14 09:20:48.648: INFO: Got endpoints: latency-svc-v868k [746.174085ms]
Dec 14 09:20:48.699: INFO: Got endpoints: latency-svc-qphpx [750.228183ms]
Dec 14 09:20:48.748: INFO: Got endpoints: latency-svc-k8zx6 [750.250132ms]
Dec 14 09:20:48.798: INFO: Got endpoints: latency-svc-tf6xd [749.393109ms]
Dec 14 09:20:48.848: INFO: Got endpoints: latency-svc-jchdz [750.474591ms]
Dec 14 09:20:48.923: INFO: Got endpoints: latency-svc-zstgn [762.638419ms]
Dec 14 09:20:48.949: INFO: Got endpoints: latency-svc-wd9zw [749.07132ms]
Dec 14 09:20:48.999: INFO: Got endpoints: latency-svc-hn8g6 [750.82133ms]
Dec 14 09:20:49.048: INFO: Got endpoints: latency-svc-q698d [750.683351ms]
Dec 14 09:20:49.103: INFO: Got endpoints: latency-svc-jgmbx [754.205302ms]
Dec 14 09:20:49.148: INFO: Got endpoints: latency-svc-rgnb5 [746.876142ms]
Dec 14 09:20:49.148: INFO: Latencies: [42.324587ms 53.53606ms 62.34137ms 74.749562ms 91.659142ms 106.206813ms 131.736843ms 152.435428ms 172.681643ms 176.805896ms 178.293856ms 181.11053ms 183.022914ms 184.876099ms 185.207028ms 187.251243ms 187.533141ms 188.208437ms 189.659214ms 190.540563ms 190.568918ms 191.402272ms 191.473707ms 193.009043ms 193.481689ms 194.863544ms 196.400295ms 197.208714ms 198.860652ms 202.460542ms 208.86483ms 211.565458ms 216.246788ms 216.272719ms 218.107941ms 218.582329ms 221.34527ms 222.796492ms 226.185853ms 228.225772ms 252.112359ms 256.580347ms 297.021347ms 333.313ms 367.836925ms 405.139254ms 438.848686ms 466.437076ms 509.073332ms 546.650989ms 583.097703ms 619.4972ms 662.77799ms 698.318335ms 734.127598ms 739.032525ms 739.311245ms 739.621757ms 740.168338ms 740.696607ms 741.981456ms 742.713515ms 743.100822ms 743.570152ms 743.760698ms 744.220991ms 744.497091ms 744.667064ms 744.768069ms 745.226752ms 745.428395ms 745.675011ms 745.771069ms 745.778102ms 746.174085ms 746.222544ms 746.304187ms 746.381394ms 746.550837ms 746.649471ms 746.688686ms 746.773118ms 746.876142ms 746.878196ms 746.916649ms 746.941164ms 747.14651ms 747.258056ms 747.265128ms 747.284788ms 747.540335ms 747.759988ms 747.791358ms 748.265035ms 748.33542ms 748.387027ms 748.573359ms 748.627463ms 748.729489ms 748.82817ms 748.910276ms 748.961382ms 748.992157ms 749.011376ms 749.061012ms 749.07132ms 749.078685ms 749.130171ms 749.166543ms 749.214198ms 749.286653ms 749.360196ms 749.393109ms 749.402436ms 749.629958ms 749.654395ms 749.660808ms 749.699518ms 749.779591ms 749.787298ms 749.791282ms 749.799871ms 749.86307ms 749.863227ms 749.886211ms 749.927587ms 749.940765ms 749.954903ms 749.95848ms 749.964477ms 750.047261ms 750.073229ms 750.10487ms 750.117165ms 750.151632ms 750.154281ms 750.201127ms 750.228183ms 750.24848ms 750.250132ms 750.250394ms 750.268423ms 750.28304ms 750.311168ms 750.399567ms 750.474591ms 750.549805ms 750.662349ms 750.683351ms 750.699436ms 750.707889ms 750.711722ms 750.810046ms 750.82133ms 750.828924ms 750.857357ms 751.079359ms 751.201249ms 751.579028ms 751.627542ms 751.638477ms 751.685415ms 751.696725ms 751.710361ms 751.743142ms 751.959208ms 752.109304ms 752.253415ms 752.353751ms 752.527334ms 753.014573ms 753.072181ms 753.115975ms 753.155424ms 753.265157ms 753.289783ms 753.455861ms 753.482342ms 753.509566ms 753.511708ms 753.902374ms 753.956593ms 754.205302ms 754.277496ms 754.391819ms 754.617052ms 754.648007ms 754.718989ms 755.33724ms 756.480041ms 756.876291ms 757.640963ms 758.178727ms 758.504448ms 759.710793ms 760.093167ms 760.934198ms 761.236941ms 762.638419ms 763.402488ms]
Dec 14 09:20:49.148: INFO: 50 %ile: 748.910276ms
Dec 14 09:20:49.148: INFO: 90 %ile: 753.902374ms
Dec 14 09:20:49.148: INFO: 99 %ile: 762.638419ms
Dec 14 09:20:49.148: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Dec 14 09:20:49.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8456" for this suite. 12/14/22 09:20:49.199
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":215,"skipped":4005,"failed":0}
------------------------------
• [11.022 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:38.204
    Dec 14 09:20:38.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svc-latency 12/14/22 09:20:38.204
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:38.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:38.327
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Dec 14 09:20:38.374: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-8456 12/14/22 09:20:38.376
    I1214 09:20:38.402875    6274 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8456, replica count: 1
    I1214 09:20:39.453482    6274 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 09:20:40.458160    6274 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:20:40.594: INFO: Created: latency-svc-66gkd
    Dec 14 09:20:40.600: INFO: Got endpoints: latency-svc-66gkd [42.466375ms]
    Dec 14 09:20:40.635: INFO: Created: latency-svc-8mfw2
    Dec 14 09:20:40.643: INFO: Got endpoints: latency-svc-8mfw2 [42.324587ms]
    Dec 14 09:20:40.647: INFO: Created: latency-svc-svplx
    Dec 14 09:20:40.654: INFO: Got endpoints: latency-svc-svplx [53.53606ms]
    Dec 14 09:20:40.655: INFO: Created: latency-svc-d5s4d
    Dec 14 09:20:40.663: INFO: Got endpoints: latency-svc-d5s4d [62.34137ms]
    Dec 14 09:20:40.670: INFO: Created: latency-svc-vspzs
    Dec 14 09:20:40.675: INFO: Got endpoints: latency-svc-vspzs [74.749562ms]
    Dec 14 09:20:40.684: INFO: Created: latency-svc-k2r22
    Dec 14 09:20:40.692: INFO: Got endpoints: latency-svc-k2r22 [91.659142ms]
    Dec 14 09:20:40.703: INFO: Created: latency-svc-l4plk
    Dec 14 09:20:40.707: INFO: Got endpoints: latency-svc-l4plk [106.206813ms]
    Dec 14 09:20:40.729: INFO: Created: latency-svc-v5dr9
    Dec 14 09:20:40.732: INFO: Got endpoints: latency-svc-v5dr9 [131.736843ms]
    Dec 14 09:20:40.744: INFO: Created: latency-svc-6c7qq
    Dec 14 09:20:40.753: INFO: Got endpoints: latency-svc-6c7qq [152.435428ms]
    Dec 14 09:20:40.761: INFO: Created: latency-svc-mjjjr
    Dec 14 09:20:40.773: INFO: Got endpoints: latency-svc-mjjjr [172.681643ms]
    Dec 14 09:20:40.776: INFO: Created: latency-svc-9b54l
    Dec 14 09:20:40.778: INFO: Got endpoints: latency-svc-9b54l [176.805896ms]
    Dec 14 09:20:40.789: INFO: Created: latency-svc-2fkqc
    Dec 14 09:20:40.797: INFO: Got endpoints: latency-svc-2fkqc [196.400295ms]
    Dec 14 09:20:40.806: INFO: Created: latency-svc-2nlxq
    Dec 14 09:20:40.810: INFO: Got endpoints: latency-svc-2nlxq [208.86483ms]
    Dec 14 09:20:40.814: INFO: Created: latency-svc-wxh46
    Dec 14 09:20:40.817: INFO: Got endpoints: latency-svc-wxh46 [216.246788ms]
    Dec 14 09:20:40.825: INFO: Created: latency-svc-kxffx
    Dec 14 09:20:40.827: INFO: Got endpoints: latency-svc-kxffx [226.185853ms]
    Dec 14 09:20:40.845: INFO: Created: latency-svc-tkct2
    Dec 14 09:20:40.853: INFO: Got endpoints: latency-svc-tkct2 [252.112359ms]
    Dec 14 09:20:40.859: INFO: Created: latency-svc-cg9qb
    Dec 14 09:20:40.862: INFO: Got endpoints: latency-svc-cg9qb [218.582329ms]
    Dec 14 09:20:40.869: INFO: Created: latency-svc-lk25m
    Dec 14 09:20:40.872: INFO: Got endpoints: latency-svc-lk25m [218.107941ms]
    Dec 14 09:20:40.879: INFO: Created: latency-svc-p4nfk
    Dec 14 09:20:40.891: INFO: Created: latency-svc-bhhdk
    Dec 14 09:20:40.891: INFO: Got endpoints: latency-svc-p4nfk [228.225772ms]
    Dec 14 09:20:40.898: INFO: Got endpoints: latency-svc-bhhdk [222.796492ms]
    Dec 14 09:20:40.906: INFO: Created: latency-svc-p878v
    Dec 14 09:20:40.913: INFO: Got endpoints: latency-svc-p878v [221.34527ms]
    Dec 14 09:20:40.914: INFO: Created: latency-svc-frk2v
    Dec 14 09:20:40.919: INFO: Got endpoints: latency-svc-frk2v [211.565458ms]
    Dec 14 09:20:40.924: INFO: Created: latency-svc-pdvqm
    Dec 14 09:20:40.926: INFO: Got endpoints: latency-svc-pdvqm [193.481689ms]
    Dec 14 09:20:40.935: INFO: Created: latency-svc-4mc7q
    Dec 14 09:20:40.940: INFO: Got endpoints: latency-svc-4mc7q [187.251243ms]
    Dec 14 09:20:40.954: INFO: Created: latency-svc-pb5fg
    Dec 14 09:20:40.962: INFO: Got endpoints: latency-svc-pb5fg [188.208437ms]
    Dec 14 09:20:40.967: INFO: Created: latency-svc-mmw8q
    Dec 14 09:20:40.969: INFO: Got endpoints: latency-svc-mmw8q [191.473707ms]
    Dec 14 09:20:40.976: INFO: Created: latency-svc-8cr8t
    Dec 14 09:20:40.980: INFO: Got endpoints: latency-svc-8cr8t [183.022914ms]
    Dec 14 09:20:40.985: INFO: Created: latency-svc-jjlmf
    Dec 14 09:20:40.991: INFO: Got endpoints: latency-svc-jjlmf [181.11053ms]
    Dec 14 09:20:40.996: INFO: Created: latency-svc-w7t9s
    Dec 14 09:20:41.002: INFO: Got endpoints: latency-svc-w7t9s [184.876099ms]
    Dec 14 09:20:41.012: INFO: Created: latency-svc-pvzvs
    Dec 14 09:20:41.018: INFO: Got endpoints: latency-svc-pvzvs [190.540563ms]
    Dec 14 09:20:41.022: INFO: Created: latency-svc-l525v
    Dec 14 09:20:41.031: INFO: Got endpoints: latency-svc-l525v [178.293856ms]
    Dec 14 09:20:41.036: INFO: Created: latency-svc-wvfvh
    Dec 14 09:20:41.047: INFO: Got endpoints: latency-svc-wvfvh [185.207028ms]
    Dec 14 09:20:41.052: INFO: Created: latency-svc-b42tq
    Dec 14 09:20:41.069: INFO: Got endpoints: latency-svc-b42tq [197.208714ms]
    Dec 14 09:20:41.071: INFO: Created: latency-svc-hl5td
    Dec 14 09:20:41.081: INFO: Got endpoints: latency-svc-hl5td [189.659214ms]
    Dec 14 09:20:41.085: INFO: Created: latency-svc-bsblk
    Dec 14 09:20:41.089: INFO: Got endpoints: latency-svc-bsblk [190.568918ms]
    Dec 14 09:20:41.102: INFO: Created: latency-svc-npd98
    Dec 14 09:20:41.105: INFO: Got endpoints: latency-svc-npd98 [191.402272ms]
    Dec 14 09:20:41.115: INFO: Created: latency-svc-bpqkk
    Dec 14 09:20:41.117: INFO: Got endpoints: latency-svc-bpqkk [198.860652ms]
    Dec 14 09:20:41.125: INFO: Created: latency-svc-c9zbf
    Dec 14 09:20:41.128: INFO: Got endpoints: latency-svc-c9zbf [202.460542ms]
    Dec 14 09:20:41.133: INFO: Created: latency-svc-7m9kh
    Dec 14 09:20:41.135: INFO: Got endpoints: latency-svc-7m9kh [194.863544ms]
    Dec 14 09:20:41.147: INFO: Created: latency-svc-lzr8t
    Dec 14 09:20:41.149: INFO: Got endpoints: latency-svc-lzr8t [187.533141ms]
    Dec 14 09:20:41.157: INFO: Created: latency-svc-dw896
    Dec 14 09:20:41.162: INFO: Got endpoints: latency-svc-dw896 [193.009043ms]
    Dec 14 09:20:41.178: INFO: Created: latency-svc-dh2jl
    Dec 14 09:20:41.185: INFO: Created: latency-svc-w5h5t
    Dec 14 09:20:41.193: INFO: Created: latency-svc-zhqbk
    Dec 14 09:20:41.197: INFO: Got endpoints: latency-svc-dh2jl [216.272719ms]
    Dec 14 09:20:41.204: INFO: Created: latency-svc-wzkkj
    Dec 14 09:20:41.214: INFO: Created: latency-svc-24mf4
    Dec 14 09:20:41.222: INFO: Created: latency-svc-6vx78
    Dec 14 09:20:41.231: INFO: Created: latency-svc-7lwmt
    Dec 14 09:20:41.247: INFO: Got endpoints: latency-svc-w5h5t [256.580347ms]
    Dec 14 09:20:41.252: INFO: Created: latency-svc-qf9hn
    Dec 14 09:20:41.266: INFO: Created: latency-svc-nkszx
    Dec 14 09:20:41.286: INFO: Created: latency-svc-db2rb
    Dec 14 09:20:41.297: INFO: Created: latency-svc-pbzv7
    Dec 14 09:20:41.299: INFO: Got endpoints: latency-svc-zhqbk [297.021347ms]
    Dec 14 09:20:41.316: INFO: Created: latency-svc-jxp2g
    Dec 14 09:20:41.321: INFO: Created: latency-svc-x6lmh
    Dec 14 09:20:41.338: INFO: Created: latency-svc-8wwts
    Dec 14 09:20:41.351: INFO: Created: latency-svc-lgw2t
    Dec 14 09:20:41.351: INFO: Got endpoints: latency-svc-wzkkj [333.313ms]
    Dec 14 09:20:41.363: INFO: Created: latency-svc-6pgx7
    Dec 14 09:20:41.371: INFO: Created: latency-svc-j77tx
    Dec 14 09:20:41.383: INFO: Created: latency-svc-c6j7m
    Dec 14 09:20:41.399: INFO: Got endpoints: latency-svc-24mf4 [367.836925ms]
    Dec 14 09:20:41.401: INFO: Created: latency-svc-shkbb
    Dec 14 09:20:41.445: INFO: Created: latency-svc-rdt5z
    Dec 14 09:20:41.452: INFO: Got endpoints: latency-svc-6vx78 [405.139254ms]
    Dec 14 09:20:41.485: INFO: Created: latency-svc-k7cn6
    Dec 14 09:20:41.508: INFO: Got endpoints: latency-svc-7lwmt [438.848686ms]
    Dec 14 09:20:41.543: INFO: Created: latency-svc-9vkwc
    Dec 14 09:20:41.547: INFO: Got endpoints: latency-svc-qf9hn [466.437076ms]
    Dec 14 09:20:41.583: INFO: Created: latency-svc-lsw7r
    Dec 14 09:20:41.598: INFO: Got endpoints: latency-svc-nkszx [509.073332ms]
    Dec 14 09:20:41.632: INFO: Created: latency-svc-fw9z7
    Dec 14 09:20:41.652: INFO: Got endpoints: latency-svc-db2rb [546.650989ms]
    Dec 14 09:20:41.685: INFO: Created: latency-svc-kxmzk
    Dec 14 09:20:41.701: INFO: Got endpoints: latency-svc-pbzv7 [583.097703ms]
    Dec 14 09:20:41.735: INFO: Created: latency-svc-22rzp
    Dec 14 09:20:41.748: INFO: Got endpoints: latency-svc-jxp2g [619.4972ms]
    Dec 14 09:20:41.783: INFO: Created: latency-svc-8fs6z
    Dec 14 09:20:41.798: INFO: Got endpoints: latency-svc-x6lmh [662.77799ms]
    Dec 14 09:20:41.835: INFO: Created: latency-svc-d6jrp
    Dec 14 09:20:41.848: INFO: Got endpoints: latency-svc-8wwts [698.318335ms]
    Dec 14 09:20:41.881: INFO: Created: latency-svc-fwrgw
    Dec 14 09:20:41.902: INFO: Got endpoints: latency-svc-lgw2t [740.168338ms]
    Dec 14 09:20:41.943: INFO: Created: latency-svc-4fzfc
    Dec 14 09:20:41.950: INFO: Got endpoints: latency-svc-6pgx7 [753.265157ms]
    Dec 14 09:20:41.985: INFO: Created: latency-svc-gb6ps
    Dec 14 09:20:42.001: INFO: Got endpoints: latency-svc-j77tx [753.455861ms]
    Dec 14 09:20:42.046: INFO: Created: latency-svc-z5hsq
    Dec 14 09:20:42.049: INFO: Got endpoints: latency-svc-c6j7m [749.654395ms]
    Dec 14 09:20:42.085: INFO: Created: latency-svc-r5lvb
    Dec 14 09:20:42.104: INFO: Got endpoints: latency-svc-shkbb [753.155424ms]
    Dec 14 09:20:42.138: INFO: Created: latency-svc-52bbv
    Dec 14 09:20:42.155: INFO: Got endpoints: latency-svc-rdt5z [755.33724ms]
    Dec 14 09:20:42.192: INFO: Created: latency-svc-js42p
    Dec 14 09:20:42.198: INFO: Got endpoints: latency-svc-k7cn6 [745.675011ms]
    Dec 14 09:20:42.237: INFO: Created: latency-svc-xzr7v
    Dec 14 09:20:42.248: INFO: Got endpoints: latency-svc-9vkwc [739.621757ms]
    Dec 14 09:20:42.291: INFO: Created: latency-svc-rs48z
    Dec 14 09:20:42.298: INFO: Got endpoints: latency-svc-lsw7r [750.857357ms]
    Dec 14 09:20:42.331: INFO: Created: latency-svc-sfzkx
    Dec 14 09:20:42.352: INFO: Got endpoints: latency-svc-fw9z7 [753.956593ms]
    Dec 14 09:20:42.388: INFO: Created: latency-svc-r7tww
    Dec 14 09:20:42.402: INFO: Got endpoints: latency-svc-kxmzk [750.154281ms]
    Dec 14 09:20:42.436: INFO: Created: latency-svc-d4klg
    Dec 14 09:20:42.451: INFO: Got endpoints: latency-svc-22rzp [750.151632ms]
    Dec 14 09:20:42.491: INFO: Created: latency-svc-trqvr
    Dec 14 09:20:42.498: INFO: Got endpoints: latency-svc-8fs6z [749.940765ms]
    Dec 14 09:20:42.533: INFO: Created: latency-svc-q8pf2
    Dec 14 09:20:42.548: INFO: Got endpoints: latency-svc-d6jrp [749.927587ms]
    Dec 14 09:20:42.583: INFO: Created: latency-svc-9ptsw
    Dec 14 09:20:42.598: INFO: Got endpoints: latency-svc-fwrgw [750.662349ms]
    Dec 14 09:20:42.633: INFO: Created: latency-svc-nkqjc
    Dec 14 09:20:42.653: INFO: Got endpoints: latency-svc-4fzfc [750.311168ms]
    Dec 14 09:20:42.688: INFO: Created: latency-svc-q7ttl
    Dec 14 09:20:42.713: INFO: Got endpoints: latency-svc-gb6ps [763.402488ms]
    Dec 14 09:20:42.759: INFO: Got endpoints: latency-svc-z5hsq [757.640963ms]
    Dec 14 09:20:42.759: INFO: Created: latency-svc-lbr6p
    Dec 14 09:20:42.797: INFO: Created: latency-svc-2zzlb
    Dec 14 09:20:42.803: INFO: Got endpoints: latency-svc-r5lvb [754.648007ms]
    Dec 14 09:20:42.837: INFO: Created: latency-svc-hnjrb
    Dec 14 09:20:42.848: INFO: Got endpoints: latency-svc-52bbv [743.570152ms]
    Dec 14 09:20:42.886: INFO: Created: latency-svc-mpgt2
    Dec 14 09:20:42.899: INFO: Got endpoints: latency-svc-js42p [744.220991ms]
    Dec 14 09:20:42.934: INFO: Created: latency-svc-8rpqn
    Dec 14 09:20:42.948: INFO: Got endpoints: latency-svc-xzr7v [750.268423ms]
    Dec 14 09:20:42.981: INFO: Created: latency-svc-k22m8
    Dec 14 09:20:43.001: INFO: Got endpoints: latency-svc-rs48z [753.014573ms]
    Dec 14 09:20:43.039: INFO: Created: latency-svc-rgp95
    Dec 14 09:20:43.048: INFO: Got endpoints: latency-svc-sfzkx [749.660808ms]
    Dec 14 09:20:43.083: INFO: Created: latency-svc-vsx26
    Dec 14 09:20:43.100: INFO: Got endpoints: latency-svc-r7tww [748.387027ms]
    Dec 14 09:20:43.141: INFO: Created: latency-svc-28xtv
    Dec 14 09:20:43.148: INFO: Got endpoints: latency-svc-d4klg [745.771069ms]
    Dec 14 09:20:43.182: INFO: Created: latency-svc-mmvft
    Dec 14 09:20:43.198: INFO: Got endpoints: latency-svc-trqvr [746.688686ms]
    Dec 14 09:20:43.232: INFO: Created: latency-svc-54g5l
    Dec 14 09:20:43.252: INFO: Got endpoints: latency-svc-q8pf2 [753.509566ms]
    Dec 14 09:20:43.285: INFO: Created: latency-svc-4k6v5
    Dec 14 09:20:43.297: INFO: Got endpoints: latency-svc-9ptsw [749.130171ms]
    Dec 14 09:20:43.337: INFO: Created: latency-svc-2p2pt
    Dec 14 09:20:43.355: INFO: Got endpoints: latency-svc-nkqjc [756.876291ms]
    Dec 14 09:20:43.398: INFO: Created: latency-svc-sxrmn
    Dec 14 09:20:43.399: INFO: Got endpoints: latency-svc-q7ttl [746.550837ms]
    Dec 14 09:20:43.436: INFO: Created: latency-svc-dpjpt
    Dec 14 09:20:43.448: INFO: Got endpoints: latency-svc-lbr6p [734.127598ms]
    Dec 14 09:20:43.485: INFO: Created: latency-svc-kmf72
    Dec 14 09:20:43.502: INFO: Got endpoints: latency-svc-2zzlb [743.760698ms]
    Dec 14 09:20:43.537: INFO: Created: latency-svc-mzfxw
    Dec 14 09:20:43.549: INFO: Got endpoints: latency-svc-hnjrb [745.428395ms]
    Dec 14 09:20:43.595: INFO: Created: latency-svc-22mhh
    Dec 14 09:20:43.602: INFO: Got endpoints: latency-svc-mpgt2 [754.277496ms]
    Dec 14 09:20:43.643: INFO: Created: latency-svc-pgl6q
    Dec 14 09:20:43.648: INFO: Got endpoints: latency-svc-8rpqn [748.910276ms]
    Dec 14 09:20:43.688: INFO: Created: latency-svc-h2k9g
    Dec 14 09:20:43.698: INFO: Got endpoints: latency-svc-k22m8 [749.799871ms]
    Dec 14 09:20:43.733: INFO: Created: latency-svc-f66jr
    Dec 14 09:20:43.748: INFO: Got endpoints: latency-svc-rgp95 [746.916649ms]
    Dec 14 09:20:43.783: INFO: Created: latency-svc-zwtwp
    Dec 14 09:20:43.800: INFO: Got endpoints: latency-svc-vsx26 [752.109304ms]
    Dec 14 09:20:43.836: INFO: Created: latency-svc-xclc8
    Dec 14 09:20:43.852: INFO: Got endpoints: latency-svc-28xtv [751.579028ms]
    Dec 14 09:20:43.886: INFO: Created: latency-svc-lq547
    Dec 14 09:20:43.902: INFO: Got endpoints: latency-svc-mmvft [754.718989ms]
    Dec 14 09:20:43.948: INFO: Created: latency-svc-47fzv
    Dec 14 09:20:43.949: INFO: Got endpoints: latency-svc-54g5l [751.627542ms]
    Dec 14 09:20:43.984: INFO: Created: latency-svc-28lqw
    Dec 14 09:20:44.001: INFO: Got endpoints: latency-svc-4k6v5 [749.402436ms]
    Dec 14 09:20:44.037: INFO: Created: latency-svc-rpjhl
    Dec 14 09:20:44.048: INFO: Got endpoints: latency-svc-2p2pt [750.399567ms]
    Dec 14 09:20:44.081: INFO: Created: latency-svc-v9bqc
    Dec 14 09:20:44.098: INFO: Got endpoints: latency-svc-sxrmn [742.713515ms]
    Dec 14 09:20:44.135: INFO: Created: latency-svc-t8d6t
    Dec 14 09:20:44.153: INFO: Got endpoints: latency-svc-dpjpt [753.115975ms]
    Dec 14 09:20:44.189: INFO: Created: latency-svc-lj7nb
    Dec 14 09:20:44.206: INFO: Got endpoints: latency-svc-kmf72 [758.504448ms]
    Dec 14 09:20:44.244: INFO: Created: latency-svc-9pfhx
    Dec 14 09:20:44.248: INFO: Got endpoints: latency-svc-mzfxw [745.778102ms]
    Dec 14 09:20:44.282: INFO: Created: latency-svc-5blkt
    Dec 14 09:20:44.298: INFO: Got endpoints: latency-svc-22mhh [748.627463ms]
    Dec 14 09:20:44.338: INFO: Created: latency-svc-blt2p
    Dec 14 09:20:44.349: INFO: Got endpoints: latency-svc-pgl6q [746.773118ms]
    Dec 14 09:20:44.385: INFO: Created: latency-svc-sdk4l
    Dec 14 09:20:44.402: INFO: Got endpoints: latency-svc-h2k9g [754.391819ms]
    Dec 14 09:20:44.438: INFO: Created: latency-svc-d8xgp
    Dec 14 09:20:44.448: INFO: Got endpoints: latency-svc-f66jr [749.886211ms]
    Dec 14 09:20:44.482: INFO: Created: latency-svc-ls7gg
    Dec 14 09:20:44.500: INFO: Got endpoints: latency-svc-zwtwp [752.253415ms]
    Dec 14 09:20:44.535: INFO: Created: latency-svc-c5nct
    Dec 14 09:20:44.557: INFO: Got endpoints: latency-svc-xclc8 [756.480041ms]
    Dec 14 09:20:44.590: INFO: Created: latency-svc-clf9b
    Dec 14 09:20:44.598: INFO: Got endpoints: latency-svc-lq547 [746.222544ms]
    Dec 14 09:20:44.634: INFO: Created: latency-svc-5mm8f
    Dec 14 09:20:44.652: INFO: Got endpoints: latency-svc-47fzv [749.286653ms]
    Dec 14 09:20:44.699: INFO: Got endpoints: latency-svc-28lqw [749.629958ms]
    Dec 14 09:20:44.699: INFO: Created: latency-svc-k9c9v
    Dec 14 09:20:44.736: INFO: Created: latency-svc-wqmvh
    Dec 14 09:20:44.748: INFO: Got endpoints: latency-svc-rpjhl [747.284788ms]
    Dec 14 09:20:44.785: INFO: Created: latency-svc-587h5
    Dec 14 09:20:44.801: INFO: Got endpoints: latency-svc-v9bqc [753.482342ms]
    Dec 14 09:20:44.837: INFO: Created: latency-svc-s7blz
    Dec 14 09:20:44.848: INFO: Got endpoints: latency-svc-t8d6t [750.073229ms]
    Dec 14 09:20:44.885: INFO: Created: latency-svc-tk6gl
    Dec 14 09:20:44.899: INFO: Got endpoints: latency-svc-lj7nb [746.381394ms]
    Dec 14 09:20:44.934: INFO: Created: latency-svc-twcl6
    Dec 14 09:20:44.948: INFO: Got endpoints: latency-svc-9pfhx [741.981456ms]
    Dec 14 09:20:44.985: INFO: Created: latency-svc-8b9zm
    Dec 14 09:20:44.998: INFO: Got endpoints: latency-svc-5blkt [749.360196ms]
    Dec 14 09:20:45.033: INFO: Created: latency-svc-rzmts
    Dec 14 09:20:45.048: INFO: Got endpoints: latency-svc-blt2p [750.250394ms]
    Dec 14 09:20:45.091: INFO: Created: latency-svc-x6fgj
    Dec 14 09:20:45.101: INFO: Got endpoints: latency-svc-sdk4l [751.743142ms]
    Dec 14 09:20:45.134: INFO: Created: latency-svc-mjnb5
    Dec 14 09:20:45.150: INFO: Got endpoints: latency-svc-d8xgp [747.791358ms]
    Dec 14 09:20:45.188: INFO: Created: latency-svc-bmws2
    Dec 14 09:20:45.198: INFO: Got endpoints: latency-svc-ls7gg [749.791282ms]
    Dec 14 09:20:45.235: INFO: Created: latency-svc-k6pgg
    Dec 14 09:20:45.254: INFO: Got endpoints: latency-svc-c5nct [753.511708ms]
    Dec 14 09:20:45.287: INFO: Created: latency-svc-snsz8
    Dec 14 09:20:45.304: INFO: Got endpoints: latency-svc-clf9b [747.258056ms]
    Dec 14 09:20:45.348: INFO: Created: latency-svc-wtqls
    Dec 14 09:20:45.353: INFO: Got endpoints: latency-svc-5mm8f [754.617052ms]
    Dec 14 09:20:45.393: INFO: Created: latency-svc-f8lmd
    Dec 14 09:20:45.398: INFO: Got endpoints: latency-svc-k9c9v [746.649471ms]
    Dec 14 09:20:45.433: INFO: Created: latency-svc-kgvtg
    Dec 14 09:20:45.452: INFO: Got endpoints: latency-svc-wqmvh [753.072181ms]
    Dec 14 09:20:45.486: INFO: Created: latency-svc-n5bdv
    Dec 14 09:20:45.501: INFO: Got endpoints: latency-svc-587h5 [752.353751ms]
    Dec 14 09:20:45.535: INFO: Created: latency-svc-trz8x
    Dec 14 09:20:45.551: INFO: Got endpoints: latency-svc-s7blz [749.214198ms]
    Dec 14 09:20:45.585: INFO: Created: latency-svc-6qjx2
    Dec 14 09:20:45.598: INFO: Got endpoints: latency-svc-tk6gl [749.954903ms]
    Dec 14 09:20:45.632: INFO: Created: latency-svc-fjknf
    Dec 14 09:20:45.651: INFO: Got endpoints: latency-svc-twcl6 [751.696725ms]
    Dec 14 09:20:45.686: INFO: Created: latency-svc-6x8fb
    Dec 14 09:20:45.699: INFO: Got endpoints: latency-svc-8b9zm [750.711722ms]
    Dec 14 09:20:45.740: INFO: Created: latency-svc-vr9vd
    Dec 14 09:20:45.748: INFO: Got endpoints: latency-svc-rzmts [750.201127ms]
    Dec 14 09:20:45.781: INFO: Created: latency-svc-8v4vc
    Dec 14 09:20:45.798: INFO: Got endpoints: latency-svc-x6fgj [750.117165ms]
    Dec 14 09:20:45.839: INFO: Created: latency-svc-4mwj5
    Dec 14 09:20:45.849: INFO: Got endpoints: latency-svc-mjnb5 [748.573359ms]
    Dec 14 09:20:45.884: INFO: Created: latency-svc-rjvww
    Dec 14 09:20:45.898: INFO: Got endpoints: latency-svc-bmws2 [747.759988ms]
    Dec 14 09:20:45.938: INFO: Created: latency-svc-7sjnd
    Dec 14 09:20:45.956: INFO: Got endpoints: latency-svc-k6pgg [758.178727ms]
    Dec 14 09:20:45.995: INFO: Created: latency-svc-th8lv
    Dec 14 09:20:45.997: INFO: Got endpoints: latency-svc-snsz8 [743.100822ms]
    Dec 14 09:20:46.031: INFO: Created: latency-svc-79lkh
    Dec 14 09:20:46.049: INFO: Got endpoints: latency-svc-wtqls [744.497091ms]
    Dec 14 09:20:46.082: INFO: Created: latency-svc-cwblf
    Dec 14 09:20:46.098: INFO: Got endpoints: latency-svc-f8lmd [745.226752ms]
    Dec 14 09:20:46.134: INFO: Created: latency-svc-xj4ql
    Dec 14 09:20:46.147: INFO: Got endpoints: latency-svc-kgvtg [748.961382ms]
    Dec 14 09:20:46.182: INFO: Created: latency-svc-rhfpt
    Dec 14 09:20:46.198: INFO: Got endpoints: latency-svc-n5bdv [746.304187ms]
    Dec 14 09:20:46.233: INFO: Created: latency-svc-gp9kj
    Dec 14 09:20:46.251: INFO: Got endpoints: latency-svc-trz8x [749.95848ms]
    Dec 14 09:20:46.289: INFO: Created: latency-svc-v96l7
    Dec 14 09:20:46.302: INFO: Got endpoints: latency-svc-6qjx2 [751.079359ms]
    Dec 14 09:20:46.337: INFO: Created: latency-svc-z4grg
    Dec 14 09:20:46.360: INFO: Got endpoints: latency-svc-fjknf [761.236941ms]
    Dec 14 09:20:46.400: INFO: Created: latency-svc-8p97h
    Dec 14 09:20:46.400: INFO: Got endpoints: latency-svc-6x8fb [749.166543ms]
    Dec 14 09:20:46.437: INFO: Created: latency-svc-cgz4t
    Dec 14 09:20:46.448: INFO: Got endpoints: latency-svc-vr9vd [748.82817ms]
    Dec 14 09:20:46.482: INFO: Created: latency-svc-f4vq4
    Dec 14 09:20:46.500: INFO: Got endpoints: latency-svc-8v4vc [752.527334ms]
    Dec 14 09:20:46.535: INFO: Created: latency-svc-25qzk
    Dec 14 09:20:46.548: INFO: Got endpoints: latency-svc-4mwj5 [749.863227ms]
    Dec 14 09:20:46.584: INFO: Created: latency-svc-zp5d6
    Dec 14 09:20:46.609: INFO: Got endpoints: latency-svc-rjvww [759.710793ms]
    Dec 14 09:20:46.646: INFO: Created: latency-svc-bkjxh
    Dec 14 09:20:46.651: INFO: Got endpoints: latency-svc-7sjnd [753.289783ms]
    Dec 14 09:20:46.688: INFO: Created: latency-svc-hszk7
    Dec 14 09:20:46.701: INFO: Got endpoints: latency-svc-th8lv [744.768069ms]
    Dec 14 09:20:46.741: INFO: Created: latency-svc-6bwzp
    Dec 14 09:20:46.747: INFO: Got endpoints: latency-svc-79lkh [750.24848ms]
    Dec 14 09:20:46.790: INFO: Created: latency-svc-8gzf5
    Dec 14 09:20:46.798: INFO: Got endpoints: latency-svc-cwblf [749.699518ms]
    Dec 14 09:20:46.840: INFO: Created: latency-svc-2gcmz
    Dec 14 09:20:46.848: INFO: Got endpoints: latency-svc-xj4ql [749.061012ms]
    Dec 14 09:20:46.881: INFO: Created: latency-svc-n8qck
    Dec 14 09:20:46.898: INFO: Got endpoints: latency-svc-rhfpt [750.699436ms]
    Dec 14 09:20:46.944: INFO: Created: latency-svc-bfrxl
    Dec 14 09:20:46.947: INFO: Got endpoints: latency-svc-gp9kj [748.992157ms]
    Dec 14 09:20:46.984: INFO: Created: latency-svc-mc48z
    Dec 14 09:20:47.003: INFO: Got endpoints: latency-svc-v96l7 [751.959208ms]
    Dec 14 09:20:47.037: INFO: Created: latency-svc-tcg72
    Dec 14 09:20:47.051: INFO: Got endpoints: latency-svc-z4grg [749.011376ms]
    Dec 14 09:20:47.084: INFO: Created: latency-svc-9dbxz
    Dec 14 09:20:47.099: INFO: Got endpoints: latency-svc-8p97h [739.311245ms]
    Dec 14 09:20:47.134: INFO: Created: latency-svc-57mvh
    Dec 14 09:20:47.151: INFO: Got endpoints: latency-svc-cgz4t [750.549805ms]
    Dec 14 09:20:47.184: INFO: Created: latency-svc-7cpqx
    Dec 14 09:20:47.199: INFO: Got endpoints: latency-svc-f4vq4 [750.828924ms]
    Dec 14 09:20:47.235: INFO: Created: latency-svc-gg2l9
    Dec 14 09:20:47.251: INFO: Got endpoints: latency-svc-25qzk [750.047261ms]
    Dec 14 09:20:47.288: INFO: Created: latency-svc-bc5rm
    Dec 14 09:20:47.298: INFO: Got endpoints: latency-svc-zp5d6 [750.10487ms]
    Dec 14 09:20:47.333: INFO: Created: latency-svc-vl689
    Dec 14 09:20:47.348: INFO: Got endpoints: latency-svc-bkjxh [739.032525ms]
    Dec 14 09:20:47.400: INFO: Created: latency-svc-4zctz
    Dec 14 09:20:47.400: INFO: Got endpoints: latency-svc-hszk7 [748.265035ms]
    Dec 14 09:20:47.433: INFO: Created: latency-svc-rsqw2
    Dec 14 09:20:47.448: INFO: Got endpoints: latency-svc-6bwzp [747.265128ms]
    Dec 14 09:20:47.482: INFO: Created: latency-svc-8nnp5
    Dec 14 09:20:47.499: INFO: Got endpoints: latency-svc-8gzf5 [751.685415ms]
    Dec 14 09:20:47.532: INFO: Created: latency-svc-2fbhj
    Dec 14 09:20:47.550: INFO: Got endpoints: latency-svc-2gcmz [751.201249ms]
    Dec 14 09:20:47.583: INFO: Created: latency-svc-5lz2j
    Dec 14 09:20:47.608: INFO: Got endpoints: latency-svc-n8qck [760.093167ms]
    Dec 14 09:20:47.640: INFO: Created: latency-svc-x5hrk
    Dec 14 09:20:47.652: INFO: Got endpoints: latency-svc-bfrxl [753.902374ms]
    Dec 14 09:20:47.686: INFO: Created: latency-svc-xgsl2
    Dec 14 09:20:47.697: INFO: Got endpoints: latency-svc-mc48z [749.86307ms]
    Dec 14 09:20:47.732: INFO: Created: latency-svc-4vrb6
    Dec 14 09:20:47.748: INFO: Got endpoints: latency-svc-tcg72 [744.667064ms]
    Dec 14 09:20:47.781: INFO: Created: latency-svc-ps5qb
    Dec 14 09:20:47.798: INFO: Got endpoints: latency-svc-9dbxz [746.941164ms]
    Dec 14 09:20:47.831: INFO: Created: latency-svc-zxs79
    Dec 14 09:20:47.851: INFO: Got endpoints: latency-svc-57mvh [751.710361ms]
    Dec 14 09:20:47.885: INFO: Created: latency-svc-26p5h
    Dec 14 09:20:47.901: INFO: Got endpoints: latency-svc-7cpqx [750.810046ms]
    Dec 14 09:20:47.941: INFO: Created: latency-svc-v868k
    Dec 14 09:20:47.949: INFO: Got endpoints: latency-svc-gg2l9 [749.787298ms]
    Dec 14 09:20:47.982: INFO: Created: latency-svc-qphpx
    Dec 14 09:20:47.998: INFO: Got endpoints: latency-svc-bc5rm [746.878196ms]
    Dec 14 09:20:48.046: INFO: Created: latency-svc-k8zx6
    Dec 14 09:20:48.048: INFO: Got endpoints: latency-svc-vl689 [749.964477ms]
    Dec 14 09:20:48.086: INFO: Created: latency-svc-tf6xd
    Dec 14 09:20:48.097: INFO: Got endpoints: latency-svc-4zctz [749.078685ms]
    Dec 14 09:20:48.135: INFO: Created: latency-svc-jchdz
    Dec 14 09:20:48.161: INFO: Got endpoints: latency-svc-rsqw2 [760.934198ms]
    Dec 14 09:20:48.200: INFO: Got endpoints: latency-svc-8nnp5 [751.638477ms]
    Dec 14 09:20:48.200: INFO: Created: latency-svc-zstgn
    Dec 14 09:20:48.234: INFO: Created: latency-svc-wd9zw
    Dec 14 09:20:48.248: INFO: Got endpoints: latency-svc-2fbhj [748.33542ms]
    Dec 14 09:20:48.281: INFO: Created: latency-svc-hn8g6
    Dec 14 09:20:48.297: INFO: Got endpoints: latency-svc-5lz2j [747.540335ms]
    Dec 14 09:20:48.331: INFO: Created: latency-svc-q698d
    Dec 14 09:20:48.348: INFO: Got endpoints: latency-svc-x5hrk [740.696607ms]
    Dec 14 09:20:48.386: INFO: Created: latency-svc-jgmbx
    Dec 14 09:20:48.401: INFO: Got endpoints: latency-svc-xgsl2 [748.729489ms]
    Dec 14 09:20:48.435: INFO: Created: latency-svc-rgnb5
    Dec 14 09:20:48.448: INFO: Got endpoints: latency-svc-4vrb6 [750.28304ms]
    Dec 14 09:20:48.498: INFO: Got endpoints: latency-svc-ps5qb [750.707889ms]
    Dec 14 09:20:48.548: INFO: Got endpoints: latency-svc-zxs79 [749.779591ms]
    Dec 14 09:20:48.598: INFO: Got endpoints: latency-svc-26p5h [747.14651ms]
    Dec 14 09:20:48.648: INFO: Got endpoints: latency-svc-v868k [746.174085ms]
    Dec 14 09:20:48.699: INFO: Got endpoints: latency-svc-qphpx [750.228183ms]
    Dec 14 09:20:48.748: INFO: Got endpoints: latency-svc-k8zx6 [750.250132ms]
    Dec 14 09:20:48.798: INFO: Got endpoints: latency-svc-tf6xd [749.393109ms]
    Dec 14 09:20:48.848: INFO: Got endpoints: latency-svc-jchdz [750.474591ms]
    Dec 14 09:20:48.923: INFO: Got endpoints: latency-svc-zstgn [762.638419ms]
    Dec 14 09:20:48.949: INFO: Got endpoints: latency-svc-wd9zw [749.07132ms]
    Dec 14 09:20:48.999: INFO: Got endpoints: latency-svc-hn8g6 [750.82133ms]
    Dec 14 09:20:49.048: INFO: Got endpoints: latency-svc-q698d [750.683351ms]
    Dec 14 09:20:49.103: INFO: Got endpoints: latency-svc-jgmbx [754.205302ms]
    Dec 14 09:20:49.148: INFO: Got endpoints: latency-svc-rgnb5 [746.876142ms]
    Dec 14 09:20:49.148: INFO: Latencies: [42.324587ms 53.53606ms 62.34137ms 74.749562ms 91.659142ms 106.206813ms 131.736843ms 152.435428ms 172.681643ms 176.805896ms 178.293856ms 181.11053ms 183.022914ms 184.876099ms 185.207028ms 187.251243ms 187.533141ms 188.208437ms 189.659214ms 190.540563ms 190.568918ms 191.402272ms 191.473707ms 193.009043ms 193.481689ms 194.863544ms 196.400295ms 197.208714ms 198.860652ms 202.460542ms 208.86483ms 211.565458ms 216.246788ms 216.272719ms 218.107941ms 218.582329ms 221.34527ms 222.796492ms 226.185853ms 228.225772ms 252.112359ms 256.580347ms 297.021347ms 333.313ms 367.836925ms 405.139254ms 438.848686ms 466.437076ms 509.073332ms 546.650989ms 583.097703ms 619.4972ms 662.77799ms 698.318335ms 734.127598ms 739.032525ms 739.311245ms 739.621757ms 740.168338ms 740.696607ms 741.981456ms 742.713515ms 743.100822ms 743.570152ms 743.760698ms 744.220991ms 744.497091ms 744.667064ms 744.768069ms 745.226752ms 745.428395ms 745.675011ms 745.771069ms 745.778102ms 746.174085ms 746.222544ms 746.304187ms 746.381394ms 746.550837ms 746.649471ms 746.688686ms 746.773118ms 746.876142ms 746.878196ms 746.916649ms 746.941164ms 747.14651ms 747.258056ms 747.265128ms 747.284788ms 747.540335ms 747.759988ms 747.791358ms 748.265035ms 748.33542ms 748.387027ms 748.573359ms 748.627463ms 748.729489ms 748.82817ms 748.910276ms 748.961382ms 748.992157ms 749.011376ms 749.061012ms 749.07132ms 749.078685ms 749.130171ms 749.166543ms 749.214198ms 749.286653ms 749.360196ms 749.393109ms 749.402436ms 749.629958ms 749.654395ms 749.660808ms 749.699518ms 749.779591ms 749.787298ms 749.791282ms 749.799871ms 749.86307ms 749.863227ms 749.886211ms 749.927587ms 749.940765ms 749.954903ms 749.95848ms 749.964477ms 750.047261ms 750.073229ms 750.10487ms 750.117165ms 750.151632ms 750.154281ms 750.201127ms 750.228183ms 750.24848ms 750.250132ms 750.250394ms 750.268423ms 750.28304ms 750.311168ms 750.399567ms 750.474591ms 750.549805ms 750.662349ms 750.683351ms 750.699436ms 750.707889ms 750.711722ms 750.810046ms 750.82133ms 750.828924ms 750.857357ms 751.079359ms 751.201249ms 751.579028ms 751.627542ms 751.638477ms 751.685415ms 751.696725ms 751.710361ms 751.743142ms 751.959208ms 752.109304ms 752.253415ms 752.353751ms 752.527334ms 753.014573ms 753.072181ms 753.115975ms 753.155424ms 753.265157ms 753.289783ms 753.455861ms 753.482342ms 753.509566ms 753.511708ms 753.902374ms 753.956593ms 754.205302ms 754.277496ms 754.391819ms 754.617052ms 754.648007ms 754.718989ms 755.33724ms 756.480041ms 756.876291ms 757.640963ms 758.178727ms 758.504448ms 759.710793ms 760.093167ms 760.934198ms 761.236941ms 762.638419ms 763.402488ms]
    Dec 14 09:20:49.148: INFO: 50 %ile: 748.910276ms
    Dec 14 09:20:49.148: INFO: 90 %ile: 753.902374ms
    Dec 14 09:20:49.148: INFO: 99 %ile: 762.638419ms
    Dec 14 09:20:49.148: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Dec 14 09:20:49.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-8456" for this suite. 12/14/22 09:20:49.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:49.226
Dec 14 09:20:49.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:20:49.227
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:49.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:49.35
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:20:49.45
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:20:49.785
STEP: Deploying the webhook pod 12/14/22 09:20:49.811
STEP: Wait for the deployment to be ready 12/14/22 09:20:49.867
Dec 14 09:20:49.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:20:51.981
STEP: Verifying the service has paired with the endpoint 12/14/22 09:20:52.017
Dec 14 09:20:53.018: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/14/22 09:20:53.044
STEP: create a pod that should be updated by the webhook 12/14/22 09:20:53.194
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:20:53.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4646" for this suite. 12/14/22 09:20:53.391
STEP: Destroying namespace "webhook-4646-markers" for this suite. 12/14/22 09:20:53.422
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":216,"skipped":4031,"failed":0}
------------------------------
• [4.451 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:49.226
    Dec 14 09:20:49.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:20:49.227
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:49.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:49.35
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:20:49.45
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:20:49.785
    STEP: Deploying the webhook pod 12/14/22 09:20:49.811
    STEP: Wait for the deployment to be ready 12/14/22 09:20:49.867
    Dec 14 09:20:49.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:20:51.981
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:20:52.017
    Dec 14 09:20:53.018: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/14/22 09:20:53.044
    STEP: create a pod that should be updated by the webhook 12/14/22 09:20:53.194
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:20:53.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4646" for this suite. 12/14/22 09:20:53.391
    STEP: Destroying namespace "webhook-4646-markers" for this suite. 12/14/22 09:20:53.422
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:53.679
Dec 14 09:20:53.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:20:53.68
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:53.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:53.807
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:20:53.908
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:20:54.467
STEP: Deploying the webhook pod 12/14/22 09:20:54.495
STEP: Wait for the deployment to be ready 12/14/22 09:20:54.549
Dec 14 09:20:54.634: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:20:56.66
STEP: Verifying the service has paired with the endpoint 12/14/22 09:20:56.714
Dec 14 09:20:57.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:20:58.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:20:59.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:00.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:01.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:02.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:03.716: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:04.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:05.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:06.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Dec 14 09:21:07.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/14/22 09:21:07.741
STEP: create a configmap that should be updated by the webhook 12/14/22 09:21:07.894
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:21:08.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3195" for this suite. 12/14/22 09:21:08.126
STEP: Destroying namespace "webhook-3195-markers" for this suite. 12/14/22 09:21:08.154
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":217,"skipped":4045,"failed":0}
------------------------------
• [14.625 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:53.679
    Dec 14 09:20:53.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:20:53.68
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:53.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:53.807
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:20:53.908
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:20:54.467
    STEP: Deploying the webhook pod 12/14/22 09:20:54.495
    STEP: Wait for the deployment to be ready 12/14/22 09:20:54.549
    Dec 14 09:20:54.634: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 20, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:20:56.66
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:20:56.714
    Dec 14 09:20:57.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:20:58.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:20:59.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:00.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:01.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:02.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:03.716: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:04.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:05.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:06.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Dec 14 09:21:07.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/14/22 09:21:07.741
    STEP: create a configmap that should be updated by the webhook 12/14/22 09:21:07.894
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:21:08.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3195" for this suite. 12/14/22 09:21:08.126
    STEP: Destroying namespace "webhook-3195-markers" for this suite. 12/14/22 09:21:08.154
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:21:08.304
Dec 14 09:21:08.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:21:08.306
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:08.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:08.429
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 12/14/22 09:21:08.476
STEP: Ensuring job reaches completions 12/14/22 09:21:08.503
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:21:20.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2902" for this suite. 12/14/22 09:21:20.579
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":218,"skipped":4049,"failed":0}
------------------------------
• [12.302 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:21:08.304
    Dec 14 09:21:08.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:21:08.306
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:08.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:08.429
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 12/14/22 09:21:08.476
    STEP: Ensuring job reaches completions 12/14/22 09:21:08.503
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:21:20.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2902" for this suite. 12/14/22 09:21:20.579
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:21:20.608
Dec 14 09:21:20.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:21:20.61
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:20.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:20.742
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:21:20.817
Dec 14 09:21:20.850: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4958" to be "running and ready"
Dec 14 09:21:20.876: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.340634ms
Dec 14 09:21:20.876: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:21:22.902: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.051601529s
Dec 14 09:21:22.902: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:21:22.902: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 12/14/22 09:21:22.927
Dec 14 09:21:22.958: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4958" to be "running and ready"
Dec 14 09:21:22.983: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 25.344858ms
Dec 14 09:21:22.983: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:21:25.010: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.05188746s
Dec 14 09:21:25.010: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Dec 14 09:21:25.010: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/14/22 09:21:25.035
Dec 14 09:21:25.063: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:21:25.089: INFO: Pod pod-with-prestop-http-hook still exists
Dec 14 09:21:27.090: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:21:27.116: INFO: Pod pod-with-prestop-http-hook still exists
Dec 14 09:21:29.090: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:21:29.119: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 12/14/22 09:21:29.119
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:21:29.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4958" for this suite. 12/14/22 09:21:29.201
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":219,"skipped":4078,"failed":0}
------------------------------
• [8.620 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:21:20.608
    Dec 14 09:21:20.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:21:20.61
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:20.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:20.742
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:21:20.817
    Dec 14 09:21:20.850: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4958" to be "running and ready"
    Dec 14 09:21:20.876: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 25.340634ms
    Dec 14 09:21:20.876: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:21:22.902: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.051601529s
    Dec 14 09:21:22.902: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:21:22.902: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 12/14/22 09:21:22.927
    Dec 14 09:21:22.958: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4958" to be "running and ready"
    Dec 14 09:21:22.983: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 25.344858ms
    Dec 14 09:21:22.983: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:21:25.010: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.05188746s
    Dec 14 09:21:25.010: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Dec 14 09:21:25.010: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/14/22 09:21:25.035
    Dec 14 09:21:25.063: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:21:25.089: INFO: Pod pod-with-prestop-http-hook still exists
    Dec 14 09:21:27.090: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:21:27.116: INFO: Pod pod-with-prestop-http-hook still exists
    Dec 14 09:21:29.090: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:21:29.119: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 12/14/22 09:21:29.119
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:21:29.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4958" for this suite. 12/14/22 09:21:29.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:21:29.229
Dec 14 09:21:29.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:21:29.231
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:29.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:29.356
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Dec 14 09:21:29.463: INFO: created pod
Dec 14 09:21:29.463: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-6323" to be "Succeeded or Failed"
Dec 14 09:21:29.488: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 25.228063ms
Dec 14 09:21:31.515: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 2.052278205s
Dec 14 09:21:33.522: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058915012s
STEP: Saw pod success 12/14/22 09:21:33.522
Dec 14 09:21:33.522: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Dec 14 09:22:03.525: INFO: polling logs
Dec 14 09:22:03.561: INFO: Pod logs: 
I1214 09:21:30.241399       1 log.go:195] OK: Got token
I1214 09:21:30.241426       1 log.go:195] validating with in-cluster discovery
I1214 09:21:30.243799       1 log.go:195] OK: got issuer https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com
I1214 09:21:30.244391       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-6323:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671010289, NotBefore:1671009689, IssuedAt:1671009689, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6323", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e35e6c3f-a485-44dd-ac6a-0b012fdb04d4"}}}
I1214 09:21:30.257700       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com
I1214 09:21:30.260447       1 log.go:195] OK: Validated signature on JWT
I1214 09:21:30.260540       1 log.go:195] OK: Got valid claims from token!
I1214 09:21:30.260560       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-6323:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671010289, NotBefore:1671009689, IssuedAt:1671009689, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6323", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e35e6c3f-a485-44dd-ac6a-0b012fdb04d4"}}}

Dec 14 09:22:03.561: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:22:03.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6323" for this suite. 12/14/22 09:22:03.636
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":220,"skipped":4088,"failed":0}
------------------------------
• [34.434 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:21:29.229
    Dec 14 09:21:29.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:21:29.231
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:21:29.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:21:29.356
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Dec 14 09:21:29.463: INFO: created pod
    Dec 14 09:21:29.463: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-6323" to be "Succeeded or Failed"
    Dec 14 09:21:29.488: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 25.228063ms
    Dec 14 09:21:31.515: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 2.052278205s
    Dec 14 09:21:33.522: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058915012s
    STEP: Saw pod success 12/14/22 09:21:33.522
    Dec 14 09:21:33.522: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Dec 14 09:22:03.525: INFO: polling logs
    Dec 14 09:22:03.561: INFO: Pod logs: 
    I1214 09:21:30.241399       1 log.go:195] OK: Got token
    I1214 09:21:30.241426       1 log.go:195] validating with in-cluster discovery
    I1214 09:21:30.243799       1 log.go:195] OK: got issuer https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com
    I1214 09:21:30.244391       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-6323:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671010289, NotBefore:1671009689, IssuedAt:1671009689, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6323", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e35e6c3f-a485-44dd-ac6a-0b012fdb04d4"}}}
    I1214 09:21:30.257700       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com
    I1214 09:21:30.260447       1 log.go:195] OK: Validated signature on JWT
    I1214 09:21:30.260540       1 log.go:195] OK: Got valid claims from token!
    I1214 09:21:30.260560       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tm0ct-io0.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-6323:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671010289, NotBefore:1671009689, IssuedAt:1671009689, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6323", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e35e6c3f-a485-44dd-ac6a-0b012fdb04d4"}}}

    Dec 14 09:22:03.561: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:22:03.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6323" for this suite. 12/14/22 09:22:03.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:03.669
Dec 14 09:22:03.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:22:03.67
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:03.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:03.794
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-9378 12/14/22 09:22:03.841
STEP: creating a selector 12/14/22 09:22:03.842
STEP: Creating the service pods in kubernetes 12/14/22 09:22:03.842
Dec 14 09:22:03.842: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:22:03.959: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9378" to be "running and ready"
Dec 14 09:22:03.984: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.691954ms
Dec 14 09:22:03.984: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:22:06.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.051822504s
Dec 14 09:22:06.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:22:08.011: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.052227144s
Dec 14 09:22:08.011: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:22:10.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.051680758s
Dec 14 09:22:10.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:22:12.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.051805591s
Dec 14 09:22:12.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:22:14.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.051547166s
Dec 14 09:22:14.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:22:16.014: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.055439668s
Dec 14 09:22:16.014: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:22:16.014: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:22:16.040: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9378" to be "running and ready"
Dec 14 09:22:16.065: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.297928ms
Dec 14 09:22:16.065: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:22:16.065: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:22:16.091
Dec 14 09:22:16.122: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9378" to be "running"
Dec 14 09:22:16.148: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.479616ms
Dec 14 09:22:18.178: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.055414726s
Dec 14 09:22:18.178: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:22:18.204: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:22:18.204: INFO: Breadth first check of 100.64.0.153 on host 10.250.0.5...
Dec 14 09:22:18.230: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.154:9080/dial?request=hostname&protocol=http&host=100.64.0.153&port=8083&tries=1'] Namespace:pod-network-test-9378 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:22:18.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:22:18.230: INFO: ExecWithOptions: Clientset creation
Dec 14 09:22:18.230: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-9378/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.64.0.153%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:22:18.722: INFO: Waiting for responses: map[]
Dec 14 09:22:18.722: INFO: reached 100.64.0.153 after 0/1 tries
Dec 14 09:22:18.722: INFO: Breadth first check of 100.64.1.211 on host 10.250.0.4...
Dec 14 09:22:18.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.154:9080/dial?request=hostname&protocol=http&host=100.64.1.211&port=8083&tries=1'] Namespace:pod-network-test-9378 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:22:18.748: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:22:18.748: INFO: ExecWithOptions: Clientset creation
Dec 14 09:22:18.748: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-9378/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.64.1.211%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:22:19.244: INFO: Waiting for responses: map[]
Dec 14 09:22:19.244: INFO: reached 100.64.1.211 after 0/1 tries
Dec 14 09:22:19.244: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:22:19.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9378" for this suite. 12/14/22 09:22:19.295
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":221,"skipped":4134,"failed":0}
------------------------------
• [15.653 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:03.669
    Dec 14 09:22:03.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:22:03.67
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:03.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:03.794
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-9378 12/14/22 09:22:03.841
    STEP: creating a selector 12/14/22 09:22:03.842
    STEP: Creating the service pods in kubernetes 12/14/22 09:22:03.842
    Dec 14 09:22:03.842: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:22:03.959: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9378" to be "running and ready"
    Dec 14 09:22:03.984: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.691954ms
    Dec 14 09:22:03.984: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:22:06.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.051822504s
    Dec 14 09:22:06.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:22:08.011: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.052227144s
    Dec 14 09:22:08.011: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:22:10.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.051680758s
    Dec 14 09:22:10.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:22:12.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.051805591s
    Dec 14 09:22:12.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:22:14.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.051547166s
    Dec 14 09:22:14.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:22:16.014: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.055439668s
    Dec 14 09:22:16.014: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:22:16.014: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:22:16.040: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9378" to be "running and ready"
    Dec 14 09:22:16.065: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.297928ms
    Dec 14 09:22:16.065: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:22:16.065: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:22:16.091
    Dec 14 09:22:16.122: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9378" to be "running"
    Dec 14 09:22:16.148: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.479616ms
    Dec 14 09:22:18.178: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.055414726s
    Dec 14 09:22:18.178: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:22:18.204: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:22:18.204: INFO: Breadth first check of 100.64.0.153 on host 10.250.0.5...
    Dec 14 09:22:18.230: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.154:9080/dial?request=hostname&protocol=http&host=100.64.0.153&port=8083&tries=1'] Namespace:pod-network-test-9378 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:22:18.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:22:18.230: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:22:18.230: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-9378/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.64.0.153%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:22:18.722: INFO: Waiting for responses: map[]
    Dec 14 09:22:18.722: INFO: reached 100.64.0.153 after 0/1 tries
    Dec 14 09:22:18.722: INFO: Breadth first check of 100.64.1.211 on host 10.250.0.4...
    Dec 14 09:22:18.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.154:9080/dial?request=hostname&protocol=http&host=100.64.1.211&port=8083&tries=1'] Namespace:pod-network-test-9378 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:22:18.748: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:22:18.748: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:22:18.748: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-9378/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.64.0.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.64.1.211%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:22:19.244: INFO: Waiting for responses: map[]
    Dec 14 09:22:19.244: INFO: reached 100.64.1.211 after 0/1 tries
    Dec 14 09:22:19.244: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:22:19.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9378" for this suite. 12/14/22 09:22:19.295
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:19.323
Dec 14 09:22:19.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:22:19.324
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:19.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:19.447
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 12/14/22 09:22:19.495
STEP: submitting the pod to kubernetes 12/14/22 09:22:19.495
STEP: verifying QOS class is set on the pod 12/14/22 09:22:19.53
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Dec 14 09:22:19.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-752" for this suite. 12/14/22 09:22:19.581
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":222,"skipped":4158,"failed":0}
------------------------------
• [0.284 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:19.323
    Dec 14 09:22:19.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:22:19.324
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:19.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:19.447
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 12/14/22 09:22:19.495
    STEP: submitting the pod to kubernetes 12/14/22 09:22:19.495
    STEP: verifying QOS class is set on the pod 12/14/22 09:22:19.53
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Dec 14 09:22:19.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-752" for this suite. 12/14/22 09:22:19.581
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:19.608
Dec 14 09:22:19.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:22:19.609
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:19.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:19.731
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-1071 12/14/22 09:22:19.779
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[] 12/14/22 09:22:19.814
Dec 14 09:22:19.892: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-1071 12/14/22 09:22:19.892
Dec 14 09:22:19.925: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1071" to be "running and ready"
Dec 14 09:22:19.950: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.820144ms
Dec 14 09:22:19.950: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:22:21.979: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.053787988s
Dec 14 09:22:21.979: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 09:22:21.979: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod1:[80]] 12/14/22 09:22:22.004
Dec 14 09:22:22.108: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 12/14/22 09:22:22.108
Dec 14 09:22:22.108: INFO: Creating new exec pod
Dec 14 09:22:22.142: INFO: Waiting up to 5m0s for pod "execpodn86qg" in namespace "services-1071" to be "running"
Dec 14 09:22:22.167: INFO: Pod "execpodn86qg": Phase="Pending", Reason="", readiness=false. Elapsed: 25.201482ms
Dec 14 09:22:24.196: INFO: Pod "execpodn86qg": Phase="Running", Reason="", readiness=true. Elapsed: 2.054117775s
Dec 14 09:22:24.196: INFO: Pod "execpodn86qg" satisfied condition "running"
Dec 14 09:22:25.197: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:22:25.782: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:25.782: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:22:25.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
Dec 14 09:22:26.291: INFO: stderr: "+ nc -v -t -w 2 100.105.143.212 80\n+ echo hostName\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:26.292: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-1071 12/14/22 09:22:26.292
Dec 14 09:22:26.324: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1071" to be "running and ready"
Dec 14 09:22:26.352: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.472862ms
Dec 14 09:22:26.352: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:22:28.379: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.055120492s
Dec 14 09:22:28.379: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 09:22:28.379: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod1:[80] pod2:[80]] 12/14/22 09:22:28.404
Dec 14 09:22:28.528: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 12/14/22 09:22:28.528
Dec 14 09:22:29.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:22:30.106: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:30.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:22:30.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
Dec 14 09:22:30.712: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.105.143.212 80\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:30.712: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-1071 12/14/22 09:22:30.712
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod2:[80]] 12/14/22 09:22:30.748
Dec 14 09:22:30.852: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 12/14/22 09:22:30.853
Dec 14 09:22:31.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:22:32.435: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:32.435: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:22:32.435: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
Dec 14 09:22:33.048: INFO: stderr: "+ nc -v -t -w 2 100.105.143.212 80\n+ echo hostName\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
Dec 14 09:22:33.048: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-1071 12/14/22 09:22:33.048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[] 12/14/22 09:22:33.089
Dec 14 09:22:33.163: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:22:33.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1071" for this suite. 12/14/22 09:22:33.251
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":223,"skipped":4160,"failed":0}
------------------------------
• [13.670 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:19.608
    Dec 14 09:22:19.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:22:19.609
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:19.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:19.731
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-1071 12/14/22 09:22:19.779
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[] 12/14/22 09:22:19.814
    Dec 14 09:22:19.892: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-1071 12/14/22 09:22:19.892
    Dec 14 09:22:19.925: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1071" to be "running and ready"
    Dec 14 09:22:19.950: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.820144ms
    Dec 14 09:22:19.950: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:22:21.979: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.053787988s
    Dec 14 09:22:21.979: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 09:22:21.979: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod1:[80]] 12/14/22 09:22:22.004
    Dec 14 09:22:22.108: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 12/14/22 09:22:22.108
    Dec 14 09:22:22.108: INFO: Creating new exec pod
    Dec 14 09:22:22.142: INFO: Waiting up to 5m0s for pod "execpodn86qg" in namespace "services-1071" to be "running"
    Dec 14 09:22:22.167: INFO: Pod "execpodn86qg": Phase="Pending", Reason="", readiness=false. Elapsed: 25.201482ms
    Dec 14 09:22:24.196: INFO: Pod "execpodn86qg": Phase="Running", Reason="", readiness=true. Elapsed: 2.054117775s
    Dec 14 09:22:24.196: INFO: Pod "execpodn86qg" satisfied condition "running"
    Dec 14 09:22:25.197: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:22:25.782: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:25.782: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:22:25.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
    Dec 14 09:22:26.291: INFO: stderr: "+ nc -v -t -w 2 100.105.143.212 80\n+ echo hostName\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:26.292: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-1071 12/14/22 09:22:26.292
    Dec 14 09:22:26.324: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1071" to be "running and ready"
    Dec 14 09:22:26.352: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.472862ms
    Dec 14 09:22:26.352: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:22:28.379: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.055120492s
    Dec 14 09:22:28.379: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 09:22:28.379: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod1:[80] pod2:[80]] 12/14/22 09:22:28.404
    Dec 14 09:22:28.528: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 12/14/22 09:22:28.528
    Dec 14 09:22:29.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:22:30.106: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:30.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:22:30.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
    Dec 14 09:22:30.712: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.105.143.212 80\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:30.712: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-1071 12/14/22 09:22:30.712
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[pod2:[80]] 12/14/22 09:22:30.748
    Dec 14 09:22:30.852: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 12/14/22 09:22:30.853
    Dec 14 09:22:31.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:22:32.435: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:32.435: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:22:32.435: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1071 exec execpodn86qg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.105.143.212 80'
    Dec 14 09:22:33.048: INFO: stderr: "+ nc -v -t -w 2 100.105.143.212 80\n+ echo hostName\nConnection to 100.105.143.212 80 port [tcp/http] succeeded!\n"
    Dec 14 09:22:33.048: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-1071 12/14/22 09:22:33.048
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1071 to expose endpoints map[] 12/14/22 09:22:33.089
    Dec 14 09:22:33.163: INFO: successfully validated that service endpoint-test2 in namespace services-1071 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:22:33.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1071" for this suite. 12/14/22 09:22:33.251
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:33.279
Dec 14 09:22:33.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:22:33.279
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:33.355
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:33.401
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 12/14/22 09:22:33.449
STEP: fetching the ConfigMap 12/14/22 09:22:33.475
STEP: patching the ConfigMap 12/14/22 09:22:33.5
STEP: listing all ConfigMaps in all namespaces with a label selector 12/14/22 09:22:33.528
STEP: deleting the ConfigMap by collection with a label selector 12/14/22 09:22:33.555
STEP: listing all ConfigMaps in test namespace 12/14/22 09:22:33.583
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:22:33.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8204" for this suite. 12/14/22 09:22:33.634
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":224,"skipped":4162,"failed":0}
------------------------------
• [0.382 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:33.279
    Dec 14 09:22:33.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:22:33.279
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:33.355
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:33.401
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 12/14/22 09:22:33.449
    STEP: fetching the ConfigMap 12/14/22 09:22:33.475
    STEP: patching the ConfigMap 12/14/22 09:22:33.5
    STEP: listing all ConfigMaps in all namespaces with a label selector 12/14/22 09:22:33.528
    STEP: deleting the ConfigMap by collection with a label selector 12/14/22 09:22:33.555
    STEP: listing all ConfigMaps in test namespace 12/14/22 09:22:33.583
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:22:33.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8204" for this suite. 12/14/22 09:22:33.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:33.664
Dec 14 09:22:33.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:22:33.665
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:33.747
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:33.797
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e 12/14/22 09:22:33.845
Dec 14 09:22:33.899: INFO: Pod name my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e: Found 1 pods out of 1
Dec 14 09:22:33.899: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e" are running
Dec 14 09:22:33.899: INFO: Waiting up to 5m0s for pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" in namespace "replication-controller-7026" to be "running"
Dec 14 09:22:33.925: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn": Phase="Pending", Reason="", readiness=false. Elapsed: 25.595811ms
Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn": Phase="Running", Reason="", readiness=true. Elapsed: 2.053209378s
Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" satisfied condition "running"
Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:22:33 +0000 UTC Reason: Message:}])
Dec 14 09:22:35.952: INFO: Trying to dial the pod
Dec 14 09:22:41.134: INFO: Controller my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e: Got expected result from replica 1 [my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn]: "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:22:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7026" for this suite. 12/14/22 09:22:41.183
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":225,"skipped":4241,"failed":0}
------------------------------
• [7.545 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:33.664
    Dec 14 09:22:33.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:22:33.665
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:33.747
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:33.797
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e 12/14/22 09:22:33.845
    Dec 14 09:22:33.899: INFO: Pod name my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e: Found 1 pods out of 1
    Dec 14 09:22:33.899: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e" are running
    Dec 14 09:22:33.899: INFO: Waiting up to 5m0s for pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" in namespace "replication-controller-7026" to be "running"
    Dec 14 09:22:33.925: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn": Phase="Pending", Reason="", readiness=false. Elapsed: 25.595811ms
    Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn": Phase="Running", Reason="", readiness=true. Elapsed: 2.053209378s
    Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" satisfied condition "running"
    Dec 14 09:22:35.952: INFO: Pod "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:22:33 +0000 UTC Reason: Message:}])
    Dec 14 09:22:35.952: INFO: Trying to dial the pod
    Dec 14 09:22:41.134: INFO: Controller my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e: Got expected result from replica 1 [my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn]: "my-hostname-basic-809df6af-a4e9-412c-b034-f3144a046b1e-w7nqn", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:22:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7026" for this suite. 12/14/22 09:22:41.183
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:41.21
Dec 14 09:22:41.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:22:41.211
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:41.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:41.334
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:22:41.436
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:22:41.933
STEP: Deploying the webhook pod 12/14/22 09:22:41.959
STEP: Wait for the deployment to be ready 12/14/22 09:22:42.013
Dec 14 09:22:42.115: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:22:44.14
STEP: Verifying the service has paired with the endpoint 12/14/22 09:22:44.175
Dec 14 09:22:45.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Dec 14 09:22:45.202: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8509-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:22:45.277
STEP: Creating a custom resource while v1 is storage version 12/14/22 09:22:45.438
STEP: Patching Custom Resource Definition to set v2 as storage 12/14/22 09:22:47.686
STEP: Patching the custom resource while v2 is storage version 12/14/22 09:22:47.724
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:22:48.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3534" for this suite. 12/14/22 09:22:48.476
STEP: Destroying namespace "webhook-3534-markers" for this suite. 12/14/22 09:22:48.504
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":226,"skipped":4249,"failed":0}
------------------------------
• [7.437 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:41.21
    Dec 14 09:22:41.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:22:41.211
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:41.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:41.334
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:22:41.436
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:22:41.933
    STEP: Deploying the webhook pod 12/14/22 09:22:41.959
    STEP: Wait for the deployment to be ready 12/14/22 09:22:42.013
    Dec 14 09:22:42.115: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:22:44.14
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:22:44.175
    Dec 14 09:22:45.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Dec 14 09:22:45.202: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8509-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:22:45.277
    STEP: Creating a custom resource while v1 is storage version 12/14/22 09:22:45.438
    STEP: Patching Custom Resource Definition to set v2 as storage 12/14/22 09:22:47.686
    STEP: Patching the custom resource while v2 is storage version 12/14/22 09:22:47.724
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:22:48.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3534" for this suite. 12/14/22 09:22:48.476
    STEP: Destroying namespace "webhook-3534-markers" for this suite. 12/14/22 09:22:48.504
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:48.648
Dec 14 09:22:48.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 09:22:48.649
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:48.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:48.771
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 09:22:48.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7503" for this suite. 12/14/22 09:22:49.017
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":227,"skipped":4268,"failed":0}
------------------------------
• [0.395 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:48.648
    Dec 14 09:22:48.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 09:22:48.649
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:48.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:48.771
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 09:22:48.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7503" for this suite. 12/14/22 09:22:49.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:49.044
Dec 14 09:22:49.044: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:22:49.045
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:49.12
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:49.168
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 12/14/22 09:22:49.215
STEP: creating 12/14/22 09:22:49.215
STEP: getting 12/14/22 09:22:49.243
STEP: listing 12/14/22 09:22:49.269
STEP: watching 12/14/22 09:22:49.294
Dec 14 09:22:49.294: INFO: starting watch
STEP: cluster-wide listing 12/14/22 09:22:49.318
STEP: cluster-wide watching 12/14/22 09:22:49.343
Dec 14 09:22:49.343: INFO: starting watch
STEP: patching 12/14/22 09:22:49.366
STEP: updating 12/14/22 09:22:49.393
Dec 14 09:22:49.445: INFO: waiting for watch events with expected annotations
Dec 14 09:22:49.445: INFO: saw patched and updated annotations
STEP: patching /status 12/14/22 09:22:49.445
STEP: updating /status 12/14/22 09:22:49.471
STEP: get /status 12/14/22 09:22:49.523
STEP: deleting 12/14/22 09:22:49.548
STEP: deleting a collection 12/14/22 09:22:49.63
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:22:49.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5429" for this suite. 12/14/22 09:22:49.709
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":228,"skipped":4287,"failed":0}
------------------------------
• [0.691 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:49.044
    Dec 14 09:22:49.044: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:22:49.045
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:49.12
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:49.168
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 12/14/22 09:22:49.215
    STEP: creating 12/14/22 09:22:49.215
    STEP: getting 12/14/22 09:22:49.243
    STEP: listing 12/14/22 09:22:49.269
    STEP: watching 12/14/22 09:22:49.294
    Dec 14 09:22:49.294: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 09:22:49.318
    STEP: cluster-wide watching 12/14/22 09:22:49.343
    Dec 14 09:22:49.343: INFO: starting watch
    STEP: patching 12/14/22 09:22:49.366
    STEP: updating 12/14/22 09:22:49.393
    Dec 14 09:22:49.445: INFO: waiting for watch events with expected annotations
    Dec 14 09:22:49.445: INFO: saw patched and updated annotations
    STEP: patching /status 12/14/22 09:22:49.445
    STEP: updating /status 12/14/22 09:22:49.471
    STEP: get /status 12/14/22 09:22:49.523
    STEP: deleting 12/14/22 09:22:49.548
    STEP: deleting a collection 12/14/22 09:22:49.63
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:22:49.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5429" for this suite. 12/14/22 09:22:49.709
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:49.736
Dec 14 09:22:49.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:22:49.737
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:49.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:49.864
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-eb08863f-524b-4ff0-903e-b0a9211ef9b6 12/14/22 09:22:49.911
STEP: Creating a pod to test consume secrets 12/14/22 09:22:49.936
Dec 14 09:22:49.968: INFO: Waiting up to 5m0s for pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432" in namespace "secrets-8778" to be "Succeeded or Failed"
Dec 14 09:22:49.993: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Pending", Reason="", readiness=false. Elapsed: 24.759912ms
Dec 14 09:22:52.024: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056336949s
Dec 14 09:22:54.019: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050662845s
STEP: Saw pod success 12/14/22 09:22:54.019
Dec 14 09:22:54.019: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432" satisfied condition "Succeeded or Failed"
Dec 14 09:22:54.044: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:22:54.159
Dec 14 09:22:54.197: INFO: Waiting for pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 to disappear
Dec 14 09:22:54.224: INFO: Pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:22:54.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8778" for this suite. 12/14/22 09:22:54.275
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":229,"skipped":4298,"failed":0}
------------------------------
• [4.566 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:49.736
    Dec 14 09:22:49.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:22:49.737
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:49.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:49.864
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-eb08863f-524b-4ff0-903e-b0a9211ef9b6 12/14/22 09:22:49.911
    STEP: Creating a pod to test consume secrets 12/14/22 09:22:49.936
    Dec 14 09:22:49.968: INFO: Waiting up to 5m0s for pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432" in namespace "secrets-8778" to be "Succeeded or Failed"
    Dec 14 09:22:49.993: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Pending", Reason="", readiness=false. Elapsed: 24.759912ms
    Dec 14 09:22:52.024: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056336949s
    Dec 14 09:22:54.019: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050662845s
    STEP: Saw pod success 12/14/22 09:22:54.019
    Dec 14 09:22:54.019: INFO: Pod "pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432" satisfied condition "Succeeded or Failed"
    Dec 14 09:22:54.044: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:22:54.159
    Dec 14 09:22:54.197: INFO: Waiting for pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 to disappear
    Dec 14 09:22:54.224: INFO: Pod pod-secrets-4f01199e-ec9f-4576-890b-b43d92387432 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:22:54.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8778" for this suite. 12/14/22 09:22:54.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:54.303
Dec 14 09:22:54.303: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:22:54.303
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:54.38
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:54.428
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 12/14/22 09:22:54.478
Dec 14 09:22:54.510: INFO: Waiting up to 5m0s for pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95" in namespace "var-expansion-4930" to be "Succeeded or Failed"
Dec 14 09:22:54.535: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Pending", Reason="", readiness=false. Elapsed: 24.748549ms
Dec 14 09:22:56.562: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052178202s
Dec 14 09:22:58.563: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052391068s
STEP: Saw pod success 12/14/22 09:22:58.563
Dec 14 09:22:58.563: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95" satisfied condition "Succeeded or Failed"
Dec 14 09:22:58.588: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:22:58.619
Dec 14 09:22:58.653: INFO: Waiting for pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 to disappear
Dec 14 09:22:58.678: INFO: Pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:22:58.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4930" for this suite. 12/14/22 09:22:58.733
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":230,"skipped":4312,"failed":0}
------------------------------
• [4.457 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:54.303
    Dec 14 09:22:54.303: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:22:54.303
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:54.38
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:54.428
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 12/14/22 09:22:54.478
    Dec 14 09:22:54.510: INFO: Waiting up to 5m0s for pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95" in namespace "var-expansion-4930" to be "Succeeded or Failed"
    Dec 14 09:22:54.535: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Pending", Reason="", readiness=false. Elapsed: 24.748549ms
    Dec 14 09:22:56.562: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052178202s
    Dec 14 09:22:58.563: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052391068s
    STEP: Saw pod success 12/14/22 09:22:58.563
    Dec 14 09:22:58.563: INFO: Pod "var-expansion-bf13e336-a724-4c35-8378-557f303b7b95" satisfied condition "Succeeded or Failed"
    Dec 14 09:22:58.588: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:22:58.619
    Dec 14 09:22:58.653: INFO: Waiting for pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 to disappear
    Dec 14 09:22:58.678: INFO: Pod var-expansion-bf13e336-a724-4c35-8378-557f303b7b95 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:22:58.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4930" for this suite. 12/14/22 09:22:58.733
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:58.76
Dec 14 09:22:58.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:22:58.761
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:58.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:58.884
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-58f2989f-6962-4e4f-902a-ad282662839f 12/14/22 09:22:58.932
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:22:58.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9417" for this suite. 12/14/22 09:22:58.982
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":231,"skipped":4316,"failed":0}
------------------------------
• [0.248 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:58.76
    Dec 14 09:22:58.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:22:58.761
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:58.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:58.884
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-58f2989f-6962-4e4f-902a-ad282662839f 12/14/22 09:22:58.932
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:22:58.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9417" for this suite. 12/14/22 09:22:58.982
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:59.009
Dec 14 09:22:59.009: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:22:59.01
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:59.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:59.133
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Dec 14 09:22:59.313: INFO: Create a RollingUpdate DaemonSet
Dec 14 09:22:59.339: INFO: Check that daemon pods launch on every node of the cluster
Dec 14 09:22:59.394: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:22:59.394: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 09:23:00.470: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:23:00.470: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 09:23:01.470: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:23:01.470: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Dec 14 09:23:01.470: INFO: Update the DaemonSet to trigger a rollout
Dec 14 09:23:01.526: INFO: Updating DaemonSet daemon-set
Dec 14 09:23:04.657: INFO: Roll back the DaemonSet before rollout is complete
Dec 14 09:23:04.710: INFO: Updating DaemonSet daemon-set
Dec 14 09:23:04.710: INFO: Make sure DaemonSet rollback is complete
Dec 14 09:23:06.789: INFO: Pod daemon-set-px9kg is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:23:06.893
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9897, will wait for the garbage collector to delete the pods 12/14/22 09:23:06.893
Dec 14 09:23:06.996: INFO: Deleting DaemonSet.extensions daemon-set took: 26.801294ms
Dec 14 09:23:07.098: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.171736ms
Dec 14 09:23:09.724: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:23:09.724: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:23:09.749: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41439"},"items":null}

Dec 14 09:23:09.774: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41439"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:23:09.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9897" for this suite. 12/14/22 09:23:09.904
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":232,"skipped":4326,"failed":0}
------------------------------
• [10.924 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:59.009
    Dec 14 09:22:59.009: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:22:59.01
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:59.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:59.133
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Dec 14 09:22:59.313: INFO: Create a RollingUpdate DaemonSet
    Dec 14 09:22:59.339: INFO: Check that daemon pods launch on every node of the cluster
    Dec 14 09:22:59.394: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:22:59.394: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 09:23:00.470: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:23:00.470: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 09:23:01.470: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:23:01.470: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    Dec 14 09:23:01.470: INFO: Update the DaemonSet to trigger a rollout
    Dec 14 09:23:01.526: INFO: Updating DaemonSet daemon-set
    Dec 14 09:23:04.657: INFO: Roll back the DaemonSet before rollout is complete
    Dec 14 09:23:04.710: INFO: Updating DaemonSet daemon-set
    Dec 14 09:23:04.710: INFO: Make sure DaemonSet rollback is complete
    Dec 14 09:23:06.789: INFO: Pod daemon-set-px9kg is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:23:06.893
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9897, will wait for the garbage collector to delete the pods 12/14/22 09:23:06.893
    Dec 14 09:23:06.996: INFO: Deleting DaemonSet.extensions daemon-set took: 26.801294ms
    Dec 14 09:23:07.098: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.171736ms
    Dec 14 09:23:09.724: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:23:09.724: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:23:09.749: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41439"},"items":null}

    Dec 14 09:23:09.774: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41439"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:23:09.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9897" for this suite. 12/14/22 09:23:09.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:09.934
Dec 14 09:23:09.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 09:23:09.934
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:10.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:10.058
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 09:23:10.106: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 09:23:10.159: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 09:23:10.184: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
Dec 14 09:23:10.240: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:23:10.240: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:23:10.240: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:23:10.240: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:23:10.240: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:23:10.240: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:23:10.240: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:23:10.240: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:23:10.240: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:23:10.240: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:23:10.240: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:23:10.240: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 09:23:10.240: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:23:10.240: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:23:10.240: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:23:10.240: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:23:10.240: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:23:10.240: INFO: pod-qos-class-205c04c9-052a-475a-b474-da3cef9516ce from pods-752 started at 2022-12-14 09:22:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.240: INFO: 	Container agnhost ready: false, restart count 0
Dec 14 09:23:10.240: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
Dec 14 09:23:10.276: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 09:23:10.276: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 09:23:10.276: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:23:10.276: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:23:10.276: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:23:10.276: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 09:23:10.276: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:23:10.276: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 09:23:10.276: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 09:23:10.276: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:23:10.276: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:23:10.276: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:23:10.276: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 09:23:10.276: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:23:10.276: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:23:10.276: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:23:10.276: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:23:10.276: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:23:10.276: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:23:10.276: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:23:10.276: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:23:10.276: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 09:23:10.276: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 09:23:10.276: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 09:23:10.276: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 12/14/22 09:23:10.276
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.17309e8d0a741c66], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 12/14/22 09:23:10.4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:23:11.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2931" for this suite. 12/14/22 09:23:11.471
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":233,"skipped":4338,"failed":0}
------------------------------
• [1.565 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:09.934
    Dec 14 09:23:09.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 09:23:09.934
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:10.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:10.058
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 09:23:10.106: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 09:23:10.159: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 09:23:10.184: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
    Dec 14 09:23:10.240: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:23:10.240: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:23:10.240: INFO: pod-qos-class-205c04c9-052a-475a-b474-da3cef9516ce from pods-752 started at 2022-12-14 09:22:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.240: INFO: 	Container agnhost ready: false, restart count 0
    Dec 14 09:23:10.240: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
    Dec 14 09:23:10.276: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:23:10.276: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 09:23:10.276: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:23:10.276: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 09:23:10.276: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 09:23:10.276: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 12/14/22 09:23:10.276
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.17309e8d0a741c66], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 12/14/22 09:23:10.4
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:23:11.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2931" for this suite. 12/14/22 09:23:11.471
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:11.5
Dec 14 09:23:11.500: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:23:11.501
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:11.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:11.625
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 12/14/22 09:23:11.707
STEP: Patching the Job 12/14/22 09:23:11.734
STEP: Watching for Job to be patched 12/14/22 09:23:11.767
Dec 14 09:23:11.791: INFO: Event ADDED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec 14 09:23:11.791: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec 14 09:23:11.791: INFO: Event MODIFIED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 12/14/22 09:23:11.791
STEP: Watching for Job to be updated 12/14/22 09:23:11.845
Dec 14 09:23:11.868: INFO: Event MODIFIED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:11.869: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 12/14/22 09:23:11.869
Dec 14 09:23:11.900: INFO: Job: e2e-jjpnz as labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz]
STEP: Waiting for job to complete 12/14/22 09:23:11.9
STEP: Delete a job collection with a labelselector 12/14/22 09:23:19.926
STEP: Watching for Job to be deleted 12/14/22 09:23:19.958
Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:20.004: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:23:20.004: INFO: Event DELETED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 12/14/22 09:23:20.004
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:23:20.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-284" for this suite. 12/14/22 09:23:20.078
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":234,"skipped":4355,"failed":0}
------------------------------
• [8.605 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:11.5
    Dec 14 09:23:11.500: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:23:11.501
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:11.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:11.625
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 12/14/22 09:23:11.707
    STEP: Patching the Job 12/14/22 09:23:11.734
    STEP: Watching for Job to be patched 12/14/22 09:23:11.767
    Dec 14 09:23:11.791: INFO: Event ADDED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec 14 09:23:11.791: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec 14 09:23:11.791: INFO: Event MODIFIED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 12/14/22 09:23:11.791
    STEP: Watching for Job to be updated 12/14/22 09:23:11.845
    Dec 14 09:23:11.868: INFO: Event MODIFIED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:11.869: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 12/14/22 09:23:11.869
    Dec 14 09:23:11.900: INFO: Job: e2e-jjpnz as labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz]
    STEP: Waiting for job to complete 12/14/22 09:23:11.9
    STEP: Delete a job collection with a labelselector 12/14/22 09:23:19.926
    STEP: Watching for Job to be deleted 12/14/22 09:23:19.958
    Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:19.982: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:20.004: INFO: Event MODIFIED observed for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:23:20.004: INFO: Event DELETED found for Job e2e-jjpnz in namespace job-284 with labels: map[e2e-jjpnz:patched e2e-job-label:e2e-jjpnz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 12/14/22 09:23:20.004
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:23:20.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-284" for this suite. 12/14/22 09:23:20.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:20.105
Dec 14 09:23:20.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:23:20.106
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.191
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.239
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:20.286
Dec 14 09:23:20.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption-2 12/14/22 09:23:20.286
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.408
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.481
STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.531
STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.584
STEP: listing a collection of PDBs across all namespaces 12/14/22 09:23:20.609
STEP: listing a collection of PDBs in namespace disruption-3646 12/14/22 09:23:20.635
STEP: deleting a collection of PDBs 12/14/22 09:23:20.666
STEP: Waiting for the PDB collection to be deleted 12/14/22 09:23:20.698
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Dec 14 09:23:20.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-7808" for this suite. 12/14/22 09:23:20.75
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:23:20.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3646" for this suite. 12/14/22 09:23:20.804
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":235,"skipped":4363,"failed":0}
------------------------------
• [0.725 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:20.105
    Dec 14 09:23:20.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:23:20.106
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.191
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.239
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:20.286
    Dec 14 09:23:20.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption-2 12/14/22 09:23:20.286
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.408
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.481
    STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.531
    STEP: Waiting for the pdb to be processed 12/14/22 09:23:20.584
    STEP: listing a collection of PDBs across all namespaces 12/14/22 09:23:20.609
    STEP: listing a collection of PDBs in namespace disruption-3646 12/14/22 09:23:20.635
    STEP: deleting a collection of PDBs 12/14/22 09:23:20.666
    STEP: Waiting for the PDB collection to be deleted 12/14/22 09:23:20.698
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Dec 14 09:23:20.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-7808" for this suite. 12/14/22 09:23:20.75
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:23:20.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3646" for this suite. 12/14/22 09:23:20.804
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:20.832
Dec 14 09:23:20.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:23:20.833
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.956
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Dec 14 09:23:21.003: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:23:21.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5391" for this suite. 12/14/22 09:23:21.773
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":236,"skipped":4400,"failed":0}
------------------------------
• [0.968 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:20.832
    Dec 14 09:23:20.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:23:20.833
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:20.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:20.956
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Dec 14 09:23:21.003: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:23:21.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5391" for this suite. 12/14/22 09:23:21.773
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:21.801
Dec 14 09:23:21.801: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:23:21.802
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:21.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:21.924
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 12/14/22 09:23:21.972
STEP: submitting the pod to kubernetes 12/14/22 09:23:21.972
Dec 14 09:23:22.004: INFO: Waiting up to 5m0s for pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" in namespace "pods-3150" to be "running and ready"
Dec 14 09:23:22.029: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Pending", Reason="", readiness=false. Elapsed: 24.537477ms
Dec 14 09:23:22.029: INFO: The phase of Pod pod-update-44369731-4788-42c8-b1ca-c6831159a911 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:23:24.055: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Running", Reason="", readiness=true. Elapsed: 2.050989655s
Dec 14 09:23:24.055: INFO: The phase of Pod pod-update-44369731-4788-42c8-b1ca-c6831159a911 is Running (Ready = true)
Dec 14 09:23:24.055: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/14/22 09:23:24.08
STEP: updating the pod 12/14/22 09:23:24.105
Dec 14 09:23:24.660: INFO: Successfully updated pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911"
Dec 14 09:23:24.660: INFO: Waiting up to 5m0s for pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" in namespace "pods-3150" to be "running"
Dec 14 09:23:24.685: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Running", Reason="", readiness=true. Elapsed: 25.078331ms
Dec 14 09:23:24.685: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 12/14/22 09:23:24.685
Dec 14 09:23:24.710: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:23:24.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3150" for this suite. 12/14/22 09:23:24.766
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":237,"skipped":4402,"failed":0}
------------------------------
• [2.991 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:21.801
    Dec 14 09:23:21.801: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:23:21.802
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:21.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:21.924
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 12/14/22 09:23:21.972
    STEP: submitting the pod to kubernetes 12/14/22 09:23:21.972
    Dec 14 09:23:22.004: INFO: Waiting up to 5m0s for pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" in namespace "pods-3150" to be "running and ready"
    Dec 14 09:23:22.029: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Pending", Reason="", readiness=false. Elapsed: 24.537477ms
    Dec 14 09:23:22.029: INFO: The phase of Pod pod-update-44369731-4788-42c8-b1ca-c6831159a911 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:23:24.055: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Running", Reason="", readiness=true. Elapsed: 2.050989655s
    Dec 14 09:23:24.055: INFO: The phase of Pod pod-update-44369731-4788-42c8-b1ca-c6831159a911 is Running (Ready = true)
    Dec 14 09:23:24.055: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/14/22 09:23:24.08
    STEP: updating the pod 12/14/22 09:23:24.105
    Dec 14 09:23:24.660: INFO: Successfully updated pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911"
    Dec 14 09:23:24.660: INFO: Waiting up to 5m0s for pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" in namespace "pods-3150" to be "running"
    Dec 14 09:23:24.685: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911": Phase="Running", Reason="", readiness=true. Elapsed: 25.078331ms
    Dec 14 09:23:24.685: INFO: Pod "pod-update-44369731-4788-42c8-b1ca-c6831159a911" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 12/14/22 09:23:24.685
    Dec 14 09:23:24.710: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:23:24.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3150" for this suite. 12/14/22 09:23:24.766
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:24.793
Dec 14 09:23:24.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:23:24.794
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:24.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:24.918
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-6859/configmap-test-718e9bf0-941e-4658-bc44-0a6be1b05c5f 12/14/22 09:23:24.965
STEP: Creating a pod to test consume configMaps 12/14/22 09:23:24.991
Dec 14 09:23:25.026: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d" in namespace "configmap-6859" to be "Succeeded or Failed"
Dec 14 09:23:25.051: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.523674ms
Dec 14 09:23:27.078: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052292488s
Dec 14 09:23:29.077: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050569891s
STEP: Saw pod success 12/14/22 09:23:29.077
Dec 14 09:23:29.077: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d" satisfied condition "Succeeded or Failed"
Dec 14 09:23:29.102: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d container env-test: <nil>
STEP: delete the pod 12/14/22 09:23:29.136
Dec 14 09:23:29.169: INFO: Waiting for pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d to disappear
Dec 14 09:23:29.204: INFO: Pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:23:29.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6859" for this suite. 12/14/22 09:23:29.252
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":238,"skipped":4417,"failed":0}
------------------------------
• [4.486 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:24.793
    Dec 14 09:23:24.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:23:24.794
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:24.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:24.918
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-6859/configmap-test-718e9bf0-941e-4658-bc44-0a6be1b05c5f 12/14/22 09:23:24.965
    STEP: Creating a pod to test consume configMaps 12/14/22 09:23:24.991
    Dec 14 09:23:25.026: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d" in namespace "configmap-6859" to be "Succeeded or Failed"
    Dec 14 09:23:25.051: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.523674ms
    Dec 14 09:23:27.078: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052292488s
    Dec 14 09:23:29.077: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050569891s
    STEP: Saw pod success 12/14/22 09:23:29.077
    Dec 14 09:23:29.077: INFO: Pod "pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d" satisfied condition "Succeeded or Failed"
    Dec 14 09:23:29.102: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d container env-test: <nil>
    STEP: delete the pod 12/14/22 09:23:29.136
    Dec 14 09:23:29.169: INFO: Waiting for pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d to disappear
    Dec 14 09:23:29.204: INFO: Pod pod-configmaps-4ee06c05-8d89-4778-b0ea-196b2374616d no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:23:29.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6859" for this suite. 12/14/22 09:23:29.252
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:29.28
Dec 14 09:23:29.280: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:23:29.281
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:29.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:29.405
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 12/14/22 09:23:29.453
STEP: Creating a ResourceQuota 12/14/22 09:23:34.48
STEP: Ensuring resource quota status is calculated 12/14/22 09:23:34.507
STEP: Creating a ReplicationController 12/14/22 09:23:36.533
STEP: Ensuring resource quota status captures replication controller creation 12/14/22 09:23:36.571
STEP: Deleting a ReplicationController 12/14/22 09:23:38.599
STEP: Ensuring resource quota status released usage 12/14/22 09:23:38.626
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:23:40.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2674" for this suite. 12/14/22 09:23:40.701
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":239,"skipped":4433,"failed":0}
------------------------------
• [11.449 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:29.28
    Dec 14 09:23:29.280: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:23:29.281
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:29.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:29.405
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 12/14/22 09:23:29.453
    STEP: Creating a ResourceQuota 12/14/22 09:23:34.48
    STEP: Ensuring resource quota status is calculated 12/14/22 09:23:34.507
    STEP: Creating a ReplicationController 12/14/22 09:23:36.533
    STEP: Ensuring resource quota status captures replication controller creation 12/14/22 09:23:36.571
    STEP: Deleting a ReplicationController 12/14/22 09:23:38.599
    STEP: Ensuring resource quota status released usage 12/14/22 09:23:38.626
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:23:40.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2674" for this suite. 12/14/22 09:23:40.701
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:40.73
Dec 14 09:23:40.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:23:40.731
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:40.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:40.856
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b in namespace container-probe-9889 12/14/22 09:23:40.903
Dec 14 09:23:40.936: INFO: Waiting up to 5m0s for pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b" in namespace "container-probe-9889" to be "not pending"
Dec 14 09:23:40.965: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 29.04401ms
Dec 14 09:23:42.991: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.055338755s
Dec 14 09:23:42.991: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b" satisfied condition "not pending"
Dec 14 09:23:42.991: INFO: Started pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b in namespace container-probe-9889
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:23:42.991
Dec 14 09:23:43.017: INFO: Initial restart count of pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b is 0
STEP: deleting the pod 12/14/22 09:27:44.204
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:27:44.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9889" for this suite. 12/14/22 09:27:44.297
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":240,"skipped":4452,"failed":0}
------------------------------
• [243.594 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:40.73
    Dec 14 09:23:40.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:23:40.731
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:40.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:40.856
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b in namespace container-probe-9889 12/14/22 09:23:40.903
    Dec 14 09:23:40.936: INFO: Waiting up to 5m0s for pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b" in namespace "container-probe-9889" to be "not pending"
    Dec 14 09:23:40.965: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 29.04401ms
    Dec 14 09:23:42.991: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.055338755s
    Dec 14 09:23:42.991: INFO: Pod "test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b" satisfied condition "not pending"
    Dec 14 09:23:42.991: INFO: Started pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b in namespace container-probe-9889
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:23:42.991
    Dec 14 09:23:43.017: INFO: Initial restart count of pod test-webserver-0a4bd4f3-24f9-4457-bafc-6e859af71c8b is 0
    STEP: deleting the pod 12/14/22 09:27:44.204
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:27:44.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9889" for this suite. 12/14/22 09:27:44.297
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:27:44.324
Dec 14 09:27:44.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:27:44.325
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:44.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:44.449
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:27:44.497
Dec 14 09:27:44.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2" in namespace "projected-2707" to be "Succeeded or Failed"
Dec 14 09:27:44.572: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.987869ms
Dec 14 09:27:46.599: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056806102s
Dec 14 09:27:48.598: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055902955s
STEP: Saw pod success 12/14/22 09:27:48.599
Dec 14 09:27:48.599: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2" satisfied condition "Succeeded or Failed"
Dec 14 09:27:48.625: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 container client-container: <nil>
STEP: delete the pod 12/14/22 09:27:48.661
Dec 14 09:27:48.697: INFO: Waiting for pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 to disappear
Dec 14 09:27:48.722: INFO: Pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:27:48.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2707" for this suite. 12/14/22 09:27:48.771
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":241,"skipped":4456,"failed":0}
------------------------------
• [4.473 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:27:44.324
    Dec 14 09:27:44.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:27:44.325
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:44.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:44.449
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:27:44.497
    Dec 14 09:27:44.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2" in namespace "projected-2707" to be "Succeeded or Failed"
    Dec 14 09:27:44.572: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.987869ms
    Dec 14 09:27:46.599: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056806102s
    Dec 14 09:27:48.598: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055902955s
    STEP: Saw pod success 12/14/22 09:27:48.599
    Dec 14 09:27:48.599: INFO: Pod "downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2" satisfied condition "Succeeded or Failed"
    Dec 14 09:27:48.625: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:27:48.661
    Dec 14 09:27:48.697: INFO: Waiting for pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 to disappear
    Dec 14 09:27:48.722: INFO: Pod downwardapi-volume-fe0b5596-e3a4-4a9a-ac84-d3c5ecc4eba2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:27:48.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2707" for this suite. 12/14/22 09:27:48.771
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:27:48.798
Dec 14 09:27:48.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:27:48.799
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:48.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:48.921
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 09:27:48.968
Dec 14 09:27:49.000: INFO: Waiting up to 5m0s for pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e" in namespace "emptydir-4923" to be "Succeeded or Failed"
Dec 14 09:27:49.025: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.242744ms
Dec 14 09:27:51.054: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054242571s
Dec 14 09:27:53.051: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051683115s
STEP: Saw pod success 12/14/22 09:27:53.052
Dec 14 09:27:53.052: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e" satisfied condition "Succeeded or Failed"
Dec 14 09:27:53.077: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e container test-container: <nil>
STEP: delete the pod 12/14/22 09:27:53.11
Dec 14 09:27:53.143: INFO: Waiting for pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e to disappear
Dec 14 09:27:53.167: INFO: Pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:27:53.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4923" for this suite. 12/14/22 09:27:53.216
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":242,"skipped":4474,"failed":0}
------------------------------
• [4.445 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:27:48.798
    Dec 14 09:27:48.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:27:48.799
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:48.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:48.921
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 09:27:48.968
    Dec 14 09:27:49.000: INFO: Waiting up to 5m0s for pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e" in namespace "emptydir-4923" to be "Succeeded or Failed"
    Dec 14 09:27:49.025: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.242744ms
    Dec 14 09:27:51.054: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054242571s
    Dec 14 09:27:53.051: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051683115s
    STEP: Saw pod success 12/14/22 09:27:53.052
    Dec 14 09:27:53.052: INFO: Pod "pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e" satisfied condition "Succeeded or Failed"
    Dec 14 09:27:53.077: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e container test-container: <nil>
    STEP: delete the pod 12/14/22 09:27:53.11
    Dec 14 09:27:53.143: INFO: Waiting for pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e to disappear
    Dec 14 09:27:53.167: INFO: Pod pod-e70236c3-2ff3-44fe-b97e-15b8972ce37e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:27:53.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4923" for this suite. 12/14/22 09:27:53.216
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:27:53.244
Dec 14 09:27:53.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:27:53.245
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:53.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:53.368
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 12/14/22 09:27:53.415
STEP: Getting a ResourceQuota 12/14/22 09:27:53.441
STEP: Listing all ResourceQuotas with LabelSelector 12/14/22 09:27:53.466
STEP: Patching the ResourceQuota 12/14/22 09:27:53.491
STEP: Deleting a Collection of ResourceQuotas 12/14/22 09:27:53.519
STEP: Verifying the deleted ResourceQuota 12/14/22 09:27:53.547
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:27:53.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4063" for this suite. 12/14/22 09:27:53.599
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":243,"skipped":4487,"failed":0}
------------------------------
• [0.381 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:27:53.244
    Dec 14 09:27:53.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:27:53.245
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:53.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:53.368
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 12/14/22 09:27:53.415
    STEP: Getting a ResourceQuota 12/14/22 09:27:53.441
    STEP: Listing all ResourceQuotas with LabelSelector 12/14/22 09:27:53.466
    STEP: Patching the ResourceQuota 12/14/22 09:27:53.491
    STEP: Deleting a Collection of ResourceQuotas 12/14/22 09:27:53.519
    STEP: Verifying the deleted ResourceQuota 12/14/22 09:27:53.547
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:27:53.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4063" for this suite. 12/14/22 09:27:53.599
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:27:53.627
Dec 14 09:27:53.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslicemirroring 12/14/22 09:27:53.628
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:53.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:53.749
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 12/14/22 09:27:53.83
STEP: mirroring an update to a custom Endpoint 12/14/22 09:27:53.884
STEP: mirroring deletion of a custom Endpoint 12/14/22 09:27:53.934
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Dec 14 09:27:53.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-7427" for this suite. 12/14/22 09:27:54.013
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":244,"skipped":4522,"failed":0}
------------------------------
• [0.413 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:27:53.627
    Dec 14 09:27:53.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslicemirroring 12/14/22 09:27:53.628
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:53.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:53.749
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 12/14/22 09:27:53.83
    STEP: mirroring an update to a custom Endpoint 12/14/22 09:27:53.884
    STEP: mirroring deletion of a custom Endpoint 12/14/22 09:27:53.934
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Dec 14 09:27:53.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-7427" for this suite. 12/14/22 09:27:54.013
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:27:54.042
Dec 14 09:27:54.042: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:27:54.042
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:54.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:54.172
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 12/14/22 09:27:54.22
Dec 14 09:27:54.253: INFO: Waiting up to 2m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102" to be "running"
Dec 14 09:27:54.280: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 27.034737ms
Dec 14 09:27:56.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054832344s
Dec 14 09:27:58.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054716074s
Dec 14 09:28:00.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055267924s
Dec 14 09:28:02.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054142252s
Dec 14 09:28:04.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 10.05444902s
Dec 14 09:28:06.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 12.054039991s
Dec 14 09:28:08.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 14.053450469s
Dec 14 09:28:10.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054027758s
Dec 14 09:28:12.311: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 18.058456578s
Dec 14 09:28:14.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 20.053607364s
Dec 14 09:28:16.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 22.053874824s
Dec 14 09:28:18.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 24.053176123s
Dec 14 09:28:20.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053567888s
Dec 14 09:28:22.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 28.053244231s
Dec 14 09:28:24.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 30.053503622s
Dec 14 09:28:26.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 32.052685245s
Dec 14 09:28:28.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054910335s
Dec 14 09:28:30.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 36.053860373s
Dec 14 09:28:32.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 38.053849909s
Dec 14 09:28:34.305: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 40.052372891s
Dec 14 09:28:36.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 42.052918904s
Dec 14 09:28:38.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 44.053764113s
Dec 14 09:28:40.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 46.052866958s
Dec 14 09:28:42.313: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 48.059830161s
Dec 14 09:28:44.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 50.053508568s
Dec 14 09:28:46.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 52.054231902s
Dec 14 09:28:48.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 54.052828986s
Dec 14 09:28:50.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 56.053412478s
Dec 14 09:28:52.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 58.053511811s
Dec 14 09:28:54.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.053116347s
Dec 14 09:28:56.309: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.056462145s
Dec 14 09:28:58.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.053163397s
Dec 14 09:29:00.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.053722369s
Dec 14 09:29:02.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.053743417s
Dec 14 09:29:04.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.054190986s
Dec 14 09:29:06.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.053405458s
Dec 14 09:29:08.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.054114516s
Dec 14 09:29:10.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.05413845s
Dec 14 09:29:12.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.053800877s
Dec 14 09:29:14.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.053632377s
Dec 14 09:29:16.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.057385175s
Dec 14 09:29:18.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.05404892s
Dec 14 09:29:20.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.053576951s
Dec 14 09:29:22.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.056768825s
Dec 14 09:29:24.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.055358994s
Dec 14 09:29:26.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.056624575s
Dec 14 09:29:28.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.057370605s
Dec 14 09:29:30.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.053571965s
Dec 14 09:29:32.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.053252039s
Dec 14 09:29:34.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.053096934s
Dec 14 09:29:36.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.054436175s
Dec 14 09:29:38.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.053622348s
Dec 14 09:29:40.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.053577082s
Dec 14 09:29:42.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.053490854s
Dec 14 09:29:44.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.053614359s
Dec 14 09:29:46.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.054636232s
Dec 14 09:29:48.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.053934625s
Dec 14 09:29:50.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.052827816s
Dec 14 09:29:52.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.053019669s
Dec 14 09:29:54.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.052774965s
Dec 14 09:29:54.331: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.077935816s
STEP: updating the pod 12/14/22 09:29:54.331
Dec 14 09:29:54.886: INFO: Successfully updated pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35"
STEP: waiting for pod running 12/14/22 09:29:54.886
Dec 14 09:29:54.888: INFO: Waiting up to 2m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102" to be "running"
Dec 14 09:29:54.913: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 25.346482ms
Dec 14 09:29:56.940: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Running", Reason="", readiness=true. Elapsed: 2.052302122s
Dec 14 09:29:56.940: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 09:29:56.94
Dec 14 09:29:56.940: INFO: Deleting pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102"
Dec 14 09:29:56.967: INFO: Wait up to 5m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:30:29.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9102" for this suite. 12/14/22 09:30:29.067
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":245,"skipped":4551,"failed":0}
------------------------------
• [155.053 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:27:54.042
    Dec 14 09:27:54.042: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:27:54.042
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:27:54.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:27:54.172
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 12/14/22 09:27:54.22
    Dec 14 09:27:54.253: INFO: Waiting up to 2m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102" to be "running"
    Dec 14 09:27:54.280: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 27.034737ms
    Dec 14 09:27:56.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054832344s
    Dec 14 09:27:58.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054716074s
    Dec 14 09:28:00.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055267924s
    Dec 14 09:28:02.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054142252s
    Dec 14 09:28:04.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 10.05444902s
    Dec 14 09:28:06.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 12.054039991s
    Dec 14 09:28:08.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 14.053450469s
    Dec 14 09:28:10.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054027758s
    Dec 14 09:28:12.311: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 18.058456578s
    Dec 14 09:28:14.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 20.053607364s
    Dec 14 09:28:16.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 22.053874824s
    Dec 14 09:28:18.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 24.053176123s
    Dec 14 09:28:20.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053567888s
    Dec 14 09:28:22.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 28.053244231s
    Dec 14 09:28:24.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 30.053503622s
    Dec 14 09:28:26.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 32.052685245s
    Dec 14 09:28:28.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054910335s
    Dec 14 09:28:30.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 36.053860373s
    Dec 14 09:28:32.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 38.053849909s
    Dec 14 09:28:34.305: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 40.052372891s
    Dec 14 09:28:36.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 42.052918904s
    Dec 14 09:28:38.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 44.053764113s
    Dec 14 09:28:40.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 46.052866958s
    Dec 14 09:28:42.313: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 48.059830161s
    Dec 14 09:28:44.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 50.053508568s
    Dec 14 09:28:46.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 52.054231902s
    Dec 14 09:28:48.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 54.052828986s
    Dec 14 09:28:50.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 56.053412478s
    Dec 14 09:28:52.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 58.053511811s
    Dec 14 09:28:54.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.053116347s
    Dec 14 09:28:56.309: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.056462145s
    Dec 14 09:28:58.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.053163397s
    Dec 14 09:29:00.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.053722369s
    Dec 14 09:29:02.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.053743417s
    Dec 14 09:29:04.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.054190986s
    Dec 14 09:29:06.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.053405458s
    Dec 14 09:29:08.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.054114516s
    Dec 14 09:29:10.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.05413845s
    Dec 14 09:29:12.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.053800877s
    Dec 14 09:29:14.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.053632377s
    Dec 14 09:29:16.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.057385175s
    Dec 14 09:29:18.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.05404892s
    Dec 14 09:29:20.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.053576951s
    Dec 14 09:29:22.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.056768825s
    Dec 14 09:29:24.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.055358994s
    Dec 14 09:29:26.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.056624575s
    Dec 14 09:29:28.310: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.057370605s
    Dec 14 09:29:30.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.053571965s
    Dec 14 09:29:32.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.053252039s
    Dec 14 09:29:34.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.053096934s
    Dec 14 09:29:36.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.054436175s
    Dec 14 09:29:38.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.053622348s
    Dec 14 09:29:40.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.053577082s
    Dec 14 09:29:42.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.053490854s
    Dec 14 09:29:44.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.053614359s
    Dec 14 09:29:46.308: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.054636232s
    Dec 14 09:29:48.307: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.053934625s
    Dec 14 09:29:50.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.052827816s
    Dec 14 09:29:52.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.053019669s
    Dec 14 09:29:54.306: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.052774965s
    Dec 14 09:29:54.331: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.077935816s
    STEP: updating the pod 12/14/22 09:29:54.331
    Dec 14 09:29:54.886: INFO: Successfully updated pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35"
    STEP: waiting for pod running 12/14/22 09:29:54.886
    Dec 14 09:29:54.888: INFO: Waiting up to 2m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102" to be "running"
    Dec 14 09:29:54.913: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Pending", Reason="", readiness=false. Elapsed: 25.346482ms
    Dec 14 09:29:56.940: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35": Phase="Running", Reason="", readiness=true. Elapsed: 2.052302122s
    Dec 14 09:29:56.940: INFO: Pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 09:29:56.94
    Dec 14 09:29:56.940: INFO: Deleting pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" in namespace "var-expansion-9102"
    Dec 14 09:29:56.967: INFO: Wait up to 5m0s for pod "var-expansion-4c04d3cf-a5a0-4432-955f-de2d21884d35" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:30:29.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9102" for this suite. 12/14/22 09:30:29.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:29.095
Dec 14 09:30:29.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:30:29.096
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:29.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:29.222
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 09:30:29.269
Dec 14 09:30:29.324: INFO: Waiting up to 5m0s for pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289" in namespace "emptydir-7077" to be "Succeeded or Failed"
Dec 14 09:30:29.354: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Pending", Reason="", readiness=false. Elapsed: 29.512129ms
Dec 14 09:30:31.380: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055762236s
Dec 14 09:30:33.381: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056127924s
STEP: Saw pod success 12/14/22 09:30:33.381
Dec 14 09:30:33.381: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289" satisfied condition "Succeeded or Failed"
Dec 14 09:30:33.407: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 container test-container: <nil>
STEP: delete the pod 12/14/22 09:30:33.439
Dec 14 09:30:33.475: INFO: Waiting for pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 to disappear
Dec 14 09:30:33.504: INFO: Pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:30:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7077" for this suite. 12/14/22 09:30:33.552
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":246,"skipped":4557,"failed":0}
------------------------------
• [4.483 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:29.095
    Dec 14 09:30:29.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:30:29.096
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:29.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:29.222
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 09:30:29.269
    Dec 14 09:30:29.324: INFO: Waiting up to 5m0s for pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289" in namespace "emptydir-7077" to be "Succeeded or Failed"
    Dec 14 09:30:29.354: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Pending", Reason="", readiness=false. Elapsed: 29.512129ms
    Dec 14 09:30:31.380: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055762236s
    Dec 14 09:30:33.381: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056127924s
    STEP: Saw pod success 12/14/22 09:30:33.381
    Dec 14 09:30:33.381: INFO: Pod "pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289" satisfied condition "Succeeded or Failed"
    Dec 14 09:30:33.407: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:30:33.439
    Dec 14 09:30:33.475: INFO: Waiting for pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 to disappear
    Dec 14 09:30:33.504: INFO: Pod pod-4d2ca68e-396c-4e2f-b5f4-1a241ddbc289 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:30:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7077" for this suite. 12/14/22 09:30:33.552
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:33.578
Dec 14 09:30:33.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:30:33.579
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:33.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:33.707
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3638 12/14/22 09:30:33.757
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-3638 12/14/22 09:30:33.808
Dec 14 09:30:33.859: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:30:43.885: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 12/14/22 09:30:43.937
STEP: Getting /status 12/14/22 09:30:43.967
Dec 14 09:30:43.993: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 12/14/22 09:30:43.993
Dec 14 09:30:44.060: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 12/14/22 09:30:44.06
Dec 14 09:30:44.084: INFO: Observed &StatefulSet event: ADDED
Dec 14 09:30:44.084: INFO: Found Statefulset ss in namespace statefulset-3638 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:30:44.084: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 12/14/22 09:30:44.084
Dec 14 09:30:44.084: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 09:30:44.113: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 12/14/22 09:30:44.113
Dec 14 09:30:44.136: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:30:44.137: INFO: Deleting all statefulset in ns statefulset-3638
Dec 14 09:30:44.164: INFO: Scaling statefulset ss to 0
Dec 14 09:30:54.275: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:30:54.300: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:30:54.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3638" for this suite. 12/14/22 09:30:54.431
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":247,"skipped":4557,"failed":0}
------------------------------
• [20.879 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:33.578
    Dec 14 09:30:33.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:30:33.579
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:33.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:33.707
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3638 12/14/22 09:30:33.757
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-3638 12/14/22 09:30:33.808
    Dec 14 09:30:33.859: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:30:43.885: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 12/14/22 09:30:43.937
    STEP: Getting /status 12/14/22 09:30:43.967
    Dec 14 09:30:43.993: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 12/14/22 09:30:43.993
    Dec 14 09:30:44.060: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 12/14/22 09:30:44.06
    Dec 14 09:30:44.084: INFO: Observed &StatefulSet event: ADDED
    Dec 14 09:30:44.084: INFO: Found Statefulset ss in namespace statefulset-3638 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:30:44.084: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 12/14/22 09:30:44.084
    Dec 14 09:30:44.084: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 09:30:44.113: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 12/14/22 09:30:44.113
    Dec 14 09:30:44.136: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:30:44.137: INFO: Deleting all statefulset in ns statefulset-3638
    Dec 14 09:30:44.164: INFO: Scaling statefulset ss to 0
    Dec 14 09:30:54.275: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:30:54.300: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:30:54.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3638" for this suite. 12/14/22 09:30:54.431
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:54.46
Dec 14 09:30:54.460: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:54.461
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:54.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:54.582
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Dec 14 09:30:54.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:30:59.154
Dec 14 09:30:59.154: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 create -f -'
Dec 14 09:31:00.113: INFO: stderr: ""
Dec 14 09:31:00.113: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 14 09:31:00.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 delete e2e-test-crd-publish-openapi-7120-crds test-cr'
Dec 14 09:31:00.294: INFO: stderr: ""
Dec 14 09:31:00.294: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 14 09:31:00.294: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 apply -f -'
Dec 14 09:31:01.004: INFO: stderr: ""
Dec 14 09:31:01.004: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 14 09:31:01.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 delete e2e-test-crd-publish-openapi-7120-crds test-cr'
Dec 14 09:31:01.182: INFO: stderr: ""
Dec 14 09:31:01.183: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 12/14/22 09:31:01.183
Dec 14 09:31:01.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 explain e2e-test-crd-publish-openapi-7120-crds'
Dec 14 09:31:01.469: INFO: stderr: ""
Dec 14 09:31:01.469: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7120-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:31:05.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9772" for this suite. 12/14/22 09:31:06.022
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":248,"skipped":4627,"failed":0}
------------------------------
• [11.589 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:54.46
    Dec 14 09:30:54.460: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:54.461
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:54.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:54.582
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Dec 14 09:30:54.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:30:59.154
    Dec 14 09:30:59.154: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 create -f -'
    Dec 14 09:31:00.113: INFO: stderr: ""
    Dec 14 09:31:00.113: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec 14 09:31:00.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 delete e2e-test-crd-publish-openapi-7120-crds test-cr'
    Dec 14 09:31:00.294: INFO: stderr: ""
    Dec 14 09:31:00.294: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Dec 14 09:31:00.294: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 apply -f -'
    Dec 14 09:31:01.004: INFO: stderr: ""
    Dec 14 09:31:01.004: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec 14 09:31:01.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 --namespace=crd-publish-openapi-9772 delete e2e-test-crd-publish-openapi-7120-crds test-cr'
    Dec 14 09:31:01.182: INFO: stderr: ""
    Dec 14 09:31:01.183: INFO: stdout: "e2e-test-crd-publish-openapi-7120-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 12/14/22 09:31:01.183
    Dec 14 09:31:01.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9772 explain e2e-test-crd-publish-openapi-7120-crds'
    Dec 14 09:31:01.469: INFO: stderr: ""
    Dec 14 09:31:01.469: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7120-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:31:05.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9772" for this suite. 12/14/22 09:31:06.022
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:06.051
Dec 14 09:31:06.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:31:06.052
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.181
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-142 12/14/22 09:31:06.23
STEP: changing the ExternalName service to type=ClusterIP 12/14/22 09:31:06.256
STEP: creating replication controller externalname-service in namespace services-142 12/14/22 09:31:06.317
I1214 09:31:06.343853    6274 runners.go:193] Created replication controller with name: externalname-service, namespace: services-142, replica count: 2
I1214 09:31:09.394737    6274 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:31:09.394: INFO: Creating new exec pod
Dec 14 09:31:09.424: INFO: Waiting up to 5m0s for pod "execpod65hjv" in namespace "services-142" to be "running"
Dec 14 09:31:09.450: INFO: Pod "execpod65hjv": Phase="Pending", Reason="", readiness=false. Elapsed: 25.683341ms
Dec 14 09:31:11.477: INFO: Pod "execpod65hjv": Phase="Running", Reason="", readiness=true. Elapsed: 2.05312892s
Dec 14 09:31:11.477: INFO: Pod "execpod65hjv" satisfied condition "running"
Dec 14 09:31:12.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:31:13.129: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:13.130: INFO: stdout: "externalname-service-nk8kp"
Dec 14 09:31:13.130: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
Dec 14 09:31:13.706: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.108.114.17 80\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:13.706: INFO: stdout: ""
Dec 14 09:31:14.706: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
Dec 14 09:31:15.332: INFO: stderr: "+ nc -v -t -w 2 100.108.114.17 80\n+ echo hostName\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:15.332: INFO: stdout: ""
Dec 14 09:31:15.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
Dec 14 09:31:16.378: INFO: stderr: "+ nc -v -t -w 2 100.108.114.17 80\n+ echo hostName\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:16.378: INFO: stdout: "externalname-service-nk8kp"
Dec 14 09:31:16.378: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:31:16.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-142" for this suite. 12/14/22 09:31:16.466
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":249,"skipped":4662,"failed":0}
------------------------------
• [10.442 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:06.051
    Dec 14 09:31:06.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:31:06.052
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.181
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-142 12/14/22 09:31:06.23
    STEP: changing the ExternalName service to type=ClusterIP 12/14/22 09:31:06.256
    STEP: creating replication controller externalname-service in namespace services-142 12/14/22 09:31:06.317
    I1214 09:31:06.343853    6274 runners.go:193] Created replication controller with name: externalname-service, namespace: services-142, replica count: 2
    I1214 09:31:09.394737    6274 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:31:09.394: INFO: Creating new exec pod
    Dec 14 09:31:09.424: INFO: Waiting up to 5m0s for pod "execpod65hjv" in namespace "services-142" to be "running"
    Dec 14 09:31:09.450: INFO: Pod "execpod65hjv": Phase="Pending", Reason="", readiness=false. Elapsed: 25.683341ms
    Dec 14 09:31:11.477: INFO: Pod "execpod65hjv": Phase="Running", Reason="", readiness=true. Elapsed: 2.05312892s
    Dec 14 09:31:11.477: INFO: Pod "execpod65hjv" satisfied condition "running"
    Dec 14 09:31:12.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:31:13.129: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:13.130: INFO: stdout: "externalname-service-nk8kp"
    Dec 14 09:31:13.130: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
    Dec 14 09:31:13.706: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.108.114.17 80\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:13.706: INFO: stdout: ""
    Dec 14 09:31:14.706: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
    Dec 14 09:31:15.332: INFO: stderr: "+ nc -v -t -w 2 100.108.114.17 80\n+ echo hostName\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:15.332: INFO: stdout: ""
    Dec 14 09:31:15.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-142 exec execpod65hjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.108.114.17 80'
    Dec 14 09:31:16.378: INFO: stderr: "+ nc -v -t -w 2 100.108.114.17 80\n+ echo hostName\nConnection to 100.108.114.17 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:16.378: INFO: stdout: "externalname-service-nk8kp"
    Dec 14 09:31:16.378: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:31:16.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-142" for this suite. 12/14/22 09:31:16.466
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:16.494
Dec 14 09:31:16.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 09:31:16.494
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:16.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:16.62
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 12/14/22 09:31:16.669
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:16.746
STEP: Creating a pod in the namespace 12/14/22 09:31:16.795
STEP: Waiting for the pod to have running status 12/14/22 09:31:16.827
Dec 14 09:31:16.828: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7908" to be "running"
Dec 14 09:31:16.853: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.112297ms
Dec 14 09:31:18.879: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05165872s
Dec 14 09:31:18.879: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 12/14/22 09:31:18.879
STEP: Waiting for the namespace to be removed. 12/14/22 09:31:18.91
STEP: Recreating the namespace 12/14/22 09:31:29.937
STEP: Verifying there are no pods in the namespace 12/14/22 09:31:30.02
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:31:30.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4171" for this suite. 12/14/22 09:31:30.102
STEP: Destroying namespace "nsdeletetest-7908" for this suite. 12/14/22 09:31:30.138
Dec 14 09:31:30.165: INFO: Namespace nsdeletetest-7908 was already deleted
STEP: Destroying namespace "nsdeletetest-2759" for this suite. 12/14/22 09:31:30.165
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":250,"skipped":4673,"failed":0}
------------------------------
• [13.699 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:16.494
    Dec 14 09:31:16.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 09:31:16.494
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:16.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:16.62
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 12/14/22 09:31:16.669
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:16.746
    STEP: Creating a pod in the namespace 12/14/22 09:31:16.795
    STEP: Waiting for the pod to have running status 12/14/22 09:31:16.827
    Dec 14 09:31:16.828: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7908" to be "running"
    Dec 14 09:31:16.853: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 25.112297ms
    Dec 14 09:31:18.879: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05165872s
    Dec 14 09:31:18.879: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 12/14/22 09:31:18.879
    STEP: Waiting for the namespace to be removed. 12/14/22 09:31:18.91
    STEP: Recreating the namespace 12/14/22 09:31:29.937
    STEP: Verifying there are no pods in the namespace 12/14/22 09:31:30.02
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:31:30.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4171" for this suite. 12/14/22 09:31:30.102
    STEP: Destroying namespace "nsdeletetest-7908" for this suite. 12/14/22 09:31:30.138
    Dec 14 09:31:30.165: INFO: Namespace nsdeletetest-7908 was already deleted
    STEP: Destroying namespace "nsdeletetest-2759" for this suite. 12/14/22 09:31:30.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:30.195
Dec 14 09:31:30.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:31:30.195
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:30.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:30.323
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 12/14/22 09:31:30.407
STEP: Waiting for all pods to be running 12/14/22 09:31:30.529
Dec 14 09:31:30.555: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:31:32.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3604" for this suite. 12/14/22 09:31:32.658
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":251,"skipped":4743,"failed":0}
------------------------------
• [2.491 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:30.195
    Dec 14 09:31:30.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:31:30.195
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:30.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:30.323
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 12/14/22 09:31:30.407
    STEP: Waiting for all pods to be running 12/14/22 09:31:30.529
    Dec 14 09:31:30.555: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:31:32.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3604" for this suite. 12/14/22 09:31:32.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:32.687
Dec 14 09:31:32.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:31:32.688
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:32.766
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:32.815
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Dec 14 09:31:32.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod 12/14/22 09:31:32.865
STEP: submitting the pod to kubernetes 12/14/22 09:31:32.865
Dec 14 09:31:32.897: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd" in namespace "pods-2886" to be "running and ready"
Dec 14 09:31:32.923: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd": Phase="Pending", Reason="", readiness=false. Elapsed: 26.123956ms
Dec 14 09:31:32.923: INFO: The phase of Pod pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:31:34.950: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.053150409s
Dec 14 09:31:34.950: INFO: The phase of Pod pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd is Running (Ready = true)
Dec 14 09:31:34.950: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:31:35.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2886" for this suite. 12/14/22 09:31:35.307
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":252,"skipped":4756,"failed":0}
------------------------------
• [2.647 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:32.687
    Dec 14 09:31:32.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:31:32.688
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:32.766
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:32.815
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Dec 14 09:31:32.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating the pod 12/14/22 09:31:32.865
    STEP: submitting the pod to kubernetes 12/14/22 09:31:32.865
    Dec 14 09:31:32.897: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd" in namespace "pods-2886" to be "running and ready"
    Dec 14 09:31:32.923: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd": Phase="Pending", Reason="", readiness=false. Elapsed: 26.123956ms
    Dec 14 09:31:32.923: INFO: The phase of Pod pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:31:34.950: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.053150409s
    Dec 14 09:31:34.950: INFO: The phase of Pod pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd is Running (Ready = true)
    Dec 14 09:31:34.950: INFO: Pod "pod-exec-websocket-77c19516-e139-4790-ab73-d60480b8a4bd" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:31:35.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2886" for this suite. 12/14/22 09:31:35.307
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:35.335
Dec 14 09:31:35.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:31:35.336
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:35.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:35.465
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-5392f42a-336d-404a-9dd5-a87f014cd671 12/14/22 09:31:35.514
STEP: Creating a pod to test consume configMaps 12/14/22 09:31:35.542
Dec 14 09:31:35.575: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a" in namespace "configmap-2676" to be "Succeeded or Failed"
Dec 14 09:31:35.612: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Pending", Reason="", readiness=false. Elapsed: 37.494768ms
Dec 14 09:31:37.642: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067404245s
Dec 14 09:31:39.639: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064292617s
STEP: Saw pod success 12/14/22 09:31:39.639
Dec 14 09:31:39.639: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a" satisfied condition "Succeeded or Failed"
Dec 14 09:31:39.665: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:31:39.742
Dec 14 09:31:39.780: INFO: Waiting for pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a to disappear
Dec 14 09:31:39.806: INFO: Pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:31:39.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2676" for this suite. 12/14/22 09:31:39.856
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":253,"skipped":4800,"failed":0}
------------------------------
• [4.548 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:35.335
    Dec 14 09:31:35.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:31:35.336
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:35.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:35.465
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-5392f42a-336d-404a-9dd5-a87f014cd671 12/14/22 09:31:35.514
    STEP: Creating a pod to test consume configMaps 12/14/22 09:31:35.542
    Dec 14 09:31:35.575: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a" in namespace "configmap-2676" to be "Succeeded or Failed"
    Dec 14 09:31:35.612: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Pending", Reason="", readiness=false. Elapsed: 37.494768ms
    Dec 14 09:31:37.642: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067404245s
    Dec 14 09:31:39.639: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064292617s
    STEP: Saw pod success 12/14/22 09:31:39.639
    Dec 14 09:31:39.639: INFO: Pod "pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a" satisfied condition "Succeeded or Failed"
    Dec 14 09:31:39.665: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:31:39.742
    Dec 14 09:31:39.780: INFO: Waiting for pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a to disappear
    Dec 14 09:31:39.806: INFO: Pod pod-configmaps-6c13c7f9-30ab-48ad-8a5e-bbef080fc18a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:31:39.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2676" for this suite. 12/14/22 09:31:39.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:39.883
Dec 14 09:31:39.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 09:31:39.884
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:39.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:40.018
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 12/14/22 09:31:40.067
STEP: getting /apis/discovery.k8s.io 12/14/22 09:31:40.115
STEP: getting /apis/discovery.k8s.iov1 12/14/22 09:31:40.139
STEP: creating 12/14/22 09:31:40.163
STEP: getting 12/14/22 09:31:40.243
STEP: listing 12/14/22 09:31:40.27
STEP: watching 12/14/22 09:31:40.295
Dec 14 09:31:40.295: INFO: starting watch
STEP: cluster-wide listing 12/14/22 09:31:40.32
STEP: cluster-wide watching 12/14/22 09:31:40.347
Dec 14 09:31:40.347: INFO: starting watch
STEP: patching 12/14/22 09:31:40.38
STEP: updating 12/14/22 09:31:40.407
Dec 14 09:31:40.458: INFO: waiting for watch events with expected annotations
Dec 14 09:31:40.458: INFO: saw patched and updated annotations
STEP: deleting 12/14/22 09:31:40.458
STEP: deleting a collection 12/14/22 09:31:40.537
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 09:31:40.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2923" for this suite. 12/14/22 09:31:40.623
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":254,"skipped":4807,"failed":0}
------------------------------
• [0.766 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:39.883
    Dec 14 09:31:39.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 09:31:39.884
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:39.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:40.018
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 12/14/22 09:31:40.067
    STEP: getting /apis/discovery.k8s.io 12/14/22 09:31:40.115
    STEP: getting /apis/discovery.k8s.iov1 12/14/22 09:31:40.139
    STEP: creating 12/14/22 09:31:40.163
    STEP: getting 12/14/22 09:31:40.243
    STEP: listing 12/14/22 09:31:40.27
    STEP: watching 12/14/22 09:31:40.295
    Dec 14 09:31:40.295: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 09:31:40.32
    STEP: cluster-wide watching 12/14/22 09:31:40.347
    Dec 14 09:31:40.347: INFO: starting watch
    STEP: patching 12/14/22 09:31:40.38
    STEP: updating 12/14/22 09:31:40.407
    Dec 14 09:31:40.458: INFO: waiting for watch events with expected annotations
    Dec 14 09:31:40.458: INFO: saw patched and updated annotations
    STEP: deleting 12/14/22 09:31:40.458
    STEP: deleting a collection 12/14/22 09:31:40.537
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 09:31:40.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2923" for this suite. 12/14/22 09:31:40.623
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:40.65
Dec 14 09:31:40.650: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables 12/14/22 09:31:40.651
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:40.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:40.782
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Dec 14 09:31:40.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4440" for this suite. 12/14/22 09:31:40.909
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":255,"skipped":4808,"failed":0}
------------------------------
• [0.286 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:40.65
    Dec 14 09:31:40.650: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename tables 12/14/22 09:31:40.651
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:40.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:40.782
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Dec 14 09:31:40.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-4440" for this suite. 12/14/22 09:31:40.909
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:40.937
Dec 14 09:31:40.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:31:40.938
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:41.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:41.079
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 12/14/22 09:31:41.235
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:31:41.264
Dec 14 09:31:41.327: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:31:41.327: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 09:31:42.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:31:42.407: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 09:31:43.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:31:43.404: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/14/22 09:31:43.43
Dec 14 09:31:43.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:31:43.539: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 09:31:44.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:31:44.656: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 12/14/22 09:31:44.656
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:31:44.709
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-371, will wait for the garbage collector to delete the pods 12/14/22 09:31:44.709
Dec 14 09:31:44.812: INFO: Deleting DaemonSet.extensions daemon-set took: 27.465732ms
Dec 14 09:31:44.913: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.458225ms
Dec 14 09:31:47.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:31:47.739: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:31:47.765: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"45314"},"items":null}

Dec 14 09:31:47.791: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"45314"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:31:47.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-371" for this suite. 12/14/22 09:31:47.92
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":256,"skipped":4819,"failed":0}
------------------------------
• [7.010 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:40.937
    Dec 14 09:31:40.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:31:40.938
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:41.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:41.079
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 12/14/22 09:31:41.235
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:31:41.264
    Dec 14 09:31:41.327: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:31:41.327: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 09:31:42.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:31:42.407: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 09:31:43.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:31:43.404: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/14/22 09:31:43.43
    Dec 14 09:31:43.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:31:43.539: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 09:31:44.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:31:44.656: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 12/14/22 09:31:44.656
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:31:44.709
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-371, will wait for the garbage collector to delete the pods 12/14/22 09:31:44.709
    Dec 14 09:31:44.812: INFO: Deleting DaemonSet.extensions daemon-set took: 27.465732ms
    Dec 14 09:31:44.913: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.458225ms
    Dec 14 09:31:47.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:31:47.739: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:31:47.765: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"45314"},"items":null}

    Dec 14 09:31:47.791: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"45314"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:31:47.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-371" for this suite. 12/14/22 09:31:47.92
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:47.948
Dec 14 09:31:47.948: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 09:31:47.948
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:48.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:48.08
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Dec 14 09:31:48.160: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165" in namespace "security-context-test-9531" to be "Succeeded or Failed"
Dec 14 09:31:48.198: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Pending", Reason="", readiness=false. Elapsed: 37.703271ms
Dec 14 09:31:50.226: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065227966s
Dec 14 09:31:52.226: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Running", Reason="", readiness=false. Elapsed: 4.065531179s
Dec 14 09:31:54.225: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064701768s
Dec 14 09:31:54.225: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 09:31:54.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9531" for this suite. 12/14/22 09:31:54.312
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":257,"skipped":4822,"failed":0}
------------------------------
• [6.391 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:47.948
    Dec 14 09:31:47.948: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 09:31:47.948
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:48.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:48.08
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Dec 14 09:31:48.160: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165" in namespace "security-context-test-9531" to be "Succeeded or Failed"
    Dec 14 09:31:48.198: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Pending", Reason="", readiness=false. Elapsed: 37.703271ms
    Dec 14 09:31:50.226: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065227966s
    Dec 14 09:31:52.226: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Running", Reason="", readiness=false. Elapsed: 4.065531179s
    Dec 14 09:31:54.225: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064701768s
    Dec 14 09:31:54.225: INFO: Pod "alpine-nnp-false-b9e35773-bfe0-464b-b8db-ba0ea6179165" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 09:31:54.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9531" for this suite. 12/14/22 09:31:54.312
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:54.339
Dec 14 09:31:54.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:31:54.34
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:54.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:54.469
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Dec 14 09:31:54.518: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:31:59.228
Dec 14 09:31:59.228: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 create -f -'
Dec 14 09:32:00.119: INFO: stderr: ""
Dec 14 09:32:00.119: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 14 09:32:00.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 delete e2e-test-crd-publish-openapi-9359-crds test-cr'
Dec 14 09:32:00.313: INFO: stderr: ""
Dec 14 09:32:00.314: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 14 09:32:00.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 apply -f -'
Dec 14 09:32:00.716: INFO: stderr: ""
Dec 14 09:32:00.716: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 14 09:32:00.716: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 delete e2e-test-crd-publish-openapi-9359-crds test-cr'
Dec 14 09:32:00.909: INFO: stderr: ""
Dec 14 09:32:00.909: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/14/22 09:32:00.909
Dec 14 09:32:00.909: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 explain e2e-test-crd-publish-openapi-9359-crds'
Dec 14 09:32:01.683: INFO: stderr: ""
Dec 14 09:32:01.683: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9359-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:32:06.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-768" for this suite. 12/14/22 09:32:06.392
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":258,"skipped":4823,"failed":0}
------------------------------
• [12.082 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:54.339
    Dec 14 09:31:54.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:31:54.34
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:54.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:54.469
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Dec 14 09:31:54.518: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:31:59.228
    Dec 14 09:31:59.228: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 create -f -'
    Dec 14 09:32:00.119: INFO: stderr: ""
    Dec 14 09:32:00.119: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec 14 09:32:00.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 delete e2e-test-crd-publish-openapi-9359-crds test-cr'
    Dec 14 09:32:00.313: INFO: stderr: ""
    Dec 14 09:32:00.314: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Dec 14 09:32:00.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 apply -f -'
    Dec 14 09:32:00.716: INFO: stderr: ""
    Dec 14 09:32:00.716: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec 14 09:32:00.716: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 --namespace=crd-publish-openapi-768 delete e2e-test-crd-publish-openapi-9359-crds test-cr'
    Dec 14 09:32:00.909: INFO: stderr: ""
    Dec 14 09:32:00.909: INFO: stdout: "e2e-test-crd-publish-openapi-9359-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/14/22 09:32:00.909
    Dec 14 09:32:00.909: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-768 explain e2e-test-crd-publish-openapi-9359-crds'
    Dec 14 09:32:01.683: INFO: stderr: ""
    Dec 14 09:32:01.683: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9359-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:32:06.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-768" for this suite. 12/14/22 09:32:06.392
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:06.421
Dec 14 09:32:06.421: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:32:06.422
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:06.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:06.544
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 12/14/22 09:32:06.591
Dec 14 09:32:06.623: INFO: Waiting up to 5m0s for pod "pod-tl56n" in namespace "pods-1486" to be "running"
Dec 14 09:32:06.650: INFO: Pod "pod-tl56n": Phase="Pending", Reason="", readiness=false. Elapsed: 27.794771ms
Dec 14 09:32:08.675: INFO: Pod "pod-tl56n": Phase="Running", Reason="", readiness=true. Elapsed: 2.05264946s
Dec 14 09:32:08.675: INFO: Pod "pod-tl56n" satisfied condition "running"
STEP: patching /status 12/14/22 09:32:08.675
Dec 14 09:32:08.705: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:32:08.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1486" for this suite. 12/14/22 09:32:08.752
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":259,"skipped":4826,"failed":0}
------------------------------
• [2.357 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:06.421
    Dec 14 09:32:06.421: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:32:06.422
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:06.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:06.544
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 12/14/22 09:32:06.591
    Dec 14 09:32:06.623: INFO: Waiting up to 5m0s for pod "pod-tl56n" in namespace "pods-1486" to be "running"
    Dec 14 09:32:06.650: INFO: Pod "pod-tl56n": Phase="Pending", Reason="", readiness=false. Elapsed: 27.794771ms
    Dec 14 09:32:08.675: INFO: Pod "pod-tl56n": Phase="Running", Reason="", readiness=true. Elapsed: 2.05264946s
    Dec 14 09:32:08.675: INFO: Pod "pod-tl56n" satisfied condition "running"
    STEP: patching /status 12/14/22 09:32:08.675
    Dec 14 09:32:08.705: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:32:08.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1486" for this suite. 12/14/22 09:32:08.752
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:08.779
Dec 14 09:32:08.779: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:32:08.78
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:08.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:08.913
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 12/14/22 09:32:08.96
STEP: Ensure pods equal to paralellism count is attached to the job 12/14/22 09:32:08.988
STEP: patching /status 12/14/22 09:32:11.014
STEP: updating /status 12/14/22 09:32:11.041
STEP: get /status 12/14/22 09:32:11.093
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:32:11.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6962" for this suite. 12/14/22 09:32:11.165
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":260,"skipped":4830,"failed":0}
------------------------------
• [2.412 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:08.779
    Dec 14 09:32:08.779: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:32:08.78
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:08.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:08.913
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 12/14/22 09:32:08.96
    STEP: Ensure pods equal to paralellism count is attached to the job 12/14/22 09:32:08.988
    STEP: patching /status 12/14/22 09:32:11.014
    STEP: updating /status 12/14/22 09:32:11.041
    STEP: get /status 12/14/22 09:32:11.093
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:32:11.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6962" for this suite. 12/14/22 09:32:11.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:11.191
Dec 14 09:32:11.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:32:11.192
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:11.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:11.317
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Dec 14 09:32:11.417: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 09:32:11.417
Dec 14 09:32:11.417: INFO: Waiting up to 5m0s for pod "test-rollover-controller-x4t7l" in namespace "deployment-347" to be "running"
Dec 14 09:32:11.441: INFO: Pod "test-rollover-controller-x4t7l": Phase="Pending", Reason="", readiness=false. Elapsed: 24.416369ms
Dec 14 09:32:13.468: INFO: Pod "test-rollover-controller-x4t7l": Phase="Running", Reason="", readiness=true. Elapsed: 2.050991501s
Dec 14 09:32:13.468: INFO: Pod "test-rollover-controller-x4t7l" satisfied condition "running"
Dec 14 09:32:13.468: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 14 09:32:15.493: INFO: Creating deployment "test-rollover-deployment"
Dec 14 09:32:15.552: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 14 09:32:15.576: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 14 09:32:15.626: INFO: Ensure that both replica sets have 1 created replica
Dec 14 09:32:15.675: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 14 09:32:15.725: INFO: Updating deployment test-rollover-deployment
Dec 14 09:32:15.725: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 14 09:32:17.777: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 14 09:32:17.827: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 14 09:32:17.877: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 09:32:17.877: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:32:19.928: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 09:32:19.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:32:21.929: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 09:32:21.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:32:23.930: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 09:32:23.930: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:32:25.931: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 09:32:25.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:32:27.931: INFO: 
Dec 14 09:32:27.931: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:32:28.005: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-347  ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 45724 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ac3938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 09:32:15 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-14 09:32:26 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 09:32:28.030: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-347  66a443c2-cc3e-4819-8d79-f17017dadf34 45717 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004aec1a7 0xc004aec1a8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aec2a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:32:28.030: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 14 09:32:28.030: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-347  f711edd4-611f-4b26-b644-d6fc8ef1796c 45723 2 2022-12-14 09:32:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004ac3e77 0xc004ac3e78}] [] [{e2e.test Update apps/v1 2022-12-14 09:32:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004ac3f98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:32:28.031: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-347  5b550ede-d1dc-4760-9806-8cfda71c61d8 45629 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004aec037 0xc004aec038}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aec128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:32:28.056: INFO: Pod "test-rollover-deployment-6d45fd857b-r4vd2" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-r4vd2 test-rollover-deployment-6d45fd857b- deployment-347  a92c2a5d-eb75-4623-b047-6db9475064f9 45654 0 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:1929ab1bf62dd08415228f128bf5dd8cb50f656e97c36173e8a2f48b7beb8c58 cni.projectcalico.org/podIP:100.64.0.190/32 cni.projectcalico.org/podIPs:100.64.0.190/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 66a443c2-cc3e-4819-8d79-f17017dadf34 0xc004aec927 0xc004aec928}] [] [{kube-controller-manager Update v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66a443c2-cc3e-4819-8d79-f17017dadf34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:32:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.190\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t25vn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t25vn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.190,StartTime:2022-12-14 09:32:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:32:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3f0fdecccf3e201910ceea43d31b66262208cf0e9b1dd6cfab2484dd615613b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:32:28.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-347" for this suite. 12/14/22 09:32:28.103
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":261,"skipped":4835,"failed":0}
------------------------------
• [16.938 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:11.191
    Dec 14 09:32:11.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:32:11.192
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:11.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:11.317
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Dec 14 09:32:11.417: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 09:32:11.417
    Dec 14 09:32:11.417: INFO: Waiting up to 5m0s for pod "test-rollover-controller-x4t7l" in namespace "deployment-347" to be "running"
    Dec 14 09:32:11.441: INFO: Pod "test-rollover-controller-x4t7l": Phase="Pending", Reason="", readiness=false. Elapsed: 24.416369ms
    Dec 14 09:32:13.468: INFO: Pod "test-rollover-controller-x4t7l": Phase="Running", Reason="", readiness=true. Elapsed: 2.050991501s
    Dec 14 09:32:13.468: INFO: Pod "test-rollover-controller-x4t7l" satisfied condition "running"
    Dec 14 09:32:13.468: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Dec 14 09:32:15.493: INFO: Creating deployment "test-rollover-deployment"
    Dec 14 09:32:15.552: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Dec 14 09:32:15.576: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Dec 14 09:32:15.626: INFO: Ensure that both replica sets have 1 created replica
    Dec 14 09:32:15.675: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Dec 14 09:32:15.725: INFO: Updating deployment test-rollover-deployment
    Dec 14 09:32:15.725: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Dec 14 09:32:17.777: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Dec 14 09:32:17.827: INFO: Make sure deployment "test-rollover-deployment" is complete
    Dec 14 09:32:17.877: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 09:32:17.877: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:32:19.928: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 09:32:19.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:32:21.929: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 09:32:21.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:32:23.930: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 09:32:23.930: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:32:25.931: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 09:32:25.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 32, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:32:27.931: INFO: 
    Dec 14 09:32:27.931: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:32:28.005: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-347  ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 45724 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ac3938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 09:32:15 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-14 09:32:26 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 09:32:28.030: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-347  66a443c2-cc3e-4819-8d79-f17017dadf34 45717 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004aec1a7 0xc004aec1a8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aec2a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:32:28.030: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Dec 14 09:32:28.030: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-347  f711edd4-611f-4b26-b644-d6fc8ef1796c 45723 2 2022-12-14 09:32:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004ac3e77 0xc004ac3e78}] [] [{e2e.test Update apps/v1 2022-12-14 09:32:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:26 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004ac3f98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:32:28.031: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-347  5b550ede-d1dc-4760-9806-8cfda71c61d8 45629 2 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4 0xc004aec037 0xc004aec038}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec3e3416-cf9d-44bf-ab9a-619f3ebbb3e4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aec128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:32:28.056: INFO: Pod "test-rollover-deployment-6d45fd857b-r4vd2" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-r4vd2 test-rollover-deployment-6d45fd857b- deployment-347  a92c2a5d-eb75-4623-b047-6db9475064f9 45654 0 2022-12-14 09:32:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:1929ab1bf62dd08415228f128bf5dd8cb50f656e97c36173e8a2f48b7beb8c58 cni.projectcalico.org/podIP:100.64.0.190/32 cni.projectcalico.org/podIPs:100.64.0.190/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 66a443c2-cc3e-4819-8d79-f17017dadf34 0xc004aec927 0xc004aec928}] [] [{kube-controller-manager Update v1 2022-12-14 09:32:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66a443c2-cc3e-4819-8d79-f17017dadf34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:32:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.190\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t25vn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t25vn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:32:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.190,StartTime:2022-12-14 09:32:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:32:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3f0fdecccf3e201910ceea43d31b66262208cf0e9b1dd6cfab2484dd615613b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:32:28.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-347" for this suite. 12/14/22 09:32:28.103
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:28.129
Dec 14 09:32:28.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:32:28.131
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:28.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:28.25
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 12/14/22 09:32:28.297
STEP: When the matched label of one of its pods change 12/14/22 09:32:28.323
Dec 14 09:32:28.348: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 12/14/22 09:32:28.399
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:32:28.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7249" for this suite. 12/14/22 09:32:28.453
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":262,"skipped":4842,"failed":0}
------------------------------
• [0.350 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:28.129
    Dec 14 09:32:28.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:32:28.131
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:28.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:28.25
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 12/14/22 09:32:28.297
    STEP: When the matched label of one of its pods change 12/14/22 09:32:28.323
    Dec 14 09:32:28.348: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/14/22 09:32:28.399
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:32:28.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7249" for this suite. 12/14/22 09:32:28.453
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:28.479
Dec 14 09:32:28.479: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:32:28.48
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:28.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:28.6
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-4fe6682b-a849-41bd-9756-66ee175ab5e4 12/14/22 09:32:28.645
STEP: Creating a pod to test consume configMaps 12/14/22 09:32:28.671
Dec 14 09:32:28.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740" in namespace "projected-9311" to be "Succeeded or Failed"
Dec 14 09:32:28.730: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Pending", Reason="", readiness=false. Elapsed: 26.961097ms
Dec 14 09:32:30.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053076235s
Dec 14 09:32:32.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053143797s
STEP: Saw pod success 12/14/22 09:32:32.756
Dec 14 09:32:32.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740" satisfied condition "Succeeded or Failed"
Dec 14 09:32:32.780: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:32:32.813
Dec 14 09:32:32.846: INFO: Waiting for pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 to disappear
Dec 14 09:32:32.870: INFO: Pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:32:32.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9311" for this suite. 12/14/22 09:32:32.917
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":263,"skipped":4845,"failed":0}
------------------------------
• [4.464 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:28.479
    Dec 14 09:32:28.479: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:32:28.48
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:28.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:28.6
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-4fe6682b-a849-41bd-9756-66ee175ab5e4 12/14/22 09:32:28.645
    STEP: Creating a pod to test consume configMaps 12/14/22 09:32:28.671
    Dec 14 09:32:28.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740" in namespace "projected-9311" to be "Succeeded or Failed"
    Dec 14 09:32:28.730: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Pending", Reason="", readiness=false. Elapsed: 26.961097ms
    Dec 14 09:32:30.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053076235s
    Dec 14 09:32:32.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053143797s
    STEP: Saw pod success 12/14/22 09:32:32.756
    Dec 14 09:32:32.756: INFO: Pod "pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740" satisfied condition "Succeeded or Failed"
    Dec 14 09:32:32.780: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:32:32.813
    Dec 14 09:32:32.846: INFO: Waiting for pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 to disappear
    Dec 14 09:32:32.870: INFO: Pod pod-projected-configmaps-e6c9b608-89c1-4a29-949b-b36bf9bc5740 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:32:32.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9311" for this suite. 12/14/22 09:32:32.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:32.945
Dec 14 09:32:32.945: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:32:32.946
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:33.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:33.068
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Dec 14 09:32:33.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:32:35.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6761" for this suite. 12/14/22 09:32:36.028
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":264,"skipped":4884,"failed":0}
------------------------------
• [3.109 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:32.945
    Dec 14 09:32:32.945: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:32:32.946
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:33.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:33.068
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Dec 14 09:32:33.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:32:35.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6761" for this suite. 12/14/22 09:32:36.028
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:36.057
Dec 14 09:32:36.057: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:32:36.058
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:36.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:36.181
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 12/14/22 09:32:36.227
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:32:36.252
STEP: Creating a ResourceQuota with not best effort scope 12/14/22 09:32:38.278
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:32:38.304
STEP: Creating a best-effort pod 12/14/22 09:32:40.329
STEP: Ensuring resource quota with best effort scope captures the pod usage 12/14/22 09:32:40.366
STEP: Ensuring resource quota with not best effort ignored the pod usage 12/14/22 09:32:42.393
STEP: Deleting the pod 12/14/22 09:32:44.419
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:32:44.452
STEP: Creating a not best-effort pod 12/14/22 09:32:46.478
STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/14/22 09:32:46.514
STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/14/22 09:32:48.54
STEP: Deleting the pod 12/14/22 09:32:50.565
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:32:50.594
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:32:52.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5269" for this suite. 12/14/22 09:32:52.667
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":265,"skipped":4942,"failed":0}
------------------------------
• [16.636 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:36.057
    Dec 14 09:32:36.057: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:32:36.058
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:36.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:36.181
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 12/14/22 09:32:36.227
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:32:36.252
    STEP: Creating a ResourceQuota with not best effort scope 12/14/22 09:32:38.278
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:32:38.304
    STEP: Creating a best-effort pod 12/14/22 09:32:40.329
    STEP: Ensuring resource quota with best effort scope captures the pod usage 12/14/22 09:32:40.366
    STEP: Ensuring resource quota with not best effort ignored the pod usage 12/14/22 09:32:42.393
    STEP: Deleting the pod 12/14/22 09:32:44.419
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:32:44.452
    STEP: Creating a not best-effort pod 12/14/22 09:32:46.478
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/14/22 09:32:46.514
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/14/22 09:32:48.54
    STEP: Deleting the pod 12/14/22 09:32:50.565
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:32:50.594
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:32:52.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5269" for this suite. 12/14/22 09:32:52.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:52.693
Dec 14 09:32:52.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:32:52.694
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:52.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:52.814
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Dec 14 09:32:52.915: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9440 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 09:32:52.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9440" for this suite. 12/14/22 09:32:52.991
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":266,"skipped":4952,"failed":0}
------------------------------
• [0.323 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:52.693
    Dec 14 09:32:52.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:32:52.694
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:52.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:52.814
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Dec 14 09:32:52.915: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9440 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 09:32:52.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9440" for this suite. 12/14/22 09:32:52.991
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:53.017
Dec 14 09:32:53.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:32:53.018
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:53.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:53.137
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Dec 14 09:32:53.214: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242" in namespace "kubelet-test-9492" to be "running and ready"
Dec 14 09:32:53.239: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242": Phase="Pending", Reason="", readiness=false. Elapsed: 24.335379ms
Dec 14 09:32:53.239: INFO: The phase of Pod busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:32:55.266: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242": Phase="Running", Reason="", readiness=true. Elapsed: 2.051944414s
Dec 14 09:32:55.267: INFO: The phase of Pod busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242 is Running (Ready = true)
Dec 14 09:32:55.267: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:32:55.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9492" for this suite. 12/14/22 09:32:55.398
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":267,"skipped":4961,"failed":0}
------------------------------
• [2.441 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:53.017
    Dec 14 09:32:53.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:32:53.018
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:53.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:53.137
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Dec 14 09:32:53.214: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242" in namespace "kubelet-test-9492" to be "running and ready"
    Dec 14 09:32:53.239: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242": Phase="Pending", Reason="", readiness=false. Elapsed: 24.335379ms
    Dec 14 09:32:53.239: INFO: The phase of Pod busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:32:55.266: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242": Phase="Running", Reason="", readiness=true. Elapsed: 2.051944414s
    Dec 14 09:32:55.267: INFO: The phase of Pod busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242 is Running (Ready = true)
    Dec 14 09:32:55.267: INFO: Pod "busybox-readonly-fs5fa3ef84-70d5-4b4c-b4cb-c50771123242" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:32:55.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9492" for this suite. 12/14/22 09:32:55.398
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:55.459
Dec 14 09:32:55.459: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:32:55.46
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:55.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:55.741
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-3357 12/14/22 09:32:55.787
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[] 12/14/22 09:32:55.825
Dec 14 09:32:55.897: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3357 12/14/22 09:32:55.898
Dec 14 09:32:55.928: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3357" to be "running and ready"
Dec 14 09:32:55.952: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.239361ms
Dec 14 09:32:55.953: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:32:57.979: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051186071s
Dec 14 09:32:57.979: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 09:32:57.979: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod1:[100]] 12/14/22 09:32:58.004
Dec 14 09:32:58.105: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-3357 12/14/22 09:32:58.105
Dec 14 09:32:58.134: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3357" to be "running and ready"
Dec 14 09:32:58.164: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.920739ms
Dec 14 09:32:58.164: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:33:00.189: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.053528928s
Dec 14 09:33:00.190: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 09:33:00.190: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod1:[100] pod2:[101]] 12/14/22 09:33:00.216
Dec 14 09:33:00.341: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 12/14/22 09:33:00.341
Dec 14 09:33:00.342: INFO: Creating new exec pod
Dec 14 09:33:00.372: INFO: Waiting up to 5m0s for pod "execpodw298f" in namespace "services-3357" to be "running"
Dec 14 09:33:00.398: INFO: Pod "execpodw298f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.214973ms
Dec 14 09:33:02.424: INFO: Pod "execpodw298f": Phase="Running", Reason="", readiness=true. Elapsed: 2.052344399s
Dec 14 09:33:02.424: INFO: Pod "execpodw298f" satisfied condition "running"
Dec 14 09:33:03.425: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Dec 14 09:33:04.086: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:33:04.086: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:33:04.086: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.107.63.162 80'
Dec 14 09:33:04.687: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.107.63.162 80\nConnection to 100.107.63.162 80 port [tcp/http] succeeded!\n"
Dec 14 09:33:04.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:33:04.687: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Dec 14 09:33:05.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Dec 14 09:33:05.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:33:05.309: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.107.63.162 81'
Dec 14 09:33:05.849: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.107.63.162 81\nConnection to 100.107.63.162 81 port [tcp/*] succeeded!\n"
Dec 14 09:33:05.849: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3357 12/14/22 09:33:05.849
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod2:[101]] 12/14/22 09:33:05.885
Dec 14 09:33:05.979: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-3357 12/14/22 09:33:05.979
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[] 12/14/22 09:33:06.018
Dec 14 09:33:06.090: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:33:06.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3357" for this suite. 12/14/22 09:33:06.185
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":268,"skipped":4974,"failed":0}
------------------------------
• [10.754 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:55.459
    Dec 14 09:32:55.459: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:32:55.46
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:55.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:55.741
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-3357 12/14/22 09:32:55.787
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[] 12/14/22 09:32:55.825
    Dec 14 09:32:55.897: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-3357 12/14/22 09:32:55.898
    Dec 14 09:32:55.928: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3357" to be "running and ready"
    Dec 14 09:32:55.952: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.239361ms
    Dec 14 09:32:55.953: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:32:57.979: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.051186071s
    Dec 14 09:32:57.979: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 09:32:57.979: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod1:[100]] 12/14/22 09:32:58.004
    Dec 14 09:32:58.105: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-3357 12/14/22 09:32:58.105
    Dec 14 09:32:58.134: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3357" to be "running and ready"
    Dec 14 09:32:58.164: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.920739ms
    Dec 14 09:32:58.164: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:33:00.189: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.053528928s
    Dec 14 09:33:00.190: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 09:33:00.190: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod1:[100] pod2:[101]] 12/14/22 09:33:00.216
    Dec 14 09:33:00.341: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 12/14/22 09:33:00.341
    Dec 14 09:33:00.342: INFO: Creating new exec pod
    Dec 14 09:33:00.372: INFO: Waiting up to 5m0s for pod "execpodw298f" in namespace "services-3357" to be "running"
    Dec 14 09:33:00.398: INFO: Pod "execpodw298f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.214973ms
    Dec 14 09:33:02.424: INFO: Pod "execpodw298f": Phase="Running", Reason="", readiness=true. Elapsed: 2.052344399s
    Dec 14 09:33:02.424: INFO: Pod "execpodw298f" satisfied condition "running"
    Dec 14 09:33:03.425: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Dec 14 09:33:04.086: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:33:04.086: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:33:04.086: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.107.63.162 80'
    Dec 14 09:33:04.687: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.107.63.162 80\nConnection to 100.107.63.162 80 port [tcp/http] succeeded!\n"
    Dec 14 09:33:04.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:33:04.687: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Dec 14 09:33:05.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Dec 14 09:33:05.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:33:05.309: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3357 exec execpodw298f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.107.63.162 81'
    Dec 14 09:33:05.849: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.107.63.162 81\nConnection to 100.107.63.162 81 port [tcp/*] succeeded!\n"
    Dec 14 09:33:05.849: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-3357 12/14/22 09:33:05.849
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[pod2:[101]] 12/14/22 09:33:05.885
    Dec 14 09:33:05.979: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-3357 12/14/22 09:33:05.979
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3357 to expose endpoints map[] 12/14/22 09:33:06.018
    Dec 14 09:33:06.090: INFO: successfully validated that service multi-endpoint-test in namespace services-3357 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:33:06.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3357" for this suite. 12/14/22 09:33:06.185
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:06.214
Dec 14 09:33:06.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:33:06.215
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:06.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:06.338
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:33:06.386
Dec 14 09:33:06.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3" in namespace "downward-api-2419" to be "Succeeded or Failed"
Dec 14 09:33:06.446: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.878335ms
Dec 14 09:33:08.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052721178s
Dec 14 09:33:10.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052444589s
STEP: Saw pod success 12/14/22 09:33:10.472
Dec 14 09:33:10.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3" satisfied condition "Succeeded or Failed"
Dec 14 09:33:10.497: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 container client-container: <nil>
STEP: delete the pod 12/14/22 09:33:10.571
Dec 14 09:33:10.604: INFO: Waiting for pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 to disappear
Dec 14 09:33:10.628: INFO: Pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:33:10.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2419" for this suite. 12/14/22 09:33:10.678
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":269,"skipped":5001,"failed":0}
------------------------------
• [4.490 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:06.214
    Dec 14 09:33:06.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:33:06.215
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:06.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:06.338
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:33:06.386
    Dec 14 09:33:06.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3" in namespace "downward-api-2419" to be "Succeeded or Failed"
    Dec 14 09:33:06.446: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.878335ms
    Dec 14 09:33:08.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052721178s
    Dec 14 09:33:10.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052444589s
    STEP: Saw pod success 12/14/22 09:33:10.472
    Dec 14 09:33:10.472: INFO: Pod "downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3" satisfied condition "Succeeded or Failed"
    Dec 14 09:33:10.497: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:33:10.571
    Dec 14 09:33:10.604: INFO: Waiting for pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 to disappear
    Dec 14 09:33:10.628: INFO: Pod downwardapi-volume-1a0ddd70-5d92-45a0-b38e-b276d12e4bf3 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:33:10.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2419" for this suite. 12/14/22 09:33:10.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:10.706
Dec 14 09:33:10.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch 12/14/22 09:33:10.706
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:10.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:10.828
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Dec 14 09:33:10.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR  12/14/22 09:33:13.072
Dec 14 09:33:13.098: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:13Z]] name:name1 resourceVersion:46204 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 12/14/22 09:33:23.101
Dec 14 09:33:23.126: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:23Z]] name:name2 resourceVersion:46301 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 12/14/22 09:33:33.127
Dec 14 09:33:33.154: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:33Z]] name:name1 resourceVersion:46364 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 12/14/22 09:33:43.157
Dec 14 09:33:43.186: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:43Z]] name:name2 resourceVersion:46425 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 12/14/22 09:33:53.187
Dec 14 09:33:53.215: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:33Z]] name:name1 resourceVersion:46482 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 12/14/22 09:34:03.217
Dec 14 09:34:03.247: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:43Z]] name:name2 resourceVersion:46541 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:34:13.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4898" for this suite. 12/14/22 09:34:13.348
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":270,"skipped":5061,"failed":0}
------------------------------
• [62.669 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:10.706
    Dec 14 09:33:10.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-watch 12/14/22 09:33:10.706
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:10.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:10.828
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Dec 14 09:33:10.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating first CR  12/14/22 09:33:13.072
    Dec 14 09:33:13.098: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:13Z]] name:name1 resourceVersion:46204 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 12/14/22 09:33:23.101
    Dec 14 09:33:23.126: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:23Z]] name:name2 resourceVersion:46301 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 12/14/22 09:33:33.127
    Dec 14 09:33:33.154: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:33Z]] name:name1 resourceVersion:46364 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 12/14/22 09:33:43.157
    Dec 14 09:33:43.186: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:43Z]] name:name2 resourceVersion:46425 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 12/14/22 09:33:53.187
    Dec 14 09:33:53.215: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:33Z]] name:name1 resourceVersion:46482 uid:523eb781-a51b-4e84-9957-afd2c7e5364c] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 12/14/22 09:34:03.217
    Dec 14 09:34:03.247: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:33:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:33:43Z]] name:name2 resourceVersion:46541 uid:b7c74631-9695-4ff3-b9dc-b6d38bd74878] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:34:13.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-4898" for this suite. 12/14/22 09:34:13.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:13.376
Dec 14 09:34:13.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:34:13.377
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:13.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:13.496
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-1146 12/14/22 09:34:13.549
STEP: creating a selector 12/14/22 09:34:13.549
STEP: Creating the service pods in kubernetes 12/14/22 09:34:13.549
Dec 14 09:34:13.550: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:34:13.666: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1146" to be "running and ready"
Dec 14 09:34:13.690: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.144332ms
Dec 14 09:34:13.690: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:34:15.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.050112157s
Dec 14 09:34:15.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:17.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.054694044s
Dec 14 09:34:17.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:19.715: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.048962933s
Dec 14 09:34:19.715: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:21.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.053309343s
Dec 14 09:34:21.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:23.722: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.056317393s
Dec 14 09:34:23.723: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:25.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.049471566s
Dec 14 09:34:25.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:27.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.049919272s
Dec 14 09:34:27.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:29.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.050132638s
Dec 14 09:34:29.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:31.717: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.051154793s
Dec 14 09:34:31.717: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:33.717: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.050370064s
Dec 14 09:34:33.717: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:35.715: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.049151013s
Dec 14 09:34:35.715: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:34:35.715: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:34:35.740: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1146" to be "running and ready"
Dec 14 09:34:35.765: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 24.72481ms
Dec 14 09:34:35.765: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:34:35.765: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:34:35.79
Dec 14 09:34:35.846: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1146" to be "running"
Dec 14 09:34:35.870: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.36158ms
Dec 14 09:34:37.902: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05590482s
Dec 14 09:34:37.902: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:34:37.927: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1146" to be "running"
Dec 14 09:34:37.951: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 24.291594ms
Dec 14 09:34:37.951: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec 14 09:34:37.977: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:34:37.977: INFO: Going to poll 100.64.0.196 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:34:38.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.196:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1146 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:34:38.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:34:38.002: INFO: ExecWithOptions: Clientset creation
Dec 14 09:34:38.002: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1146/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.64.0.196%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:34:38.487: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 14 09:34:38.487: INFO: Going to poll 100.64.1.218 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:34:38.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.218:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1146 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:34:38.512: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:34:38.512: INFO: ExecWithOptions: Clientset creation
Dec 14 09:34:38.512: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1146/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.64.1.218%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:34:38.968: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:34:38.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1146" for this suite. 12/14/22 09:34:39.016
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":271,"skipped":5087,"failed":0}
------------------------------
• [25.670 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:13.376
    Dec 14 09:34:13.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:34:13.377
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:13.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:13.496
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-1146 12/14/22 09:34:13.549
    STEP: creating a selector 12/14/22 09:34:13.549
    STEP: Creating the service pods in kubernetes 12/14/22 09:34:13.549
    Dec 14 09:34:13.550: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:34:13.666: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1146" to be "running and ready"
    Dec 14 09:34:13.690: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.144332ms
    Dec 14 09:34:13.690: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:34:15.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.050112157s
    Dec 14 09:34:15.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:17.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.054694044s
    Dec 14 09:34:17.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:19.715: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.048962933s
    Dec 14 09:34:19.715: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:21.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.053309343s
    Dec 14 09:34:21.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:23.722: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.056317393s
    Dec 14 09:34:23.723: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:25.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.049471566s
    Dec 14 09:34:25.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:27.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.049919272s
    Dec 14 09:34:27.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:29.716: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.050132638s
    Dec 14 09:34:29.716: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:31.717: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.051154793s
    Dec 14 09:34:31.717: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:33.717: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.050370064s
    Dec 14 09:34:33.717: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:35.715: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.049151013s
    Dec 14 09:34:35.715: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:34:35.715: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:34:35.740: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1146" to be "running and ready"
    Dec 14 09:34:35.765: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 24.72481ms
    Dec 14 09:34:35.765: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:34:35.765: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:34:35.79
    Dec 14 09:34:35.846: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1146" to be "running"
    Dec 14 09:34:35.870: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.36158ms
    Dec 14 09:34:37.902: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.05590482s
    Dec 14 09:34:37.902: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:34:37.927: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1146" to be "running"
    Dec 14 09:34:37.951: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 24.291594ms
    Dec 14 09:34:37.951: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec 14 09:34:37.977: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:34:37.977: INFO: Going to poll 100.64.0.196 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:34:38.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.196:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1146 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:34:38.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:34:38.002: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:34:38.002: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1146/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.64.0.196%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:34:38.487: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec 14 09:34:38.487: INFO: Going to poll 100.64.1.218 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:34:38.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.218:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1146 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:34:38.512: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:34:38.512: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:34:38.512: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1146/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.64.1.218%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:34:38.968: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:34:38.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1146" for this suite. 12/14/22 09:34:39.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:39.046
Dec 14 09:34:39.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:34:39.047
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:39.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:39.172
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2366/configmap-test-7ff7cbdf-dac1-4d23-b86a-dd7a4d6fb5f1 12/14/22 09:34:39.219
STEP: Creating a pod to test consume configMaps 12/14/22 09:34:39.244
Dec 14 09:34:39.274: INFO: Waiting up to 5m0s for pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651" in namespace "configmap-2366" to be "Succeeded or Failed"
Dec 14 09:34:39.299: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Pending", Reason="", readiness=false. Elapsed: 24.340608ms
Dec 14 09:34:41.325: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Running", Reason="", readiness=false. Elapsed: 2.05039516s
Dec 14 09:34:43.326: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051168261s
STEP: Saw pod success 12/14/22 09:34:43.326
Dec 14 09:34:43.326: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651" satisfied condition "Succeeded or Failed"
Dec 14 09:34:43.351: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 container env-test: <nil>
STEP: delete the pod 12/14/22 09:34:43.386
Dec 14 09:34:43.425: INFO: Waiting for pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 to disappear
Dec 14 09:34:43.449: INFO: Pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:34:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2366" for this suite. 12/14/22 09:34:43.497
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":272,"skipped":5102,"failed":0}
------------------------------
• [4.477 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:39.046
    Dec 14 09:34:39.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:34:39.047
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:39.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:39.172
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2366/configmap-test-7ff7cbdf-dac1-4d23-b86a-dd7a4d6fb5f1 12/14/22 09:34:39.219
    STEP: Creating a pod to test consume configMaps 12/14/22 09:34:39.244
    Dec 14 09:34:39.274: INFO: Waiting up to 5m0s for pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651" in namespace "configmap-2366" to be "Succeeded or Failed"
    Dec 14 09:34:39.299: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Pending", Reason="", readiness=false. Elapsed: 24.340608ms
    Dec 14 09:34:41.325: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Running", Reason="", readiness=false. Elapsed: 2.05039516s
    Dec 14 09:34:43.326: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051168261s
    STEP: Saw pod success 12/14/22 09:34:43.326
    Dec 14 09:34:43.326: INFO: Pod "pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651" satisfied condition "Succeeded or Failed"
    Dec 14 09:34:43.351: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 container env-test: <nil>
    STEP: delete the pod 12/14/22 09:34:43.386
    Dec 14 09:34:43.425: INFO: Waiting for pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 to disappear
    Dec 14 09:34:43.449: INFO: Pod pod-configmaps-335f0a46-b7ed-4fa9-bc28-bff2cc0c8651 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:34:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2366" for this suite. 12/14/22 09:34:43.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:43.523
Dec 14 09:34:43.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:34:43.524
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:43.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:43.647
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 12/14/22 09:34:43.693
Dec 14 09:34:43.693: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2405 cluster-info'
Dec 14 09:34:43.859: INFO: stderr: ""
Dec 14 09:34:43.859: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:34:43.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2405" for this suite. 12/14/22 09:34:43.886
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":273,"skipped":5108,"failed":0}
------------------------------
• [0.389 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:43.523
    Dec 14 09:34:43.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:34:43.524
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:43.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:43.647
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 12/14/22 09:34:43.693
    Dec 14 09:34:43.693: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2405 cluster-info'
    Dec 14 09:34:43.859: INFO: stderr: ""
    Dec 14 09:34:43.859: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:34:43.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2405" for this suite. 12/14/22 09:34:43.886
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:43.912
Dec 14 09:34:43.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:34:43.913
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:43.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:44.034
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Dec 14 09:34:44.112: INFO: Waiting up to 5m0s for pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5" in namespace "containers-9723" to be "running"
Dec 14 09:34:44.138: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.129845ms
Dec 14 09:34:46.163: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.049966008s
Dec 14 09:34:46.164: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:34:46.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9723" for this suite. 12/14/22 09:34:46.248
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":274,"skipped":5110,"failed":0}
------------------------------
• [2.362 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:43.912
    Dec 14 09:34:43.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:34:43.913
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:43.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:44.034
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Dec 14 09:34:44.112: INFO: Waiting up to 5m0s for pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5" in namespace "containers-9723" to be "running"
    Dec 14 09:34:44.138: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.129845ms
    Dec 14 09:34:46.163: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.049966008s
    Dec 14 09:34:46.164: INFO: Pod "client-containers-9662d210-9498-40ea-bfde-2f6cff2677d5" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:34:46.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9723" for this suite. 12/14/22 09:34:46.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:46.275
Dec 14 09:34:46.276: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:34:46.276
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:46.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:46.397
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 09:34:46.444
Dec 14 09:34:46.475: INFO: Waiting up to 5m0s for pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5" in namespace "emptydir-7992" to be "Succeeded or Failed"
Dec 14 09:34:46.499: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.07523ms
Dec 14 09:34:48.524: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049245307s
Dec 14 09:34:50.526: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051182041s
STEP: Saw pod success 12/14/22 09:34:50.526
Dec 14 09:34:50.527: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5" satisfied condition "Succeeded or Failed"
Dec 14 09:34:50.551: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 container test-container: <nil>
STEP: delete the pod 12/14/22 09:34:50.605
Dec 14 09:34:50.639: INFO: Waiting for pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 to disappear
Dec 14 09:34:50.664: INFO: Pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:34:50.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7992" for this suite. 12/14/22 09:34:50.712
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":275,"skipped":5139,"failed":0}
------------------------------
• [4.462 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:46.275
    Dec 14 09:34:46.276: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:34:46.276
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:46.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:46.397
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 09:34:46.444
    Dec 14 09:34:46.475: INFO: Waiting up to 5m0s for pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5" in namespace "emptydir-7992" to be "Succeeded or Failed"
    Dec 14 09:34:46.499: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.07523ms
    Dec 14 09:34:48.524: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049245307s
    Dec 14 09:34:50.526: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051182041s
    STEP: Saw pod success 12/14/22 09:34:50.526
    Dec 14 09:34:50.527: INFO: Pod "pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5" satisfied condition "Succeeded or Failed"
    Dec 14 09:34:50.551: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:34:50.605
    Dec 14 09:34:50.639: INFO: Waiting for pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 to disappear
    Dec 14 09:34:50.664: INFO: Pod pod-77a3ef2a-9a12-423b-b09f-f2e32e5e41b5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:34:50.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7992" for this suite. 12/14/22 09:34:50.712
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:50.739
Dec 14 09:34:50.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:34:50.74
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:50.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:50.864
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-1065 12/14/22 09:34:50.91
STEP: creating a selector 12/14/22 09:34:50.911
STEP: Creating the service pods in kubernetes 12/14/22 09:34:50.911
Dec 14 09:34:50.911: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:34:51.021: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1065" to be "running and ready"
Dec 14 09:34:51.046: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.576073ms
Dec 14 09:34:51.046: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:34:53.071: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.049615089s
Dec 14 09:34:53.071: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:55.075: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.053498265s
Dec 14 09:34:55.075: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:57.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.051757013s
Dec 14 09:34:57.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:34:59.072: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.050636986s
Dec 14 09:34:59.072: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:35:01.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.051543112s
Dec 14 09:35:01.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:35:03.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.051781561s
Dec 14 09:35:03.073: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:35:03.073: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:35:03.102: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1065" to be "running and ready"
Dec 14 09:35:03.128: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.334416ms
Dec 14 09:35:03.128: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:35:03.128: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:35:03.16
Dec 14 09:35:03.217: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1065" to be "running"
Dec 14 09:35:03.244: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.292643ms
Dec 14 09:35:05.269: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052020364s
Dec 14 09:35:05.269: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:35:05.294: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1065" to be "running"
Dec 14 09:35:05.319: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 24.498873ms
Dec 14 09:35:05.319: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec 14 09:35:05.343: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:35:05.343: INFO: Going to poll 100.64.0.201 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:35:05.368: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.201 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:35:05.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:35:05.369: INFO: ExecWithOptions: Clientset creation
Dec 14 09:35:05.369: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.64.0.201+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:35:06.845: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 14 09:35:06.845: INFO: Going to poll 100.64.1.219 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:35:06.870: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.219 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:35:06.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:35:06.871: INFO: ExecWithOptions: Clientset creation
Dec 14 09:35:06.871: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.64.1.219+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:35:08.319: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:35:08.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1065" for this suite. 12/14/22 09:35:08.368
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":276,"skipped":5158,"failed":0}
------------------------------
• [17.656 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:50.739
    Dec 14 09:34:50.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:34:50.74
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:50.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:50.864
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-1065 12/14/22 09:34:50.91
    STEP: creating a selector 12/14/22 09:34:50.911
    STEP: Creating the service pods in kubernetes 12/14/22 09:34:50.911
    Dec 14 09:34:50.911: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:34:51.021: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1065" to be "running and ready"
    Dec 14 09:34:51.046: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.576073ms
    Dec 14 09:34:51.046: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:34:53.071: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.049615089s
    Dec 14 09:34:53.071: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:55.075: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.053498265s
    Dec 14 09:34:55.075: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:57.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.051757013s
    Dec 14 09:34:57.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:34:59.072: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.050636986s
    Dec 14 09:34:59.072: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:35:01.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.051543112s
    Dec 14 09:35:01.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:35:03.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.051781561s
    Dec 14 09:35:03.073: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:35:03.073: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:35:03.102: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1065" to be "running and ready"
    Dec 14 09:35:03.128: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 25.334416ms
    Dec 14 09:35:03.128: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:35:03.128: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:35:03.16
    Dec 14 09:35:03.217: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1065" to be "running"
    Dec 14 09:35:03.244: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 26.292643ms
    Dec 14 09:35:05.269: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052020364s
    Dec 14 09:35:05.269: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:35:05.294: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1065" to be "running"
    Dec 14 09:35:05.319: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 24.498873ms
    Dec 14 09:35:05.319: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec 14 09:35:05.343: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:35:05.343: INFO: Going to poll 100.64.0.201 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:35:05.368: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.201 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:35:05.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:35:05.369: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:35:05.369: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.64.0.201+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:35:06.845: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec 14 09:35:06.845: INFO: Going to poll 100.64.1.219 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:35:06.870: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.219 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:35:06.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:35:06.871: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:35:06.871: INFO: ExecWithOptions: execute(POST https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-1065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.64.1.219+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:35:08.319: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:35:08.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1065" for this suite. 12/14/22 09:35:08.368
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:35:08.396
Dec 14 09:35:08.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:35:08.397
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:08.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:08.528
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:35:08.574
Dec 14 09:35:08.606: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272" in namespace "downward-api-5071" to be "Succeeded or Failed"
Dec 14 09:35:08.631: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Pending", Reason="", readiness=false. Elapsed: 24.295639ms
Dec 14 09:35:10.656: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050017996s
Dec 14 09:35:12.657: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050487309s
STEP: Saw pod success 12/14/22 09:35:12.657
Dec 14 09:35:12.657: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272" satisfied condition "Succeeded or Failed"
Dec 14 09:35:12.690: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 container client-container: <nil>
STEP: delete the pod 12/14/22 09:35:12.761
Dec 14 09:35:12.796: INFO: Waiting for pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 to disappear
Dec 14 09:35:12.821: INFO: Pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:35:12.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5071" for this suite. 12/14/22 09:35:12.869
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":277,"skipped":5173,"failed":0}
------------------------------
• [4.500 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:35:08.396
    Dec 14 09:35:08.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:35:08.397
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:08.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:08.528
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:35:08.574
    Dec 14 09:35:08.606: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272" in namespace "downward-api-5071" to be "Succeeded or Failed"
    Dec 14 09:35:08.631: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Pending", Reason="", readiness=false. Elapsed: 24.295639ms
    Dec 14 09:35:10.656: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050017996s
    Dec 14 09:35:12.657: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050487309s
    STEP: Saw pod success 12/14/22 09:35:12.657
    Dec 14 09:35:12.657: INFO: Pod "downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272" satisfied condition "Succeeded or Failed"
    Dec 14 09:35:12.690: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:35:12.761
    Dec 14 09:35:12.796: INFO: Waiting for pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 to disappear
    Dec 14 09:35:12.821: INFO: Pod downwardapi-volume-a0d2a066-ede9-4ccf-8df9-80ec32fb6272 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:35:12.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5071" for this suite. 12/14/22 09:35:12.869
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:35:12.896
Dec 14 09:35:12.896: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:35:12.897
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:12.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:13.016
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 12/14/22 09:35:13.062
STEP: wait for the container to reach Succeeded 12/14/22 09:35:13.093
STEP: get the container status 12/14/22 09:35:18.253
STEP: the container should be terminated 12/14/22 09:35:18.278
STEP: the termination message should be set 12/14/22 09:35:18.278
Dec 14 09:35:18.278: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 12/14/22 09:35:18.278
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:35:18.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-466" for this suite. 12/14/22 09:35:18.383
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":278,"skipped":5182,"failed":0}
------------------------------
• [5.513 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:35:12.896
    Dec 14 09:35:12.896: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:35:12.897
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:12.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:13.016
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 12/14/22 09:35:13.062
    STEP: wait for the container to reach Succeeded 12/14/22 09:35:13.093
    STEP: get the container status 12/14/22 09:35:18.253
    STEP: the container should be terminated 12/14/22 09:35:18.278
    STEP: the termination message should be set 12/14/22 09:35:18.278
    Dec 14 09:35:18.278: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 12/14/22 09:35:18.278
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:35:18.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-466" for this suite. 12/14/22 09:35:18.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:35:18.41
Dec 14 09:35:18.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:35:18.411
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:18.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:18.534
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2675 12/14/22 09:35:18.58
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 12/14/22 09:35:18.606
STEP: Creating stateful set ss in namespace statefulset-2675 12/14/22 09:35:18.63
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2675 12/14/22 09:35:18.655
Dec 14 09:35:18.681: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec 14 09:35:28.707: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/14/22 09:35:28.707
Dec 14 09:35:28.732: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:35:29.369: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:35:29.369: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:35:29.369: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:35:29.394: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 14 09:35:39.421: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:35:39.421: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:35:39.530: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999928s
Dec 14 09:35:40.556: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.967829449s
Dec 14 09:35:41.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.941483266s
Dec 14 09:35:42.607: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.91588164s
Dec 14 09:35:43.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.890195012s
Dec 14 09:35:44.663: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.859845732s
Dec 14 09:35:45.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.834259153s
Dec 14 09:35:46.713: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.809154979s
Dec 14 09:35:47.739: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.78385242s
Dec 14 09:35:48.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 758.547779ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2675 12/14/22 09:35:49.765
Dec 14 09:35:49.790: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:35:50.423: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:35:50.423: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:35:50.423: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:35:50.448: INFO: Found 1 stateful pods, waiting for 3
Dec 14 09:36:00.475: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:36:00.475: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:36:00.475: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 12/14/22 09:36:00.475
STEP: Scale down will halt with unhealthy stateful pod 12/14/22 09:36:00.475
Dec 14 09:36:00.525: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:36:01.131: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:36:01.131: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:36:01.131: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:36:01.131: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:36:01.807: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:36:01.807: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:36:01.807: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:36:01.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:36:02.484: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:36:02.484: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:36:02.484: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:36:02.484: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:36:02.509: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 14 09:36:12.562: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:36:12.562: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:36:12.562: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:36:12.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999375s
Dec 14 09:36:13.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.973755904s
Dec 14 09:36:14.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.94808684s
Dec 14 09:36:15.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.920784091s
Dec 14 09:36:16.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.894856487s
Dec 14 09:36:17.768: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.869401176s
Dec 14 09:36:18.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.842669743s
Dec 14 09:36:19.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.815916977s
Dec 14 09:36:20.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.789766194s
Dec 14 09:36:21.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 763.781702ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2675 12/14/22 09:36:22.874
Dec 14 09:36:22.900: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:23.535: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:36:23.535: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:36:23.535: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:36:23.535: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:24.157: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:36:24.157: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:36:24.157: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:36:24.157: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:24.798: INFO: rc: 1
Dec 14 09:36:24.798: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state

error:
exit status 1
Dec 14 09:36:34.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:34.990: INFO: rc: 1
Dec 14 09:36:34.990: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:36:44.990: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:45.192: INFO: rc: 1
Dec 14 09:36:45.192: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:36:55.193: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:36:55.389: INFO: rc: 1
Dec 14 09:36:55.399: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:05.399: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:05.669: INFO: rc: 1
Dec 14 09:37:05.669: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:15.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:15.894: INFO: rc: 1
Dec 14 09:37:15.894: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:25.895: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:26.136: INFO: rc: 1
Dec 14 09:37:26.136: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:36.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:36.400: INFO: rc: 1
Dec 14 09:37:36.400: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:46.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:46.599: INFO: rc: 1
Dec 14 09:37:46.599: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:37:56.600: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:37:56.799: INFO: rc: 1
Dec 14 09:37:56.799: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:06.801: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:07.004: INFO: rc: 1
Dec 14 09:38:07.004: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:17.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:17.230: INFO: rc: 1
Dec 14 09:38:17.230: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:27.232: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:27.519: INFO: rc: 1
Dec 14 09:38:27.519: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:37.521: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:37.763: INFO: rc: 1
Dec 14 09:38:37.763: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:47.765: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:48.094: INFO: rc: 1
Dec 14 09:38:48.094: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:38:58.094: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:38:58.412: INFO: rc: 1
Dec 14 09:38:58.412: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:08.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:08.664: INFO: rc: 1
Dec 14 09:39:08.687: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:18.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:18.999: INFO: rc: 1
Dec 14 09:39:18.999: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:29.000: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:29.323: INFO: rc: 1
Dec 14 09:39:29.323: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:39.324: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:39.546: INFO: rc: 1
Dec 14 09:39:39.546: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:49.547: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:49.775: INFO: rc: 1
Dec 14 09:39:49.775: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:39:59.776: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:39:59.965: INFO: rc: 1
Dec 14 09:39:59.965: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:40:09.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:40:10.165: INFO: rc: 1
Dec 14 09:40:10.165: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:40:20.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:40:20.372: INFO: rc: 1
Dec 14 09:40:20.373: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:40:30.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:40:30.567: INFO: rc: 1
Dec 14 09:40:30.567: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:40:40.568: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:40:40.801: INFO: rc: 1
Dec 14 09:40:40.801: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:40:50.802: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:40:50.988: INFO: rc: 1
Dec 14 09:40:50.988: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:41:00.989: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:41:01.186: INFO: rc: 1
Dec 14 09:41:01.186: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:41:11.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:41:11.356: INFO: rc: 1
Dec 14 09:41:11.356: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:41:21.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:41:21.538: INFO: rc: 1
Dec 14 09:41:21.538: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 14 09:41:31.538: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:41:31.704: INFO: rc: 1
Dec 14 09:41:31.704: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Dec 14 09:41:31.704: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 12/14/22 09:41:31.779
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:41:31.779: INFO: Deleting all statefulset in ns statefulset-2675
Dec 14 09:41:31.811: INFO: Scaling statefulset ss to 0
Dec 14 09:41:31.886: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:41:31.910: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:41:31.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2675" for this suite. 12/14/22 09:41:32.039
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":279,"skipped":5209,"failed":0}
------------------------------
• [SLOW TEST] [373.658 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:35:18.41
    Dec 14 09:35:18.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:35:18.411
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:35:18.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:35:18.534
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2675 12/14/22 09:35:18.58
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 12/14/22 09:35:18.606
    STEP: Creating stateful set ss in namespace statefulset-2675 12/14/22 09:35:18.63
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2675 12/14/22 09:35:18.655
    Dec 14 09:35:18.681: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Dec 14 09:35:28.707: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/14/22 09:35:28.707
    Dec 14 09:35:28.732: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:35:29.369: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:35:29.369: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:35:29.369: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:35:29.394: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec 14 09:35:39.421: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:35:39.421: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:35:39.530: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999928s
    Dec 14 09:35:40.556: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.967829449s
    Dec 14 09:35:41.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.941483266s
    Dec 14 09:35:42.607: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.91588164s
    Dec 14 09:35:43.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.890195012s
    Dec 14 09:35:44.663: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.859845732s
    Dec 14 09:35:45.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.834259153s
    Dec 14 09:35:46.713: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.809154979s
    Dec 14 09:35:47.739: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.78385242s
    Dec 14 09:35:48.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 758.547779ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2675 12/14/22 09:35:49.765
    Dec 14 09:35:49.790: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:35:50.423: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:35:50.423: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:35:50.423: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:35:50.448: INFO: Found 1 stateful pods, waiting for 3
    Dec 14 09:36:00.475: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:36:00.475: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:36:00.475: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 12/14/22 09:36:00.475
    STEP: Scale down will halt with unhealthy stateful pod 12/14/22 09:36:00.475
    Dec 14 09:36:00.525: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:36:01.131: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:36:01.131: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:36:01.131: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:36:01.131: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:36:01.807: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:36:01.807: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:36:01.807: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:36:01.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:36:02.484: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:36:02.484: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:36:02.484: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:36:02.484: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:36:02.509: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Dec 14 09:36:12.562: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:36:12.562: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:36:12.562: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:36:12.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999375s
    Dec 14 09:36:13.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.973755904s
    Dec 14 09:36:14.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.94808684s
    Dec 14 09:36:15.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.920784091s
    Dec 14 09:36:16.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.894856487s
    Dec 14 09:36:17.768: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.869401176s
    Dec 14 09:36:18.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.842669743s
    Dec 14 09:36:19.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.815916977s
    Dec 14 09:36:20.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.789766194s
    Dec 14 09:36:21.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 763.781702ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2675 12/14/22 09:36:22.874
    Dec 14 09:36:22.900: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:23.535: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:36:23.535: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:36:23.535: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:36:23.535: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:24.157: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:36:24.157: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:36:24.157: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:36:24.157: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:24.798: INFO: rc: 1
    Dec 14 09:36:24.798: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state

    error:
    exit status 1
    Dec 14 09:36:34.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:34.990: INFO: rc: 1
    Dec 14 09:36:34.990: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:36:44.990: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:45.192: INFO: rc: 1
    Dec 14 09:36:45.192: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:36:55.193: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:36:55.389: INFO: rc: 1
    Dec 14 09:36:55.399: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:05.399: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:05.669: INFO: rc: 1
    Dec 14 09:37:05.669: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:15.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:15.894: INFO: rc: 1
    Dec 14 09:37:15.894: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:25.895: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:26.136: INFO: rc: 1
    Dec 14 09:37:26.136: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:36.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:36.400: INFO: rc: 1
    Dec 14 09:37:36.400: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:46.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:46.599: INFO: rc: 1
    Dec 14 09:37:46.599: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:37:56.600: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:37:56.799: INFO: rc: 1
    Dec 14 09:37:56.799: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:06.801: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:07.004: INFO: rc: 1
    Dec 14 09:38:07.004: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:17.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:17.230: INFO: rc: 1
    Dec 14 09:38:17.230: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:27.232: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:27.519: INFO: rc: 1
    Dec 14 09:38:27.519: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:37.521: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:37.763: INFO: rc: 1
    Dec 14 09:38:37.763: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:47.765: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:48.094: INFO: rc: 1
    Dec 14 09:38:48.094: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:38:58.094: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:38:58.412: INFO: rc: 1
    Dec 14 09:38:58.412: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:08.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:08.664: INFO: rc: 1
    Dec 14 09:39:08.687: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:18.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:18.999: INFO: rc: 1
    Dec 14 09:39:18.999: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:29.000: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:29.323: INFO: rc: 1
    Dec 14 09:39:29.323: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:39.324: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:39.546: INFO: rc: 1
    Dec 14 09:39:39.546: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:49.547: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:49.775: INFO: rc: 1
    Dec 14 09:39:49.775: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:39:59.776: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:39:59.965: INFO: rc: 1
    Dec 14 09:39:59.965: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:40:09.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:40:10.165: INFO: rc: 1
    Dec 14 09:40:10.165: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:40:20.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:40:20.372: INFO: rc: 1
    Dec 14 09:40:20.373: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:40:30.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:40:30.567: INFO: rc: 1
    Dec 14 09:40:30.567: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:40:40.568: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:40:40.801: INFO: rc: 1
    Dec 14 09:40:40.801: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:40:50.802: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:40:50.988: INFO: rc: 1
    Dec 14 09:40:50.988: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:41:00.989: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:41:01.186: INFO: rc: 1
    Dec 14 09:41:01.186: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:41:11.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:41:11.356: INFO: rc: 1
    Dec 14 09:41:11.356: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:41:21.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:41:21.538: INFO: rc: 1
    Dec 14 09:41:21.538: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Dec 14 09:41:31.538: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-2675 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:41:31.704: INFO: rc: 1
    Dec 14 09:41:31.704: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
    Dec 14 09:41:31.704: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 12/14/22 09:41:31.779
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:41:31.779: INFO: Deleting all statefulset in ns statefulset-2675
    Dec 14 09:41:31.811: INFO: Scaling statefulset ss to 0
    Dec 14 09:41:31.886: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:41:31.910: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:41:31.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2675" for this suite. 12/14/22 09:41:32.039
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:32.068
Dec 14 09:41:32.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 09:41:32.069
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:32.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:32.188
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 09:41:32.311: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 09:42:32.561: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:32.586
Dec 14 09:42:32.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 09:42:32.587
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:32.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:32.711
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 12/14/22 09:42:32.757
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 09:42:32.757
Dec 14 09:42:32.797: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7396" to be "running"
Dec 14 09:42:32.821: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 24.328219ms
Dec 14 09:42:34.847: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.050259597s
Dec 14 09:42:34.847: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 09:42:34.871
Dec 14 09:42:34.904: INFO: found a healthy node: shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Dec 14 09:42:45.329: INFO: pods created so far: [1 1 1]
Dec 14 09:42:45.329: INFO: length of pods created so far: 3
Dec 14 09:42:47.384: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Dec 14 09:42:54.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7396" for this suite. 12/14/22 09:42:54.441
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:42:54.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4069" for this suite. 12/14/22 09:42:54.628
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":280,"skipped":5211,"failed":0}
------------------------------
• [82.743 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:32.068
    Dec 14 09:41:32.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 09:41:32.069
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:32.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:32.188
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 09:41:32.311: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 09:42:32.561: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:32.586
    Dec 14 09:42:32.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 09:42:32.587
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:32.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:32.711
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 12/14/22 09:42:32.757
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 09:42:32.757
    Dec 14 09:42:32.797: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7396" to be "running"
    Dec 14 09:42:32.821: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 24.328219ms
    Dec 14 09:42:34.847: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.050259597s
    Dec 14 09:42:34.847: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 09:42:34.871
    Dec 14 09:42:34.904: INFO: found a healthy node: shoot--it--tm0ct-io0-worker-1-6f755-hwmlx
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Dec 14 09:42:45.329: INFO: pods created so far: [1 1 1]
    Dec 14 09:42:45.329: INFO: length of pods created so far: 3
    Dec 14 09:42:47.384: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Dec 14 09:42:54.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7396" for this suite. 12/14/22 09:42:54.441
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:42:54.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4069" for this suite. 12/14/22 09:42:54.628
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:54.812
Dec 14 09:42:54.812: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:42:54.813
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:54.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:54.939
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/14/22 09:42:54.985
Dec 14 09:42:54.986: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:42:59.510: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:43:17.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8886" for this suite. 12/14/22 09:43:17.659
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":281,"skipped":5227,"failed":0}
------------------------------
• [22.875 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:54.812
    Dec 14 09:42:54.812: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:42:54.813
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:54.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:54.939
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/14/22 09:42:54.985
    Dec 14 09:42:54.986: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:42:59.510: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:43:17.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8886" for this suite. 12/14/22 09:43:17.659
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:17.688
Dec 14 09:43:17.688: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:43:17.689
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:17.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:17.811
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-588 12/14/22 09:43:17.859
STEP: changing the ExternalName service to type=NodePort 12/14/22 09:43:17.884
STEP: creating replication controller externalname-service in namespace services-588 12/14/22 09:43:17.955
I1214 09:43:17.981613    6274 runners.go:193] Created replication controller with name: externalname-service, namespace: services-588, replica count: 2
I1214 09:43:21.033226    6274 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:43:21.033: INFO: Creating new exec pod
Dec 14 09:43:21.063: INFO: Waiting up to 5m0s for pod "execpod47qvz" in namespace "services-588" to be "running"
Dec 14 09:43:21.088: INFO: Pod "execpod47qvz": Phase="Pending", Reason="", readiness=false. Elapsed: 24.604711ms
Dec 14 09:43:23.116: INFO: Pod "execpod47qvz": Phase="Running", Reason="", readiness=true. Elapsed: 2.052102939s
Dec 14 09:43:23.116: INFO: Pod "execpod47qvz" satisfied condition "running"
Dec 14 09:43:24.165: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:43:24.747: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:24.747: INFO: stdout: "externalname-service-glvfd"
Dec 14 09:43:24.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
Dec 14 09:43:25.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:25.368: INFO: stdout: ""
Dec 14 09:43:26.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
Dec 14 09:43:26.868: INFO: stderr: "+ nc -v -t -w 2 100.111.179.54 80\n+ echo hostName\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:26.869: INFO: stdout: ""
Dec 14 09:43:27.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
Dec 14 09:43:28.012: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:28.012: INFO: stdout: ""
Dec 14 09:43:28.369: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
Dec 14 09:43:28.939: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:28.939: INFO: stdout: ""
Dec 14 09:43:29.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
Dec 14 09:43:29.938: INFO: stderr: "+ nc -v -t -w 2 100.111.179.54 80\n+ echo hostName\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
Dec 14 09:43:29.938: INFO: stdout: "externalname-service-x9tzg"
Dec 14 09:43:29.938: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32431'
Dec 14 09:43:30.512: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32431\nConnection to 10.250.0.5 32431 port [tcp/*] succeeded!\n"
Dec 14 09:43:30.512: INFO: stdout: ""
Dec 14 09:43:31.512: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32431'
Dec 14 09:43:32.161: INFO: stderr: "+ nc -v -t -w 2 10.250.0.5 32431\n+ echo hostName\nConnection to 10.250.0.5 32431 port [tcp/*] succeeded!\n"
Dec 14 09:43:32.161: INFO: stdout: "externalname-service-x9tzg"
Dec 14 09:43:32.161: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32431'
Dec 14 09:43:32.798: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32431\n+ echo hostName\nConnection to 10.250.0.4 32431 port [tcp/*] succeeded!\n"
Dec 14 09:43:32.798: INFO: stdout: ""
Dec 14 09:43:33.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32431'
Dec 14 09:43:34.355: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32431\n+ echo hostName\nConnection to 10.250.0.4 32431 port [tcp/*] succeeded!\n"
Dec 14 09:43:34.355: INFO: stdout: "externalname-service-x9tzg"
Dec 14 09:43:34.355: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:43:34.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-588" for this suite. 12/14/22 09:43:34.446
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":282,"skipped":5268,"failed":0}
------------------------------
• [16.784 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:17.688
    Dec 14 09:43:17.688: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:43:17.689
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:17.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:17.811
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-588 12/14/22 09:43:17.859
    STEP: changing the ExternalName service to type=NodePort 12/14/22 09:43:17.884
    STEP: creating replication controller externalname-service in namespace services-588 12/14/22 09:43:17.955
    I1214 09:43:17.981613    6274 runners.go:193] Created replication controller with name: externalname-service, namespace: services-588, replica count: 2
    I1214 09:43:21.033226    6274 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:43:21.033: INFO: Creating new exec pod
    Dec 14 09:43:21.063: INFO: Waiting up to 5m0s for pod "execpod47qvz" in namespace "services-588" to be "running"
    Dec 14 09:43:21.088: INFO: Pod "execpod47qvz": Phase="Pending", Reason="", readiness=false. Elapsed: 24.604711ms
    Dec 14 09:43:23.116: INFO: Pod "execpod47qvz": Phase="Running", Reason="", readiness=true. Elapsed: 2.052102939s
    Dec 14 09:43:23.116: INFO: Pod "execpod47qvz" satisfied condition "running"
    Dec 14 09:43:24.165: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:43:24.747: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:24.747: INFO: stdout: "externalname-service-glvfd"
    Dec 14 09:43:24.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
    Dec 14 09:43:25.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:25.368: INFO: stdout: ""
    Dec 14 09:43:26.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
    Dec 14 09:43:26.868: INFO: stderr: "+ nc -v -t -w 2 100.111.179.54 80\n+ echo hostName\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:26.869: INFO: stdout: ""
    Dec 14 09:43:27.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
    Dec 14 09:43:28.012: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:28.012: INFO: stdout: ""
    Dec 14 09:43:28.369: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
    Dec 14 09:43:28.939: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.179.54 80\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:28.939: INFO: stdout: ""
    Dec 14 09:43:29.368: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.179.54 80'
    Dec 14 09:43:29.938: INFO: stderr: "+ nc -v -t -w 2 100.111.179.54 80\n+ echo hostName\nConnection to 100.111.179.54 80 port [tcp/http] succeeded!\n"
    Dec 14 09:43:29.938: INFO: stdout: "externalname-service-x9tzg"
    Dec 14 09:43:29.938: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32431'
    Dec 14 09:43:30.512: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.5 32431\nConnection to 10.250.0.5 32431 port [tcp/*] succeeded!\n"
    Dec 14 09:43:30.512: INFO: stdout: ""
    Dec 14 09:43:31.512: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 32431'
    Dec 14 09:43:32.161: INFO: stderr: "+ nc -v -t -w 2 10.250.0.5 32431\n+ echo hostName\nConnection to 10.250.0.5 32431 port [tcp/*] succeeded!\n"
    Dec 14 09:43:32.161: INFO: stdout: "externalname-service-x9tzg"
    Dec 14 09:43:32.161: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32431'
    Dec 14 09:43:32.798: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32431\n+ echo hostName\nConnection to 10.250.0.4 32431 port [tcp/*] succeeded!\n"
    Dec 14 09:43:32.798: INFO: stdout: ""
    Dec 14 09:43:33.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-588 exec execpod47qvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 32431'
    Dec 14 09:43:34.355: INFO: stderr: "+ nc -v -t -w 2 10.250.0.4 32431\n+ echo hostName\nConnection to 10.250.0.4 32431 port [tcp/*] succeeded!\n"
    Dec 14 09:43:34.355: INFO: stdout: "externalname-service-x9tzg"
    Dec 14 09:43:34.355: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:43:34.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-588" for this suite. 12/14/22 09:43:34.446
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:34.472
Dec 14 09:43:34.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:43:34.473
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:34.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:34.596
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 12/14/22 09:43:34.668
STEP: waiting for available Endpoint 12/14/22 09:43:34.696
STEP: listing all Endpoints 12/14/22 09:43:34.721
STEP: updating the Endpoint 12/14/22 09:43:34.748
STEP: fetching the Endpoint 12/14/22 09:43:34.798
STEP: patching the Endpoint 12/14/22 09:43:34.823
STEP: fetching the Endpoint 12/14/22 09:43:34.877
STEP: deleting the Endpoint by Collection 12/14/22 09:43:34.901
STEP: waiting for Endpoint deletion 12/14/22 09:43:34.928
STEP: fetching the Endpoint 12/14/22 09:43:34.952
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:43:34.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3397" for this suite. 12/14/22 09:43:35.004
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":283,"skipped":5282,"failed":0}
------------------------------
• [0.558 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:34.472
    Dec 14 09:43:34.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:43:34.473
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:34.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:34.596
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 12/14/22 09:43:34.668
    STEP: waiting for available Endpoint 12/14/22 09:43:34.696
    STEP: listing all Endpoints 12/14/22 09:43:34.721
    STEP: updating the Endpoint 12/14/22 09:43:34.748
    STEP: fetching the Endpoint 12/14/22 09:43:34.798
    STEP: patching the Endpoint 12/14/22 09:43:34.823
    STEP: fetching the Endpoint 12/14/22 09:43:34.877
    STEP: deleting the Endpoint by Collection 12/14/22 09:43:34.901
    STEP: waiting for Endpoint deletion 12/14/22 09:43:34.928
    STEP: fetching the Endpoint 12/14/22 09:43:34.952
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:43:34.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3397" for this suite. 12/14/22 09:43:35.004
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:35.03
Dec 14 09:43:35.031: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:43:35.031
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:35.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:35.161
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Dec 14 09:43:35.267: INFO: Waiting up to 5m0s for pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645" in namespace "svcaccounts-7968" to be "running"
Dec 14 09:43:35.292: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645": Phase="Pending", Reason="", readiness=false. Elapsed: 24.727654ms
Dec 14 09:43:37.319: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645": Phase="Running", Reason="", readiness=true. Elapsed: 2.05117905s
Dec 14 09:43:37.319: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645" satisfied condition "running"
STEP: reading a file in the container 12/14/22 09:43:37.319
Dec 14 09:43:37.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 12/14/22 09:43:37.858
Dec 14 09:43:37.859: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 12/14/22 09:43:38.486
Dec 14 09:43:38.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Dec 14 09:43:39.145: INFO: Got root ca configmap in namespace "svcaccounts-7968"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:43:39.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7968" for this suite. 12/14/22 09:43:39.218
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":284,"skipped":5284,"failed":0}
------------------------------
• [4.213 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:35.03
    Dec 14 09:43:35.031: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:43:35.031
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:35.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:35.161
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Dec 14 09:43:35.267: INFO: Waiting up to 5m0s for pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645" in namespace "svcaccounts-7968" to be "running"
    Dec 14 09:43:35.292: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645": Phase="Pending", Reason="", readiness=false. Elapsed: 24.727654ms
    Dec 14 09:43:37.319: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645": Phase="Running", Reason="", readiness=true. Elapsed: 2.05117905s
    Dec 14 09:43:37.319: INFO: Pod "pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645" satisfied condition "running"
    STEP: reading a file in the container 12/14/22 09:43:37.319
    Dec 14 09:43:37.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 12/14/22 09:43:37.858
    Dec 14 09:43:37.859: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 12/14/22 09:43:38.486
    Dec 14 09:43:38.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7968 pod-service-account-0e813975-fc15-4785-8cd3-aa029f04c645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Dec 14 09:43:39.145: INFO: Got root ca configmap in namespace "svcaccounts-7968"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:43:39.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7968" for this suite. 12/14/22 09:43:39.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:39.244
Dec 14 09:43:39.245: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 09:43:39.245
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:39.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:39.367
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Dec 14 09:43:39.414: INFO: Creating pod...
Dec 14 09:43:39.451: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2922" to be "running"
Dec 14 09:43:39.475: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 24.5492ms
Dec 14 09:43:41.505: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053863144s
Dec 14 09:43:41.505: INFO: Pod "agnhost" satisfied condition "running"
Dec 14 09:43:41.505: INFO: Creating service...
Dec 14 09:43:41.544: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/DELETE
Dec 14 09:43:41.665: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 09:43:41.665: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/GET
Dec 14 09:43:41.711: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 14 09:43:41.711: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/HEAD
Dec 14 09:43:41.739: INFO: http.Client request:HEAD | StatusCode:200
Dec 14 09:43:41.739: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/OPTIONS
Dec 14 09:43:41.768: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 09:43:41.768: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/PATCH
Dec 14 09:43:41.799: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 09:43:41.799: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/POST
Dec 14 09:43:41.828: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 09:43:41.828: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/PUT
Dec 14 09:43:41.857: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 09:43:41.857: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/DELETE
Dec 14 09:43:41.887: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 09:43:41.887: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/GET
Dec 14 09:43:41.919: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 14 09:43:41.919: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/HEAD
Dec 14 09:43:41.948: INFO: http.Client request:HEAD | StatusCode:200
Dec 14 09:43:41.948: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/OPTIONS
Dec 14 09:43:41.979: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 09:43:41.979: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/PATCH
Dec 14 09:43:42.015: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 09:43:42.015: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/POST
Dec 14 09:43:42.045: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 09:43:42.045: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/PUT
Dec 14 09:43:42.075: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 09:43:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2922" for this suite. 12/14/22 09:43:42.124
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":285,"skipped":5294,"failed":0}
------------------------------
• [2.905 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:39.244
    Dec 14 09:43:39.245: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 09:43:39.245
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:39.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:39.367
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Dec 14 09:43:39.414: INFO: Creating pod...
    Dec 14 09:43:39.451: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2922" to be "running"
    Dec 14 09:43:39.475: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 24.5492ms
    Dec 14 09:43:41.505: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053863144s
    Dec 14 09:43:41.505: INFO: Pod "agnhost" satisfied condition "running"
    Dec 14 09:43:41.505: INFO: Creating service...
    Dec 14 09:43:41.544: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/DELETE
    Dec 14 09:43:41.665: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 09:43:41.665: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/GET
    Dec 14 09:43:41.711: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec 14 09:43:41.711: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/HEAD
    Dec 14 09:43:41.739: INFO: http.Client request:HEAD | StatusCode:200
    Dec 14 09:43:41.739: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/OPTIONS
    Dec 14 09:43:41.768: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 09:43:41.768: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/PATCH
    Dec 14 09:43:41.799: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 09:43:41.799: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/POST
    Dec 14 09:43:41.828: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 09:43:41.828: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/pods/agnhost/proxy/some/path/with/PUT
    Dec 14 09:43:41.857: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 09:43:41.857: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/DELETE
    Dec 14 09:43:41.887: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 09:43:41.887: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/GET
    Dec 14 09:43:41.919: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec 14 09:43:41.919: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/HEAD
    Dec 14 09:43:41.948: INFO: http.Client request:HEAD | StatusCode:200
    Dec 14 09:43:41.948: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/OPTIONS
    Dec 14 09:43:41.979: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 09:43:41.979: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/PATCH
    Dec 14 09:43:42.015: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 09:43:42.015: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/POST
    Dec 14 09:43:42.045: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 09:43:42.045: INFO: Starting http.Client for https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-2922/services/test-service/proxy/some/path/with/PUT
    Dec 14 09:43:42.075: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 09:43:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2922" for this suite. 12/14/22 09:43:42.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:42.152
Dec 14 09:43:42.153: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:43:42.153
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:42.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:42.276
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Dec 14 09:43:42.355: INFO: Waiting up to 5m0s for pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade" in namespace "kubelet-test-4927" to be "running and ready"
Dec 14 09:43:42.380: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade": Phase="Pending", Reason="", readiness=false. Elapsed: 24.748736ms
Dec 14 09:43:42.380: INFO: The phase of Pod busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:43:44.405: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade": Phase="Running", Reason="", readiness=true. Elapsed: 2.050055372s
Dec 14 09:43:44.405: INFO: The phase of Pod busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade is Running (Ready = true)
Dec 14 09:43:44.405: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:43:44.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4927" for this suite. 12/14/22 09:43:44.549
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":286,"skipped":5306,"failed":0}
------------------------------
• [2.424 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:42.152
    Dec 14 09:43:42.153: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:43:42.153
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:42.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:42.276
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Dec 14 09:43:42.355: INFO: Waiting up to 5m0s for pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade" in namespace "kubelet-test-4927" to be "running and ready"
    Dec 14 09:43:42.380: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade": Phase="Pending", Reason="", readiness=false. Elapsed: 24.748736ms
    Dec 14 09:43:42.380: INFO: The phase of Pod busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:43:44.405: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade": Phase="Running", Reason="", readiness=true. Elapsed: 2.050055372s
    Dec 14 09:43:44.405: INFO: The phase of Pod busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade is Running (Ready = true)
    Dec 14 09:43:44.405: INFO: Pod "busybox-scheduling-929fb20b-7e57-4374-b443-ddb531a17ade" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:43:44.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4927" for this suite. 12/14/22 09:43:44.549
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:44.577
Dec 14 09:43:44.577: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:43:44.578
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:44.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:44.701
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-6e2a8273-9a2f-4ba3-935e-10d7b2d07438 12/14/22 09:43:44.749
STEP: Creating a pod to test consume secrets 12/14/22 09:43:44.774
Dec 14 09:43:44.813: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698" in namespace "projected-6203" to be "Succeeded or Failed"
Dec 14 09:43:44.838: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Pending", Reason="", readiness=false. Elapsed: 24.670749ms
Dec 14 09:43:46.865: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05174387s
Dec 14 09:43:48.863: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050440509s
STEP: Saw pod success 12/14/22 09:43:48.864
Dec 14 09:43:48.864: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698" satisfied condition "Succeeded or Failed"
Dec 14 09:43:48.889: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:43:48.922
Dec 14 09:43:48.961: INFO: Waiting for pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 to disappear
Dec 14 09:43:48.986: INFO: Pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:43:48.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6203" for this suite. 12/14/22 09:43:49.035
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":287,"skipped":5333,"failed":0}
------------------------------
• [4.485 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:44.577
    Dec 14 09:43:44.577: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:43:44.578
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:44.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:44.701
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-6e2a8273-9a2f-4ba3-935e-10d7b2d07438 12/14/22 09:43:44.749
    STEP: Creating a pod to test consume secrets 12/14/22 09:43:44.774
    Dec 14 09:43:44.813: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698" in namespace "projected-6203" to be "Succeeded or Failed"
    Dec 14 09:43:44.838: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Pending", Reason="", readiness=false. Elapsed: 24.670749ms
    Dec 14 09:43:46.865: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05174387s
    Dec 14 09:43:48.863: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050440509s
    STEP: Saw pod success 12/14/22 09:43:48.864
    Dec 14 09:43:48.864: INFO: Pod "pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698" satisfied condition "Succeeded or Failed"
    Dec 14 09:43:48.889: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:43:48.922
    Dec 14 09:43:48.961: INFO: Waiting for pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 to disappear
    Dec 14 09:43:48.986: INFO: Pod pod-projected-secrets-d1ea1951-6d39-4a94-8f12-14950532c698 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:43:48.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6203" for this suite. 12/14/22 09:43:49.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:49.063
Dec 14 09:43:49.063: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:43:49.063
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:49.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:49.186
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 12/14/22 09:43:49.233
Dec 14 09:43:49.266: INFO: Waiting up to 5m0s for pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb" in namespace "downward-api-9484" to be "running and ready"
Dec 14 09:43:49.290: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.444215ms
Dec 14 09:43:49.290: INFO: The phase of Pod annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:43:51.317: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb": Phase="Running", Reason="", readiness=true. Elapsed: 2.050697959s
Dec 14 09:43:51.317: INFO: The phase of Pod annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb is Running (Ready = true)
Dec 14 09:43:51.317: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb" satisfied condition "running and ready"
Dec 14 09:43:51.932: INFO: Successfully updated pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:43:56.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9484" for this suite. 12/14/22 09:43:56.081
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":288,"skipped":5356,"failed":0}
------------------------------
• [7.045 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:49.063
    Dec 14 09:43:49.063: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:43:49.063
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:49.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:49.186
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 12/14/22 09:43:49.233
    Dec 14 09:43:49.266: INFO: Waiting up to 5m0s for pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb" in namespace "downward-api-9484" to be "running and ready"
    Dec 14 09:43:49.290: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.444215ms
    Dec 14 09:43:49.290: INFO: The phase of Pod annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:43:51.317: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb": Phase="Running", Reason="", readiness=true. Elapsed: 2.050697959s
    Dec 14 09:43:51.317: INFO: The phase of Pod annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb is Running (Ready = true)
    Dec 14 09:43:51.317: INFO: Pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb" satisfied condition "running and ready"
    Dec 14 09:43:51.932: INFO: Successfully updated pod "annotationupdate88e8dacb-5a60-433d-b8e3-67a95486accb"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:43:56.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9484" for this suite. 12/14/22 09:43:56.081
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:56.108
Dec 14 09:43:56.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:43:56.109
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:56.185
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:56.234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:43:56.281
Dec 14 09:43:56.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea" in namespace "projected-3205" to be "Succeeded or Failed"
Dec 14 09:43:56.338: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Pending", Reason="", readiness=false. Elapsed: 25.301881ms
Dec 14 09:43:58.365: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051805418s
Dec 14 09:44:00.366: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052620793s
STEP: Saw pod success 12/14/22 09:44:00.366
Dec 14 09:44:00.366: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea" satisfied condition "Succeeded or Failed"
Dec 14 09:44:00.391: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea container client-container: <nil>
STEP: delete the pod 12/14/22 09:44:00.425
Dec 14 09:44:00.456: INFO: Waiting for pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea to disappear
Dec 14 09:44:00.480: INFO: Pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:44:00.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3205" for this suite. 12/14/22 09:44:00.532
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":289,"skipped":5361,"failed":0}
------------------------------
• [4.451 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:56.108
    Dec 14 09:43:56.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:43:56.109
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:56.185
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:56.234
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:43:56.281
    Dec 14 09:43:56.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea" in namespace "projected-3205" to be "Succeeded or Failed"
    Dec 14 09:43:56.338: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Pending", Reason="", readiness=false. Elapsed: 25.301881ms
    Dec 14 09:43:58.365: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051805418s
    Dec 14 09:44:00.366: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052620793s
    STEP: Saw pod success 12/14/22 09:44:00.366
    Dec 14 09:44:00.366: INFO: Pod "downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea" satisfied condition "Succeeded or Failed"
    Dec 14 09:44:00.391: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea container client-container: <nil>
    STEP: delete the pod 12/14/22 09:44:00.425
    Dec 14 09:44:00.456: INFO: Waiting for pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea to disappear
    Dec 14 09:44:00.480: INFO: Pod downwardapi-volume-ba347422-6dc2-4bf6-8060-704c0e1c49ea no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:44:00.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3205" for this suite. 12/14/22 09:44:00.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:00.56
Dec 14 09:44:00.560: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:44:00.561
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:00.636
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:00.684
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Dec 14 09:44:00.810: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 14 09:44:05.837: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 09:44:05.837
STEP: Scaling up "test-rs" replicaset  12/14/22 09:44:05.837
Dec 14 09:44:05.889: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 12/14/22 09:44:05.89
W1214 09:44:05.920104    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:44:05.947: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:44:07.464: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 2, AvailableReplicas 2
Dec 14 09:44:07.652: INFO: observed Replicaset test-rs in namespace replicaset-9931 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:44:07.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9931" for this suite. 12/14/22 09:44:07.705
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":290,"skipped":5377,"failed":0}
------------------------------
• [7.171 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:00.56
    Dec 14 09:44:00.560: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:44:00.561
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:00.636
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:00.684
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Dec 14 09:44:00.810: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec 14 09:44:05.837: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 09:44:05.837
    STEP: Scaling up "test-rs" replicaset  12/14/22 09:44:05.837
    Dec 14 09:44:05.889: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 12/14/22 09:44:05.89
    W1214 09:44:05.920104    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:44:05.943: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:44:05.947: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:44:07.464: INFO: observed ReplicaSet test-rs in namespace replicaset-9931 with ReadyReplicas 2, AvailableReplicas 2
    Dec 14 09:44:07.652: INFO: observed Replicaset test-rs in namespace replicaset-9931 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:44:07.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9931" for this suite. 12/14/22 09:44:07.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:07.734
Dec 14 09:44:07.734: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:44:07.735
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:07.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:07.858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-2d3f7913-ee37-4635-b4fd-bdc799475043 12/14/22 09:44:07.905
STEP: Creating a pod to test consume configMaps 12/14/22 09:44:07.93
Dec 14 09:44:07.962: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06" in namespace "projected-6482" to be "Succeeded or Failed"
Dec 14 09:44:07.992: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Pending", Reason="", readiness=false. Elapsed: 29.584087ms
Dec 14 09:44:10.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057372903s
Dec 14 09:44:12.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057147804s
STEP: Saw pod success 12/14/22 09:44:12.02
Dec 14 09:44:12.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06" satisfied condition "Succeeded or Failed"
Dec 14 09:44:12.049: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 container projected-configmap-volume-test: <nil>
STEP: delete the pod 12/14/22 09:44:12.08
Dec 14 09:44:12.121: INFO: Waiting for pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 to disappear
Dec 14 09:44:12.146: INFO: Pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:44:12.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6482" for this suite. 12/14/22 09:44:12.194
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":291,"skipped":5430,"failed":0}
------------------------------
• [4.486 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:07.734
    Dec 14 09:44:07.734: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:44:07.735
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:07.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:07.858
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-2d3f7913-ee37-4635-b4fd-bdc799475043 12/14/22 09:44:07.905
    STEP: Creating a pod to test consume configMaps 12/14/22 09:44:07.93
    Dec 14 09:44:07.962: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06" in namespace "projected-6482" to be "Succeeded or Failed"
    Dec 14 09:44:07.992: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Pending", Reason="", readiness=false. Elapsed: 29.584087ms
    Dec 14 09:44:10.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057372903s
    Dec 14 09:44:12.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057147804s
    STEP: Saw pod success 12/14/22 09:44:12.02
    Dec 14 09:44:12.020: INFO: Pod "pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06" satisfied condition "Succeeded or Failed"
    Dec 14 09:44:12.049: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:44:12.08
    Dec 14 09:44:12.121: INFO: Waiting for pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 to disappear
    Dec 14 09:44:12.146: INFO: Pod pod-projected-configmaps-337c6fb6-8886-4f8c-a77f-e316a02ade06 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:44:12.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6482" for this suite. 12/14/22 09:44:12.194
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:12.221
Dec 14 09:44:12.222: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:44:12.223
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:12.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:12.345
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e in namespace container-probe-1097 12/14/22 09:44:12.392
Dec 14 09:44:12.423: INFO: Waiting up to 5m0s for pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e" in namespace "container-probe-1097" to be "not pending"
Dec 14 09:44:12.450: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.990242ms
Dec 14 09:44:14.476: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052705774s
Dec 14 09:44:16.477: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Running", Reason="", readiness=true. Elapsed: 4.053284148s
Dec 14 09:44:16.477: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e" satisfied condition "not pending"
Dec 14 09:44:16.477: INFO: Started pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e in namespace container-probe-1097
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:44:16.477
Dec 14 09:44:16.502: INFO: Initial restart count of pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e is 0
Dec 14 09:45:05.168: INFO: Restart count of pod container-probe-1097/busybox-16cadb37-90fe-446c-9efe-278f7ad7477e is now 1 (48.66610427s elapsed)
STEP: deleting the pod 12/14/22 09:45:05.168
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:45:05.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1097" for this suite. 12/14/22 09:45:05.266
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":292,"skipped":5460,"failed":0}
------------------------------
• [53.072 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:12.221
    Dec 14 09:44:12.222: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:44:12.223
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:12.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:12.345
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e in namespace container-probe-1097 12/14/22 09:44:12.392
    Dec 14 09:44:12.423: INFO: Waiting up to 5m0s for pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e" in namespace "container-probe-1097" to be "not pending"
    Dec 14 09:44:12.450: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.990242ms
    Dec 14 09:44:14.476: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052705774s
    Dec 14 09:44:16.477: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e": Phase="Running", Reason="", readiness=true. Elapsed: 4.053284148s
    Dec 14 09:44:16.477: INFO: Pod "busybox-16cadb37-90fe-446c-9efe-278f7ad7477e" satisfied condition "not pending"
    Dec 14 09:44:16.477: INFO: Started pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e in namespace container-probe-1097
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:44:16.477
    Dec 14 09:44:16.502: INFO: Initial restart count of pod busybox-16cadb37-90fe-446c-9efe-278f7ad7477e is 0
    Dec 14 09:45:05.168: INFO: Restart count of pod container-probe-1097/busybox-16cadb37-90fe-446c-9efe-278f7ad7477e is now 1 (48.66610427s elapsed)
    STEP: deleting the pod 12/14/22 09:45:05.168
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:45:05.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1097" for this suite. 12/14/22 09:45:05.266
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:05.295
Dec 14 09:45:05.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:45:05.296
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:05.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:05.421
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:45:05.521
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:45:06.412
STEP: Deploying the webhook pod 12/14/22 09:45:06.44
STEP: Wait for the deployment to be ready 12/14/22 09:45:06.492
Dec 14 09:45:06.577: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:45:08.603
STEP: Verifying the service has paired with the endpoint 12/14/22 09:45:08.638
Dec 14 09:45:09.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Dec 14 09:45:09.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8288-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:45:09.739
STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:45:09.898
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:45:12.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9954" for this suite. 12/14/22 09:45:12.799
STEP: Destroying namespace "webhook-9954-markers" for this suite. 12/14/22 09:45:12.824
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":293,"skipped":5483,"failed":0}
------------------------------
• [7.744 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:05.295
    Dec 14 09:45:05.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:45:05.296
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:05.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:05.421
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:45:05.521
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:45:06.412
    STEP: Deploying the webhook pod 12/14/22 09:45:06.44
    STEP: Wait for the deployment to be ready 12/14/22 09:45:06.492
    Dec 14 09:45:06.577: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:45:08.603
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:45:08.638
    Dec 14 09:45:09.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Dec 14 09:45:09.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8288-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:45:09.739
    STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:45:09.898
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:45:12.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9954" for this suite. 12/14/22 09:45:12.799
    STEP: Destroying namespace "webhook-9954-markers" for this suite. 12/14/22 09:45:12.824
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:13.04
Dec 14 09:45:13.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:45:13.041
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:13.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:13.166
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 12/14/22 09:45:13.243
STEP: watching for Pod to be ready 12/14/22 09:45:13.275
Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions []
Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
Dec 14 09:45:13.740: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
Dec 14 09:45:14.636: INFO: Found Pod pod-test in namespace pods-5830 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 12/14/22 09:45:14.661
STEP: getting the Pod and ensuring that it's patched 12/14/22 09:45:14.713
STEP: replacing the Pod's status Ready condition to False 12/14/22 09:45:14.738
STEP: check the Pod again to ensure its Ready conditions are False 12/14/22 09:45:14.797
STEP: deleting the Pod via a Collection with a LabelSelector 12/14/22 09:45:14.797
STEP: watching for the Pod to be deleted 12/14/22 09:45:14.825
Dec 14 09:45:14.849: INFO: observed event type MODIFIED
Dec 14 09:45:15.102: INFO: observed event type MODIFIED
Dec 14 09:45:16.940: INFO: observed event type MODIFIED
Dec 14 09:45:17.645: INFO: observed event type MODIFIED
Dec 14 09:45:17.650: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:45:17.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5830" for this suite. 12/14/22 09:45:17.731
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":294,"skipped":5520,"failed":0}
------------------------------
• [4.717 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:13.04
    Dec 14 09:45:13.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:45:13.041
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:13.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:13.166
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 12/14/22 09:45:13.243
    STEP: watching for Pod to be ready 12/14/22 09:45:13.275
    Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
    Dec 14 09:45:13.299: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
    Dec 14 09:45:13.740: INFO: observed Pod pod-test in namespace pods-5830 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
    Dec 14 09:45:14.636: INFO: Found Pod pod-test in namespace pods-5830 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:45:13 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 12/14/22 09:45:14.661
    STEP: getting the Pod and ensuring that it's patched 12/14/22 09:45:14.713
    STEP: replacing the Pod's status Ready condition to False 12/14/22 09:45:14.738
    STEP: check the Pod again to ensure its Ready conditions are False 12/14/22 09:45:14.797
    STEP: deleting the Pod via a Collection with a LabelSelector 12/14/22 09:45:14.797
    STEP: watching for the Pod to be deleted 12/14/22 09:45:14.825
    Dec 14 09:45:14.849: INFO: observed event type MODIFIED
    Dec 14 09:45:15.102: INFO: observed event type MODIFIED
    Dec 14 09:45:16.940: INFO: observed event type MODIFIED
    Dec 14 09:45:17.645: INFO: observed event type MODIFIED
    Dec 14 09:45:17.650: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:45:17.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5830" for this suite. 12/14/22 09:45:17.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:17.757
Dec 14 09:45:17.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:45:17.758
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:17.834
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:17.881
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 12/14/22 09:45:17.928
Dec 14 09:45:17.928: INFO: Creating e2e-svc-a-gw7t9
Dec 14 09:45:17.977: INFO: Creating e2e-svc-b-6wh7x
Dec 14 09:45:18.031: INFO: Creating e2e-svc-c-xmkrr
STEP: deleting service collection 12/14/22 09:45:18.093
Dec 14 09:45:18.170: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:45:18.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2055" for this suite. 12/14/22 09:45:18.203
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":295,"skipped":5531,"failed":0}
------------------------------
• [0.475 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:17.757
    Dec 14 09:45:17.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:45:17.758
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:17.834
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:17.881
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 12/14/22 09:45:17.928
    Dec 14 09:45:17.928: INFO: Creating e2e-svc-a-gw7t9
    Dec 14 09:45:17.977: INFO: Creating e2e-svc-b-6wh7x
    Dec 14 09:45:18.031: INFO: Creating e2e-svc-c-xmkrr
    STEP: deleting service collection 12/14/22 09:45:18.093
    Dec 14 09:45:18.170: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:45:18.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2055" for this suite. 12/14/22 09:45:18.203
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:18.233
Dec 14 09:45:18.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:45:18.234
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:18.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:18.358
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Dec 14 09:45:18.406: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 create -f -'
Dec 14 09:45:19.434: INFO: stderr: ""
Dec 14 09:45:19.434: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Dec 14 09:45:19.434: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 create -f -'
Dec 14 09:45:20.528: INFO: stderr: ""
Dec 14 09:45:20.528: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 09:45:20.528
Dec 14 09:45:21.554: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:45:21.554: INFO: Found 1 / 1
Dec 14 09:45:21.554: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 14 09:45:21.580: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:45:21.580: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 09:45:21.580: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe pod agnhost-primary-2n6fn'
Dec 14 09:45:21.782: INFO: stderr: ""
Dec 14 09:45:21.782: INFO: stdout: "Name:             agnhost-primary-2n6fn\nNamespace:        kubectl-4943\nPriority:         0\nService Account:  default\nNode:             shoot--it--tm0ct-io0-worker-1-6f755-hwmlx/10.250.0.5\nStart Time:       Wed, 14 Dec 2022 09:45:19 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: a55007c06b5d9fb81d27f650e3338ac05769edcbaf737078e5ab49fe80a3ed15\n                  cni.projectcalico.org/podIP: 100.64.0.226/32\n                  cni.projectcalico.org/podIPs: 100.64.0.226/32\nStatus:           Running\nIP:               100.64.0.226\nIPs:\n  IP:           100.64.0.226\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://d6c02405cc9e207422b3b07bdfaeceb27c46cfdc08db54dcd2cac87c084e2215\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Dec 2022 09:45:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.tm0ct-io0.it.internal.staging.k8s.ondemand.com\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gtrft (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-gtrft:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-4943/agnhost-primary-2n6fn to shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Dec 14 09:45:21.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe rc agnhost-primary'
Dec 14 09:45:22.006: INFO: stderr: ""
Dec 14 09:45:22.006: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-4943\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-2n6fn\n"
Dec 14 09:45:22.006: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe service agnhost-primary'
Dec 14 09:45:22.229: INFO: stderr: ""
Dec 14 09:45:22.229: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-4943\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.110.73.3\nIPs:               100.110.73.3\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.0.226:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 14 09:45:22.281: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx'
Dec 14 09:45:22.642: INFO: stderr: ""
Dec 14 09:45:22.642: INFO: stdout: "Name:               shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=northeurope\n                    failure-domain.beta.kubernetes.io/zone=1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=true\n                    node.kubernetes.io/instance-type=Standard_DS2_v2\n                    node.kubernetes.io/role=node\n                    topology.disk.csi.azure.com/zone=\n                    topology.kubernetes.io/region=northeurope\n                    topology.kubernetes.io/zone=1\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.4\n                    worker.gardener.cloud/pool=worker-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: 967cf49ae6a4849b8a2a99599a3bfbc6bd3d81c73c3ec58349793c7580e5df0c\n                    csi.volume.kubernetes.io/nodeid:\n                      {\"disk.csi.azure.com\":\"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\",\"file.csi.azure.com\":\"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"true\",\"no...\n                    projectcalico.org/IPv4Address: 10.250.0.5/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Dec 2022 08:09:34 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 14 Dec 2022 09:45:16 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ClusterNetworkProblem         False   Wed, 14 Dec 2022 09:42:34 +0000   Wed, 14 Dec 2022 08:17:17 +0000   NoNetworkProblems               no cluster network problems\n  HostNetworkProblem            False   Wed, 14 Dec 2022 09:44:11 +0000   Wed, 14 Dec 2022 08:18:50 +0000   NoNetworkProblems               no host network problems\n  CorruptDockerOverlay2         False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Wed, 14 Dec 2022 08:15:40 +0000   Wed, 14 Dec 2022 08:15:40 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:10:15 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.0.5\n  Hostname:    shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nCapacity:\n  cpu:                  2\n  ephemeral-storage:    34167716Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7115036Ki\n  pods:                 110\nAllocatable:\n  cpu:                  1920m\n  ephemeral-storage:    33238354099\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               5964060Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 275b3b84ec5949e3a436169f064888bd\n  System UUID:                478f6750-194a-b741-9adc-b2232df7b247\n  Boot ID:                    dba42ff1-0674-4f9c-9329-952dfc1d050f\n  Kernel Version:             5.15.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 934.1\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      100.64.0.0/24\nPodCIDRs:                     100.64.0.0/24\nProviderID:                   azure:///subscriptions/0b9904be-2a50-4fda-a947-c5f1b1d07666/resourceGroups/shoot--it--tm0ct-io0/providers/Microsoft.Compute/virtualMachines/shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nNon-terminated Pods:          (17 in total)\n  Namespace                   Name                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits   Age\n  ---------                   ----                                   ------------  ----------  ---------------  -------------   ---\n  kube-system                 apiserver-proxy-fdh6d                  40m (2%)      0 (0%)      40Mi (0%)        1114Mi (19%)    95m\n  kube-system                 blackbox-exporter-59447f4c55-gg28g     10m (0%)      0 (0%)      25Mi (0%)        128Mi (2%)      98m\n  kube-system                 blackbox-exporter-59447f4c55-l4sl8     10m (0%)      0 (0%)      25Mi (0%)        128Mi (2%)      98m\n  kube-system                 calico-node-nm9fv                      250m (13%)    0 (0%)      100Mi (1%)       2800Mi (48%)    95m\n  kube-system                 cloud-node-manager-d7nl7               50m (2%)      200m (10%)  50Mi (0%)        200Mi (3%)      95m\n  kube-system                 csi-driver-node-disk-ffbkk             42m (2%)      0 (0%)      114Mi (1%)       750Mi (12%)     95m\n  kube-system                 csi-driver-node-file-fqj5x             42m (2%)      0 (0%)      114Mi (1%)       750Mi (12%)     95m\n  kube-system                 egress-filter-applier-ch9gv            50m (2%)      0 (0%)      64Mi (1%)        256Mi (4%)      95m\n  kube-system                 kube-proxy-worker-1-v1.25.4-9z98n      34m (1%)      0 (0%)      47753748 (0%)    2Gi (35%)       58m\n  kube-system                 metrics-server-8688dbf74b-kz62g        50m (2%)      0 (0%)      60Mi (1%)        1Gi (17%)       98m\n  kube-system                 metrics-server-8688dbf74b-twwq4        50m (2%)      0 (0%)      60Mi (1%)        1Gi (17%)       98m\n  kube-system                 network-problem-detector-host-hs2n4    10m (0%)      50m (2%)    32Mi (0%)        64Mi (1%)       95m\n  kube-system                 network-problem-detector-pod-rk4t7     10m (0%)      50m (2%)    32Mi (0%)        64Mi (1%)       95m\n  kube-system                 node-exporter-tx6hc                    50m (2%)      0 (0%)      50Mi (0%)        250Mi (4%)      95m\n  kube-system                 node-local-dns-d8jbc                   11m (0%)      0 (0%)      36253748 (0%)    145014992 (2%)  71m\n  kube-system                 node-problem-detector-p9pfw            11m (0%)      0 (0%)      49566436 (0%)    120Mi (2%)      37m\n  kubectl-4943                agnhost-primary-2n6fn                  0 (0%)        0 (0%)      0 (0%)           0 (0%)          3s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests         Limits\n  --------             --------         ------\n  cpu                  720m (37%)       300m (15%)\n  memory               936783148 (15%)  11385749712 (186%)\n  ephemeral-storage    0 (0%)           0 (0%)\n  hugepages-1Gi        0 (0%)           0 (0%)\n  hugepages-2Mi        0 (0%)           0 (0%)\n  example.com/fakecpu  0                0\nEvents:\n  Type    Reason    Age   From        Message\n  ----    ------    ----  ----        -------\n  Normal  Starting  58m   kube-proxy  \n"
Dec 14 09:45:22.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe namespace kubectl-4943'
Dec 14 09:45:22.865: INFO: stderr: ""
Dec 14 09:45:22.865: INFO: stdout: "Name:         kubectl-4943\nLabels:       e2e-framework=kubectl\n              e2e-run=9ae8086e-b003-4dc8-a6f0-714e56cd5c18\n              kubernetes.io/metadata.name=kubectl-4943\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:45:22.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4943" for this suite. 12/14/22 09:45:22.913
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":296,"skipped":5544,"failed":0}
------------------------------
• [4.706 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:18.233
    Dec 14 09:45:18.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:45:18.234
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:18.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:18.358
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Dec 14 09:45:18.406: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 create -f -'
    Dec 14 09:45:19.434: INFO: stderr: ""
    Dec 14 09:45:19.434: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Dec 14 09:45:19.434: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 create -f -'
    Dec 14 09:45:20.528: INFO: stderr: ""
    Dec 14 09:45:20.528: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 09:45:20.528
    Dec 14 09:45:21.554: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:45:21.554: INFO: Found 1 / 1
    Dec 14 09:45:21.554: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec 14 09:45:21.580: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:45:21.580: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 09:45:21.580: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe pod agnhost-primary-2n6fn'
    Dec 14 09:45:21.782: INFO: stderr: ""
    Dec 14 09:45:21.782: INFO: stdout: "Name:             agnhost-primary-2n6fn\nNamespace:        kubectl-4943\nPriority:         0\nService Account:  default\nNode:             shoot--it--tm0ct-io0-worker-1-6f755-hwmlx/10.250.0.5\nStart Time:       Wed, 14 Dec 2022 09:45:19 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: a55007c06b5d9fb81d27f650e3338ac05769edcbaf737078e5ab49fe80a3ed15\n                  cni.projectcalico.org/podIP: 100.64.0.226/32\n                  cni.projectcalico.org/podIPs: 100.64.0.226/32\nStatus:           Running\nIP:               100.64.0.226\nIPs:\n  IP:           100.64.0.226\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://d6c02405cc9e207422b3b07bdfaeceb27c46cfdc08db54dcd2cac87c084e2215\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Dec 2022 09:45:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.tm0ct-io0.it.internal.staging.k8s.ondemand.com\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gtrft (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-gtrft:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-4943/agnhost-primary-2n6fn to shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Dec 14 09:45:21.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe rc agnhost-primary'
    Dec 14 09:45:22.006: INFO: stderr: ""
    Dec 14 09:45:22.006: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-4943\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-2n6fn\n"
    Dec 14 09:45:22.006: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe service agnhost-primary'
    Dec 14 09:45:22.229: INFO: stderr: ""
    Dec 14 09:45:22.229: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-4943\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.110.73.3\nIPs:               100.110.73.3\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.0.226:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Dec 14 09:45:22.281: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx'
    Dec 14 09:45:22.642: INFO: stderr: ""
    Dec 14 09:45:22.642: INFO: stdout: "Name:               shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=northeurope\n                    failure-domain.beta.kubernetes.io/zone=1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=true\n                    node.kubernetes.io/instance-type=Standard_DS2_v2\n                    node.kubernetes.io/role=node\n                    topology.disk.csi.azure.com/zone=\n                    topology.kubernetes.io/region=northeurope\n                    topology.kubernetes.io/zone=1\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.4\n                    worker.gardener.cloud/pool=worker-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: 967cf49ae6a4849b8a2a99599a3bfbc6bd3d81c73c3ec58349793c7580e5df0c\n                    csi.volume.kubernetes.io/nodeid:\n                      {\"disk.csi.azure.com\":\"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\",\"file.csi.azure.com\":\"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"true\",\"no...\n                    projectcalico.org/IPv4Address: 10.250.0.5/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Dec 2022 08:09:34 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 14 Dec 2022 09:45:16 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ClusterNetworkProblem         False   Wed, 14 Dec 2022 09:42:34 +0000   Wed, 14 Dec 2022 08:17:17 +0000   NoNetworkProblems               no cluster network problems\n  HostNetworkProblem            False   Wed, 14 Dec 2022 09:44:11 +0000   Wed, 14 Dec 2022 08:18:50 +0000   NoNetworkProblems               no host network problems\n  CorruptDockerOverlay2         False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Wed, 14 Dec 2022 09:43:20 +0000   Wed, 14 Dec 2022 09:08:16 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Wed, 14 Dec 2022 08:15:40 +0000   Wed, 14 Dec 2022 08:15:40 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:09:34 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Wed, 14 Dec 2022 09:45:12 +0000   Wed, 14 Dec 2022 08:10:15 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.0.5\n  Hostname:    shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nCapacity:\n  cpu:                  2\n  ephemeral-storage:    34167716Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7115036Ki\n  pods:                 110\nAllocatable:\n  cpu:                  1920m\n  ephemeral-storage:    33238354099\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               5964060Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 275b3b84ec5949e3a436169f064888bd\n  System UUID:                478f6750-194a-b741-9adc-b2232df7b247\n  Boot ID:                    dba42ff1-0674-4f9c-9329-952dfc1d050f\n  Kernel Version:             5.15.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 934.1\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      100.64.0.0/24\nPodCIDRs:                     100.64.0.0/24\nProviderID:                   azure:///subscriptions/0b9904be-2a50-4fda-a947-c5f1b1d07666/resourceGroups/shoot--it--tm0ct-io0/providers/Microsoft.Compute/virtualMachines/shoot--it--tm0ct-io0-worker-1-6f755-hwmlx\nNon-terminated Pods:          (17 in total)\n  Namespace                   Name                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits   Age\n  ---------                   ----                                   ------------  ----------  ---------------  -------------   ---\n  kube-system                 apiserver-proxy-fdh6d                  40m (2%)      0 (0%)      40Mi (0%)        1114Mi (19%)    95m\n  kube-system                 blackbox-exporter-59447f4c55-gg28g     10m (0%)      0 (0%)      25Mi (0%)        128Mi (2%)      98m\n  kube-system                 blackbox-exporter-59447f4c55-l4sl8     10m (0%)      0 (0%)      25Mi (0%)        128Mi (2%)      98m\n  kube-system                 calico-node-nm9fv                      250m (13%)    0 (0%)      100Mi (1%)       2800Mi (48%)    95m\n  kube-system                 cloud-node-manager-d7nl7               50m (2%)      200m (10%)  50Mi (0%)        200Mi (3%)      95m\n  kube-system                 csi-driver-node-disk-ffbkk             42m (2%)      0 (0%)      114Mi (1%)       750Mi (12%)     95m\n  kube-system                 csi-driver-node-file-fqj5x             42m (2%)      0 (0%)      114Mi (1%)       750Mi (12%)     95m\n  kube-system                 egress-filter-applier-ch9gv            50m (2%)      0 (0%)      64Mi (1%)        256Mi (4%)      95m\n  kube-system                 kube-proxy-worker-1-v1.25.4-9z98n      34m (1%)      0 (0%)      47753748 (0%)    2Gi (35%)       58m\n  kube-system                 metrics-server-8688dbf74b-kz62g        50m (2%)      0 (0%)      60Mi (1%)        1Gi (17%)       98m\n  kube-system                 metrics-server-8688dbf74b-twwq4        50m (2%)      0 (0%)      60Mi (1%)        1Gi (17%)       98m\n  kube-system                 network-problem-detector-host-hs2n4    10m (0%)      50m (2%)    32Mi (0%)        64Mi (1%)       95m\n  kube-system                 network-problem-detector-pod-rk4t7     10m (0%)      50m (2%)    32Mi (0%)        64Mi (1%)       95m\n  kube-system                 node-exporter-tx6hc                    50m (2%)      0 (0%)      50Mi (0%)        250Mi (4%)      95m\n  kube-system                 node-local-dns-d8jbc                   11m (0%)      0 (0%)      36253748 (0%)    145014992 (2%)  71m\n  kube-system                 node-problem-detector-p9pfw            11m (0%)      0 (0%)      49566436 (0%)    120Mi (2%)      37m\n  kubectl-4943                agnhost-primary-2n6fn                  0 (0%)        0 (0%)      0 (0%)           0 (0%)          3s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests         Limits\n  --------             --------         ------\n  cpu                  720m (37%)       300m (15%)\n  memory               936783148 (15%)  11385749712 (186%)\n  ephemeral-storage    0 (0%)           0 (0%)\n  hugepages-1Gi        0 (0%)           0 (0%)\n  hugepages-2Mi        0 (0%)           0 (0%)\n  example.com/fakecpu  0                0\nEvents:\n  Type    Reason    Age   From        Message\n  ----    ------    ----  ----        -------\n  Normal  Starting  58m   kube-proxy  \n"
    Dec 14 09:45:22.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4943 describe namespace kubectl-4943'
    Dec 14 09:45:22.865: INFO: stderr: ""
    Dec 14 09:45:22.865: INFO: stdout: "Name:         kubectl-4943\nLabels:       e2e-framework=kubectl\n              e2e-run=9ae8086e-b003-4dc8-a6f0-714e56cd5c18\n              kubernetes.io/metadata.name=kubectl-4943\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:45:22.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4943" for this suite. 12/14/22 09:45:22.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:22.94
Dec 14 09:45:22.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:45:22.941
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:23.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:23.062
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:45:23.11
Dec 14 09:45:23.141: INFO: Waiting up to 5m0s for pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e" in namespace "downward-api-915" to be "Succeeded or Failed"
Dec 14 09:45:23.166: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.865571ms
Dec 14 09:45:25.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051777562s
Dec 14 09:45:27.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051707661s
STEP: Saw pod success 12/14/22 09:45:27.193
Dec 14 09:45:27.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e" satisfied condition "Succeeded or Failed"
Dec 14 09:45:27.218: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e container client-container: <nil>
STEP: delete the pod 12/14/22 09:45:27.249
Dec 14 09:45:27.281: INFO: Waiting for pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e to disappear
Dec 14 09:45:27.307: INFO: Pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:45:27.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-915" for this suite. 12/14/22 09:45:27.355
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":297,"skipped":5552,"failed":0}
------------------------------
• [4.441 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:22.94
    Dec 14 09:45:22.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:45:22.941
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:23.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:23.062
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:45:23.11
    Dec 14 09:45:23.141: INFO: Waiting up to 5m0s for pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e" in namespace "downward-api-915" to be "Succeeded or Failed"
    Dec 14 09:45:23.166: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.865571ms
    Dec 14 09:45:25.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051777562s
    Dec 14 09:45:27.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051707661s
    STEP: Saw pod success 12/14/22 09:45:27.193
    Dec 14 09:45:27.193: INFO: Pod "downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e" satisfied condition "Succeeded or Failed"
    Dec 14 09:45:27.218: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e container client-container: <nil>
    STEP: delete the pod 12/14/22 09:45:27.249
    Dec 14 09:45:27.281: INFO: Waiting for pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e to disappear
    Dec 14 09:45:27.307: INFO: Pod downwardapi-volume-085ed583-a9d6-4ecd-8caa-05009ade746e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:45:27.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-915" for this suite. 12/14/22 09:45:27.355
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:27.383
Dec 14 09:45:27.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:45:27.384
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:27.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:27.509
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:45:27.609
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:45:28.036
STEP: Deploying the webhook pod 12/14/22 09:45:28.061
STEP: Wait for the deployment to be ready 12/14/22 09:45:28.116
Dec 14 09:45:28.192: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:45:30.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:45:32.219
STEP: Verifying the service has paired with the endpoint 12/14/22 09:45:32.253
Dec 14 09:45:33.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 12/14/22 09:45:33.28
STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/14/22 09:45:33.469
STEP: Creating a configMap that should not be mutated 12/14/22 09:45:33.494
STEP: Patching a mutating webhook configuration's rules to include the create operation 12/14/22 09:45:33.546
STEP: Creating a configMap that should be mutated 12/14/22 09:45:33.572
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:45:33.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3950" for this suite. 12/14/22 09:45:33.816
STEP: Destroying namespace "webhook-3950-markers" for this suite. 12/14/22 09:45:33.844
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":298,"skipped":5592,"failed":0}
------------------------------
• [6.615 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:27.383
    Dec 14 09:45:27.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:45:27.384
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:27.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:27.509
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:45:27.609
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:45:28.036
    STEP: Deploying the webhook pod 12/14/22 09:45:28.061
    STEP: Wait for the deployment to be ready 12/14/22 09:45:28.116
    Dec 14 09:45:28.192: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:45:30.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 45, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:45:32.219
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:45:32.253
    Dec 14 09:45:33.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 12/14/22 09:45:33.28
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/14/22 09:45:33.469
    STEP: Creating a configMap that should not be mutated 12/14/22 09:45:33.494
    STEP: Patching a mutating webhook configuration's rules to include the create operation 12/14/22 09:45:33.546
    STEP: Creating a configMap that should be mutated 12/14/22 09:45:33.572
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:45:33.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3950" for this suite. 12/14/22 09:45:33.816
    STEP: Destroying namespace "webhook-3950-markers" for this suite. 12/14/22 09:45:33.844
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:33.998
Dec 14 09:45:33.998: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:45:33.999
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:34.074
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:34.122
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 12/14/22 09:45:34.196
STEP: Verify that the required pods have come up. 12/14/22 09:45:34.222
Dec 14 09:45:34.247: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 09:45:34.247
Dec 14 09:45:34.247: INFO: Waiting up to 5m0s for pod "test-rs-5nmc5" in namespace "replicaset-684" to be "running"
Dec 14 09:45:34.274: INFO: Pod "test-rs-5nmc5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.55691ms
Dec 14 09:45:36.300: INFO: Pod "test-rs-5nmc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.052865633s
Dec 14 09:45:36.300: INFO: Pod "test-rs-5nmc5" satisfied condition "running"
STEP: Getting /status 12/14/22 09:45:36.3
Dec 14 09:45:36.326: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 12/14/22 09:45:36.326
Dec 14 09:45:36.377: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 12/14/22 09:45:36.377
Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: ADDED
Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.403: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.403: INFO: Found replicaset test-rs in namespace replicaset-684 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 09:45:36.403: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 12/14/22 09:45:36.403
Dec 14 09:45:36.403: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 09:45:36.429: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 12/14/22 09:45:36.429
Dec 14 09:45:36.453: INFO: Observed &ReplicaSet event: ADDED
Dec 14 09:45:36.453: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.454: INFO: Observed replicaset test-rs in namespace replicaset-684 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:45:36.454: INFO: Found replicaset test-rs in namespace replicaset-684 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Dec 14 09:45:36.454: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:45:36.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-684" for this suite. 12/14/22 09:45:36.501
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":299,"skipped":5610,"failed":0}
------------------------------
• [2.529 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:33.998
    Dec 14 09:45:33.998: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:45:33.999
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:34.074
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:34.122
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 12/14/22 09:45:34.196
    STEP: Verify that the required pods have come up. 12/14/22 09:45:34.222
    Dec 14 09:45:34.247: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 09:45:34.247
    Dec 14 09:45:34.247: INFO: Waiting up to 5m0s for pod "test-rs-5nmc5" in namespace "replicaset-684" to be "running"
    Dec 14 09:45:34.274: INFO: Pod "test-rs-5nmc5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.55691ms
    Dec 14 09:45:36.300: INFO: Pod "test-rs-5nmc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.052865633s
    Dec 14 09:45:36.300: INFO: Pod "test-rs-5nmc5" satisfied condition "running"
    STEP: Getting /status 12/14/22 09:45:36.3
    Dec 14 09:45:36.326: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 12/14/22 09:45:36.326
    Dec 14 09:45:36.377: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 12/14/22 09:45:36.377
    Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: ADDED
    Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.402: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.403: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.403: INFO: Found replicaset test-rs in namespace replicaset-684 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 09:45:36.403: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 12/14/22 09:45:36.403
    Dec 14 09:45:36.403: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 09:45:36.429: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 12/14/22 09:45:36.429
    Dec 14 09:45:36.453: INFO: Observed &ReplicaSet event: ADDED
    Dec 14 09:45:36.453: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.454: INFO: Observed replicaset test-rs in namespace replicaset-684 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:45:36.454: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:45:36.454: INFO: Found replicaset test-rs in namespace replicaset-684 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Dec 14 09:45:36.454: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:45:36.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-684" for this suite. 12/14/22 09:45:36.501
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:36.528
Dec 14 09:45:36.528: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:45:36.529
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:36.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:36.652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 12/14/22 09:45:36.699
Dec 14 09:45:36.730: INFO: Waiting up to 5m0s for pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f" in namespace "projected-5131" to be "running and ready"
Dec 14 09:45:36.756: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.714286ms
Dec 14 09:45:36.756: INFO: The phase of Pod annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:45:38.782: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f": Phase="Running", Reason="", readiness=true. Elapsed: 2.051562445s
Dec 14 09:45:38.782: INFO: The phase of Pod annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f is Running (Ready = true)
Dec 14 09:45:38.782: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f" satisfied condition "running and ready"
Dec 14 09:45:39.395: INFO: Successfully updated pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:45:43.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5131" for this suite. 12/14/22 09:45:43.549
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":300,"skipped":5610,"failed":0}
------------------------------
• [7.047 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:36.528
    Dec 14 09:45:36.528: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:45:36.529
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:36.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:36.652
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 12/14/22 09:45:36.699
    Dec 14 09:45:36.730: INFO: Waiting up to 5m0s for pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f" in namespace "projected-5131" to be "running and ready"
    Dec 14 09:45:36.756: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.714286ms
    Dec 14 09:45:36.756: INFO: The phase of Pod annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:45:38.782: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f": Phase="Running", Reason="", readiness=true. Elapsed: 2.051562445s
    Dec 14 09:45:38.782: INFO: The phase of Pod annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f is Running (Ready = true)
    Dec 14 09:45:38.782: INFO: Pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f" satisfied condition "running and ready"
    Dec 14 09:45:39.395: INFO: Successfully updated pod "annotationupdatef8cf2ada-ccf5-42c8-81e8-26453190a00f"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:45:43.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5131" for this suite. 12/14/22 09:45:43.549
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:43.576
Dec 14 09:45:43.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 09:45:43.577
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:43.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:43.703
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 09:45:43.75
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-4npl 12/14/22 09:45:43.801
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 09:45:43.802
Dec 14 09:45:43.834: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4npl" in namespace "subpath-6133" to be "Succeeded or Failed"
Dec 14 09:45:43.858: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Pending", Reason="", readiness=false. Elapsed: 24.391716ms
Dec 14 09:45:45.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 2.051565805s
Dec 14 09:45:47.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 4.050779117s
Dec 14 09:45:49.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 6.050575747s
Dec 14 09:45:51.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 8.051595552s
Dec 14 09:45:53.887: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 10.053772916s
Dec 14 09:45:55.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 12.05096694s
Dec 14 09:45:57.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 14.051178419s
Dec 14 09:45:59.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 16.050445261s
Dec 14 09:46:01.886: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 18.05248387s
Dec 14 09:46:03.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 20.050045219s
Dec 14 09:46:05.886: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=false. Elapsed: 22.052046489s
Dec 14 09:46:07.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051602238s
STEP: Saw pod success 12/14/22 09:46:07.885
Dec 14 09:46:07.885: INFO: Pod "pod-subpath-test-downwardapi-4npl" satisfied condition "Succeeded or Failed"
Dec 14 09:46:07.911: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-downwardapi-4npl container test-container-subpath-downwardapi-4npl: <nil>
STEP: delete the pod 12/14/22 09:46:07.941
Dec 14 09:46:07.977: INFO: Waiting for pod pod-subpath-test-downwardapi-4npl to disappear
Dec 14 09:46:08.002: INFO: Pod pod-subpath-test-downwardapi-4npl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4npl 12/14/22 09:46:08.002
Dec 14 09:46:08.002: INFO: Deleting pod "pod-subpath-test-downwardapi-4npl" in namespace "subpath-6133"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 09:46:08.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6133" for this suite. 12/14/22 09:46:08.079
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":301,"skipped":5621,"failed":0}
------------------------------
• [24.530 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:43.576
    Dec 14 09:45:43.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 09:45:43.577
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:43.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:43.703
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 09:45:43.75
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-4npl 12/14/22 09:45:43.801
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 09:45:43.802
    Dec 14 09:45:43.834: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4npl" in namespace "subpath-6133" to be "Succeeded or Failed"
    Dec 14 09:45:43.858: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Pending", Reason="", readiness=false. Elapsed: 24.391716ms
    Dec 14 09:45:45.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 2.051565805s
    Dec 14 09:45:47.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 4.050779117s
    Dec 14 09:45:49.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 6.050575747s
    Dec 14 09:45:51.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 8.051595552s
    Dec 14 09:45:53.887: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 10.053772916s
    Dec 14 09:45:55.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 12.05096694s
    Dec 14 09:45:57.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 14.051178419s
    Dec 14 09:45:59.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 16.050445261s
    Dec 14 09:46:01.886: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 18.05248387s
    Dec 14 09:46:03.884: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=true. Elapsed: 20.050045219s
    Dec 14 09:46:05.886: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Running", Reason="", readiness=false. Elapsed: 22.052046489s
    Dec 14 09:46:07.885: INFO: Pod "pod-subpath-test-downwardapi-4npl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051602238s
    STEP: Saw pod success 12/14/22 09:46:07.885
    Dec 14 09:46:07.885: INFO: Pod "pod-subpath-test-downwardapi-4npl" satisfied condition "Succeeded or Failed"
    Dec 14 09:46:07.911: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-downwardapi-4npl container test-container-subpath-downwardapi-4npl: <nil>
    STEP: delete the pod 12/14/22 09:46:07.941
    Dec 14 09:46:07.977: INFO: Waiting for pod pod-subpath-test-downwardapi-4npl to disappear
    Dec 14 09:46:08.002: INFO: Pod pod-subpath-test-downwardapi-4npl no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-4npl 12/14/22 09:46:08.002
    Dec 14 09:46:08.002: INFO: Deleting pod "pod-subpath-test-downwardapi-4npl" in namespace "subpath-6133"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 09:46:08.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6133" for this suite. 12/14/22 09:46:08.079
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:08.106
Dec 14 09:46:08.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:46:08.107
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:08.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:08.233
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 12/14/22 09:46:08.281
STEP: Creating a ResourceQuota 12/14/22 09:46:13.306
STEP: Ensuring resource quota status is calculated 12/14/22 09:46:13.332
STEP: Creating a Pod that fits quota 12/14/22 09:46:15.359
STEP: Ensuring ResourceQuota status captures the pod usage 12/14/22 09:46:15.396
STEP: Not allowing a pod to be created that exceeds remaining quota 12/14/22 09:46:17.422
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/14/22 09:46:17.451
STEP: Ensuring a pod cannot update its resource requirements 12/14/22 09:46:17.479
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/14/22 09:46:17.505
STEP: Deleting the pod 12/14/22 09:46:19.531
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:46:19.564
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:46:21.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-606" for this suite. 12/14/22 09:46:21.639
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":302,"skipped":5621,"failed":0}
------------------------------
• [13.559 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:08.106
    Dec 14 09:46:08.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:46:08.107
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:08.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:08.233
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 12/14/22 09:46:08.281
    STEP: Creating a ResourceQuota 12/14/22 09:46:13.306
    STEP: Ensuring resource quota status is calculated 12/14/22 09:46:13.332
    STEP: Creating a Pod that fits quota 12/14/22 09:46:15.359
    STEP: Ensuring ResourceQuota status captures the pod usage 12/14/22 09:46:15.396
    STEP: Not allowing a pod to be created that exceeds remaining quota 12/14/22 09:46:17.422
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/14/22 09:46:17.451
    STEP: Ensuring a pod cannot update its resource requirements 12/14/22 09:46:17.479
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/14/22 09:46:17.505
    STEP: Deleting the pod 12/14/22 09:46:19.531
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:46:19.564
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:46:21.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-606" for this suite. 12/14/22 09:46:21.639
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:21.666
Dec 14 09:46:21.666: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:46:21.667
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:21.742
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:21.789
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2203 12/14/22 09:46:21.838
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 12/14/22 09:46:21.863
Dec 14 09:46:21.915: INFO: Found 1 stateful pods, waiting for 3
Dec 14 09:46:31.942: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:46:31.942: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:46:31.942: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 09:46:32.017
Dec 14 09:46:32.081: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/14/22 09:46:32.081
STEP: Not applying an update when the partition is greater than the number of replicas 12/14/22 09:46:42.189
STEP: Performing a canary update 12/14/22 09:46:42.189
Dec 14 09:46:42.251: INFO: Updating stateful set ss2
Dec 14 09:46:42.302: INFO: Waiting for Pod statefulset-2203/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 12/14/22 09:46:52.358
Dec 14 09:46:52.476: INFO: Found 2 stateful pods, waiting for 3
Dec 14 09:47:02.506: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:47:02.506: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:47:02.506: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 12/14/22 09:47:02.556
Dec 14 09:47:02.618: INFO: Updating stateful set ss2
Dec 14 09:47:02.667: INFO: Waiting for Pod statefulset-2203/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Dec 14 09:47:12.785: INFO: Updating stateful set ss2
Dec 14 09:47:12.835: INFO: Waiting for StatefulSet statefulset-2203/ss2 to complete update
Dec 14 09:47:12.835: INFO: Waiting for Pod statefulset-2203/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:47:22.887: INFO: Deleting all statefulset in ns statefulset-2203
Dec 14 09:47:22.911: INFO: Scaling statefulset ss2 to 0
Dec 14 09:47:33.026: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:47:33.053: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:47:33.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2203" for this suite. 12/14/22 09:47:33.179
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":303,"skipped":5632,"failed":0}
------------------------------
• [71.538 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:21.666
    Dec 14 09:46:21.666: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:46:21.667
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:21.742
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:21.789
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2203 12/14/22 09:46:21.838
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 12/14/22 09:46:21.863
    Dec 14 09:46:21.915: INFO: Found 1 stateful pods, waiting for 3
    Dec 14 09:46:31.942: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:46:31.942: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:46:31.942: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 09:46:32.017
    Dec 14 09:46:32.081: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/14/22 09:46:32.081
    STEP: Not applying an update when the partition is greater than the number of replicas 12/14/22 09:46:42.189
    STEP: Performing a canary update 12/14/22 09:46:42.189
    Dec 14 09:46:42.251: INFO: Updating stateful set ss2
    Dec 14 09:46:42.302: INFO: Waiting for Pod statefulset-2203/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 12/14/22 09:46:52.358
    Dec 14 09:46:52.476: INFO: Found 2 stateful pods, waiting for 3
    Dec 14 09:47:02.506: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:47:02.506: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:47:02.506: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 12/14/22 09:47:02.556
    Dec 14 09:47:02.618: INFO: Updating stateful set ss2
    Dec 14 09:47:02.667: INFO: Waiting for Pod statefulset-2203/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Dec 14 09:47:12.785: INFO: Updating stateful set ss2
    Dec 14 09:47:12.835: INFO: Waiting for StatefulSet statefulset-2203/ss2 to complete update
    Dec 14 09:47:12.835: INFO: Waiting for Pod statefulset-2203/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:47:22.887: INFO: Deleting all statefulset in ns statefulset-2203
    Dec 14 09:47:22.911: INFO: Scaling statefulset ss2 to 0
    Dec 14 09:47:33.026: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:47:33.053: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:47:33.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2203" for this suite. 12/14/22 09:47:33.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:47:33.206
Dec 14 09:47:33.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:47:33.207
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:33.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:33.33
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 12/14/22 09:47:50.405
STEP: Creating a ResourceQuota 12/14/22 09:47:55.431
STEP: Ensuring resource quota status is calculated 12/14/22 09:47:55.456
STEP: Creating a ConfigMap 12/14/22 09:47:57.482
STEP: Ensuring resource quota status captures configMap creation 12/14/22 09:47:57.514
STEP: Deleting a ConfigMap 12/14/22 09:47:59.539
STEP: Ensuring resource quota status released usage 12/14/22 09:47:59.566
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:48:01.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2580" for this suite. 12/14/22 09:48:01.641
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":304,"skipped":5656,"failed":0}
------------------------------
• [28.461 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:47:33.206
    Dec 14 09:47:33.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:47:33.207
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:33.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:33.33
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 12/14/22 09:47:50.405
    STEP: Creating a ResourceQuota 12/14/22 09:47:55.431
    STEP: Ensuring resource quota status is calculated 12/14/22 09:47:55.456
    STEP: Creating a ConfigMap 12/14/22 09:47:57.482
    STEP: Ensuring resource quota status captures configMap creation 12/14/22 09:47:57.514
    STEP: Deleting a ConfigMap 12/14/22 09:47:59.539
    STEP: Ensuring resource quota status released usage 12/14/22 09:47:59.566
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:48:01.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2580" for this suite. 12/14/22 09:48:01.641
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:01.669
Dec 14 09:48:01.670: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod 12/14/22 09:48:01.67
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:01.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:01.793
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Dec 14 09:48:01.840: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 09:49:02.069: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Dec 14 09:49:02.094: INFO: Starting informer...
STEP: Starting pod... 12/14/22 09:49:02.094
Dec 14 09:49:02.162: INFO: Pod is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
STEP: Trying to apply a taint on the Node 12/14/22 09:49:02.162
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:49:02.221
STEP: Waiting short time to make sure Pod is queued for deletion 12/14/22 09:49:02.246
Dec 14 09:49:02.246: INFO: Pod wasn't evicted. Proceeding
Dec 14 09:49:02.246: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:49:02.305
STEP: Waiting some time to make sure that toleration time passed. 12/14/22 09:49:02.334
Dec 14 09:50:17.337: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:50:17.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7671" for this suite. 12/14/22 09:50:17.388
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":305,"skipped":5708,"failed":0}
------------------------------
• [135.746 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:01.669
    Dec 14 09:48:01.670: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename taint-single-pod 12/14/22 09:48:01.67
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:01.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:01.793
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Dec 14 09:48:01.840: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 09:49:02.069: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Dec 14 09:49:02.094: INFO: Starting informer...
    STEP: Starting pod... 12/14/22 09:49:02.094
    Dec 14 09:49:02.162: INFO: Pod is running on shoot--it--tm0ct-io0-worker-1-6f755-hwmlx. Tainting Node
    STEP: Trying to apply a taint on the Node 12/14/22 09:49:02.162
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:49:02.221
    STEP: Waiting short time to make sure Pod is queued for deletion 12/14/22 09:49:02.246
    Dec 14 09:49:02.246: INFO: Pod wasn't evicted. Proceeding
    Dec 14 09:49:02.246: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:49:02.305
    STEP: Waiting some time to make sure that toleration time passed. 12/14/22 09:49:02.334
    Dec 14 09:50:17.337: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:50:17.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-7671" for this suite. 12/14/22 09:50:17.388
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:17.417
Dec 14 09:50:17.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:50:17.418
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:17.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:17.541
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 12/14/22 09:50:17.588
STEP: Ensuring no jobs are scheduled 12/14/22 09:50:17.614
STEP: Ensuring no job exists by listing jobs explicitly 12/14/22 09:55:17.667
STEP: Removing cronjob 12/14/22 09:55:17.692
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:55:17.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1297" for this suite. 12/14/22 09:55:17.767
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":306,"skipped":5760,"failed":0}
------------------------------
• [SLOW TEST] [300.377 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:17.417
    Dec 14 09:50:17.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:50:17.418
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:17.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:17.541
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 12/14/22 09:50:17.588
    STEP: Ensuring no jobs are scheduled 12/14/22 09:50:17.614
    STEP: Ensuring no job exists by listing jobs explicitly 12/14/22 09:55:17.667
    STEP: Removing cronjob 12/14/22 09:55:17.692
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:55:17.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1297" for this suite. 12/14/22 09:55:17.767
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:17.795
Dec 14 09:55:17.795: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:55:17.796
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:17.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:17.918
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:55:17.967
Dec 14 09:55:18.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f" in namespace "projected-2915" to be "Succeeded or Failed"
Dec 14 09:55:18.034: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.679021ms
Dec 14 09:55:20.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Running", Reason="", readiness=false. Elapsed: 2.050826018s
Dec 14 09:55:22.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050961569s
STEP: Saw pod success 12/14/22 09:55:22.06
Dec 14 09:55:22.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f" satisfied condition "Succeeded or Failed"
Dec 14 09:55:22.086: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f container client-container: <nil>
STEP: delete the pod 12/14/22 09:55:22.12
Dec 14 09:55:22.157: INFO: Waiting for pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f to disappear
Dec 14 09:55:22.182: INFO: Pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:55:22.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2915" for this suite. 12/14/22 09:55:22.23
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":307,"skipped":5773,"failed":0}
------------------------------
• [4.466 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:17.795
    Dec 14 09:55:17.795: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:55:17.796
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:17.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:17.918
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:55:17.967
    Dec 14 09:55:18.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f" in namespace "projected-2915" to be "Succeeded or Failed"
    Dec 14 09:55:18.034: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.679021ms
    Dec 14 09:55:20.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Running", Reason="", readiness=false. Elapsed: 2.050826018s
    Dec 14 09:55:22.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050961569s
    STEP: Saw pod success 12/14/22 09:55:22.06
    Dec 14 09:55:22.060: INFO: Pod "downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:22.086: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f container client-container: <nil>
    STEP: delete the pod 12/14/22 09:55:22.12
    Dec 14 09:55:22.157: INFO: Waiting for pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f to disappear
    Dec 14 09:55:22.182: INFO: Pod downwardapi-volume-ee50ce03-fdb3-4877-9279-b7a22df7977f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:55:22.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2915" for this suite. 12/14/22 09:55:22.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:22.262
Dec 14 09:55:22.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:55:22.263
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:22.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:22.394
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 12/14/22 09:55:22.441
STEP: listing events in all namespaces 12/14/22 09:55:22.467
STEP: listing events in test namespace 12/14/22 09:55:22.493
STEP: listing events with field selection filtering on source 12/14/22 09:55:22.518
STEP: listing events with field selection filtering on reportingController 12/14/22 09:55:22.544
STEP: getting the test event 12/14/22 09:55:22.569
STEP: patching the test event 12/14/22 09:55:22.594
STEP: getting the test event 12/14/22 09:55:22.623
STEP: updating the test event 12/14/22 09:55:22.648
STEP: getting the test event 12/14/22 09:55:22.675
STEP: deleting the test event 12/14/22 09:55:22.7
STEP: listing events in all namespaces 12/14/22 09:55:22.727
STEP: listing events in test namespace 12/14/22 09:55:22.752
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec 14 09:55:22.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8368" for this suite. 12/14/22 09:55:22.803
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":308,"skipped":5808,"failed":0}
------------------------------
• [0.568 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:22.262
    Dec 14 09:55:22.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:55:22.263
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:22.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:22.394
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 12/14/22 09:55:22.441
    STEP: listing events in all namespaces 12/14/22 09:55:22.467
    STEP: listing events in test namespace 12/14/22 09:55:22.493
    STEP: listing events with field selection filtering on source 12/14/22 09:55:22.518
    STEP: listing events with field selection filtering on reportingController 12/14/22 09:55:22.544
    STEP: getting the test event 12/14/22 09:55:22.569
    STEP: patching the test event 12/14/22 09:55:22.594
    STEP: getting the test event 12/14/22 09:55:22.623
    STEP: updating the test event 12/14/22 09:55:22.648
    STEP: getting the test event 12/14/22 09:55:22.675
    STEP: deleting the test event 12/14/22 09:55:22.7
    STEP: listing events in all namespaces 12/14/22 09:55:22.727
    STEP: listing events in test namespace 12/14/22 09:55:22.752
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec 14 09:55:22.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8368" for this suite. 12/14/22 09:55:22.803
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:22.831
Dec 14 09:55:22.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 09:55:22.831
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:22.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:22.958
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 12/14/22 09:55:23.005
Dec 14 09:55:23.005: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:55:26.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5410" for this suite. 12/14/22 09:55:26.979
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":309,"skipped":5808,"failed":0}
------------------------------
• [4.174 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:22.831
    Dec 14 09:55:22.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 09:55:22.831
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:22.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:22.958
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 12/14/22 09:55:23.005
    Dec 14 09:55:23.005: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:55:26.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5410" for this suite. 12/14/22 09:55:26.979
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:27.005
Dec 14 09:55:27.005: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:55:27.006
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:27.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:27.127
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-683243c0-3914-446b-ad7f-27a433572e3b 12/14/22 09:55:27.174
STEP: Creating a pod to test consume secrets 12/14/22 09:55:27.2
Dec 14 09:55:27.232: INFO: Waiting up to 5m0s for pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f" in namespace "secrets-1705" to be "Succeeded or Failed"
Dec 14 09:55:27.257: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.915875ms
Dec 14 09:55:29.283: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05090532s
Dec 14 09:55:31.287: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054745579s
STEP: Saw pod success 12/14/22 09:55:31.287
Dec 14 09:55:31.287: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f" satisfied condition "Succeeded or Failed"
Dec 14 09:55:31.312: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:55:31.342
Dec 14 09:55:31.375: INFO: Waiting for pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f to disappear
Dec 14 09:55:31.399: INFO: Pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:55:31.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1705" for this suite. 12/14/22 09:55:31.448
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":310,"skipped":5812,"failed":0}
------------------------------
• [4.470 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:27.005
    Dec 14 09:55:27.005: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:55:27.006
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:27.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:27.127
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-683243c0-3914-446b-ad7f-27a433572e3b 12/14/22 09:55:27.174
    STEP: Creating a pod to test consume secrets 12/14/22 09:55:27.2
    Dec 14 09:55:27.232: INFO: Waiting up to 5m0s for pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f" in namespace "secrets-1705" to be "Succeeded or Failed"
    Dec 14 09:55:27.257: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.915875ms
    Dec 14 09:55:29.283: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05090532s
    Dec 14 09:55:31.287: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054745579s
    STEP: Saw pod success 12/14/22 09:55:31.287
    Dec 14 09:55:31.287: INFO: Pod "pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:31.312: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:55:31.342
    Dec 14 09:55:31.375: INFO: Waiting for pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f to disappear
    Dec 14 09:55:31.399: INFO: Pod pod-secrets-7fae3313-3620-48ef-a41e-9190b544180f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:55:31.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1705" for this suite. 12/14/22 09:55:31.448
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:31.475
Dec 14 09:55:31.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:55:31.476
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:31.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:31.599
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-b46d36e0-209f-43ae-b4e1-4e2e4068c605 12/14/22 09:55:31.646
STEP: Creating a pod to test consume configMaps 12/14/22 09:55:31.671
Dec 14 09:55:31.702: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1" in namespace "projected-2113" to be "Succeeded or Failed"
Dec 14 09:55:31.727: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.889191ms
Dec 14 09:55:33.753: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05125832s
Dec 14 09:55:35.754: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052390069s
STEP: Saw pod success 12/14/22 09:55:35.754
Dec 14 09:55:35.754: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1" satisfied condition "Succeeded or Failed"
Dec 14 09:55:35.779: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:55:35.815
Dec 14 09:55:35.849: INFO: Waiting for pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 to disappear
Dec 14 09:55:35.875: INFO: Pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:55:35.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2113" for this suite. 12/14/22 09:55:35.922
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":311,"skipped":5812,"failed":0}
------------------------------
• [4.473 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:31.475
    Dec 14 09:55:31.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:55:31.476
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:31.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:31.599
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-b46d36e0-209f-43ae-b4e1-4e2e4068c605 12/14/22 09:55:31.646
    STEP: Creating a pod to test consume configMaps 12/14/22 09:55:31.671
    Dec 14 09:55:31.702: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1" in namespace "projected-2113" to be "Succeeded or Failed"
    Dec 14 09:55:31.727: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.889191ms
    Dec 14 09:55:33.753: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05125832s
    Dec 14 09:55:35.754: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052390069s
    STEP: Saw pod success 12/14/22 09:55:35.754
    Dec 14 09:55:35.754: INFO: Pod "pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:35.779: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:55:35.815
    Dec 14 09:55:35.849: INFO: Waiting for pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 to disappear
    Dec 14 09:55:35.875: INFO: Pod pod-projected-configmaps-22ec3578-e37f-40ce-a072-2abd4b9826c1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:55:35.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2113" for this suite. 12/14/22 09:55:35.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:35.95
Dec 14 09:55:35.950: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:55:35.951
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:36.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:36.073
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 12/14/22 09:55:36.12
Dec 14 09:55:36.154: INFO: Waiting up to 5m0s for pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9" in namespace "var-expansion-3997" to be "Succeeded or Failed"
Dec 14 09:55:36.178: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.531309ms
Dec 14 09:55:38.205: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Running", Reason="", readiness=false. Elapsed: 2.051017615s
Dec 14 09:55:40.206: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052225684s
STEP: Saw pod success 12/14/22 09:55:40.206
Dec 14 09:55:40.206: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9" satisfied condition "Succeeded or Failed"
Dec 14 09:55:40.232: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:55:40.266
Dec 14 09:55:40.296: INFO: Waiting for pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 to disappear
Dec 14 09:55:40.321: INFO: Pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:55:40.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3997" for this suite. 12/14/22 09:55:40.37
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":312,"skipped":5856,"failed":0}
------------------------------
• [4.446 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:35.95
    Dec 14 09:55:35.950: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:55:35.951
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:36.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:36.073
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 12/14/22 09:55:36.12
    Dec 14 09:55:36.154: INFO: Waiting up to 5m0s for pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9" in namespace "var-expansion-3997" to be "Succeeded or Failed"
    Dec 14 09:55:36.178: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.531309ms
    Dec 14 09:55:38.205: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Running", Reason="", readiness=false. Elapsed: 2.051017615s
    Dec 14 09:55:40.206: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052225684s
    STEP: Saw pod success 12/14/22 09:55:40.206
    Dec 14 09:55:40.206: INFO: Pod "var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:40.232: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:55:40.266
    Dec 14 09:55:40.296: INFO: Waiting for pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 to disappear
    Dec 14 09:55:40.321: INFO: Pod var-expansion-a9694d24-d49c-45a6-94af-36f8be385aa9 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:55:40.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3997" for this suite. 12/14/22 09:55:40.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:40.399
Dec 14 09:55:40.399: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 09:55:40.4
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.523
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 12/14/22 09:55:40.606
STEP: creating replication controller proxy-service-fdtvz in namespace proxy-1615 12/14/22 09:55:40.606
I1214 09:55:40.632502    6274 runners.go:193] Created replication controller with name: proxy-service-fdtvz, namespace: proxy-1615, replica count: 1
I1214 09:55:41.683391    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 09:55:42.683645    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1214 09:55:43.684076    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:55:43.708: INFO: setup took 3.13815368s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/14/22 09:55:43.708
Dec 14 09:55:43.751: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 42.192165ms)
Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 44.760957ms)
Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 44.886699ms)
Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 44.898832ms)
Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 44.941544ms)
Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 45.149114ms)
Dec 14 09:55:43.754: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 45.16699ms)
Dec 14 09:55:43.754: INFO: (0) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 45.02977ms)
Dec 14 09:55:43.755: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 46.54512ms)
Dec 14 09:55:43.760: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 51.319104ms)
Dec 14 09:55:43.764: INFO: (0) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 55.93311ms)
Dec 14 09:55:43.764: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 55.929518ms)
Dec 14 09:55:43.772: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 63.295181ms)
Dec 14 09:55:43.775: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 66.582709ms)
Dec 14 09:55:43.795: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 86.855664ms)
Dec 14 09:55:43.795: INFO: (0) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 87.089682ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.804664ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.953211ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.871511ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.087474ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.886452ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.045785ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.888044ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.002818ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.93376ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.954872ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.893383ms)
Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.977496ms)
Dec 14 09:55:43.831: INFO: (1) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.857666ms)
Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.359999ms)
Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 36.355557ms)
Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 36.497232ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.393886ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.535876ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.44871ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.371096ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.406974ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.456462ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.504939ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.445551ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.608088ms)
Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.997931ms)
Dec 14 09:55:43.865: INFO: (2) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.990793ms)
Dec 14 09:55:43.865: INFO: (2) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.021372ms)
Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 35.531153ms)
Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.613948ms)
Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.66839ms)
Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.60784ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.671976ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 34.029587ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.307374ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 33.253289ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 33.247032ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 33.488296ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.901603ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 33.665923ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 34.004306ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 33.120677ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.641496ms)
Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 33.798242ms)
Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.944211ms)
Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 39.017864ms)
Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 39.135154ms)
Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 39.595447ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.04745ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.065044ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.242071ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.174942ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.079276ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.070118ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.13109ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.094428ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.160944ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.170905ms)
Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.097159ms)
Dec 14 09:55:43.940: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.374985ms)
Dec 14 09:55:43.942: INFO: (4) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.014634ms)
Dec 14 09:55:43.944: INFO: (4) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.731646ms)
Dec 14 09:55:43.944: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.865417ms)
Dec 14 09:55:43.946: INFO: (4) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.769585ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.167466ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.207038ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.272663ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.488134ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 32.427361ms)
Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.434725ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.303645ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.367432ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.385004ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.330749ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 32.422299ms)
Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.388808ms)
Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.60663ms)
Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 37.246429ms)
Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 37.386552ms)
Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.3654ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.436372ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.377041ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.378085ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.289486ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.325151ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.370764ms)
Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.365357ms)
Dec 14 09:55:44.019: INFO: (6) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 35.792588ms)
Dec 14 09:55:44.019: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.9541ms)
Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.892627ms)
Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 35.931449ms)
Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.901587ms)
Dec 14 09:55:44.023: INFO: (6) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.943916ms)
Dec 14 09:55:44.023: INFO: (6) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 39.069234ms)
Dec 14 09:55:44.024: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 40.767809ms)
Dec 14 09:55:44.026: INFO: (6) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 42.274179ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.237373ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.286265ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.315307ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 31.427148ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.300053ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.316452ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.199826ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.287767ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.302001ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.309136ms)
Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.472712ms)
Dec 14 09:55:44.059: INFO: (7) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.689865ms)
Dec 14 09:55:44.061: INFO: (7) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 34.799864ms)
Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 36.594546ms)
Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.647592ms)
Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.641368ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.138283ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 38.09647ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 38.264523ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 38.240785ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 38.341839ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 38.28035ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.28598ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 38.447762ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 38.339787ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 38.415578ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 38.515886ms)
Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 38.557464ms)
Dec 14 09:55:44.104: INFO: (8) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 41.204499ms)
Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 43.574834ms)
Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 43.496599ms)
Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 43.675649ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.397186ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.436208ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.473924ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.460287ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.553863ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.583352ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.629337ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.490945ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.518685ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.646905ms)
Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.560375ms)
Dec 14 09:55:44.141: INFO: (9) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 34.016793ms)
Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.197721ms)
Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.325628ms)
Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.172324ms)
Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.256073ms)
Dec 14 09:55:44.175: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.491326ms)
Dec 14 09:55:44.175: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.384658ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.391762ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.376319ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.450175ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.52812ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.601853ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.695434ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.515875ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.658211ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.526132ms)
Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.613038ms)
Dec 14 09:55:44.179: INFO: (10) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.572672ms)
Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.430253ms)
Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.409649ms)
Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.391018ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.547916ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.627271ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.568013ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.705956ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.542586ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.697206ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.495458ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.590911ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.616389ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 31.775625ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.713483ms)
Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.645066ms)
Dec 14 09:55:44.214: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 34.79441ms)
Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.202107ms)
Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 36.222819ms)
Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.207599ms)
Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.293115ms)
Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 29.114461ms)
Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 29.077577ms)
Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 29.200805ms)
Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.250943ms)
Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 30.31825ms)
Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 30.389384ms)
Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 30.311331ms)
Dec 14 09:55:44.247: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 30.483996ms)
Dec 14 09:55:44.249: INFO: (12) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.197092ms)
Dec 14 09:55:44.249: INFO: (12) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.996731ms)
Dec 14 09:55:44.250: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.60161ms)
Dec 14 09:55:44.250: INFO: (12) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 33.556759ms)
Dec 14 09:55:44.251: INFO: (12) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 34.559491ms)
Dec 14 09:55:44.251: INFO: (12) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 34.571538ms)
Dec 14 09:55:44.255: INFO: (12) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.678902ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.64376ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.764643ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.818585ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.879167ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.590468ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 32.644526ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.770169ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.553591ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.538254ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 32.715144ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.939359ms)
Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.116833ms)
Dec 14 09:55:44.290: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.066644ms)
Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 37.496905ms)
Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.093972ms)
Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.136427ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.833401ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.865913ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.974819ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 33.035848ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.023423ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.981115ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.952056ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.049106ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.948604ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.941953ms)
Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.004771ms)
Dec 14 09:55:44.327: INFO: (14) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 34.004378ms)
Dec 14 09:55:44.330: INFO: (14) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.990938ms)
Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.904966ms)
Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.231215ms)
Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.998795ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.16755ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.234316ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 35.116656ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 35.36501ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 35.302816ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 35.422194ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 35.447626ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 35.38065ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 35.420294ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 35.312837ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 35.431807ms)
Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.525837ms)
Dec 14 09:55:44.370: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.939784ms)
Dec 14 09:55:44.371: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 40.653385ms)
Dec 14 09:55:44.372: INFO: (15) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 40.588204ms)
Dec 14 09:55:44.372: INFO: (15) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 40.601246ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.144704ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 30.701153ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.222533ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 30.907389ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 30.984167ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 30.804415ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.420668ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 30.872151ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.373323ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.096392ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.165124ms)
Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.640556ms)
Dec 14 09:55:44.406: INFO: (16) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 33.767222ms)
Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.05507ms)
Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.371231ms)
Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.041858ms)
Dec 14 09:55:44.440: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 30.038953ms)
Dec 14 09:55:44.440: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 30.006596ms)
Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.668373ms)
Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.845817ms)
Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.79587ms)
Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.698549ms)
Dec 14 09:55:44.443: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.69834ms)
Dec 14 09:55:44.443: INFO: (17) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.724137ms)
Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 34.89128ms)
Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.239834ms)
Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.433583ms)
Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.337863ms)
Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 35.619639ms)
Dec 14 09:55:44.448: INFO: (17) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 38.532787ms)
Dec 14 09:55:44.449: INFO: (17) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 39.636789ms)
Dec 14 09:55:44.451: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 41.42888ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.494797ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.526262ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.538117ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.530079ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.579196ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.559157ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.743618ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.615548ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.749768ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.619134ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.861591ms)
Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.750733ms)
Dec 14 09:55:44.487: INFO: (18) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.12373ms)
Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.315161ms)
Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.258905ms)
Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.260878ms)
Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 29.51821ms)
Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 29.759451ms)
Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.653105ms)
Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.615221ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.748421ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.931983ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.791159ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.720403ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.879362ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.81704ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.752458ms)
Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.767199ms)
Dec 14 09:55:44.523: INFO: (19) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 33.634974ms)
Dec 14 09:55:44.524: INFO: (19) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 34.951841ms)
Dec 14 09:55:44.524: INFO: (19) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 34.988723ms)
Dec 14 09:55:44.527: INFO: (19) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.176537ms)
STEP: deleting ReplicationController proxy-service-fdtvz in namespace proxy-1615, will wait for the garbage collector to delete the pods 12/14/22 09:55:44.527
Dec 14 09:55:44.631: INFO: Deleting ReplicationController proxy-service-fdtvz took: 27.202723ms
Dec 14 09:55:44.731: INFO: Terminating ReplicationController proxy-service-fdtvz pods took: 100.529909ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 09:55:47.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1615" for this suite. 12/14/22 09:55:47.083
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":313,"skipped":5916,"failed":0}
------------------------------
• [6.710 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:40.399
    Dec 14 09:55:40.399: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 09:55:40.4
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.523
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 12/14/22 09:55:40.606
    STEP: creating replication controller proxy-service-fdtvz in namespace proxy-1615 12/14/22 09:55:40.606
    I1214 09:55:40.632502    6274 runners.go:193] Created replication controller with name: proxy-service-fdtvz, namespace: proxy-1615, replica count: 1
    I1214 09:55:41.683391    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 09:55:42.683645    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I1214 09:55:43.684076    6274 runners.go:193] proxy-service-fdtvz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:55:43.708: INFO: setup took 3.13815368s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/14/22 09:55:43.708
    Dec 14 09:55:43.751: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 42.192165ms)
    Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 44.760957ms)
    Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 44.886699ms)
    Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 44.898832ms)
    Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 44.941544ms)
    Dec 14 09:55:43.753: INFO: (0) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 45.149114ms)
    Dec 14 09:55:43.754: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 45.16699ms)
    Dec 14 09:55:43.754: INFO: (0) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 45.02977ms)
    Dec 14 09:55:43.755: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 46.54512ms)
    Dec 14 09:55:43.760: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 51.319104ms)
    Dec 14 09:55:43.764: INFO: (0) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 55.93311ms)
    Dec 14 09:55:43.764: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 55.929518ms)
    Dec 14 09:55:43.772: INFO: (0) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 63.295181ms)
    Dec 14 09:55:43.775: INFO: (0) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 66.582709ms)
    Dec 14 09:55:43.795: INFO: (0) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 86.855664ms)
    Dec 14 09:55:43.795: INFO: (0) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 87.089682ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.804664ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.953211ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.871511ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.087474ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.886452ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.045785ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.888044ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.002818ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.93376ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.954872ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.893383ms)
    Dec 14 09:55:43.828: INFO: (1) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.977496ms)
    Dec 14 09:55:43.831: INFO: (1) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.857666ms)
    Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.359999ms)
    Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 36.355557ms)
    Dec 14 09:55:43.832: INFO: (1) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 36.497232ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.393886ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.535876ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.44871ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.371096ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.406974ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.456462ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.504939ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.445551ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.608088ms)
    Dec 14 09:55:43.864: INFO: (2) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.997931ms)
    Dec 14 09:55:43.865: INFO: (2) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.990793ms)
    Dec 14 09:55:43.865: INFO: (2) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.021372ms)
    Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 35.531153ms)
    Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.613948ms)
    Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.66839ms)
    Dec 14 09:55:43.868: INFO: (2) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.60784ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.671976ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 34.029587ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.307374ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 33.253289ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 33.247032ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 33.488296ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.901603ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 33.665923ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 34.004306ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 33.120677ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.641496ms)
    Dec 14 09:55:43.902: INFO: (3) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 33.798242ms)
    Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.944211ms)
    Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 39.017864ms)
    Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 39.135154ms)
    Dec 14 09:55:43.908: INFO: (3) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 39.595447ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.04745ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.065044ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.242071ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.174942ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.079276ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.070118ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.13109ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.094428ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.160944ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.170905ms)
    Dec 14 09:55:43.939: INFO: (4) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.097159ms)
    Dec 14 09:55:43.940: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.374985ms)
    Dec 14 09:55:43.942: INFO: (4) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.014634ms)
    Dec 14 09:55:43.944: INFO: (4) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.731646ms)
    Dec 14 09:55:43.944: INFO: (4) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.865417ms)
    Dec 14 09:55:43.946: INFO: (4) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.769585ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.167466ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.207038ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.272663ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.488134ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 32.427361ms)
    Dec 14 09:55:43.978: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.434725ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.303645ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.367432ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.385004ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.330749ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 32.422299ms)
    Dec 14 09:55:43.979: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.388808ms)
    Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.60663ms)
    Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 37.246429ms)
    Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 37.386552ms)
    Dec 14 09:55:43.983: INFO: (5) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.3654ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.436372ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.377041ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.378085ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.289486ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.325151ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.370764ms)
    Dec 14 09:55:44.016: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.365357ms)
    Dec 14 09:55:44.019: INFO: (6) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 35.792588ms)
    Dec 14 09:55:44.019: INFO: (6) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.9541ms)
    Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.892627ms)
    Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 35.931449ms)
    Dec 14 09:55:44.020: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.901587ms)
    Dec 14 09:55:44.023: INFO: (6) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.943916ms)
    Dec 14 09:55:44.023: INFO: (6) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 39.069234ms)
    Dec 14 09:55:44.024: INFO: (6) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 40.767809ms)
    Dec 14 09:55:44.026: INFO: (6) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 42.274179ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.237373ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.286265ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.315307ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 31.427148ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.300053ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.316452ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.199826ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.287767ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.302001ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.309136ms)
    Dec 14 09:55:44.057: INFO: (7) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.472712ms)
    Dec 14 09:55:44.059: INFO: (7) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.689865ms)
    Dec 14 09:55:44.061: INFO: (7) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 34.799864ms)
    Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 36.594546ms)
    Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.647592ms)
    Dec 14 09:55:44.063: INFO: (7) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.641368ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.138283ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 38.09647ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 38.264523ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 38.240785ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 38.341839ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 38.28035ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.28598ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 38.447762ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 38.339787ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 38.415578ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 38.515886ms)
    Dec 14 09:55:44.101: INFO: (8) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 38.557464ms)
    Dec 14 09:55:44.104: INFO: (8) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 41.204499ms)
    Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 43.574834ms)
    Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 43.496599ms)
    Dec 14 09:55:44.106: INFO: (8) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 43.675649ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.397186ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.436208ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.473924ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.460287ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.553863ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.583352ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.629337ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.490945ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.518685ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.646905ms)
    Dec 14 09:55:44.139: INFO: (9) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.560375ms)
    Dec 14 09:55:44.141: INFO: (9) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 34.016793ms)
    Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.197721ms)
    Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.325628ms)
    Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.172324ms)
    Dec 14 09:55:44.144: INFO: (9) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.256073ms)
    Dec 14 09:55:44.175: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.491326ms)
    Dec 14 09:55:44.175: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.384658ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.391762ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.376319ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.450175ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.52812ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.601853ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.695434ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.515875ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.658211ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.526132ms)
    Dec 14 09:55:44.176: INFO: (10) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.613038ms)
    Dec 14 09:55:44.179: INFO: (10) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 34.572672ms)
    Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.430253ms)
    Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.409649ms)
    Dec 14 09:55:44.180: INFO: (10) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.391018ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.547916ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.627271ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.568013ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.705956ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.542586ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.697206ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 31.495458ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.590911ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.616389ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 31.775625ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.713483ms)
    Dec 14 09:55:44.211: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.645066ms)
    Dec 14 09:55:44.214: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 34.79441ms)
    Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 36.202107ms)
    Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 36.222819ms)
    Dec 14 09:55:44.216: INFO: (11) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.207599ms)
    Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.293115ms)
    Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 29.114461ms)
    Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 29.077577ms)
    Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 29.200805ms)
    Dec 14 09:55:44.245: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.250943ms)
    Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 30.31825ms)
    Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 30.389384ms)
    Dec 14 09:55:44.246: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 30.311331ms)
    Dec 14 09:55:44.247: INFO: (12) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 30.483996ms)
    Dec 14 09:55:44.249: INFO: (12) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 33.197092ms)
    Dec 14 09:55:44.249: INFO: (12) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.996731ms)
    Dec 14 09:55:44.250: INFO: (12) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.60161ms)
    Dec 14 09:55:44.250: INFO: (12) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 33.556759ms)
    Dec 14 09:55:44.251: INFO: (12) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 34.559491ms)
    Dec 14 09:55:44.251: INFO: (12) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 34.571538ms)
    Dec 14 09:55:44.255: INFO: (12) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.678902ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.64376ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.764643ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.818585ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.879167ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.590468ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 32.644526ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.770169ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.553591ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.538254ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 32.715144ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.939359ms)
    Dec 14 09:55:44.288: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.116833ms)
    Dec 14 09:55:44.290: INFO: (13) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.066644ms)
    Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 37.496905ms)
    Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.093972ms)
    Dec 14 09:55:44.292: INFO: (13) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.136427ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.833401ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.865913ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.974819ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 33.035848ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.023423ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.981115ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.952056ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 33.049106ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.948604ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.941953ms)
    Dec 14 09:55:44.326: INFO: (14) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 33.004771ms)
    Dec 14 09:55:44.327: INFO: (14) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 34.004378ms)
    Dec 14 09:55:44.330: INFO: (14) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 36.990938ms)
    Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.904966ms)
    Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.231215ms)
    Dec 14 09:55:44.331: INFO: (14) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.998795ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 35.16755ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.234316ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 35.116656ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 35.36501ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 35.302816ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 35.422194ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 35.447626ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 35.38065ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 35.420294ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 35.312837ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 35.431807ms)
    Dec 14 09:55:44.366: INFO: (15) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.525837ms)
    Dec 14 09:55:44.370: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 38.939784ms)
    Dec 14 09:55:44.371: INFO: (15) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 40.653385ms)
    Dec 14 09:55:44.372: INFO: (15) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 40.588204ms)
    Dec 14 09:55:44.372: INFO: (15) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 40.601246ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.144704ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 30.701153ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.222533ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 30.907389ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 30.984167ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 30.804415ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.420668ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 30.872151ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.373323ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.096392ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.165124ms)
    Dec 14 09:55:44.403: INFO: (16) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.640556ms)
    Dec 14 09:55:44.406: INFO: (16) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 33.767222ms)
    Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 37.05507ms)
    Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.371231ms)
    Dec 14 09:55:44.410: INFO: (16) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.041858ms)
    Dec 14 09:55:44.440: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 30.038953ms)
    Dec 14 09:55:44.440: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 30.006596ms)
    Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.668373ms)
    Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.845817ms)
    Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 32.79587ms)
    Dec 14 09:55:44.442: INFO: (17) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 32.698549ms)
    Dec 14 09:55:44.443: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.69834ms)
    Dec 14 09:55:44.443: INFO: (17) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.724137ms)
    Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 34.89128ms)
    Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 35.239834ms)
    Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 35.433583ms)
    Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 35.337863ms)
    Dec 14 09:55:44.445: INFO: (17) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 35.619639ms)
    Dec 14 09:55:44.448: INFO: (17) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 38.532787ms)
    Dec 14 09:55:44.449: INFO: (17) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 39.636789ms)
    Dec 14 09:55:44.451: INFO: (17) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 41.42888ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.494797ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 31.526262ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 31.538117ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.530079ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 31.579196ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 31.559157ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 31.743618ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 31.615548ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 31.749768ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 31.619134ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 31.861591ms)
    Dec 14 09:55:44.483: INFO: (18) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 31.750733ms)
    Dec 14 09:55:44.487: INFO: (18) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 35.12373ms)
    Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 37.315161ms)
    Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 37.258905ms)
    Dec 14 09:55:44.489: INFO: (18) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 37.260878ms)
    Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 29.51821ms)
    Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">test<... (200; 29.759451ms)
    Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.653105ms)
    Dec 14 09:55:44.518: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:160/proxy/: foo (200; 29.615221ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd:162/proxy/: bar (200; 32.748421ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:462/proxy/: tls qux (200; 32.931983ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:460/proxy/: tls baz (200; 32.791159ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/proxy-service-fdtvz-s56dd/proxy/rewriteme">test</a> (200; 32.720403ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname1/proxy/: tls baz (200; 32.879362ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/http:proxy-service-fdtvz-s56dd:1080/proxy/rewriteme">... (200; 32.81704ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/services/https:proxy-service-fdtvz:tlsportname2/proxy/: tls qux (200; 32.752458ms)
    Dec 14 09:55:44.522: INFO: (19) /api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/: <a href="/api/v1/namespaces/proxy-1615/pods/https:proxy-service-fdtvz-s56dd:443/proxy/tlsrewritem... (200; 32.767199ms)
    Dec 14 09:55:44.523: INFO: (19) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname2/proxy/: bar (200; 33.634974ms)
    Dec 14 09:55:44.524: INFO: (19) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname1/proxy/: foo (200; 34.951841ms)
    Dec 14 09:55:44.524: INFO: (19) /api/v1/namespaces/proxy-1615/services/proxy-service-fdtvz:portname1/proxy/: foo (200; 34.988723ms)
    Dec 14 09:55:44.527: INFO: (19) /api/v1/namespaces/proxy-1615/services/http:proxy-service-fdtvz:portname2/proxy/: bar (200; 38.176537ms)
    STEP: deleting ReplicationController proxy-service-fdtvz in namespace proxy-1615, will wait for the garbage collector to delete the pods 12/14/22 09:55:44.527
    Dec 14 09:55:44.631: INFO: Deleting ReplicationController proxy-service-fdtvz took: 27.202723ms
    Dec 14 09:55:44.731: INFO: Terminating ReplicationController proxy-service-fdtvz pods took: 100.529909ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 09:55:47.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1615" for this suite. 12/14/22 09:55:47.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:47.111
Dec 14 09:55:47.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:55:47.112
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:47.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:47.235
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 12/14/22 09:55:47.282
STEP: setting up watch 12/14/22 09:55:47.282
STEP: submitting the pod to kubernetes 12/14/22 09:55:47.407
STEP: verifying the pod is in kubernetes 12/14/22 09:55:47.439
STEP: verifying pod creation was observed 12/14/22 09:55:47.468
Dec 14 09:55:47.468: INFO: Waiting up to 5m0s for pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e" in namespace "pods-4895" to be "running"
Dec 14 09:55:47.493: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.074706ms
Dec 14 09:55:49.520: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e": Phase="Running", Reason="", readiness=true. Elapsed: 2.051878497s
Dec 14 09:55:49.520: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 09:55:49.545
STEP: verifying pod deletion was observed 12/14/22 09:55:49.571
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:55:52.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4895" for this suite. 12/14/22 09:55:52.105
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":314,"skipped":5962,"failed":0}
------------------------------
• [5.023 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:47.111
    Dec 14 09:55:47.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:55:47.112
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:47.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:47.235
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 12/14/22 09:55:47.282
    STEP: setting up watch 12/14/22 09:55:47.282
    STEP: submitting the pod to kubernetes 12/14/22 09:55:47.407
    STEP: verifying the pod is in kubernetes 12/14/22 09:55:47.439
    STEP: verifying pod creation was observed 12/14/22 09:55:47.468
    Dec 14 09:55:47.468: INFO: Waiting up to 5m0s for pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e" in namespace "pods-4895" to be "running"
    Dec 14 09:55:47.493: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.074706ms
    Dec 14 09:55:49.520: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e": Phase="Running", Reason="", readiness=true. Elapsed: 2.051878497s
    Dec 14 09:55:49.520: INFO: Pod "pod-submit-remove-96882612-3ef5-4890-8b54-c132675bc79e" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 09:55:49.545
    STEP: verifying pod deletion was observed 12/14/22 09:55:49.571
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:55:52.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4895" for this suite. 12/14/22 09:55:52.105
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:52.136
Dec 14 09:55:52.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename server-version 12/14/22 09:55:52.137
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:52.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:52.258
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 12/14/22 09:55:52.311
STEP: Confirm major version 12/14/22 09:55:52.334
Dec 14 09:55:52.334: INFO: Major version: 1
STEP: Confirm minor version 12/14/22 09:55:52.334
Dec 14 09:55:52.334: INFO: cleanMinorVersion: 25
Dec 14 09:55:52.334: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Dec 14 09:55:52.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-2351" for this suite. 12/14/22 09:55:52.36
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":315,"skipped":5990,"failed":0}
------------------------------
• [0.252 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:52.136
    Dec 14 09:55:52.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename server-version 12/14/22 09:55:52.137
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:52.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:52.258
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 12/14/22 09:55:52.311
    STEP: Confirm major version 12/14/22 09:55:52.334
    Dec 14 09:55:52.334: INFO: Major version: 1
    STEP: Confirm minor version 12/14/22 09:55:52.334
    Dec 14 09:55:52.334: INFO: cleanMinorVersion: 25
    Dec 14 09:55:52.334: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Dec 14 09:55:52.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-2351" for this suite. 12/14/22 09:55:52.36
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:52.39
Dec 14 09:55:52.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:55:52.391
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:52.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:52.511
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Dec 14 09:55:52.590: INFO: Waiting up to 5m0s for pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a" in namespace "container-probe-4865" to be "running and ready"
Dec 14 09:55:52.614: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.539988ms
Dec 14 09:55:52.614: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:55:54.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 2.050606945s
Dec 14 09:55:54.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:55:56.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 4.05126928s
Dec 14 09:55:56.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:55:58.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 6.051604104s
Dec 14 09:55:58.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:00.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 8.050181931s
Dec 14 09:56:00.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:02.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 10.050051031s
Dec 14 09:56:02.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:04.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 12.050777721s
Dec 14 09:56:04.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:06.642: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 14.05209754s
Dec 14 09:56:06.642: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:08.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 16.050518185s
Dec 14 09:56:08.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:10.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 18.050285268s
Dec 14 09:56:10.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:12.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 20.051575562s
Dec 14 09:56:12.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
Dec 14 09:56:14.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=true. Elapsed: 22.05078888s
Dec 14 09:56:14.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = true)
Dec 14 09:56:14.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a" satisfied condition "running and ready"
Dec 14 09:56:14.665: INFO: Container started at 2022-12-14 09:55:53 +0000 UTC, pod became ready at 2022-12-14 09:56:12 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:56:14.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4865" for this suite. 12/14/22 09:56:14.721
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":316,"skipped":6008,"failed":0}
------------------------------
• [22.358 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:52.39
    Dec 14 09:55:52.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:55:52.391
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:52.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:52.511
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Dec 14 09:55:52.590: INFO: Waiting up to 5m0s for pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a" in namespace "container-probe-4865" to be "running and ready"
    Dec 14 09:55:52.614: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.539988ms
    Dec 14 09:55:52.614: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:55:54.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 2.050606945s
    Dec 14 09:55:54.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:55:56.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 4.05126928s
    Dec 14 09:55:56.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:55:58.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 6.051604104s
    Dec 14 09:55:58.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:00.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 8.050181931s
    Dec 14 09:56:00.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:02.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 10.050051031s
    Dec 14 09:56:02.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:04.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 12.050777721s
    Dec 14 09:56:04.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:06.642: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 14.05209754s
    Dec 14 09:56:06.642: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:08.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 16.050518185s
    Dec 14 09:56:08.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:10.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 18.050285268s
    Dec 14 09:56:10.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:12.641: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=false. Elapsed: 20.051575562s
    Dec 14 09:56:12.641: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = false)
    Dec 14 09:56:14.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a": Phase="Running", Reason="", readiness=true. Elapsed: 22.05078888s
    Dec 14 09:56:14.640: INFO: The phase of Pod test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a is Running (Ready = true)
    Dec 14 09:56:14.640: INFO: Pod "test-webserver-d2318c97-0879-42c2-af41-8a412a2d4b3a" satisfied condition "running and ready"
    Dec 14 09:56:14.665: INFO: Container started at 2022-12-14 09:55:53 +0000 UTC, pod became ready at 2022-12-14 09:56:12 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:56:14.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4865" for this suite. 12/14/22 09:56:14.721
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:14.748
Dec 14 09:56:14.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:56:14.75
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:14.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:14.874
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Dec 14 09:56:14.922: INFO: Creating ReplicaSet my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802
Dec 14 09:56:14.972: INFO: Pod name my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802: Found 1 pods out of 1
Dec 14 09:56:14.972: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802" is running
Dec 14 09:56:14.972: INFO: Waiting up to 5m0s for pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" in namespace "replicaset-9854" to be "running"
Dec 14 09:56:14.997: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs": Phase="Pending", Reason="", readiness=false. Elapsed: 24.925786ms
Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs": Phase="Running", Reason="", readiness=true. Elapsed: 2.056191298s
Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" satisfied condition "running"
Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:56:14 +0000 UTC Reason: Message:}])
Dec 14 09:56:17.028: INFO: Trying to dial the pod
Dec 14 09:56:22.149: INFO: Controller my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802: Got expected result from replica 1 [my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs]: "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:56:22.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9854" for this suite. 12/14/22 09:56:22.197
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":317,"skipped":6009,"failed":0}
------------------------------
• [7.475 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:14.748
    Dec 14 09:56:14.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:56:14.75
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:14.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:14.874
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Dec 14 09:56:14.922: INFO: Creating ReplicaSet my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802
    Dec 14 09:56:14.972: INFO: Pod name my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802: Found 1 pods out of 1
    Dec 14 09:56:14.972: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802" is running
    Dec 14 09:56:14.972: INFO: Waiting up to 5m0s for pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" in namespace "replicaset-9854" to be "running"
    Dec 14 09:56:14.997: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs": Phase="Pending", Reason="", readiness=false. Elapsed: 24.925786ms
    Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs": Phase="Running", Reason="", readiness=true. Elapsed: 2.056191298s
    Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" satisfied condition "running"
    Dec 14 09:56:17.028: INFO: Pod "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:56:14 +0000 UTC Reason: Message:}])
    Dec 14 09:56:17.028: INFO: Trying to dial the pod
    Dec 14 09:56:22.149: INFO: Controller my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802: Got expected result from replica 1 [my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs]: "my-hostname-basic-e51201ac-5ded-45f4-82b4-973416d9e802-gqmgs", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:56:22.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9854" for this suite. 12/14/22 09:56:22.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:22.226
Dec 14 09:56:22.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:56:22.227
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:22.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:22.36
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 12/14/22 09:56:22.407
STEP: getting /apis/node.k8s.io 12/14/22 09:56:22.457
STEP: getting /apis/node.k8s.io/v1 12/14/22 09:56:22.48
STEP: creating 12/14/22 09:56:22.504
STEP: watching 12/14/22 09:56:22.581
Dec 14 09:56:22.582: INFO: starting watch
STEP: getting 12/14/22 09:56:22.63
STEP: listing 12/14/22 09:56:22.656
STEP: patching 12/14/22 09:56:22.681
STEP: updating 12/14/22 09:56:22.707
Dec 14 09:56:22.733: INFO: waiting for watch events with expected annotations
STEP: deleting 12/14/22 09:56:22.733
STEP: deleting a collection 12/14/22 09:56:22.809
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 09:56:22.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8805" for this suite. 12/14/22 09:56:22.895
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":318,"skipped":6047,"failed":0}
------------------------------
• [0.695 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:22.226
    Dec 14 09:56:22.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:56:22.227
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:22.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:22.36
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 12/14/22 09:56:22.407
    STEP: getting /apis/node.k8s.io 12/14/22 09:56:22.457
    STEP: getting /apis/node.k8s.io/v1 12/14/22 09:56:22.48
    STEP: creating 12/14/22 09:56:22.504
    STEP: watching 12/14/22 09:56:22.581
    Dec 14 09:56:22.582: INFO: starting watch
    STEP: getting 12/14/22 09:56:22.63
    STEP: listing 12/14/22 09:56:22.656
    STEP: patching 12/14/22 09:56:22.681
    STEP: updating 12/14/22 09:56:22.707
    Dec 14 09:56:22.733: INFO: waiting for watch events with expected annotations
    STEP: deleting 12/14/22 09:56:22.733
    STEP: deleting a collection 12/14/22 09:56:22.809
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 09:56:22.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8805" for this suite. 12/14/22 09:56:22.895
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:22.922
Dec 14 09:56:22.922: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:56:22.923
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:22.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:23.045
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/14/22 09:56:23.093
Dec 14 09:56:23.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/14/22 09:56:40.03
Dec 14 09:56:40.031: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:56:44.512: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:57:00.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3142" for this suite. 12/14/22 09:57:00.657
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":319,"skipped":6061,"failed":0}
------------------------------
• [37.766 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:22.922
    Dec 14 09:56:22.922: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:56:22.923
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:22.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:23.045
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/14/22 09:56:23.093
    Dec 14 09:56:23.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/14/22 09:56:40.03
    Dec 14 09:56:40.031: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:56:44.512: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:57:00.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3142" for this suite. 12/14/22 09:57:00.657
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:57:00.689
Dec 14 09:57:00.689: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:57:00.69
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:00.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:00.829
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 09:57:00.884
Dec 14 09:57:00.931: INFO: Waiting up to 5m0s for pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f" in namespace "emptydir-892" to be "Succeeded or Failed"
Dec 14 09:57:00.962: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.781391ms
Dec 14 09:57:02.991: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059899973s
Dec 14 09:57:04.993: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061022987s
STEP: Saw pod success 12/14/22 09:57:04.993
Dec 14 09:57:04.993: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f" satisfied condition "Succeeded or Failed"
Dec 14 09:57:05.021: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f container test-container: <nil>
STEP: delete the pod 12/14/22 09:57:05.207
Dec 14 09:57:05.245: INFO: Waiting for pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f to disappear
Dec 14 09:57:05.273: INFO: Pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:57:05.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-892" for this suite. 12/14/22 09:57:05.329
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":320,"skipped":6093,"failed":0}
------------------------------
• [4.670 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:57:00.689
    Dec 14 09:57:00.689: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:57:00.69
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:00.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:00.829
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 09:57:00.884
    Dec 14 09:57:00.931: INFO: Waiting up to 5m0s for pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f" in namespace "emptydir-892" to be "Succeeded or Failed"
    Dec 14 09:57:00.962: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.781391ms
    Dec 14 09:57:02.991: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059899973s
    Dec 14 09:57:04.993: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061022987s
    STEP: Saw pod success 12/14/22 09:57:04.993
    Dec 14 09:57:04.993: INFO: Pod "pod-55a49e73-9b59-46a9-b862-3cc93feee79f" satisfied condition "Succeeded or Failed"
    Dec 14 09:57:05.021: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f container test-container: <nil>
    STEP: delete the pod 12/14/22 09:57:05.207
    Dec 14 09:57:05.245: INFO: Waiting for pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f to disappear
    Dec 14 09:57:05.273: INFO: Pod pod-55a49e73-9b59-46a9-b862-3cc93feee79f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:57:05.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-892" for this suite. 12/14/22 09:57:05.329
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:57:05.361
Dec 14 09:57:05.361: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:57:05.362
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:05.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:05.501
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 12/14/22 09:57:05.556
STEP: listing all events in all namespaces 12/14/22 09:57:05.586
STEP: patching the test event 12/14/22 09:57:05.615
STEP: fetching the test event 12/14/22 09:57:05.646
STEP: updating the test event 12/14/22 09:57:05.674
STEP: getting the test event 12/14/22 09:57:05.733
STEP: deleting the test event 12/14/22 09:57:05.761
STEP: listing all events in all namespaces 12/14/22 09:57:05.791
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec 14 09:57:05.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5794" for this suite. 12/14/22 09:57:05.85
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":321,"skipped":6115,"failed":0}
------------------------------
• [0.520 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:57:05.361
    Dec 14 09:57:05.361: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:57:05.362
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:05.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:05.501
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 12/14/22 09:57:05.556
    STEP: listing all events in all namespaces 12/14/22 09:57:05.586
    STEP: patching the test event 12/14/22 09:57:05.615
    STEP: fetching the test event 12/14/22 09:57:05.646
    STEP: updating the test event 12/14/22 09:57:05.674
    STEP: getting the test event 12/14/22 09:57:05.733
    STEP: deleting the test event 12/14/22 09:57:05.761
    STEP: listing all events in all namespaces 12/14/22 09:57:05.791
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec 14 09:57:05.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5794" for this suite. 12/14/22 09:57:05.85
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:57:05.881
Dec 14 09:57:05.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:57:05.882
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:05.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:06.023
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 12/14/22 09:57:06.077
Dec 14 09:57:06.078: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version 12/14/22 09:57:17.578
STEP: check the new version name is served 12/14/22 09:57:17.661
STEP: check the old version name is removed 12/14/22 09:57:22.029
STEP: check the other version is not changed 12/14/22 09:57:24.361
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:57:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6007" for this suite. 12/14/22 09:57:34.15
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":322,"skipped":6116,"failed":0}
------------------------------
• [28.295 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:57:05.881
    Dec 14 09:57:05.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:57:05.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:05.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:06.023
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 12/14/22 09:57:06.077
    Dec 14 09:57:06.078: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: rename a version 12/14/22 09:57:17.578
    STEP: check the new version name is served 12/14/22 09:57:17.661
    STEP: check the old version name is removed 12/14/22 09:57:22.029
    STEP: check the other version is not changed 12/14/22 09:57:24.361
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:57:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6007" for this suite. 12/14/22 09:57:34.15
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:57:34.177
Dec 14 09:57:34.177: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:57:34.177
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:34.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:34.3
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-490d56ab-c5b2-4e27-b2ad-766d7b05f1da 12/14/22 09:57:34.347
STEP: Creating a pod to test consume secrets 12/14/22 09:57:34.372
Dec 14 09:57:34.404: INFO: Waiting up to 5m0s for pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52" in namespace "secrets-1297" to be "Succeeded or Failed"
Dec 14 09:57:34.429: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Pending", Reason="", readiness=false. Elapsed: 24.648707ms
Dec 14 09:57:36.455: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Running", Reason="", readiness=false. Elapsed: 2.050519784s
Dec 14 09:57:38.456: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051417086s
STEP: Saw pod success 12/14/22 09:57:38.456
Dec 14 09:57:38.456: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52" satisfied condition "Succeeded or Failed"
Dec 14 09:57:38.481: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:57:38.518
Dec 14 09:57:38.549: INFO: Waiting for pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 to disappear
Dec 14 09:57:38.574: INFO: Pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:57:38.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1297" for this suite. 12/14/22 09:57:38.622
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":323,"skipped":6118,"failed":0}
------------------------------
• [4.472 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:57:34.177
    Dec 14 09:57:34.177: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:57:34.177
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:34.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:34.3
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-490d56ab-c5b2-4e27-b2ad-766d7b05f1da 12/14/22 09:57:34.347
    STEP: Creating a pod to test consume secrets 12/14/22 09:57:34.372
    Dec 14 09:57:34.404: INFO: Waiting up to 5m0s for pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52" in namespace "secrets-1297" to be "Succeeded or Failed"
    Dec 14 09:57:34.429: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Pending", Reason="", readiness=false. Elapsed: 24.648707ms
    Dec 14 09:57:36.455: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Running", Reason="", readiness=false. Elapsed: 2.050519784s
    Dec 14 09:57:38.456: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051417086s
    STEP: Saw pod success 12/14/22 09:57:38.456
    Dec 14 09:57:38.456: INFO: Pod "pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52" satisfied condition "Succeeded or Failed"
    Dec 14 09:57:38.481: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:57:38.518
    Dec 14 09:57:38.549: INFO: Waiting for pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 to disappear
    Dec 14 09:57:38.574: INFO: Pod pod-secrets-875d0a97-b3e8-4dcd-aafc-8cfd70060a52 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:57:38.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1297" for this suite. 12/14/22 09:57:38.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:57:38.651
Dec 14 09:57:38.651: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:57:38.652
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:38.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:38.783
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 12/14/22 09:57:38.831
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_udp@PTR;check="$$(dig +tcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_tcp@PTR;sleep 1; done
 12/14/22 09:57:38.891
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_udp@PTR;check="$$(dig +tcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_tcp@PTR;sleep 1; done
 12/14/22 09:57:38.891
STEP: creating a pod to probe DNS 12/14/22 09:57:38.891
STEP: submitting the pod to kubernetes 12/14/22 09:57:38.891
Dec 14 09:57:38.924: INFO: Waiting up to 15m0s for pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a" in namespace "dns-9496" to be "running"
Dec 14 09:57:38.950: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.216396ms
Dec 14 09:57:40.977: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053455292s
Dec 14 09:57:40.977: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:57:40.978
STEP: looking for the results for each expected name from probers 12/14/22 09:57:41.002
Dec 14 09:57:41.138: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.183: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.212: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.241: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.387: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.417: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.446: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.479: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:41.598: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:57:46.631: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.709: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.739: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.887: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.916: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.945: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:46.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:47.098: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:57:51.635: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.710: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.740: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.892: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.922: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.951: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:51.981: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:52.096: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:57:56.628: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.676: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.705: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.737: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.886: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.917: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.946: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:56.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:57:57.098: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:58:01.630: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.710: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.887: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.916: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:01.971: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:02.000: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:02.118: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:58:06.631: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.676: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.706: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.735: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.883: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.912: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.941: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:06.970: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
Dec 14 09:58:07.094: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

Dec 14 09:58:12.098: INFO: DNS probes using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a succeeded

STEP: deleting the pod 12/14/22 09:58:12.098
STEP: deleting the test service 12/14/22 09:58:12.135
STEP: deleting the test headless service 12/14/22 09:58:12.181
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:58:12.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9496" for this suite. 12/14/22 09:58:12.259
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":324,"skipped":6186,"failed":0}
------------------------------
• [33.634 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:57:38.651
    Dec 14 09:57:38.651: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:57:38.652
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:57:38.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:57:38.783
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 12/14/22 09:57:38.831
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_udp@PTR;check="$$(dig +tcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_tcp@PTR;sleep 1; done
     12/14/22 09:57:38.891
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9496.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_udp@PTR;check="$$(dig +tcp +noall +answer +search 211.13.111.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.111.13.211_tcp@PTR;sleep 1; done
     12/14/22 09:57:38.891
    STEP: creating a pod to probe DNS 12/14/22 09:57:38.891
    STEP: submitting the pod to kubernetes 12/14/22 09:57:38.891
    Dec 14 09:57:38.924: INFO: Waiting up to 15m0s for pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a" in namespace "dns-9496" to be "running"
    Dec 14 09:57:38.950: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.216396ms
    Dec 14 09:57:40.977: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a": Phase="Running", Reason="", readiness=true. Elapsed: 2.053455292s
    Dec 14 09:57:40.977: INFO: Pod "dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:57:40.978
    STEP: looking for the results for each expected name from probers 12/14/22 09:57:41.002
    Dec 14 09:57:41.138: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.183: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.212: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.241: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.387: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.417: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.446: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.479: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:41.598: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:57:46.631: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.709: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.739: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.887: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.916: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.945: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:46.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:47.098: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:57:51.635: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.710: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.740: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.892: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.922: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.951: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:51.981: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:52.096: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:57:56.628: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.676: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.705: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.737: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.886: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.917: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.946: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:56.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:57:57.098: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:58:01.630: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.710: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.887: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.916: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:01.971: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:02.000: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:02.118: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:58:06.631: INFO: Unable to read wheezy_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.676: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.706: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.735: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.883: INFO: Unable to read jessie_udp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.912: INFO: Unable to read jessie_tcp@dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.941: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:06.970: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local from pod dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a: the server could not find the requested resource (get pods dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a)
    Dec 14 09:58:07.094: INFO: Lookups using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a failed for: [wheezy_udp@dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@dns-test-service.dns-9496.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_udp@dns-test-service.dns-9496.svc.cluster.local jessie_tcp@dns-test-service.dns-9496.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9496.svc.cluster.local]

    Dec 14 09:58:12.098: INFO: DNS probes using dns-9496/dns-test-835a0f57-ecd5-47e0-8bfb-26847c8dd21a succeeded

    STEP: deleting the pod 12/14/22 09:58:12.098
    STEP: deleting the test service 12/14/22 09:58:12.135
    STEP: deleting the test headless service 12/14/22 09:58:12.181
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:58:12.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9496" for this suite. 12/14/22 09:58:12.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:12.286
Dec 14 09:58:12.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:58:12.287
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:12.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:12.411
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 12/14/22 09:58:12.462
Dec 14 09:58:12.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-9748 api-versions'
Dec 14 09:58:12.643: INFO: stderr: ""
Dec 14 09:58:12.643: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling.k8s.io/v1\nautoscaling.k8s.io/v1beta2\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:58:12.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9748" for this suite. 12/14/22 09:58:12.669
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":325,"skipped":6207,"failed":0}
------------------------------
• [0.409 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:12.286
    Dec 14 09:58:12.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:58:12.287
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:12.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:12.411
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 12/14/22 09:58:12.462
    Dec 14 09:58:12.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-9748 api-versions'
    Dec 14 09:58:12.643: INFO: stderr: ""
    Dec 14 09:58:12.643: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling.k8s.io/v1\nautoscaling.k8s.io/v1beta2\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:58:12.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9748" for this suite. 12/14/22 09:58:12.669
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:12.696
Dec 14 09:58:12.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:58:12.697
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:12.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:12.819
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 12/14/22 09:58:12.867
STEP: wait for the container to reach Succeeded 12/14/22 09:58:12.898
STEP: get the container status 12/14/22 09:58:17.027
STEP: the container should be terminated 12/14/22 09:58:17.052
STEP: the termination message should be set 12/14/22 09:58:17.052
Dec 14 09:58:17.053: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/14/22 09:58:17.053
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:58:17.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3804" for this suite. 12/14/22 09:58:17.165
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":326,"skipped":6211,"failed":0}
------------------------------
• [4.500 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:12.696
    Dec 14 09:58:12.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:58:12.697
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:12.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:12.819
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 12/14/22 09:58:12.867
    STEP: wait for the container to reach Succeeded 12/14/22 09:58:12.898
    STEP: get the container status 12/14/22 09:58:17.027
    STEP: the container should be terminated 12/14/22 09:58:17.052
    STEP: the termination message should be set 12/14/22 09:58:17.052
    Dec 14 09:58:17.053: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/14/22 09:58:17.053
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:58:17.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3804" for this suite. 12/14/22 09:58:17.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:17.197
Dec 14 09:58:17.197: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:58:17.197
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:17.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:17.328
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 12/14/22 09:58:17.375
STEP: Ensuring active pods == parallelism 12/14/22 09:58:17.4
STEP: delete a job 12/14/22 09:58:19.427
STEP: deleting Job.batch foo in namespace job-5999, will wait for the garbage collector to delete the pods 12/14/22 09:58:19.427
Dec 14 09:58:19.530: INFO: Deleting Job.batch foo took: 26.150469ms
Dec 14 09:58:19.631: INFO: Terminating Job.batch foo pods took: 101.039472ms
STEP: Ensuring job was deleted 12/14/22 09:58:52.532
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:58:52.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5999" for this suite. 12/14/22 09:58:52.604
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":327,"skipped":6218,"failed":0}
------------------------------
• [35.434 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:17.197
    Dec 14 09:58:17.197: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:58:17.197
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:17.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:17.328
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 12/14/22 09:58:17.375
    STEP: Ensuring active pods == parallelism 12/14/22 09:58:17.4
    STEP: delete a job 12/14/22 09:58:19.427
    STEP: deleting Job.batch foo in namespace job-5999, will wait for the garbage collector to delete the pods 12/14/22 09:58:19.427
    Dec 14 09:58:19.530: INFO: Deleting Job.batch foo took: 26.150469ms
    Dec 14 09:58:19.631: INFO: Terminating Job.batch foo pods took: 101.039472ms
    STEP: Ensuring job was deleted 12/14/22 09:58:52.532
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:58:52.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5999" for this suite. 12/14/22 09:58:52.604
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:52.631
Dec 14 09:58:52.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:58:52.632
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:52.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:52.754
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-bd6c9e81-a38e-4aa6-a0c8-d69edff01321 12/14/22 09:58:52.802
STEP: Creating a pod to test consume configMaps 12/14/22 09:58:52.828
Dec 14 09:58:52.865: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a" in namespace "projected-4968" to be "Succeeded or Failed"
Dec 14 09:58:52.889: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.46504ms
Dec 14 09:58:54.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051048597s
Dec 14 09:58:56.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050915187s
STEP: Saw pod success 12/14/22 09:58:56.916
Dec 14 09:58:56.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a" satisfied condition "Succeeded or Failed"
Dec 14 09:58:56.941: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:58:57.016
Dec 14 09:58:57.061: INFO: Waiting for pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a to disappear
Dec 14 09:58:57.086: INFO: Pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:58:57.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4968" for this suite. 12/14/22 09:58:57.134
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":328,"skipped":6231,"failed":0}
------------------------------
• [4.532 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:52.631
    Dec 14 09:58:52.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:58:52.632
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:52.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:52.754
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-bd6c9e81-a38e-4aa6-a0c8-d69edff01321 12/14/22 09:58:52.802
    STEP: Creating a pod to test consume configMaps 12/14/22 09:58:52.828
    Dec 14 09:58:52.865: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a" in namespace "projected-4968" to be "Succeeded or Failed"
    Dec 14 09:58:52.889: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.46504ms
    Dec 14 09:58:54.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051048597s
    Dec 14 09:58:56.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050915187s
    STEP: Saw pod success 12/14/22 09:58:56.916
    Dec 14 09:58:56.916: INFO: Pod "pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a" satisfied condition "Succeeded or Failed"
    Dec 14 09:58:56.941: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:58:57.016
    Dec 14 09:58:57.061: INFO: Waiting for pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a to disappear
    Dec 14 09:58:57.086: INFO: Pod pod-projected-configmaps-60507dbe-927e-499d-a369-2e2450f1bb9a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:58:57.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4968" for this suite. 12/14/22 09:58:57.134
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:57.165
Dec 14 09:58:57.165: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:58:57.166
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:57.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:57.288
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 12/14/22 09:58:57.336
Dec 14 09:58:57.368: INFO: Waiting up to 5m0s for pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb" in namespace "containers-221" to be "Succeeded or Failed"
Dec 14 09:58:57.393: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.675993ms
Dec 14 09:58:59.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050671772s
Dec 14 09:59:01.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050883079s
STEP: Saw pod success 12/14/22 09:59:01.419
Dec 14 09:59:01.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb" satisfied condition "Succeeded or Failed"
Dec 14 09:59:01.445: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:59:01.477
Dec 14 09:59:01.508: INFO: Waiting for pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb to disappear
Dec 14 09:59:01.533: INFO: Pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:59:01.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-221" for this suite. 12/14/22 09:59:01.581
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":329,"skipped":6277,"failed":0}
------------------------------
• [4.442 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:57.165
    Dec 14 09:58:57.165: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:58:57.166
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:57.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:57.288
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 12/14/22 09:58:57.336
    Dec 14 09:58:57.368: INFO: Waiting up to 5m0s for pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb" in namespace "containers-221" to be "Succeeded or Failed"
    Dec 14 09:58:57.393: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.675993ms
    Dec 14 09:58:59.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050671772s
    Dec 14 09:59:01.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050883079s
    STEP: Saw pod success 12/14/22 09:59:01.419
    Dec 14 09:59:01.419: INFO: Pod "client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb" satisfied condition "Succeeded or Failed"
    Dec 14 09:59:01.445: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:59:01.477
    Dec 14 09:59:01.508: INFO: Waiting for pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb to disappear
    Dec 14 09:59:01.533: INFO: Pod client-containers-a4339692-cbef-44e5-b1f3-1885b7988bbb no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:59:01.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-221" for this suite. 12/14/22 09:59:01.581
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:01.608
Dec 14 09:59:01.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:59:01.609
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:01.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:01.732
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 12/14/22 09:59:01.779
Dec 14 09:59:01.779: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5779 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 12/14/22 09:59:01.835
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:59:01.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5779" for this suite. 12/14/22 09:59:01.969
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":330,"skipped":6297,"failed":0}
------------------------------
• [0.387 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:01.608
    Dec 14 09:59:01.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:59:01.609
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:01.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:01.732
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 12/14/22 09:59:01.779
    Dec 14 09:59:01.779: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5779 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 12/14/22 09:59:01.835
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:59:01.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5779" for this suite. 12/14/22 09:59:01.969
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:01.996
Dec 14 09:59:01.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:59:01.997
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:02.071
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:02.122
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 12/14/22 09:59:02.194
STEP: waiting for Deployment to be created 12/14/22 09:59:02.221
STEP: waiting for all Replicas to be Ready 12/14/22 09:59:02.245
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.272: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:02.272: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 09:59:03.481: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 14 09:59:03.481: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 14 09:59:03.994: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 12/14/22 09:59:03.994
W1214 09:59:04.020570    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 09:59:04.044: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 12/14/22 09:59:04.044
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:05.500: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:05.501: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:05.517: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
STEP: listing Deployments 12/14/22 09:59:05.517
Dec 14 09:59:05.543: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 12/14/22 09:59:05.544
Dec 14 09:59:05.600: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 12/14/22 09:59:05.6
Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:06.550: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:06.574: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:06.584: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 09:59:08.094: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 12/14/22 09:59:08.111
STEP: fetching the DeploymentStatus 12/14/22 09:59:08.161
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 3
STEP: deleting the Deployment 12/14/22 09:59:08.211
Dec 14 09:59:08.263: INFO: observed event type MODIFIED
Dec 14 09:59:08.263: INFO: observed event type MODIFIED
Dec 14 09:59:08.263: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
Dec 14 09:59:08.264: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:59:08.289: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:59:08.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6769" for this suite. 12/14/22 09:59:08.34
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":331,"skipped":6316,"failed":0}
------------------------------
• [6.371 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:01.996
    Dec 14 09:59:01.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:59:01.997
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:02.071
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:02.122
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 12/14/22 09:59:02.194
    STEP: waiting for Deployment to be created 12/14/22 09:59:02.221
    STEP: waiting for all Replicas to be Ready 12/14/22 09:59:02.245
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.269: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.272: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:02.272: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 09:59:03.481: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec 14 09:59:03.481: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec 14 09:59:03.994: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 12/14/22 09:59:03.994
    W1214 09:59:04.020570    6274 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 09:59:04.044: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 12/14/22 09:59:04.044
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.067: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 0
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:04.088: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:05.500: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:05.501: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:05.517: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    STEP: listing Deployments 12/14/22 09:59:05.517
    Dec 14 09:59:05.543: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 12/14/22 09:59:05.544
    Dec 14 09:59:05.600: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 12/14/22 09:59:05.6
    Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:05.651: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:06.550: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:06.574: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:06.584: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 09:59:08.094: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 12/14/22 09:59:08.111
    STEP: fetching the DeploymentStatus 12/14/22 09:59:08.161
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 1
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 2
    Dec 14 09:59:08.211: INFO: observed Deployment test-deployment in namespace deployment-6769 with ReadyReplicas 3
    STEP: deleting the Deployment 12/14/22 09:59:08.211
    Dec 14 09:59:08.263: INFO: observed event type MODIFIED
    Dec 14 09:59:08.263: INFO: observed event type MODIFIED
    Dec 14 09:59:08.263: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    Dec 14 09:59:08.264: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:59:08.289: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:59:08.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6769" for this suite. 12/14/22 09:59:08.34
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:08.367
Dec 14 09:59:08.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:59:08.369
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:08.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:08.495
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:59:08.541
Dec 14 09:59:08.572: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647" in namespace "downward-api-1151" to be "Succeeded or Failed"
Dec 14 09:59:08.597: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Pending", Reason="", readiness=false. Elapsed: 24.695724ms
Dec 14 09:59:10.624: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051516674s
Dec 14 09:59:12.623: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050954346s
STEP: Saw pod success 12/14/22 09:59:12.623
Dec 14 09:59:12.623: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647" satisfied condition "Succeeded or Failed"
Dec 14 09:59:12.649: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 container client-container: <nil>
STEP: delete the pod 12/14/22 09:59:12.682
Dec 14 09:59:12.719: INFO: Waiting for pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 to disappear
Dec 14 09:59:12.744: INFO: Pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:59:12.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1151" for this suite. 12/14/22 09:59:12.792
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":332,"skipped":6321,"failed":0}
------------------------------
• [4.452 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:08.367
    Dec 14 09:59:08.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:59:08.369
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:08.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:08.495
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:59:08.541
    Dec 14 09:59:08.572: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647" in namespace "downward-api-1151" to be "Succeeded or Failed"
    Dec 14 09:59:08.597: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Pending", Reason="", readiness=false. Elapsed: 24.695724ms
    Dec 14 09:59:10.624: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051516674s
    Dec 14 09:59:12.623: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050954346s
    STEP: Saw pod success 12/14/22 09:59:12.623
    Dec 14 09:59:12.623: INFO: Pod "downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647" satisfied condition "Succeeded or Failed"
    Dec 14 09:59:12.649: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:59:12.682
    Dec 14 09:59:12.719: INFO: Waiting for pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 to disappear
    Dec 14 09:59:12.744: INFO: Pod downwardapi-volume-3586abf4-a58d-4635-bac7-37a0d15d0647 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:59:12.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1151" for this suite. 12/14/22 09:59:12.792
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:12.82
Dec 14 09:59:12.820: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:59:12.82
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:12.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:12.944
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Dec 14 09:59:12.991: INFO: Creating simple deployment test-new-deployment
Dec 14 09:59:13.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 12/14/22 09:59:15.143
STEP: updating a scale subresource 12/14/22 09:59:15.168
STEP: verifying the deployment Spec.Replicas was modified 12/14/22 09:59:15.194
STEP: Patch a scale subresource 12/14/22 09:59:15.225
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:59:15.417: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-7101  4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7 57982 3 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038077d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:4,UpdatedReplicas:4,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-14 09:59:14 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:59:15 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 09:59:15.443: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7101  d396ff97-33f8-4784-b755-a09f2cff45af 57981 3 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7 0xc003707d77 0xc003707d78}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003707e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-28bjg" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-28bjg test-new-deployment-845c8977d9- deployment-7101  670db759-11b1-46ba-8d2a-439ead1610ec 57954 0 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d82f1ef5494c8dfefc9da508e588a661c40aea7ade9b4335e5c1a1efe3bfce71 cni.projectcalico.org/podIP:100.64.0.12/32 cni.projectcalico.org/podIPs:100.64.0.12/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c417 0xc003c1c418}] [] [{Go-http-client Update v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-clkfp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-clkfp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.12,StartTime:2022-12-14 09:59:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://032c93e1d1d57229efa6b9afb6a689947acd050490adf218c1e9c25879979e83,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-2wxjx" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-2wxjx test-new-deployment-845c8977d9- deployment-7101  fc00bca3-3b92-4fb7-8ee9-713aac5f96fb 57980 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c6d0 0xc003c1c6d1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bwg9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bwg9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-kc6pm" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-kc6pm test-new-deployment-845c8977d9- deployment-7101  326d9d2d-7daa-4e5d-ab95-3723868dd0c1 57983 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c8e0 0xc003c1c8e1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-njcm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-njcm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:15.470: INFO: Pod "test-new-deployment-845c8977d9-sqr68" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-sqr68 test-new-deployment-845c8977d9- deployment-7101  09163772-7076-414f-b71f-5a56099244b2 57972 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1cb10 0xc003c1cb11}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xjtbl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xjtbl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:59:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7101" for this suite. 12/14/22 09:59:15.518
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":333,"skipped":6324,"failed":0}
------------------------------
• [2.724 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:12.82
    Dec 14 09:59:12.820: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:59:12.82
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:12.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:12.944
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Dec 14 09:59:12.991: INFO: Creating simple deployment test-new-deployment
    Dec 14 09:59:13.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 59, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 12/14/22 09:59:15.143
    STEP: updating a scale subresource 12/14/22 09:59:15.168
    STEP: verifying the deployment Spec.Replicas was modified 12/14/22 09:59:15.194
    STEP: Patch a scale subresource 12/14/22 09:59:15.225
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:59:15.417: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-7101  4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7 57982 3 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038077d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:4,UpdatedReplicas:4,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-14 09:59:14 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:59:15 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 09:59:15.443: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7101  d396ff97-33f8-4784-b755-a09f2cff45af 57981 3 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7 0xc003707d77 0xc003707d78}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e7c0496-cfb6-40b9-94a1-cfc3c77b72d7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003707e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-28bjg" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-28bjg test-new-deployment-845c8977d9- deployment-7101  670db759-11b1-46ba-8d2a-439ead1610ec 57954 0 2022-12-14 09:59:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d82f1ef5494c8dfefc9da508e588a661c40aea7ade9b4335e5c1a1efe3bfce71 cni.projectcalico.org/podIP:100.64.0.12/32 cni.projectcalico.org/podIPs:100.64.0.12/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c417 0xc003c1c418}] [] [{Go-http-client Update v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-clkfp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-clkfp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.12,StartTime:2022-12-14 09:59:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://032c93e1d1d57229efa6b9afb6a689947acd050490adf218c1e9c25879979e83,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-2wxjx" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-2wxjx test-new-deployment-845c8977d9- deployment-7101  fc00bca3-3b92-4fb7-8ee9-713aac5f96fb 57980 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c6d0 0xc003c1c6d1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bwg9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bwg9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:15.469: INFO: Pod "test-new-deployment-845c8977d9-kc6pm" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-kc6pm test-new-deployment-845c8977d9- deployment-7101  326d9d2d-7daa-4e5d-ab95-3723868dd0c1 57983 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1c8e0 0xc003c1c8e1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-njcm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-njcm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:15.470: INFO: Pod "test-new-deployment-845c8977d9-sqr68" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-sqr68 test-new-deployment-845c8977d9- deployment-7101  09163772-7076-414f-b71f-5a56099244b2 57972 0 2022-12-14 09:59:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 d396ff97-33f8-4784-b755-a09f2cff45af 0xc003c1cb10 0xc003c1cb11}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d396ff97-33f8-4784-b755-a09f2cff45af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xjtbl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xjtbl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:59:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7101" for this suite. 12/14/22 09:59:15.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:15.545
Dec 14 09:59:15.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:59:15.546
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:15.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:15.67
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-a2bd5743-b8de-4cd1-be35-502b73f70460 12/14/22 09:59:15.72
STEP: Creating a pod to test consume secrets 12/14/22 09:59:15.746
Dec 14 09:59:15.778: INFO: Waiting up to 5m0s for pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303" in namespace "secrets-2492" to be "Succeeded or Failed"
Dec 14 09:59:15.803: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Pending", Reason="", readiness=false. Elapsed: 24.158629ms
Dec 14 09:59:17.830: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051281833s
Dec 14 09:59:19.829: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050598271s
STEP: Saw pod success 12/14/22 09:59:19.829
Dec 14 09:59:19.829: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303" satisfied condition "Succeeded or Failed"
Dec 14 09:59:19.854: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:59:19.886
Dec 14 09:59:19.920: INFO: Waiting for pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 to disappear
Dec 14 09:59:19.946: INFO: Pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:59:19.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2492" for this suite. 12/14/22 09:59:19.994
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":334,"skipped":6356,"failed":0}
------------------------------
• [4.475 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:15.545
    Dec 14 09:59:15.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:59:15.546
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:15.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:15.67
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-a2bd5743-b8de-4cd1-be35-502b73f70460 12/14/22 09:59:15.72
    STEP: Creating a pod to test consume secrets 12/14/22 09:59:15.746
    Dec 14 09:59:15.778: INFO: Waiting up to 5m0s for pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303" in namespace "secrets-2492" to be "Succeeded or Failed"
    Dec 14 09:59:15.803: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Pending", Reason="", readiness=false. Elapsed: 24.158629ms
    Dec 14 09:59:17.830: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051281833s
    Dec 14 09:59:19.829: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050598271s
    STEP: Saw pod success 12/14/22 09:59:19.829
    Dec 14 09:59:19.829: INFO: Pod "pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303" satisfied condition "Succeeded or Failed"
    Dec 14 09:59:19.854: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:59:19.886
    Dec 14 09:59:19.920: INFO: Waiting for pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 to disappear
    Dec 14 09:59:19.946: INFO: Pod pod-secrets-74d9e84d-2160-4bde-bf15-21d8d01b9303 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:59:19.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2492" for this suite. 12/14/22 09:59:19.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:20.021
Dec 14 09:59:20.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:59:20.022
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:20.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:20.147
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Dec 14 09:59:20.194: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod 12/14/22 09:59:20.194
STEP: submitting the pod to kubernetes 12/14/22 09:59:20.194
Dec 14 09:59:20.227: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5" in namespace "pods-6061" to be "running and ready"
Dec 14 09:59:20.258: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 31.138512ms
Dec 14 09:59:20.258: INFO: The phase of Pod pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:59:22.284: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5": Phase="Running", Reason="", readiness=true. Elapsed: 2.05707756s
Dec 14 09:59:22.284: INFO: The phase of Pod pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5 is Running (Ready = true)
Dec 14 09:59:22.284: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:59:22.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6061" for this suite. 12/14/22 09:59:22.612
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":335,"skipped":6363,"failed":0}
------------------------------
• [2.620 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:20.021
    Dec 14 09:59:20.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:59:20.022
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:20.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:20.147
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Dec 14 09:59:20.194: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating the pod 12/14/22 09:59:20.194
    STEP: submitting the pod to kubernetes 12/14/22 09:59:20.194
    Dec 14 09:59:20.227: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5" in namespace "pods-6061" to be "running and ready"
    Dec 14 09:59:20.258: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 31.138512ms
    Dec 14 09:59:20.258: INFO: The phase of Pod pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:59:22.284: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5": Phase="Running", Reason="", readiness=true. Elapsed: 2.05707756s
    Dec 14 09:59:22.284: INFO: The phase of Pod pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5 is Running (Ready = true)
    Dec 14 09:59:22.284: INFO: Pod "pod-logs-websocket-6c6123b4-295b-4cde-9306-d337e90e0ca5" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:59:22.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6061" for this suite. 12/14/22 09:59:22.612
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:22.642
Dec 14 09:59:22.642: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:59:22.643
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:22.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:22.765
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Dec 14 09:59:22.814: INFO: Creating deployment "webserver-deployment"
Dec 14 09:59:22.840: INFO: Waiting for observed generation 1
Dec 14 09:59:24.892: INFO: Waiting for all required pods to come up
Dec 14 09:59:24.941: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 12/14/22 09:59:24.941
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zdxlx" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lqltv" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-s5wz6" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qrl7f" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tnjpz" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-94l28" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tdtcw" in namespace "deployment-551" to be "running"
Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-s5wz6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.211641ms
Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-94l28": Phase="Pending", Reason="", readiness=false. Elapsed: 25.068345ms
Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-lqltv": Phase="Pending", Reason="", readiness=false. Elapsed: 25.242586ms
Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-qrl7f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.164557ms
Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-tnjpz": Phase="Pending", Reason="", readiness=false. Elapsed: 25.120578ms
Dec 14 09:59:24.967: INFO: Pod "webserver-deployment-845c8977d9-zdxlx": Phase="Pending", Reason="", readiness=false. Elapsed: 25.487974ms
Dec 14 09:59:24.986: INFO: Pod "webserver-deployment-845c8977d9-tdtcw": Phase="Pending", Reason="", readiness=false. Elapsed: 44.725968ms
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-lqltv": Phase="Running", Reason="", readiness=true. Elapsed: 2.052601263s
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-lqltv" satisfied condition "running"
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-zdxlx": Phase="Running", Reason="", readiness=true. Elapsed: 2.052686866s
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-zdxlx" satisfied condition "running"
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-94l28": Phase="Running", Reason="", readiness=true. Elapsed: 2.052931721s
Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-94l28" satisfied condition "running"
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-qrl7f": Phase="Running", Reason="", readiness=true. Elapsed: 2.07427851s
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-qrl7f" satisfied condition "running"
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-s5wz6": Phase="Running", Reason="", readiness=true. Elapsed: 2.074317153s
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-s5wz6" satisfied condition "running"
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tdtcw": Phase="Running", Reason="", readiness=true. Elapsed: 2.07408291s
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tdtcw" satisfied condition "running"
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tnjpz": Phase="Running", Reason="", readiness=true. Elapsed: 2.074245981s
Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tnjpz" satisfied condition "running"
Dec 14 09:59:27.016: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 14 09:59:27.067: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 14 09:59:27.117: INFO: Updating deployment webserver-deployment
Dec 14 09:59:27.117: INFO: Waiting for observed generation 2
Dec 14 09:59:29.172: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 14 09:59:29.197: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 14 09:59:29.222: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:59:29.298: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 14 09:59:29.298: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 14 09:59:29.323: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:59:29.374: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 14 09:59:29.374: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 14 09:59:29.425: INFO: Updating deployment webserver-deployment
Dec 14 09:59:29.425: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:59:29.487: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 14 09:59:29.515: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:59:31.599: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-551  7f497c46-4967-4b90-8d5b-4abd4cf3c466 58321 3 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bec248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:59:29 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-14 09:59:29 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 14 09:59:31.624: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-551  059d8a99-c192-45e0-8a1a-8349e3cc17db 58319 3 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7f497c46-4967-4b90-8d5b-4abd4cf3c466 0xc003bec837 0xc003bec838}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f497c46-4967-4b90-8d5b-4abd4cf3c466\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bec918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:59:31.624: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 14 09:59:31.624: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-551  06eb6b69-05f2-42be-8381-e46fdf68c1aa 58303 3 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7f497c46-4967-4b90-8d5b-4abd4cf3c466 0xc003bec997 0xc003bec998}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f497c46-4967-4b90-8d5b-4abd4cf3c466\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003beca48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:59:31.719: INFO: Pod "webserver-deployment-69b7448995-785w8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-785w8 webserver-deployment-69b7448995- deployment-551  c6e9a4b4-1d95-4a09-9567-3bb9e9d799a0 58331 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:cd2c07f72402781620ad8a57259d09628f6490c5302e2656a27eefd9ba7c9452 cni.projectcalico.org/podIP:100.64.0.26/32 cni.projectcalico.org/podIPs:100.64.0.26/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cb807 0xc0058cb808}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fsv5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fsv5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.719: INFO: Pod "webserver-deployment-69b7448995-bnj8m" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-bnj8m webserver-deployment-69b7448995- deployment-551  2c936736-3a53-40cf-b429-1347a8aa7bd0 58247 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:6d64e127a20b870ebb2c8e7219726d2a5ad3446dd92c7745158806c54c7ece4a cni.projectcalico.org/podIP:100.64.1.235/32 cni.projectcalico.org/podIPs:100.64.1.235/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cba80 0xc0058cba81}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l4jkc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l4jkc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.235,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-ffgdp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ffgdp webserver-deployment-69b7448995- deployment-551  010179a5-f5b9-4a6c-99db-dd6043f81f5e 58248 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ebb8258607c498cf9a32d1601e5e426a90b7c5e3a1ded0e2220d28eaf56a1de3 cni.projectcalico.org/podIP:100.64.1.234/32 cni.projectcalico.org/podIPs:100.64.1.234/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cbd80 0xc0058cbd81}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwb74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwb74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.234,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-hmhz9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-hmhz9 webserver-deployment-69b7448995- deployment-551  faa660da-a26a-450c-ba68-ef85070ca490 58336 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:aee7511820888292e33292a36c7c76b3de4d3e7d546d43849f3b2b6ebe7f06f1 cni.projectcalico.org/podIP:100.64.0.28/32 cni.projectcalico.org/podIPs:100.64.0.28/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cbfd0 0xc0058cbfd1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jtrjc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jtrjc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-jpnt9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jpnt9 webserver-deployment-69b7448995- deployment-551  4a6e51f4-5291-48d1-84eb-e0c3eae160c2 58345 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:316708ffcf0f2cbc80a92470f44bc046c30fd292eb476d792cf59163c396db43 cni.projectcalico.org/podIP:100.64.1.241/32 cni.projectcalico.org/podIPs:100.64.1.241/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc2a0 0xc005fbc2a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zcmjp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zcmjp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-lld4v" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lld4v webserver-deployment-69b7448995- deployment-551  1c4c5179-5725-457a-be46-8bf8a448c9a8 58339 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:91bdd1c8157927e29a5ba44b062fd7c75f9449e0bc994ea0dd8f96c29bc8d8cb cni.projectcalico.org/podIP:100.64.0.31/32 cni.projectcalico.org/podIPs:100.64.0.31/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc530 0xc005fbc531}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fzkbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fzkbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-mt2jx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mt2jx webserver-deployment-69b7448995- deployment-551  c0b98495-bc0f-438c-80cd-5fb47e804aeb 58337 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7c34fa41f9dce1c61900c77e1ea34d3d3b0ccb7dea7ff3e2d20206b49e05039b cni.projectcalico.org/podIP:100.64.0.29/32 cni.projectcalico.org/podIPs:100.64.0.29/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc790 0xc005fbc791}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-psdpl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-psdpl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-pcbrt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pcbrt webserver-deployment-69b7448995- deployment-551  9e2f4d74-117e-4884-9256-a4f30dcea51a 58340 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7bd475c5740018385d2f5e11143889bc66f4a38d307009781062b42462259c7c cni.projectcalico.org/podIP:100.64.1.239/32 cni.projectcalico.org/podIPs:100.64.1.239/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc9b0 0xc005fbc9b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hf578,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hf578,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-pzbjz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pzbjz webserver-deployment-69b7448995- deployment-551  81fa451b-e9f1-4a2f-bc5a-e6633d21c4b6 58343 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:659097faaaa5c73f117f625b8a56f4796a73fc731257c09f5d2a18f376704247 cni.projectcalico.org/podIP:100.64.1.240/32 cni.projectcalico.org/podIPs:100.64.1.240/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbcc20 0xc005fbcc21}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tfwmc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tfwmc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-qv7st" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qv7st webserver-deployment-69b7448995- deployment-551  2eed8db3-a2f3-4056-a101-f90f5f3ea3aa 58347 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:407cb0e9f6870e94a8c5dea7b10bcae6d84b382a4e828d0e488eabb3e776a7ee cni.projectcalico.org/podIP:100.64.1.243/32 cni.projectcalico.org/podIPs:100.64.1.243/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbce50 0xc005fbce51}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dl7m2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dl7m2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-rj8mb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-rj8mb webserver-deployment-69b7448995- deployment-551  fbd7681b-2ea4-4ae2-ae99-31b3abdfe1d1 58322 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8cf153808eb23fec200d107ce6c4a0b2b75bf9093c99f4e0dde71f663aff1c54 cni.projectcalico.org/podIP:100.64.0.22/32 cni.projectcalico.org/podIPs:100.64.0.22/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd070 0xc005fbd071}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j58nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j58nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.22,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-69b7448995-sfqzv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sfqzv webserver-deployment-69b7448995- deployment-551  74c96818-2507-4282-a99b-f0eba0f25df6 58320 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d5f8d2c23e1762ae7e20bf7b8dc1d586b9cda614a293ee8b3545888050a4fa00 cni.projectcalico.org/podIP:100.64.0.21/32 cni.projectcalico.org/podIPs:100.64.0.21/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd2b0 0xc005fbd2b1}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n9v5k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n9v5k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.21,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-69b7448995-x95dw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-x95dw webserver-deployment-69b7448995- deployment-551  ac1baa00-c1a6-421f-aa01-610ef0ef4c7d 58318 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0df649609e8aaafddf0a11c60e8f6f7c22cda23ee658981cff918485db69c33d cni.projectcalico.org/podIP:100.64.0.20/32 cni.projectcalico.org/podIPs:100.64.0.20/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd530 0xc005fbd531}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rxlqp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rxlqp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.20,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4lzrc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4lzrc webserver-deployment-845c8977d9- deployment-551  928ac64c-4615-4eea-9efe-1445629a1c7d 58342 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6d1e3035318616ad0ca31514e9ec1590686370eaa4906e4a97e0b3c594633821 cni.projectcalico.org/podIP:100.64.0.32/32 cni.projectcalico.org/podIPs:100.64.0.32/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc005fbd7b0 0xc005fbd7b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9f7vt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9f7vt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4rmw8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4rmw8 webserver-deployment-845c8977d9- deployment-551  68e6d23b-30c9-4edc-b5fb-bc308a7c6f73 58333 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:dc045c4c9a1c4c54e84d2996e3a5957419c37d888d13d9c24dddd17af50c3183 cni.projectcalico.org/podIP:100.64.1.237/32 cni.projectcalico.org/podIPs:100.64.1.237/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc005fbdcd0 0xc005fbdcd1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4848q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4848q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4xq5w" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4xq5w webserver-deployment-845c8977d9- deployment-551  cf99abc3-2d09-4cc2-8757-ee981219f04f 58346 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:65921ccf142ddec9a0b6a077bffa3f4aed00a73e467ee561b4935ffa483b95f6 cni.projectcalico.org/podIP:100.64.1.245/32 cni.projectcalico.org/podIPs:100.64.1.245/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c0d0 0xc00434c0d1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvh7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvh7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-bwxt4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bwxt4 webserver-deployment-845c8977d9- deployment-551  aa702b42-8e85-4acc-98fc-959f57be6078 58146 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fc514027a0b514ec90566dfe33e9fef8207a6efd076c9d96dcfbc3846900cd73 cni.projectcalico.org/podIP:100.64.0.15/32 cni.projectcalico.org/podIPs:100.64.0.15/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c3e0 0xc00434c3e1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9bl7b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9bl7b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.15,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f461bfb85b6845853ad2638a9281788c54b1098a43b67e4019c40c891f84b6a1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-gjdxv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gjdxv webserver-deployment-845c8977d9- deployment-551  0fbdae21-36a4-4749-b05e-08b2f5740d25 58350 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:cbbbca13bc8b65d0030c4cb411f516b13a4626303900feeef7decae54afac677 cni.projectcalico.org/podIP:100.64.1.244/32 cni.projectcalico.org/podIPs:100.64.1.244/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c670 0xc00434c671}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xpgfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xpgfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-j2544" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j2544 webserver-deployment-845c8977d9- deployment-551  e629bec9-dbf3-477e-a8c9-c0c4cdf66228 58140 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d5c6b51f420dfbc459471bc37f6a6bb922e13dae19c029ac760823a988f0e5df cni.projectcalico.org/podIP:100.64.0.16/32 cni.projectcalico.org/podIPs:100.64.0.16/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c880 0xc00434c881}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nd9kv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nd9kv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.16,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7d71a1fd9e1aeaf223295cc052cca08fe17e1dae7e99faf4453657e40ae905f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-j5xfr" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j5xfr webserver-deployment-845c8977d9- deployment-551  c46c5562-42da-41a1-815d-3fdc70117525 58143 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e4e892ed790c908e37deeef1ba42544cf4742e2fd9824281aa94527062d308d7 cni.projectcalico.org/podIP:100.64.0.17/32 cni.projectcalico.org/podIPs:100.64.0.17/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434caa0 0xc00434caa1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vvz84,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vvz84,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.17,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f73d8506868d6efc28fa54ad058042612afe380f13d5bc4e4c3b6596f5966e41,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-kv5nk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kv5nk webserver-deployment-845c8977d9- deployment-551  37c101ac-d97b-4ea7-ad63-565335e07aa3 58334 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ce639f7a6ecb74f5c4249fb206ee5462ba8ac552957c36b4395e0e191e55f264 cni.projectcalico.org/podIP:100.64.0.27/32 cni.projectcalico.org/podIPs:100.64.0.27/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434cd60 0xc00434cd61}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l5gvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l5gvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-lqltv" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lqltv webserver-deployment-845c8977d9- deployment-551  a010b3ff-5bfe-44ae-8fb1-03a3800082f7 58157 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:450d25393cc7756d83bbcb8350ab506e83411f33377afda13e4f570f06447a96 cni.projectcalico.org/podIP:100.64.1.230/32 cni.projectcalico.org/podIPs:100.64.1.230/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434cfc0 0xc00434cfc1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.230\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fjftb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fjftb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.230,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d7b8f98d770390844d1d34702d0b68d76cc6365ba5848d31e9485a4ee52682ef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.230,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-lzkwq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lzkwq webserver-deployment-845c8977d9- deployment-551  b510597a-48c5-4706-8304-58664819d3aa 58332 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bea182b2cb087d6415483b7bf94481452a0b8d99cba6084c11c1005814af1081 cni.projectcalico.org/podIP:100.64.1.238/32 cni.projectcalico.org/podIPs:100.64.1.238/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d220 0xc00434d221}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rmmbj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rmmbj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-mz9tn" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mz9tn webserver-deployment-845c8977d9- deployment-551  3f15d30b-b435-4065-8404-b597eb7425d0 58338 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:28054e922ee07808357064f1c69af0797067527980e6cb42862c23a7e9a97948 cni.projectcalico.org/podIP:100.64.0.30/32 cni.projectcalico.org/podIPs:100.64.0.30/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d440 0xc00434d441}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lwjs2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lwjs2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-nqkg9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nqkg9 webserver-deployment-845c8977d9- deployment-551  19a79d58-0f3c-4309-8342-26b6713cb050 58328 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9b12082cc90452dae0e41efbfb0323cef4634c50127875e5f792049f922bdfa1 cni.projectcalico.org/podIP:100.64.0.24/32 cni.projectcalico.org/podIPs:100.64.0.24/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d6a0 0xc00434d6a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xh2r5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xh2r5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-nwhdn" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nwhdn webserver-deployment-845c8977d9- deployment-551  36d8704f-e953-4e23-9ddb-8a941d0c1fa1 58327 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7c727a4050aeda53c30a62646f7b3d70bb280ec6b5c1b92c5c1dfe955cc80bae cni.projectcalico.org/podIP:100.64.0.25/32 cni.projectcalico.org/podIPs:100.64.0.25/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d9e0 0xc00434d9e1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-67vsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-67vsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-p2jkb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2jkb webserver-deployment-845c8977d9- deployment-551  be91e65d-d7b1-41f6-8b07-cb8e0ea41dd8 58349 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8db5469de1231a8ce720683e6bea89507c2223e32b0e6757a79a0390439cc67a cni.projectcalico.org/podIP:100.64.1.242/32 cni.projectcalico.org/podIPs:100.64.1.242/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434dcc0 0xc00434dcc1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cw54g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cw54g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-qrl7f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qrl7f webserver-deployment-845c8977d9- deployment-551  f924710a-f4a0-4ff3-9748-86463a34e682 58154 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:cbbb5614557eca18317425934962b7c9cdafcbb05eda33aa0a15d48291f2f392 cni.projectcalico.org/podIP:100.64.1.229/32 cni.projectcalico.org/podIPs:100.64.1.229/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434df60 0xc00434df61}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-phd7b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-phd7b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.229,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bfe0ea7783365b4735f16a90af5afa621a4266b2a54b14be763f62b7c8e2abfe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-s5wz6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-s5wz6 webserver-deployment-845c8977d9- deployment-551  f80dc1a5-2edb-4da6-952f-6f080ab6ebfe 58161 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ac58bf8ff89b60e77327fbefa539549811c4a265994206cc41cbc67d791a4cc8 cni.projectcalico.org/podIP:100.64.1.233/32 cni.projectcalico.org/podIPs:100.64.1.233/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374220 0xc004374221}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mptxw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mptxw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.233,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd48a4dea8a04c993a5cd515fdc2dce58766aada54f5a93d3573c8748a985068,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-sktj2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sktj2 webserver-deployment-845c8977d9- deployment-551  5bb25864-c661-4189-a53e-85695dc8c411 58324 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:85eceb332200f349f32ac1537663ed669aff5a5367fce86ee0c2ceb4b6dabbcb cni.projectcalico.org/podIP:100.64.1.236/32 cni.projectcalico.org/podIPs:100.64.1.236/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc0043744b0 0xc0043744b1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5v8fd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5v8fd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-tnjpz" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tnjpz webserver-deployment-845c8977d9- deployment-551  642cc039-2165-48f7-b2b2-869c32dce7e2 58177 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:16b5bfd59085b4d96b94e59c177b4e4294acd139bfb5ed2cd413a21fd84facef cni.projectcalico.org/podIP:100.64.0.18/32 cni.projectcalico.org/podIPs:100.64.0.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374710 0xc004374711}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wfwc6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wfwc6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.18,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://daf627713c57c21e26d3d0f66c0054b6b565c31e806c5e932a82c2a016b78560,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-w6l5d" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-w6l5d webserver-deployment-845c8977d9- deployment-551  a9e8dd5e-5400-4159-aed7-692e51ac95ba 58325 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8cc4b5b80e3724b60703f451c22ef9095e2aa4b5a61e2d0a9555db26108d3212 cni.projectcalico.org/podIP:100.64.0.23/32 cni.projectcalico.org/podIPs:100.64.0.23/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc0043749e0 0xc0043749e1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bts2g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bts2g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-zdxlx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zdxlx webserver-deployment-845c8977d9- deployment-551  939d306f-31e0-4b02-9725-db1f4c55f692 58164 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:92a32bfb19a78781216b891e4458370d126a26ae576b7e63e7f0a21649319a27 cni.projectcalico.org/podIP:100.64.1.232/32 cni.projectcalico.org/podIPs:100.64.1.232/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374be0 0xc004374be1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9vlc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9vlc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.232,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bf00940335c98061806ab517425a99be8396e042ead41abf00f2c106e0f28688,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:59:31.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-551" for this suite. 12/14/22 09:59:31.757
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":336,"skipped":6363,"failed":0}
------------------------------
• [9.141 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:22.642
    Dec 14 09:59:22.642: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:59:22.643
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:22.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:22.765
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Dec 14 09:59:22.814: INFO: Creating deployment "webserver-deployment"
    Dec 14 09:59:22.840: INFO: Waiting for observed generation 1
    Dec 14 09:59:24.892: INFO: Waiting for all required pods to come up
    Dec 14 09:59:24.941: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 12/14/22 09:59:24.941
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zdxlx" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lqltv" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-s5wz6" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qrl7f" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tnjpz" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-94l28" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.941: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tdtcw" in namespace "deployment-551" to be "running"
    Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-s5wz6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.211641ms
    Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-94l28": Phase="Pending", Reason="", readiness=false. Elapsed: 25.068345ms
    Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-lqltv": Phase="Pending", Reason="", readiness=false. Elapsed: 25.242586ms
    Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-qrl7f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.164557ms
    Dec 14 09:59:24.966: INFO: Pod "webserver-deployment-845c8977d9-tnjpz": Phase="Pending", Reason="", readiness=false. Elapsed: 25.120578ms
    Dec 14 09:59:24.967: INFO: Pod "webserver-deployment-845c8977d9-zdxlx": Phase="Pending", Reason="", readiness=false. Elapsed: 25.487974ms
    Dec 14 09:59:24.986: INFO: Pod "webserver-deployment-845c8977d9-tdtcw": Phase="Pending", Reason="", readiness=false. Elapsed: 44.725968ms
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-lqltv": Phase="Running", Reason="", readiness=true. Elapsed: 2.052601263s
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-lqltv" satisfied condition "running"
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-zdxlx": Phase="Running", Reason="", readiness=true. Elapsed: 2.052686866s
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-zdxlx" satisfied condition "running"
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-94l28": Phase="Running", Reason="", readiness=true. Elapsed: 2.052931721s
    Dec 14 09:59:26.994: INFO: Pod "webserver-deployment-845c8977d9-94l28" satisfied condition "running"
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-qrl7f": Phase="Running", Reason="", readiness=true. Elapsed: 2.07427851s
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-qrl7f" satisfied condition "running"
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-s5wz6": Phase="Running", Reason="", readiness=true. Elapsed: 2.074317153s
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-s5wz6" satisfied condition "running"
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tdtcw": Phase="Running", Reason="", readiness=true. Elapsed: 2.07408291s
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tdtcw" satisfied condition "running"
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tnjpz": Phase="Running", Reason="", readiness=true. Elapsed: 2.074245981s
    Dec 14 09:59:27.016: INFO: Pod "webserver-deployment-845c8977d9-tnjpz" satisfied condition "running"
    Dec 14 09:59:27.016: INFO: Waiting for deployment "webserver-deployment" to complete
    Dec 14 09:59:27.067: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Dec 14 09:59:27.117: INFO: Updating deployment webserver-deployment
    Dec 14 09:59:27.117: INFO: Waiting for observed generation 2
    Dec 14 09:59:29.172: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Dec 14 09:59:29.197: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Dec 14 09:59:29.222: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:59:29.298: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Dec 14 09:59:29.298: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Dec 14 09:59:29.323: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:59:29.374: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Dec 14 09:59:29.374: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Dec 14 09:59:29.425: INFO: Updating deployment webserver-deployment
    Dec 14 09:59:29.425: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:59:29.487: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Dec 14 09:59:29.515: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:59:31.599: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-551  7f497c46-4967-4b90-8d5b-4abd4cf3c466 58321 3 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bec248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:59:29 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-14 09:59:29 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Dec 14 09:59:31.624: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-551  059d8a99-c192-45e0-8a1a-8349e3cc17db 58319 3 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7f497c46-4967-4b90-8d5b-4abd4cf3c466 0xc003bec837 0xc003bec838}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f497c46-4967-4b90-8d5b-4abd4cf3c466\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bec918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:59:31.624: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Dec 14 09:59:31.624: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-551  06eb6b69-05f2-42be-8381-e46fdf68c1aa 58303 3 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7f497c46-4967-4b90-8d5b-4abd4cf3c466 0xc003bec997 0xc003bec998}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f497c46-4967-4b90-8d5b-4abd4cf3c466\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003beca48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:59:31.719: INFO: Pod "webserver-deployment-69b7448995-785w8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-785w8 webserver-deployment-69b7448995- deployment-551  c6e9a4b4-1d95-4a09-9567-3bb9e9d799a0 58331 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:cd2c07f72402781620ad8a57259d09628f6490c5302e2656a27eefd9ba7c9452 cni.projectcalico.org/podIP:100.64.0.26/32 cni.projectcalico.org/podIPs:100.64.0.26/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cb807 0xc0058cb808}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fsv5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fsv5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.719: INFO: Pod "webserver-deployment-69b7448995-bnj8m" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-bnj8m webserver-deployment-69b7448995- deployment-551  2c936736-3a53-40cf-b429-1347a8aa7bd0 58247 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:6d64e127a20b870ebb2c8e7219726d2a5ad3446dd92c7745158806c54c7ece4a cni.projectcalico.org/podIP:100.64.1.235/32 cni.projectcalico.org/podIPs:100.64.1.235/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cba80 0xc0058cba81}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l4jkc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l4jkc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.235,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-ffgdp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ffgdp webserver-deployment-69b7448995- deployment-551  010179a5-f5b9-4a6c-99db-dd6043f81f5e 58248 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ebb8258607c498cf9a32d1601e5e426a90b7c5e3a1ded0e2220d28eaf56a1de3 cni.projectcalico.org/podIP:100.64.1.234/32 cni.projectcalico.org/podIPs:100.64.1.234/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cbd80 0xc0058cbd81}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwb74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwb74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.234,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-hmhz9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-hmhz9 webserver-deployment-69b7448995- deployment-551  faa660da-a26a-450c-ba68-ef85070ca490 58336 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:aee7511820888292e33292a36c7c76b3de4d3e7d546d43849f3b2b6ebe7f06f1 cni.projectcalico.org/podIP:100.64.0.28/32 cni.projectcalico.org/podIPs:100.64.0.28/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc0058cbfd0 0xc0058cbfd1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jtrjc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jtrjc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-jpnt9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jpnt9 webserver-deployment-69b7448995- deployment-551  4a6e51f4-5291-48d1-84eb-e0c3eae160c2 58345 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:316708ffcf0f2cbc80a92470f44bc046c30fd292eb476d792cf59163c396db43 cni.projectcalico.org/podIP:100.64.1.241/32 cni.projectcalico.org/podIPs:100.64.1.241/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc2a0 0xc005fbc2a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zcmjp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zcmjp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-lld4v" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lld4v webserver-deployment-69b7448995- deployment-551  1c4c5179-5725-457a-be46-8bf8a448c9a8 58339 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:91bdd1c8157927e29a5ba44b062fd7c75f9449e0bc994ea0dd8f96c29bc8d8cb cni.projectcalico.org/podIP:100.64.0.31/32 cni.projectcalico.org/podIPs:100.64.0.31/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc530 0xc005fbc531}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fzkbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fzkbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.720: INFO: Pod "webserver-deployment-69b7448995-mt2jx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mt2jx webserver-deployment-69b7448995- deployment-551  c0b98495-bc0f-438c-80cd-5fb47e804aeb 58337 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7c34fa41f9dce1c61900c77e1ea34d3d3b0ccb7dea7ff3e2d20206b49e05039b cni.projectcalico.org/podIP:100.64.0.29/32 cni.projectcalico.org/podIPs:100.64.0.29/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc790 0xc005fbc791}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-psdpl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-psdpl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-pcbrt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pcbrt webserver-deployment-69b7448995- deployment-551  9e2f4d74-117e-4884-9256-a4f30dcea51a 58340 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7bd475c5740018385d2f5e11143889bc66f4a38d307009781062b42462259c7c cni.projectcalico.org/podIP:100.64.1.239/32 cni.projectcalico.org/podIPs:100.64.1.239/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbc9b0 0xc005fbc9b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hf578,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hf578,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-pzbjz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pzbjz webserver-deployment-69b7448995- deployment-551  81fa451b-e9f1-4a2f-bc5a-e6633d21c4b6 58343 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:659097faaaa5c73f117f625b8a56f4796a73fc731257c09f5d2a18f376704247 cni.projectcalico.org/podIP:100.64.1.240/32 cni.projectcalico.org/podIPs:100.64.1.240/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbcc20 0xc005fbcc21}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tfwmc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tfwmc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-qv7st" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qv7st webserver-deployment-69b7448995- deployment-551  2eed8db3-a2f3-4056-a101-f90f5f3ea3aa 58347 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:407cb0e9f6870e94a8c5dea7b10bcae6d84b382a4e828d0e488eabb3e776a7ee cni.projectcalico.org/podIP:100.64.1.243/32 cni.projectcalico.org/podIPs:100.64.1.243/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbce50 0xc005fbce51}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dl7m2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dl7m2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.721: INFO: Pod "webserver-deployment-69b7448995-rj8mb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-rj8mb webserver-deployment-69b7448995- deployment-551  fbd7681b-2ea4-4ae2-ae99-31b3abdfe1d1 58322 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8cf153808eb23fec200d107ce6c4a0b2b75bf9093c99f4e0dde71f663aff1c54 cni.projectcalico.org/podIP:100.64.0.22/32 cni.projectcalico.org/podIPs:100.64.0.22/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd070 0xc005fbd071}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j58nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j58nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.22,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-69b7448995-sfqzv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sfqzv webserver-deployment-69b7448995- deployment-551  74c96818-2507-4282-a99b-f0eba0f25df6 58320 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d5f8d2c23e1762ae7e20bf7b8dc1d586b9cda614a293ee8b3545888050a4fa00 cni.projectcalico.org/podIP:100.64.0.21/32 cni.projectcalico.org/podIPs:100.64.0.21/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd2b0 0xc005fbd2b1}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n9v5k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n9v5k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.21,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-69b7448995-x95dw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-x95dw webserver-deployment-69b7448995- deployment-551  ac1baa00-c1a6-421f-aa01-610ef0ef4c7d 58318 0 2022-12-14 09:59:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0df649609e8aaafddf0a11c60e8f6f7c22cda23ee658981cff918485db69c33d cni.projectcalico.org/podIP:100.64.0.20/32 cni.projectcalico.org/podIPs:100.64.0.20/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 059d8a99-c192-45e0-8a1a-8349e3cc17db 0xc005fbd530 0xc005fbd531}] [] [{Go-http-client Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"059d8a99-c192-45e0-8a1a-8349e3cc17db\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rxlqp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rxlqp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.20,StartTime:2022-12-14 09:59:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4lzrc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4lzrc webserver-deployment-845c8977d9- deployment-551  928ac64c-4615-4eea-9efe-1445629a1c7d 58342 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6d1e3035318616ad0ca31514e9ec1590686370eaa4906e4a97e0b3c594633821 cni.projectcalico.org/podIP:100.64.0.32/32 cni.projectcalico.org/podIPs:100.64.0.32/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc005fbd7b0 0xc005fbd7b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9f7vt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9f7vt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4rmw8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4rmw8 webserver-deployment-845c8977d9- deployment-551  68e6d23b-30c9-4edc-b5fb-bc308a7c6f73 58333 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:dc045c4c9a1c4c54e84d2996e3a5957419c37d888d13d9c24dddd17af50c3183 cni.projectcalico.org/podIP:100.64.1.237/32 cni.projectcalico.org/podIPs:100.64.1.237/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc005fbdcd0 0xc005fbdcd1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4848q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4848q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.722: INFO: Pod "webserver-deployment-845c8977d9-4xq5w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4xq5w webserver-deployment-845c8977d9- deployment-551  cf99abc3-2d09-4cc2-8757-ee981219f04f 58346 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:65921ccf142ddec9a0b6a077bffa3f4aed00a73e467ee561b4935ffa483b95f6 cni.projectcalico.org/podIP:100.64.1.245/32 cni.projectcalico.org/podIPs:100.64.1.245/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c0d0 0xc00434c0d1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvh7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvh7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-bwxt4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bwxt4 webserver-deployment-845c8977d9- deployment-551  aa702b42-8e85-4acc-98fc-959f57be6078 58146 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fc514027a0b514ec90566dfe33e9fef8207a6efd076c9d96dcfbc3846900cd73 cni.projectcalico.org/podIP:100.64.0.15/32 cni.projectcalico.org/podIPs:100.64.0.15/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c3e0 0xc00434c3e1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9bl7b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9bl7b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.15,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f461bfb85b6845853ad2638a9281788c54b1098a43b67e4019c40c891f84b6a1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-gjdxv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gjdxv webserver-deployment-845c8977d9- deployment-551  0fbdae21-36a4-4749-b05e-08b2f5740d25 58350 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:cbbbca13bc8b65d0030c4cb411f516b13a4626303900feeef7decae54afac677 cni.projectcalico.org/podIP:100.64.1.244/32 cni.projectcalico.org/podIPs:100.64.1.244/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c670 0xc00434c671}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xpgfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xpgfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.723: INFO: Pod "webserver-deployment-845c8977d9-j2544" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j2544 webserver-deployment-845c8977d9- deployment-551  e629bec9-dbf3-477e-a8c9-c0c4cdf66228 58140 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d5c6b51f420dfbc459471bc37f6a6bb922e13dae19c029ac760823a988f0e5df cni.projectcalico.org/podIP:100.64.0.16/32 cni.projectcalico.org/podIPs:100.64.0.16/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434c880 0xc00434c881}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nd9kv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nd9kv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.16,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7d71a1fd9e1aeaf223295cc052cca08fe17e1dae7e99faf4453657e40ae905f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-j5xfr" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j5xfr webserver-deployment-845c8977d9- deployment-551  c46c5562-42da-41a1-815d-3fdc70117525 58143 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e4e892ed790c908e37deeef1ba42544cf4742e2fd9824281aa94527062d308d7 cni.projectcalico.org/podIP:100.64.0.17/32 cni.projectcalico.org/podIPs:100.64.0.17/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434caa0 0xc00434caa1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vvz84,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vvz84,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.17,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f73d8506868d6efc28fa54ad058042612afe380f13d5bc4e4c3b6596f5966e41,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-kv5nk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kv5nk webserver-deployment-845c8977d9- deployment-551  37c101ac-d97b-4ea7-ad63-565335e07aa3 58334 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ce639f7a6ecb74f5c4249fb206ee5462ba8ac552957c36b4395e0e191e55f264 cni.projectcalico.org/podIP:100.64.0.27/32 cni.projectcalico.org/podIPs:100.64.0.27/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434cd60 0xc00434cd61}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l5gvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l5gvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-lqltv" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lqltv webserver-deployment-845c8977d9- deployment-551  a010b3ff-5bfe-44ae-8fb1-03a3800082f7 58157 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:450d25393cc7756d83bbcb8350ab506e83411f33377afda13e4f570f06447a96 cni.projectcalico.org/podIP:100.64.1.230/32 cni.projectcalico.org/podIPs:100.64.1.230/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434cfc0 0xc00434cfc1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.230\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fjftb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fjftb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.230,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d7b8f98d770390844d1d34702d0b68d76cc6365ba5848d31e9485a4ee52682ef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.230,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-lzkwq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lzkwq webserver-deployment-845c8977d9- deployment-551  b510597a-48c5-4706-8304-58664819d3aa 58332 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bea182b2cb087d6415483b7bf94481452a0b8d99cba6084c11c1005814af1081 cni.projectcalico.org/podIP:100.64.1.238/32 cni.projectcalico.org/podIPs:100.64.1.238/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d220 0xc00434d221}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rmmbj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rmmbj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.724: INFO: Pod "webserver-deployment-845c8977d9-mz9tn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mz9tn webserver-deployment-845c8977d9- deployment-551  3f15d30b-b435-4065-8404-b597eb7425d0 58338 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:28054e922ee07808357064f1c69af0797067527980e6cb42862c23a7e9a97948 cni.projectcalico.org/podIP:100.64.0.30/32 cni.projectcalico.org/podIPs:100.64.0.30/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d440 0xc00434d441}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lwjs2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lwjs2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-nqkg9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nqkg9 webserver-deployment-845c8977d9- deployment-551  19a79d58-0f3c-4309-8342-26b6713cb050 58328 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9b12082cc90452dae0e41efbfb0323cef4634c50127875e5f792049f922bdfa1 cni.projectcalico.org/podIP:100.64.0.24/32 cni.projectcalico.org/podIPs:100.64.0.24/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d6a0 0xc00434d6a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xh2r5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xh2r5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-nwhdn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nwhdn webserver-deployment-845c8977d9- deployment-551  36d8704f-e953-4e23-9ddb-8a941d0c1fa1 58327 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7c727a4050aeda53c30a62646f7b3d70bb280ec6b5c1b92c5c1dfe955cc80bae cni.projectcalico.org/podIP:100.64.0.25/32 cni.projectcalico.org/podIPs:100.64.0.25/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434d9e0 0xc00434d9e1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-67vsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-67vsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-p2jkb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2jkb webserver-deployment-845c8977d9- deployment-551  be91e65d-d7b1-41f6-8b07-cb8e0ea41dd8 58349 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8db5469de1231a8ce720683e6bea89507c2223e32b0e6757a79a0390439cc67a cni.projectcalico.org/podIP:100.64.1.242/32 cni.projectcalico.org/podIPs:100.64.1.242/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434dcc0 0xc00434dcc1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:59:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cw54g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cw54g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-qrl7f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qrl7f webserver-deployment-845c8977d9- deployment-551  f924710a-f4a0-4ff3-9748-86463a34e682 58154 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:cbbb5614557eca18317425934962b7c9cdafcbb05eda33aa0a15d48291f2f392 cni.projectcalico.org/podIP:100.64.1.229/32 cni.projectcalico.org/podIPs:100.64.1.229/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc00434df60 0xc00434df61}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-phd7b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-phd7b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.229,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bfe0ea7783365b4735f16a90af5afa621a4266b2a54b14be763f62b7c8e2abfe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.725: INFO: Pod "webserver-deployment-845c8977d9-s5wz6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-s5wz6 webserver-deployment-845c8977d9- deployment-551  f80dc1a5-2edb-4da6-952f-6f080ab6ebfe 58161 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ac58bf8ff89b60e77327fbefa539549811c4a265994206cc41cbc67d791a4cc8 cni.projectcalico.org/podIP:100.64.1.233/32 cni.projectcalico.org/podIPs:100.64.1.233/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374220 0xc004374221}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mptxw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mptxw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.233,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd48a4dea8a04c993a5cd515fdc2dce58766aada54f5a93d3573c8748a985068,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-sktj2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sktj2 webserver-deployment-845c8977d9- deployment-551  5bb25864-c661-4189-a53e-85695dc8c411 58324 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:85eceb332200f349f32ac1537663ed669aff5a5367fce86ee0c2ceb4b6dabbcb cni.projectcalico.org/podIP:100.64.1.236/32 cni.projectcalico.org/podIPs:100.64.1.236/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc0043744b0 0xc0043744b1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5v8fd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5v8fd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-tnjpz" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tnjpz webserver-deployment-845c8977d9- deployment-551  642cc039-2165-48f7-b2b2-869c32dce7e2 58177 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:16b5bfd59085b4d96b94e59c177b4e4294acd139bfb5ed2cd413a21fd84facef cni.projectcalico.org/podIP:100.64.0.18/32 cni.projectcalico.org/podIPs:100.64.0.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374710 0xc004374711}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wfwc6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wfwc6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.18,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://daf627713c57c21e26d3d0f66c0054b6b565c31e806c5e932a82c2a016b78560,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-w6l5d" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-w6l5d webserver-deployment-845c8977d9- deployment-551  a9e8dd5e-5400-4159-aed7-692e51ac95ba 58325 0 2022-12-14 09:59:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8cc4b5b80e3724b60703f451c22ef9095e2aa4b5a61e2d0a9555db26108d3212 cni.projectcalico.org/podIP:100.64.0.23/32 cni.projectcalico.org/podIPs:100.64.0.23/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc0043749e0 0xc0043749e1}] [] [{Go-http-client Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:59:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bts2g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bts2g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-hwmlx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2022-12-14 09:59:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:59:31.726: INFO: Pod "webserver-deployment-845c8977d9-zdxlx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zdxlx webserver-deployment-845c8977d9- deployment-551  939d306f-31e0-4b02-9725-db1f4c55f692 58164 0 2022-12-14 09:59:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:92a32bfb19a78781216b891e4458370d126a26ae576b7e63e7f0a21649319a27 cni.projectcalico.org/podIP:100.64.1.232/32 cni.projectcalico.org/podIPs:100.64.1.232/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 06eb6b69-05f2-42be-8381-e46fdf68c1aa 0xc004374be0 0xc004374be1}] [] [{kube-controller-manager Update v1 2022-12-14 09:59:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06eb6b69-05f2-42be-8381-e46fdf68c1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9vlc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tm0ct-io0.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9vlc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm0ct-io0-worker-1-6f755-vb826,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:59:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.232,StartTime:2022-12-14 09:59:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bf00940335c98061806ab517425a99be8396e042ead41abf00f2c106e0f28688,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:59:31.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-551" for this suite. 12/14/22 09:59:31.757
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:31.785
Dec 14 09:59:31.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:59:31.786
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:31.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:31.909
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 12/14/22 09:59:31.957
STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:59:31.982
STEP: delete the deployment 12/14/22 09:59:32.036
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/14/22 09:59:32.062
STEP: Gathering metrics 12/14/22 09:59:32.712
W1214 09:59:32.767813    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:59:32.767: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:59:32.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1063" for this suite. 12/14/22 09:59:32.798
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":337,"skipped":6363,"failed":0}
------------------------------
• [1.038 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:31.785
    Dec 14 09:59:31.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:59:31.786
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:31.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:31.909
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 12/14/22 09:59:31.957
    STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:59:31.982
    STEP: delete the deployment 12/14/22 09:59:32.036
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/14/22 09:59:32.062
    STEP: Gathering metrics 12/14/22 09:59:32.712
    W1214 09:59:32.767813    6274 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:59:32.767: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:59:32.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1063" for this suite. 12/14/22 09:59:32.798
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:32.824
Dec 14 09:59:32.824: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:59:32.825
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:32.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:32.947
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-8ddff364-3e38-465c-85d8-fffcc124a2e9 12/14/22 09:59:32.994
STEP: Creating a pod to test consume secrets 12/14/22 09:59:33.019
Dec 14 09:59:33.049: INFO: Waiting up to 5m0s for pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db" in namespace "secrets-8662" to be "Succeeded or Failed"
Dec 14 09:59:33.073: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Pending", Reason="", readiness=false. Elapsed: 24.668457ms
Dec 14 09:59:35.099: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050021282s
Dec 14 09:59:37.109: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059865332s
STEP: Saw pod success 12/14/22 09:59:37.109
Dec 14 09:59:37.109: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db" satisfied condition "Succeeded or Failed"
Dec 14 09:59:37.140: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db container secret-env-test: <nil>
STEP: delete the pod 12/14/22 09:59:37.193
Dec 14 09:59:37.240: INFO: Waiting for pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db to disappear
Dec 14 09:59:37.267: INFO: Pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:59:37.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8662" for this suite. 12/14/22 09:59:37.317
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":338,"skipped":6367,"failed":0}
------------------------------
• [4.521 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:32.824
    Dec 14 09:59:32.824: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:59:32.825
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:32.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:32.947
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-8ddff364-3e38-465c-85d8-fffcc124a2e9 12/14/22 09:59:32.994
    STEP: Creating a pod to test consume secrets 12/14/22 09:59:33.019
    Dec 14 09:59:33.049: INFO: Waiting up to 5m0s for pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db" in namespace "secrets-8662" to be "Succeeded or Failed"
    Dec 14 09:59:33.073: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Pending", Reason="", readiness=false. Elapsed: 24.668457ms
    Dec 14 09:59:35.099: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050021282s
    Dec 14 09:59:37.109: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059865332s
    STEP: Saw pod success 12/14/22 09:59:37.109
    Dec 14 09:59:37.109: INFO: Pod "pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db" satisfied condition "Succeeded or Failed"
    Dec 14 09:59:37.140: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db container secret-env-test: <nil>
    STEP: delete the pod 12/14/22 09:59:37.193
    Dec 14 09:59:37.240: INFO: Waiting for pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db to disappear
    Dec 14 09:59:37.267: INFO: Pod pod-secrets-302bf2a8-b993-404e-b331-5b0fb58c29db no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:59:37.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8662" for this suite. 12/14/22 09:59:37.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:59:37.346
Dec 14 09:59:37.346: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:59:37.347
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:37.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:37.47
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 12/14/22 09:59:37.517
Dec 14 09:59:37.548: INFO: Waiting up to 5m0s for pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f" in namespace "projected-2209" to be "running and ready"
Dec 14 09:59:37.577: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 29.094609ms
Dec 14 09:59:37.577: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:59:39.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054747289s
Dec 14 09:59:39.603: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:59:41.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Running", Reason="", readiness=true. Elapsed: 4.055199477s
Dec 14 09:59:41.603: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Running (Ready = true)
Dec 14 09:59:41.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f" satisfied condition "running and ready"
Dec 14 09:59:42.214: INFO: Successfully updated pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 10:00:51.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2209" for this suite. 12/14/22 10:00:51.49
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":339,"skipped":6379,"failed":0}
------------------------------
• [74.170 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:59:37.346
    Dec 14 09:59:37.346: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:59:37.347
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:59:37.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:59:37.47
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 12/14/22 09:59:37.517
    Dec 14 09:59:37.548: INFO: Waiting up to 5m0s for pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f" in namespace "projected-2209" to be "running and ready"
    Dec 14 09:59:37.577: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 29.094609ms
    Dec 14 09:59:37.577: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:59:39.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054747289s
    Dec 14 09:59:39.603: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:59:41.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f": Phase="Running", Reason="", readiness=true. Elapsed: 4.055199477s
    Dec 14 09:59:41.603: INFO: The phase of Pod labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f is Running (Ready = true)
    Dec 14 09:59:41.603: INFO: Pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f" satisfied condition "running and ready"
    Dec 14 09:59:42.214: INFO: Successfully updated pod "labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 10:00:51.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2209" for this suite. 12/14/22 10:00:51.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:51.517
Dec 14 10:00:51.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:00:51.518
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:51.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:51.644
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 12/14/22 10:00:51.716
STEP: watching for the Service to be added 12/14/22 10:00:51.751
Dec 14 10:00:51.775: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Dec 14 10:00:51.775: INFO: Service test-service-fdrbc created
STEP: Getting /status 12/14/22 10:00:51.775
Dec 14 10:00:51.803: INFO: Service test-service-fdrbc has LoadBalancer: {[]}
STEP: patching the ServiceStatus 12/14/22 10:00:51.804
STEP: watching for the Service to be patched 12/14/22 10:00:51.83
Dec 14 10:00:51.854: INFO: observed Service test-service-fdrbc in namespace services-6748 with annotations: map[] & LoadBalancer: {[]}
Dec 14 10:00:51.874: INFO: Found Service test-service-fdrbc in namespace services-6748 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Dec 14 10:00:51.874: INFO: Service test-service-fdrbc has service status patched
STEP: updating the ServiceStatus 12/14/22 10:00:51.874
Dec 14 10:00:51.925: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 12/14/22 10:00:51.925
Dec 14 10:00:51.949: INFO: Observed Service test-service-fdrbc in namespace services-6748 with annotations: map[] & Conditions: {[]}
Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59108 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59109 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [azure.remedy.gardener.cloud/service] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status} {remedy-controller-azure Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:finalizers":{".":{},"v:\"azure.remedy.gardener.cloud/service\"":{}}}} }]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59110 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
Dec 14 10:00:51.949: INFO: Found Service test-service-fdrbc in namespace services-6748 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 10:00:51.949: INFO: Service test-service-fdrbc has service status updated
STEP: patching the service 12/14/22 10:00:51.949
STEP: watching for the Service to be patched 12/14/22 10:00:51.98
Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
Dec 14 10:00:52.006: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service:patched test-service-static:true]
Dec 14 10:00:52.006: INFO: Service test-service-fdrbc patched
STEP: deleting the service 12/14/22 10:00:52.006
STEP: watching for the Service to be deleted 12/14/22 10:00:52.039
Dec 14 10:00:52.063: INFO: Observed event: ADDED
Dec 14 10:00:52.063: INFO: Observed event: MODIFIED
Dec 14 10:00:52.063: INFO: Observed event: MODIFIED
Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
Dec 14 10:00:52.064: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Dec 14 10:00:52.064: INFO: Service test-service-fdrbc deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:00:52.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6748" for this suite. 12/14/22 10:00:52.09
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":340,"skipped":6393,"failed":0}
------------------------------
• [0.601 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:51.517
    Dec 14 10:00:51.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:00:51.518
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:51.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:51.644
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 12/14/22 10:00:51.716
    STEP: watching for the Service to be added 12/14/22 10:00:51.751
    Dec 14 10:00:51.775: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Dec 14 10:00:51.775: INFO: Service test-service-fdrbc created
    STEP: Getting /status 12/14/22 10:00:51.775
    Dec 14 10:00:51.803: INFO: Service test-service-fdrbc has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 12/14/22 10:00:51.804
    STEP: watching for the Service to be patched 12/14/22 10:00:51.83
    Dec 14 10:00:51.854: INFO: observed Service test-service-fdrbc in namespace services-6748 with annotations: map[] & LoadBalancer: {[]}
    Dec 14 10:00:51.874: INFO: Found Service test-service-fdrbc in namespace services-6748 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Dec 14 10:00:51.874: INFO: Service test-service-fdrbc has service status patched
    STEP: updating the ServiceStatus 12/14/22 10:00:51.874
    Dec 14 10:00:51.925: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 12/14/22 10:00:51.925
    Dec 14 10:00:51.949: INFO: Observed Service test-service-fdrbc in namespace services-6748 with annotations: map[] & Conditions: {[]}
    Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59108 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59109 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [azure.remedy.gardener.cloud/service] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status} {remedy-controller-azure Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:finalizers":{".":{},"v:\"azure.remedy.gardener.cloud/service\"":{}}}} }]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
    Dec 14 10:00:51.949: INFO: Observed event: &Service{ObjectMeta:{test-service-fdrbc  services-6748  76ea1fdf-8c3c-4f55-83b2-e7293409eaeb 59110 0 2022-12-14 10:00:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 10:00:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.107.129.74,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.107.129.74],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
    Dec 14 10:00:51.949: INFO: Found Service test-service-fdrbc in namespace services-6748 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 10:00:51.949: INFO: Service test-service-fdrbc has service status updated
    STEP: patching the service 12/14/22 10:00:51.949
    STEP: watching for the Service to be patched 12/14/22 10:00:51.98
    Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
    Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
    Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
    Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
    Dec 14 10:00:52.006: INFO: observed Service test-service-fdrbc in namespace services-6748 with labels: map[test-service-static:true]
    Dec 14 10:00:52.006: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service:patched test-service-static:true]
    Dec 14 10:00:52.006: INFO: Service test-service-fdrbc patched
    STEP: deleting the service 12/14/22 10:00:52.006
    STEP: watching for the Service to be deleted 12/14/22 10:00:52.039
    Dec 14 10:00:52.063: INFO: Observed event: ADDED
    Dec 14 10:00:52.063: INFO: Observed event: MODIFIED
    Dec 14 10:00:52.063: INFO: Observed event: MODIFIED
    Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
    Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
    Dec 14 10:00:52.064: INFO: Observed event: MODIFIED
    Dec 14 10:00:52.064: INFO: Found Service test-service-fdrbc in namespace services-6748 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Dec 14 10:00:52.064: INFO: Service test-service-fdrbc deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:00:52.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6748" for this suite. 12/14/22 10:00:52.09
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:52.118
Dec 14 10:00:52.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 10:00:52.119
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:52.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:52.241
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 10:00:52.288: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 10:00:52.339: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 10:00:52.365: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
Dec 14 10:00:52.418: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container proxy ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 10:00:52.418: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 10:00:52.418: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 10:00:52.418: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 10:00:52.418: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 10:00:52.418: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 10:00:52.418: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 10:00:52.418: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 10:00:52.418: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 10:00:52.418: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 10:00:52.418: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container metrics-server ready: true, restart count 0
Dec 14 10:00:52.418: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 10:00:52.418: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 10:00:52.418: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 10:00:52.418: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 10:00:52.418: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 10:00:52.418: INFO: labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f from projected-2209 started at 2022-12-14 09:59:37 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.418: INFO: 	Container client-container ready: true, restart count 0
Dec 14 10:00:52.418: INFO: 
Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
Dec 14 10:00:52.452: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 10:00:52.452: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 10:00:52.452: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container proxy ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 10:00:52.452: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 10:00:52.452: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 10:00:52.452: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 10:00:52.452: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 10:00:52.452: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 5
Dec 14 10:00:52.452: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container cloud-node-manager ready: true, restart count 0
Dec 14 10:00:52.452: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container coredns ready: true, restart count 0
Dec 14 10:00:52.452: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container coredns ready: true, restart count 0
Dec 14 10:00:52.452: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 10:00:52.452: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container csi-driver ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Dec 14 10:00:52.452: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 10:00:52.452: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 10:00:52.452: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 10:00:52.452: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 10:00:52.452: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 10:00:52.452: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.452: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 10:00:52.452: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.453: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 10:00:52.453: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.453: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 10:00:52.453: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.453: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 10:00:52.453: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.453: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 10:00:52.453: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
Dec 14 10:00:52.453: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:00:52.453
Dec 14 10:00:52.483: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3493" to be "running"
Dec 14 10:00:52.508: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 25.127409ms
Dec 14 10:00:54.535: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.051273463s
Dec 14 10:00:54.535: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:00:54.562
STEP: Trying to apply a random label on the found node. 12/14/22 10:00:54.643
STEP: verifying the node has the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 95 12/14/22 10:00:54.676
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/14/22 10:00:54.702
Dec 14 10:00:54.731: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3493" to be "not pending"
Dec 14 10:00:54.755: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.176401ms
Dec 14 10:00:56.780: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.049533057s
Dec 14 10:00:56.781: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.0.5 on the node which pod4 resides and expect not scheduled 12/14/22 10:00:56.781
Dec 14 10:00:56.816: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3493" to be "not pending"
Dec 14 10:00:56.842: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.170059ms
Dec 14 10:00:58.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051035439s
Dec 14 10:01:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051683284s
Dec 14 10:01:02.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052115059s
Dec 14 10:01:04.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.050304017s
Dec 14 10:01:06.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052601031s
Dec 14 10:01:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.051369649s
Dec 14 10:01:10.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052931246s
Dec 14 10:01:12.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.052780225s
Dec 14 10:01:14.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.050855234s
Dec 14 10:01:16.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.056129098s
Dec 14 10:01:18.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.051762052s
Dec 14 10:01:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.051498711s
Dec 14 10:01:22.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053570893s
Dec 14 10:01:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.051563328s
Dec 14 10:01:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.05265734s
Dec 14 10:01:28.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.050531074s
Dec 14 10:01:30.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.052339232s
Dec 14 10:01:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.051318731s
Dec 14 10:01:34.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.05661233s
Dec 14 10:01:36.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.051620482s
Dec 14 10:01:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.051447728s
Dec 14 10:01:40.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.050845037s
Dec 14 10:01:42.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.051423668s
Dec 14 10:01:44.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.050356963s
Dec 14 10:01:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.051864144s
Dec 14 10:01:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.051242594s
Dec 14 10:01:50.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.050809345s
Dec 14 10:01:52.866: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.050065117s
Dec 14 10:01:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.051005512s
Dec 14 10:01:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.051277176s
Dec 14 10:01:58.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.050624305s
Dec 14 10:02:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.051945665s
Dec 14 10:02:02.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.051837739s
Dec 14 10:02:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.051764093s
Dec 14 10:02:06.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.057905293s
Dec 14 10:02:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.051756395s
Dec 14 10:02:10.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.050879671s
Dec 14 10:02:12.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.050525819s
Dec 14 10:02:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.051200259s
Dec 14 10:02:16.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.052489244s
Dec 14 10:02:18.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.050510111s
Dec 14 10:02:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.051590572s
Dec 14 10:02:22.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.052951986s
Dec 14 10:02:24.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.050996696s
Dec 14 10:02:26.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.051993806s
Dec 14 10:02:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.051243295s
Dec 14 10:02:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.051249317s
Dec 14 10:02:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.051422579s
Dec 14 10:02:34.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.05106573s
Dec 14 10:02:36.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.050854808s
Dec 14 10:02:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.051496077s
Dec 14 10:02:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.051404703s
Dec 14 10:02:42.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.052736803s
Dec 14 10:02:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.051257246s
Dec 14 10:02:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.051938134s
Dec 14 10:02:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.051407034s
Dec 14 10:02:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.051251653s
Dec 14 10:02:52.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.052138262s
Dec 14 10:02:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.050685601s
Dec 14 10:02:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.051767423s
Dec 14 10:02:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.051567813s
Dec 14 10:03:00.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.052518316s
Dec 14 10:03:02.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.052861057s
Dec 14 10:03:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.05180044s
Dec 14 10:03:06.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.052277687s
Dec 14 10:03:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.051192019s
Dec 14 10:03:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.051639809s
Dec 14 10:03:12.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.050833517s
Dec 14 10:03:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.0516373s
Dec 14 10:03:16.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.051905643s
Dec 14 10:03:18.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.051784324s
Dec 14 10:03:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.051510086s
Dec 14 10:03:22.879: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.062585553s
Dec 14 10:03:24.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.050682125s
Dec 14 10:03:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.052707578s
Dec 14 10:03:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.051574287s
Dec 14 10:03:30.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.052593533s
Dec 14 10:03:32.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.050997761s
Dec 14 10:03:34.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.053653968s
Dec 14 10:03:36.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.052591234s
Dec 14 10:03:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.051424814s
Dec 14 10:03:40.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.050812804s
Dec 14 10:03:42.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.052650433s
Dec 14 10:03:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.051246472s
Dec 14 10:03:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.051909521s
Dec 14 10:03:48.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.052168826s
Dec 14 10:03:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.051555819s
Dec 14 10:03:52.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.051497644s
Dec 14 10:03:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.050907021s
Dec 14 10:03:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.051610239s
Dec 14 10:03:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.051166706s
Dec 14 10:04:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.051249843s
Dec 14 10:04:02.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.053455349s
Dec 14 10:04:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.051445054s
Dec 14 10:04:06.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.05162665s
Dec 14 10:04:08.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.050497938s
Dec 14 10:04:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.051334428s
Dec 14 10:04:12.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.052370792s
Dec 14 10:04:14.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.05102468s
Dec 14 10:04:16.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.051045395s
Dec 14 10:04:18.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.052533833s
Dec 14 10:04:20.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.05092522s
Dec 14 10:04:22.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.052488863s
Dec 14 10:04:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.05157125s
Dec 14 10:04:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.052271653s
Dec 14 10:04:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.051090098s
Dec 14 10:04:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.051685258s
Dec 14 10:04:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.051407648s
Dec 14 10:04:34.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.051076384s
Dec 14 10:04:36.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.052570448s
Dec 14 10:04:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.051863621s
Dec 14 10:04:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.051414326s
Dec 14 10:04:42.872: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.055580023s
Dec 14 10:04:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.05107522s
Dec 14 10:04:46.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.052268519s
Dec 14 10:04:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.051665602s
Dec 14 10:04:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.051529341s
Dec 14 10:04:52.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.050914859s
Dec 14 10:04:54.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.051357586s
Dec 14 10:04:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.051346604s
Dec 14 10:04:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.051877391s
Dec 14 10:05:00.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.050697214s
Dec 14 10:05:02.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.050687493s
Dec 14 10:05:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.052061502s
Dec 14 10:05:06.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.051271361s
Dec 14 10:05:08.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.052122385s
Dec 14 10:05:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.051604869s
Dec 14 10:05:12.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.052035221s
Dec 14 10:05:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.051194391s
Dec 14 10:05:16.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.051687031s
Dec 14 10:05:18.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.050695686s
Dec 14 10:05:20.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.052780617s
Dec 14 10:05:22.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.05206222s
Dec 14 10:05:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.05159153s
Dec 14 10:05:26.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.051412932s
Dec 14 10:05:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.051528528s
Dec 14 10:05:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.052008742s
Dec 14 10:05:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.051715663s
Dec 14 10:05:34.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.053128373s
Dec 14 10:05:36.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.056629631s
Dec 14 10:05:38.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.050719622s
Dec 14 10:05:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.051124963s
Dec 14 10:05:42.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.054073516s
Dec 14 10:05:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.051196742s
Dec 14 10:05:46.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.052918832s
Dec 14 10:05:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.051875133s
Dec 14 10:05:50.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.052334395s
Dec 14 10:05:52.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.050743801s
Dec 14 10:05:54.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.051303386s
Dec 14 10:05:56.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.052300816s
Dec 14 10:05:56.895: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.078079507s
STEP: removing the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 10:05:56.895
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 12/14/22 10:05:56.996
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:05:57.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3493" for this suite. 12/14/22 10:05:57.048
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":341,"skipped":6396,"failed":0}
------------------------------
• [SLOW TEST] [304.958 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:52.118
    Dec 14 10:00:52.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 10:00:52.119
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:52.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:52.241
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 10:00:52.288: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 10:00:52.339: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 10:00:52.365: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx before test
    Dec 14 10:00:52.418: INFO: apiserver-proxy-fdh6d from kube-system started at 2022-12-14 08:09:35 +0000 UTC (2 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: blackbox-exporter-59447f4c55-gg28g from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: blackbox-exporter-59447f4c55-l4sl8 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: calico-node-nm9fv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: cloud-node-manager-d7nl7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: csi-driver-node-disk-ffbkk from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: csi-driver-node-file-fqj5x from kube-system started at 2022-12-14 08:09:35 +0000 UTC (3 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: egress-filter-applier-ch9gv from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 10:00:52.418: INFO: kube-proxy-worker-1-v1.25.4-9z98n from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: metrics-server-8688dbf74b-kz62g from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: metrics-server-8688dbf74b-twwq4 from kube-system started at 2022-12-14 08:09:37 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container metrics-server ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: network-problem-detector-host-hs2n4 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: network-problem-detector-pod-rk4t7 from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: node-exporter-tx6hc from kube-system started at 2022-12-14 08:09:35 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: node-local-dns-d8jbc from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: node-problem-detector-p9pfw from kube-system started at 2022-12-14 09:08:15 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: labelsupdateca4103bf-f3d5-4082-a226-1a764a662a0f from projected-2209 started at 2022-12-14 09:59:37 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.418: INFO: 	Container client-container ready: true, restart count 0
    Dec 14 10:00:52.418: INFO: 
    Logging pods the apiserver thinks is on node shoot--it--tm0ct-io0-worker-1-6f755-vb826 before test
    Dec 14 10:00:52.452: INFO: addons-nginx-ingress-controller-7fb8f7fc5-tzh7n from kube-system started at 2022-12-14 08:42:41 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-lcqx7 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: apiserver-proxy-rkc87 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (2 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: calico-node-sxn8l from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: calico-node-vertical-autoscaler-6597dd8998-z22xv from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 10:00:52.452: INFO: calico-typha-deploy-65c54d4db6-78pzm from kube-system started at 2022-12-14 08:16:59 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-2nwq6 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: calico-typha-vertical-autoscaler-84df655c88-ml548 from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container autoscaler ready: true, restart count 5
    Dec 14 10:00:52.452: INFO: cloud-node-manager-ct9x9 from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container cloud-node-manager ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: coredns-7558877f6f-4drgs from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: coredns-7558877f6f-vcqln from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: csi-driver-node-disk-x2d9h from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: csi-driver-node-file-5rtwn from kube-system started at 2022-12-14 08:09:47 +0000 UTC (3 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container csi-driver ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: egress-filter-applier-f6rpl from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 10:00:52.452: INFO: kube-proxy-worker-1-v1.25.4-n64tv from kube-system started at 2022-12-14 08:47:14 +0000 UTC (2 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: network-problem-detector-host-99jhg from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: network-problem-detector-pod-ckmps from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: node-exporter-72h6z from kube-system started at 2022-12-14 08:09:47 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.452: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 10:00:52.452: INFO: node-local-dns-kjrz2 from kube-system started at 2022-12-14 08:34:15 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.453: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 10:00:52.453: INFO: node-problem-detector-9q4nh from kube-system started at 2022-12-14 09:08:14 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.453: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 10:00:52.453: INFO: vpn-shoot-85c474665b-xf7mf from kube-system started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.453: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 10:00:52.453: INFO: dashboard-metrics-scraper-6d54964d4b-j8l58 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.453: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 10:00:52.453: INFO: kubernetes-dashboard-86f4dbb8b4-s2nk9 from kubernetes-dashboard started at 2022-12-14 08:11:19 +0000 UTC (1 container statuses recorded)
    Dec 14 10:00:52.453: INFO: 	Container kubernetes-dashboard ready: true, restart count 5
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:00:52.453
    Dec 14 10:00:52.483: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3493" to be "running"
    Dec 14 10:00:52.508: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 25.127409ms
    Dec 14 10:00:54.535: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.051273463s
    Dec 14 10:00:54.535: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:00:54.562
    STEP: Trying to apply a random label on the found node. 12/14/22 10:00:54.643
    STEP: verifying the node has the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 95 12/14/22 10:00:54.676
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/14/22 10:00:54.702
    Dec 14 10:00:54.731: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3493" to be "not pending"
    Dec 14 10:00:54.755: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.176401ms
    Dec 14 10:00:56.780: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.049533057s
    Dec 14 10:00:56.781: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.0.5 on the node which pod4 resides and expect not scheduled 12/14/22 10:00:56.781
    Dec 14 10:00:56.816: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3493" to be "not pending"
    Dec 14 10:00:56.842: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.170059ms
    Dec 14 10:00:58.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051035439s
    Dec 14 10:01:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051683284s
    Dec 14 10:01:02.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052115059s
    Dec 14 10:01:04.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.050304017s
    Dec 14 10:01:06.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052601031s
    Dec 14 10:01:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.051369649s
    Dec 14 10:01:10.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052931246s
    Dec 14 10:01:12.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.052780225s
    Dec 14 10:01:14.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.050855234s
    Dec 14 10:01:16.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.056129098s
    Dec 14 10:01:18.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.051762052s
    Dec 14 10:01:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.051498711s
    Dec 14 10:01:22.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053570893s
    Dec 14 10:01:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.051563328s
    Dec 14 10:01:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.05265734s
    Dec 14 10:01:28.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.050531074s
    Dec 14 10:01:30.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.052339232s
    Dec 14 10:01:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.051318731s
    Dec 14 10:01:34.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.05661233s
    Dec 14 10:01:36.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.051620482s
    Dec 14 10:01:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.051447728s
    Dec 14 10:01:40.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.050845037s
    Dec 14 10:01:42.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.051423668s
    Dec 14 10:01:44.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.050356963s
    Dec 14 10:01:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.051864144s
    Dec 14 10:01:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.051242594s
    Dec 14 10:01:50.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.050809345s
    Dec 14 10:01:52.866: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.050065117s
    Dec 14 10:01:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.051005512s
    Dec 14 10:01:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.051277176s
    Dec 14 10:01:58.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.050624305s
    Dec 14 10:02:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.051945665s
    Dec 14 10:02:02.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.051837739s
    Dec 14 10:02:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.051764093s
    Dec 14 10:02:06.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.057905293s
    Dec 14 10:02:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.051756395s
    Dec 14 10:02:10.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.050879671s
    Dec 14 10:02:12.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.050525819s
    Dec 14 10:02:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.051200259s
    Dec 14 10:02:16.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.052489244s
    Dec 14 10:02:18.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.050510111s
    Dec 14 10:02:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.051590572s
    Dec 14 10:02:22.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.052951986s
    Dec 14 10:02:24.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.050996696s
    Dec 14 10:02:26.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.051993806s
    Dec 14 10:02:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.051243295s
    Dec 14 10:02:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.051249317s
    Dec 14 10:02:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.051422579s
    Dec 14 10:02:34.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.05106573s
    Dec 14 10:02:36.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.050854808s
    Dec 14 10:02:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.051496077s
    Dec 14 10:02:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.051404703s
    Dec 14 10:02:42.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.052736803s
    Dec 14 10:02:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.051257246s
    Dec 14 10:02:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.051938134s
    Dec 14 10:02:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.051407034s
    Dec 14 10:02:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.051251653s
    Dec 14 10:02:52.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.052138262s
    Dec 14 10:02:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.050685601s
    Dec 14 10:02:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.051767423s
    Dec 14 10:02:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.051567813s
    Dec 14 10:03:00.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.052518316s
    Dec 14 10:03:02.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.052861057s
    Dec 14 10:03:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.05180044s
    Dec 14 10:03:06.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.052277687s
    Dec 14 10:03:08.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.051192019s
    Dec 14 10:03:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.051639809s
    Dec 14 10:03:12.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.050833517s
    Dec 14 10:03:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.0516373s
    Dec 14 10:03:16.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.051905643s
    Dec 14 10:03:18.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.051784324s
    Dec 14 10:03:20.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.051510086s
    Dec 14 10:03:22.879: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.062585553s
    Dec 14 10:03:24.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.050682125s
    Dec 14 10:03:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.052707578s
    Dec 14 10:03:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.051574287s
    Dec 14 10:03:30.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.052593533s
    Dec 14 10:03:32.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.050997761s
    Dec 14 10:03:34.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.053653968s
    Dec 14 10:03:36.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.052591234s
    Dec 14 10:03:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.051424814s
    Dec 14 10:03:40.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.050812804s
    Dec 14 10:03:42.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.052650433s
    Dec 14 10:03:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.051246472s
    Dec 14 10:03:46.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.051909521s
    Dec 14 10:03:48.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.052168826s
    Dec 14 10:03:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.051555819s
    Dec 14 10:03:52.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.051497644s
    Dec 14 10:03:54.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.050907021s
    Dec 14 10:03:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.051610239s
    Dec 14 10:03:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.051166706s
    Dec 14 10:04:00.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.051249843s
    Dec 14 10:04:02.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.053455349s
    Dec 14 10:04:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.051445054s
    Dec 14 10:04:06.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.05162665s
    Dec 14 10:04:08.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.050497938s
    Dec 14 10:04:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.051334428s
    Dec 14 10:04:12.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.052370792s
    Dec 14 10:04:14.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.05102468s
    Dec 14 10:04:16.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.051045395s
    Dec 14 10:04:18.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.052533833s
    Dec 14 10:04:20.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.05092522s
    Dec 14 10:04:22.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.052488863s
    Dec 14 10:04:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.05157125s
    Dec 14 10:04:26.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.052271653s
    Dec 14 10:04:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.051090098s
    Dec 14 10:04:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.051685258s
    Dec 14 10:04:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.051407648s
    Dec 14 10:04:34.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.051076384s
    Dec 14 10:04:36.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.052570448s
    Dec 14 10:04:38.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.051863621s
    Dec 14 10:04:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.051414326s
    Dec 14 10:04:42.872: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.055580023s
    Dec 14 10:04:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.05107522s
    Dec 14 10:04:46.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.052268519s
    Dec 14 10:04:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.051665602s
    Dec 14 10:04:50.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.051529341s
    Dec 14 10:04:52.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.050914859s
    Dec 14 10:04:54.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.051357586s
    Dec 14 10:04:56.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.051346604s
    Dec 14 10:04:58.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.051877391s
    Dec 14 10:05:00.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.050697214s
    Dec 14 10:05:02.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.050687493s
    Dec 14 10:05:04.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.052061502s
    Dec 14 10:05:06.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.051271361s
    Dec 14 10:05:08.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.052122385s
    Dec 14 10:05:10.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.051604869s
    Dec 14 10:05:12.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.052035221s
    Dec 14 10:05:14.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.051194391s
    Dec 14 10:05:16.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.051687031s
    Dec 14 10:05:18.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.050695686s
    Dec 14 10:05:20.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.052780617s
    Dec 14 10:05:22.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.05206222s
    Dec 14 10:05:24.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.05159153s
    Dec 14 10:05:26.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.051412932s
    Dec 14 10:05:28.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.051528528s
    Dec 14 10:05:30.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.052008742s
    Dec 14 10:05:32.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.051715663s
    Dec 14 10:05:34.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.053128373s
    Dec 14 10:05:36.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.056629631s
    Dec 14 10:05:38.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.050719622s
    Dec 14 10:05:40.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.051124963s
    Dec 14 10:05:42.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.054073516s
    Dec 14 10:05:44.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.051196742s
    Dec 14 10:05:46.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.052918832s
    Dec 14 10:05:48.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.051875133s
    Dec 14 10:05:50.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.052334395s
    Dec 14 10:05:52.867: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.050743801s
    Dec 14 10:05:54.868: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.051303386s
    Dec 14 10:05:56.869: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.052300816s
    Dec 14 10:05:56.895: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.078079507s
    STEP: removing the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 off the node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx 12/14/22 10:05:56.895
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-e411415c-f31e-4684-883e-c9e57a1422e7 12/14/22 10:05:56.996
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:05:57.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3493" for this suite. 12/14/22 10:05:57.048
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:57.077
Dec 14 10:05:57.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:57.079
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:57.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:57.205
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 12/14/22 10:05:57.257
Dec 14 10:05:57.303: INFO: Waiting up to 5m0s for pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351" in namespace "downward-api-6916" to be "Succeeded or Failed"
Dec 14 10:05:57.330: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Pending", Reason="", readiness=false. Elapsed: 26.850923ms
Dec 14 10:05:59.356: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053082655s
Dec 14 10:06:01.358: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054424594s
STEP: Saw pod success 12/14/22 10:06:01.358
Dec 14 10:06:01.358: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351" satisfied condition "Succeeded or Failed"
Dec 14 10:06:01.383: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 container dapi-container: <nil>
STEP: delete the pod 12/14/22 10:06:01.418
Dec 14 10:06:01.454: INFO: Waiting for pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 to disappear
Dec 14 10:06:01.479: INFO: Pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 10:06:01.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6916" for this suite. 12/14/22 10:06:01.533
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":342,"skipped":6414,"failed":0}
------------------------------
• [4.482 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:57.077
    Dec 14 10:05:57.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:57.079
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:57.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:57.205
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 12/14/22 10:05:57.257
    Dec 14 10:05:57.303: INFO: Waiting up to 5m0s for pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351" in namespace "downward-api-6916" to be "Succeeded or Failed"
    Dec 14 10:05:57.330: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Pending", Reason="", readiness=false. Elapsed: 26.850923ms
    Dec 14 10:05:59.356: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053082655s
    Dec 14 10:06:01.358: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054424594s
    STEP: Saw pod success 12/14/22 10:06:01.358
    Dec 14 10:06:01.358: INFO: Pod "downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351" satisfied condition "Succeeded or Failed"
    Dec 14 10:06:01.383: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 10:06:01.418
    Dec 14 10:06:01.454: INFO: Waiting for pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 to disappear
    Dec 14 10:06:01.479: INFO: Pod downward-api-e2a7e54f-5fbd-40ad-b232-2ccf537b3351 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 10:06:01.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6916" for this suite. 12/14/22 10:06:01.533
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:01.56
Dec 14 10:06:01.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 10:06:01.562
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:01.637
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:01.685
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-7579/secret-test-d17ac1cc-91e7-47f5-a5a3-84ae054c1ba1 12/14/22 10:06:01.733
STEP: Creating a pod to test consume secrets 12/14/22 10:06:01.761
Dec 14 10:06:01.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a" in namespace "secrets-7579" to be "Succeeded or Failed"
Dec 14 10:06:01.817: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.922568ms
Dec 14 10:06:03.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051085217s
Dec 14 10:06:05.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051285973s
STEP: Saw pod success 12/14/22 10:06:05.844
Dec 14 10:06:05.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a" satisfied condition "Succeeded or Failed"
Dec 14 10:06:05.869: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a container env-test: <nil>
STEP: delete the pod 12/14/22 10:06:05.901
Dec 14 10:06:05.932: INFO: Waiting for pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a to disappear
Dec 14 10:06:05.959: INFO: Pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 10:06:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7579" for this suite. 12/14/22 10:06:06.009
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":343,"skipped":6430,"failed":0}
------------------------------
• [4.476 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:01.56
    Dec 14 10:06:01.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 10:06:01.562
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:01.637
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:01.685
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-7579/secret-test-d17ac1cc-91e7-47f5-a5a3-84ae054c1ba1 12/14/22 10:06:01.733
    STEP: Creating a pod to test consume secrets 12/14/22 10:06:01.761
    Dec 14 10:06:01.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a" in namespace "secrets-7579" to be "Succeeded or Failed"
    Dec 14 10:06:01.817: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.922568ms
    Dec 14 10:06:03.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051085217s
    Dec 14 10:06:05.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051285973s
    STEP: Saw pod success 12/14/22 10:06:05.844
    Dec 14 10:06:05.844: INFO: Pod "pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a" satisfied condition "Succeeded or Failed"
    Dec 14 10:06:05.869: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a container env-test: <nil>
    STEP: delete the pod 12/14/22 10:06:05.901
    Dec 14 10:06:05.932: INFO: Waiting for pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a to disappear
    Dec 14 10:06:05.959: INFO: Pod pod-configmaps-db9bd9ea-7b35-4c01-86e9-eb5111e9389a no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 10:06:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7579" for this suite. 12/14/22 10:06:06.009
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:06.037
Dec 14 10:06:06.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:06:06.038
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:06.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:06.163
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 12/14/22 10:06:06.211
Dec 14 10:06:06.212: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd 12/14/22 10:06:18.222
STEP: check the unserved version gets removed 12/14/22 10:06:18.331
STEP: check the other version is not changed 12/14/22 10:06:23.016
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:06:33.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9508" for this suite. 12/14/22 10:06:33.454
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":344,"skipped":6442,"failed":0}
------------------------------
• [27.444 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:06.037
    Dec 14 10:06:06.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:06:06.038
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:06.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:06.163
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 12/14/22 10:06:06.211
    Dec 14 10:06:06.212: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: mark a version not serverd 12/14/22 10:06:18.222
    STEP: check the unserved version gets removed 12/14/22 10:06:18.331
    STEP: check the other version is not changed 12/14/22 10:06:23.016
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:06:33.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9508" for this suite. 12/14/22 10:06:33.454
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:33.482
Dec 14 10:06:33.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 10:06:33.483
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:33.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:33.608
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-fd58bbc8-fd6b-4654-8d63-9148eaed6e9c 12/14/22 10:06:33.656
STEP: Creating a pod to test consume configMaps 12/14/22 10:06:33.685
Dec 14 10:06:33.730: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453" in namespace "projected-4395" to be "Succeeded or Failed"
Dec 14 10:06:33.756: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Pending", Reason="", readiness=false. Elapsed: 25.589802ms
Dec 14 10:06:35.783: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053138742s
Dec 14 10:06:37.782: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051866567s
STEP: Saw pod success 12/14/22 10:06:37.782
Dec 14 10:06:37.782: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453" satisfied condition "Succeeded or Failed"
Dec 14 10:06:37.807: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 10:06:37.99
Dec 14 10:06:38.025: INFO: Waiting for pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 to disappear
Dec 14 10:06:38.050: INFO: Pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 10:06:38.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4395" for this suite. 12/14/22 10:06:38.104
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":345,"skipped":6443,"failed":0}
------------------------------
• [4.650 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:33.482
    Dec 14 10:06:33.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 10:06:33.483
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:33.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:33.608
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-fd58bbc8-fd6b-4654-8d63-9148eaed6e9c 12/14/22 10:06:33.656
    STEP: Creating a pod to test consume configMaps 12/14/22 10:06:33.685
    Dec 14 10:06:33.730: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453" in namespace "projected-4395" to be "Succeeded or Failed"
    Dec 14 10:06:33.756: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Pending", Reason="", readiness=false. Elapsed: 25.589802ms
    Dec 14 10:06:35.783: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053138742s
    Dec 14 10:06:37.782: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051866567s
    STEP: Saw pod success 12/14/22 10:06:37.782
    Dec 14 10:06:37.782: INFO: Pod "pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453" satisfied condition "Succeeded or Failed"
    Dec 14 10:06:37.807: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 10:06:37.99
    Dec 14 10:06:38.025: INFO: Waiting for pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 to disappear
    Dec 14 10:06:38.050: INFO: Pod pod-projected-configmaps-e64204c5-4d72-4b1b-aa21-51b58ae78453 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 10:06:38.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4395" for this suite. 12/14/22 10:06:38.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:38.133
Dec 14 10:06:38.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 10:06:38.134
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:38.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:38.263
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Dec 14 10:06:38.417: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 12/14/22 10:06:38.446
Dec 14 10:06:38.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:38.476: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 12/14/22 10:06:38.476
Dec 14 10:06:38.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:38.614: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:39.642: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:39.642: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:40.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:06:40.641: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 12/14/22 10:06:40.669
Dec 14 10:06:40.797: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:40.797: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/14/22 10:06:40.797
Dec 14 10:06:40.859: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:40.859: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:41.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:41.889: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:42.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:42.885: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:43.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:43.887: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:06:44.886: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:06:44.886: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:06:44.936
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4734, will wait for the garbage collector to delete the pods 12/14/22 10:06:44.936
Dec 14 10:06:45.039: INFO: Deleting DaemonSet.extensions daemon-set took: 27.01804ms
Dec 14 10:06:45.140: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.881182ms
Dec 14 10:06:47.465: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:06:47.465: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 10:06:47.492: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"61525"},"items":null}

Dec 14 10:06:47.517: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"61525"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:06:47.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4734" for this suite. 12/14/22 10:06:47.703
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":346,"skipped":6489,"failed":0}
------------------------------
• [9.597 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:38.133
    Dec 14 10:06:38.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 10:06:38.134
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:38.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:38.263
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Dec 14 10:06:38.417: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 12/14/22 10:06:38.446
    Dec 14 10:06:38.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:38.476: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 12/14/22 10:06:38.476
    Dec 14 10:06:38.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:38.614: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:39.642: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:39.642: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:40.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:06:40.641: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 12/14/22 10:06:40.669
    Dec 14 10:06:40.797: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:40.797: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/14/22 10:06:40.797
    Dec 14 10:06:40.859: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:40.859: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:41.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:41.889: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:42.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:42.885: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:43.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:43.887: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:06:44.886: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:06:44.886: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:06:44.936
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4734, will wait for the garbage collector to delete the pods 12/14/22 10:06:44.936
    Dec 14 10:06:45.039: INFO: Deleting DaemonSet.extensions daemon-set took: 27.01804ms
    Dec 14 10:06:45.140: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.881182ms
    Dec 14 10:06:47.465: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:06:47.465: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 10:06:47.492: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"61525"},"items":null}

    Dec 14 10:06:47.517: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"61525"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:06:47.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4734" for this suite. 12/14/22 10:06:47.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:47.731
Dec 14 10:06:47.731: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:06:47.732
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:47.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:47.857
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 10:06:47.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9285" for this suite. 12/14/22 10:06:47.96
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":347,"skipped":6494,"failed":0}
------------------------------
• [0.262 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:47.731
    Dec 14 10:06:47.731: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:06:47.732
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:47.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:47.857
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 10:06:47.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9285" for this suite. 12/14/22 10:06:47.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:47.993
Dec 14 10:06:47.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 10:06:47.995
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:48.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:48.12
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Dec 14 10:06:48.169: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/14/22 10:06:48.223
STEP: Checking rc "condition-test" has the desired failure condition set 12/14/22 10:06:48.249
STEP: Scaling down rc "condition-test" to satisfy pod quota 12/14/22 10:06:49.305
Dec 14 10:06:49.357: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 12/14/22 10:06:49.357
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 10:06:49.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-610" for this suite. 12/14/22 10:06:49.439
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":348,"skipped":6501,"failed":0}
------------------------------
• [1.472 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:47.993
    Dec 14 10:06:47.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 10:06:47.995
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:48.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:48.12
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Dec 14 10:06:48.169: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/14/22 10:06:48.223
    STEP: Checking rc "condition-test" has the desired failure condition set 12/14/22 10:06:48.249
    STEP: Scaling down rc "condition-test" to satisfy pod quota 12/14/22 10:06:49.305
    Dec 14 10:06:49.357: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 12/14/22 10:06:49.357
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 10:06:49.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-610" for this suite. 12/14/22 10:06:49.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:49.466
Dec 14 10:06:49.466: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:06:49.467
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:49.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:49.596
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-6007 12/14/22 10:06:49.644
STEP: creating service affinity-nodeport-transition in namespace services-6007 12/14/22 10:06:49.645
STEP: creating replication controller affinity-nodeport-transition in namespace services-6007 12/14/22 10:06:49.687
I1214 10:06:49.713866    6274 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6007, replica count: 3
I1214 10:06:52.765230    6274 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 10:06:52.863: INFO: Creating new exec pod
Dec 14 10:06:52.899: INFO: Waiting up to 5m0s for pod "execpod-affinity25s4r" in namespace "services-6007" to be "running"
Dec 14 10:06:52.924: INFO: Pod "execpod-affinity25s4r": Phase="Pending", Reason="", readiness=false. Elapsed: 25.412944ms
Dec 14 10:06:54.952: INFO: Pod "execpod-affinity25s4r": Phase="Running", Reason="", readiness=true. Elapsed: 2.052859915s
Dec 14 10:06:54.952: INFO: Pod "execpod-affinity25s4r" satisfied condition "running"
Dec 14 10:06:56.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Dec 14 10:06:56.655: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Dec 14 10:06:56.655: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:06:56.655: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.191.170 80'
Dec 14 10:06:57.418: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.191.170 80\nConnection to 100.111.191.170 80 port [tcp/http] succeeded!\n"
Dec 14 10:06:57.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:06:57.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 31692'
Dec 14 10:06:58.106: INFO: stderr: "+ nc -v -t -w 2 10.250.0.5 31692\nConnection to 10.250.0.5 31692 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 14 10:06:58.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:06:58.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 31692'
Dec 14 10:06:58.798: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 31692\nConnection to 10.250.0.4 31692 port [tcp/*] succeeded!\n"
Dec 14 10:06:58.798: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:06:58.851: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:31692/ ; done'
Dec 14 10:06:59.594: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n"
Dec 14 10:06:59.594: INFO: stdout: "\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl"
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
Dec 14 10:06:59.648: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:31692/ ; done'
Dec 14 10:07:00.405: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n"
Dec 14 10:07:00.405: INFO: stdout: "\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2"
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
Dec 14 10:07:00.405: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6007, will wait for the garbage collector to delete the pods 12/14/22 10:07:00.442
Dec 14 10:07:00.545: INFO: Deleting ReplicationController affinity-nodeport-transition took: 27.309129ms
Dec 14 10:07:00.646: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.180966ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:07:03.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6007" for this suite. 12/14/22 10:07:03.14
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":349,"skipped":6507,"failed":0}
------------------------------
• [13.701 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:49.466
    Dec 14 10:06:49.466: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:06:49.467
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:49.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:49.596
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-6007 12/14/22 10:06:49.644
    STEP: creating service affinity-nodeport-transition in namespace services-6007 12/14/22 10:06:49.645
    STEP: creating replication controller affinity-nodeport-transition in namespace services-6007 12/14/22 10:06:49.687
    I1214 10:06:49.713866    6274 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6007, replica count: 3
    I1214 10:06:52.765230    6274 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 10:06:52.863: INFO: Creating new exec pod
    Dec 14 10:06:52.899: INFO: Waiting up to 5m0s for pod "execpod-affinity25s4r" in namespace "services-6007" to be "running"
    Dec 14 10:06:52.924: INFO: Pod "execpod-affinity25s4r": Phase="Pending", Reason="", readiness=false. Elapsed: 25.412944ms
    Dec 14 10:06:54.952: INFO: Pod "execpod-affinity25s4r": Phase="Running", Reason="", readiness=true. Elapsed: 2.052859915s
    Dec 14 10:06:54.952: INFO: Pod "execpod-affinity25s4r" satisfied condition "running"
    Dec 14 10:06:56.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Dec 14 10:06:56.655: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Dec 14 10:06:56.655: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:06:56.655: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.111.191.170 80'
    Dec 14 10:06:57.418: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.111.191.170 80\nConnection to 100.111.191.170 80 port [tcp/http] succeeded!\n"
    Dec 14 10:06:57.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:06:57.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.5 31692'
    Dec 14 10:06:58.106: INFO: stderr: "+ nc -v -t -w 2 10.250.0.5 31692\nConnection to 10.250.0.5 31692 port [tcp/*] succeeded!\n+ echo hostName\n"
    Dec 14 10:06:58.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:06:58.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.4 31692'
    Dec 14 10:06:58.798: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.4 31692\nConnection to 10.250.0.4 31692 port [tcp/*] succeeded!\n"
    Dec 14 10:06:58.798: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:06:58.851: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:31692/ ; done'
    Dec 14 10:06:59.594: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n"
    Dec 14 10:06:59.594: INFO: stdout: "\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-fn4k8\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl\naffinity-nodeport-transition-f8zbl"
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-fn4k8
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.594: INFO: Received response from host: affinity-nodeport-transition-f8zbl
    Dec 14 10:06:59.648: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6007 exec execpod-affinity25s4r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.5:31692/ ; done'
    Dec 14 10:07:00.405: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.5:31692/\n"
    Dec 14 10:07:00.405: INFO: stdout: "\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2\naffinity-nodeport-transition-d2dr2"
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Received response from host: affinity-nodeport-transition-d2dr2
    Dec 14 10:07:00.405: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6007, will wait for the garbage collector to delete the pods 12/14/22 10:07:00.442
    Dec 14 10:07:00.545: INFO: Deleting ReplicationController affinity-nodeport-transition took: 27.309129ms
    Dec 14 10:07:00.646: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.180966ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:07:03.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6007" for this suite. 12/14/22 10:07:03.14
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:03.168
Dec 14 10:07:03.168: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:07:03.169
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:03.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:03.294
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-195-delete-me 12/14/22 10:07:03.367
STEP: Waiting for the RuntimeClass to disappear 12/14/22 10:07:03.393
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 10:07:03.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-195" for this suite. 12/14/22 10:07:03.476
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":350,"skipped":6510,"failed":0}
------------------------------
• [0.334 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:03.168
    Dec 14 10:07:03.168: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:07:03.169
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:03.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:03.294
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-195-delete-me 12/14/22 10:07:03.367
    STEP: Waiting for the RuntimeClass to disappear 12/14/22 10:07:03.393
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 10:07:03.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-195" for this suite. 12/14/22 10:07:03.476
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:03.503
Dec 14 10:07:03.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 10:07:03.504
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:03.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:03.63
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 10:07:03.739
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 10:07:04.135
STEP: Deploying the webhook pod 12/14/22 10:07:04.164
STEP: Wait for the deployment to be ready 12/14/22 10:07:04.217
Dec 14 10:07:04.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 10:07:06.329
STEP: Verifying the service has paired with the endpoint 12/14/22 10:07:06.366
Dec 14 10:07:07.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 10:07:07.396
STEP: create a pod that should be denied by the webhook 12/14/22 10:07:07.539
STEP: create a pod that causes the webhook to hang 12/14/22 10:07:07.682
STEP: create a configmap that should be denied by the webhook 12/14/22 10:07:17.738
STEP: create a configmap that should be admitted by the webhook 12/14/22 10:07:17.793
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:07:17.923
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:07:18.021
STEP: create a namespace that bypass the webhook 12/14/22 10:07:18.1
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/14/22 10:07:18.129
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:07:18.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5230" for this suite. 12/14/22 10:07:18.315
STEP: Destroying namespace "webhook-5230-markers" for this suite. 12/14/22 10:07:18.343
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":351,"skipped":6511,"failed":0}
------------------------------
• [14.997 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:03.503
    Dec 14 10:07:03.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 10:07:03.504
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:03.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:03.63
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 10:07:03.739
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 10:07:04.135
    STEP: Deploying the webhook pod 12/14/22 10:07:04.164
    STEP: Wait for the deployment to be ready 12/14/22 10:07:04.217
    Dec 14 10:07:04.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 10:07:06.329
    STEP: Verifying the service has paired with the endpoint 12/14/22 10:07:06.366
    Dec 14 10:07:07.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 10:07:07.396
    STEP: create a pod that should be denied by the webhook 12/14/22 10:07:07.539
    STEP: create a pod that causes the webhook to hang 12/14/22 10:07:07.682
    STEP: create a configmap that should be denied by the webhook 12/14/22 10:07:17.738
    STEP: create a configmap that should be admitted by the webhook 12/14/22 10:07:17.793
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:07:17.923
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:07:18.021
    STEP: create a namespace that bypass the webhook 12/14/22 10:07:18.1
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/14/22 10:07:18.129
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:07:18.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5230" for this suite. 12/14/22 10:07:18.315
    STEP: Destroying namespace "webhook-5230-markers" for this suite. 12/14/22 10:07:18.343
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:18.501
Dec 14 10:07:18.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename certificates 12/14/22 10:07:18.503
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:18.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:18.632
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 12/14/22 10:07:19.525
STEP: getting /apis/certificates.k8s.io 12/14/22 10:07:19.574
STEP: getting /apis/certificates.k8s.io/v1 12/14/22 10:07:19.598
STEP: creating 12/14/22 10:07:19.622
STEP: getting 12/14/22 10:07:19.699
STEP: listing 12/14/22 10:07:19.724
STEP: watching 12/14/22 10:07:19.75
Dec 14 10:07:19.750: INFO: starting watch
STEP: patching 12/14/22 10:07:19.775
STEP: updating 12/14/22 10:07:19.802
Dec 14 10:07:19.828: INFO: waiting for watch events with expected annotations
Dec 14 10:07:19.828: INFO: saw patched and updated annotations
STEP: getting /approval 12/14/22 10:07:19.828
STEP: patching /approval 12/14/22 10:07:19.857
STEP: updating /approval 12/14/22 10:07:19.884
STEP: getting /status 12/14/22 10:07:19.911
STEP: patching /status 12/14/22 10:07:19.936
STEP: updating /status 12/14/22 10:07:19.963
STEP: deleting 12/14/22 10:07:19.99
STEP: deleting a collection 12/14/22 10:07:20.069
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:07:20.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3733" for this suite. 12/14/22 10:07:20.332
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":352,"skipped":6549,"failed":0}
------------------------------
• [1.860 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:18.501
    Dec 14 10:07:18.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename certificates 12/14/22 10:07:18.503
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:18.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:18.632
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 12/14/22 10:07:19.525
    STEP: getting /apis/certificates.k8s.io 12/14/22 10:07:19.574
    STEP: getting /apis/certificates.k8s.io/v1 12/14/22 10:07:19.598
    STEP: creating 12/14/22 10:07:19.622
    STEP: getting 12/14/22 10:07:19.699
    STEP: listing 12/14/22 10:07:19.724
    STEP: watching 12/14/22 10:07:19.75
    Dec 14 10:07:19.750: INFO: starting watch
    STEP: patching 12/14/22 10:07:19.775
    STEP: updating 12/14/22 10:07:19.802
    Dec 14 10:07:19.828: INFO: waiting for watch events with expected annotations
    Dec 14 10:07:19.828: INFO: saw patched and updated annotations
    STEP: getting /approval 12/14/22 10:07:19.828
    STEP: patching /approval 12/14/22 10:07:19.857
    STEP: updating /approval 12/14/22 10:07:19.884
    STEP: getting /status 12/14/22 10:07:19.911
    STEP: patching /status 12/14/22 10:07:19.936
    STEP: updating /status 12/14/22 10:07:19.963
    STEP: deleting 12/14/22 10:07:19.99
    STEP: deleting a collection 12/14/22 10:07:20.069
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:07:20.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-3733" for this suite. 12/14/22 10:07:20.332
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:20.362
Dec 14 10:07:20.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 10:07:20.363
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:20.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:20.487
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 12/14/22 10:07:20.535
STEP: creating a new configmap 12/14/22 10:07:20.56
STEP: modifying the configmap once 12/14/22 10:07:20.586
STEP: changing the label value of the configmap 12/14/22 10:07:20.639
STEP: Expecting to observe a delete notification for the watched object 12/14/22 10:07:20.69
Dec 14 10:07:20.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61964 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 10:07:20.690: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61965 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 10:07:20.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61967 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 12/14/22 10:07:20.69
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/14/22 10:07:20.742
STEP: changing the label value of the configmap back 12/14/22 10:07:30.742
STEP: modifying the configmap a third time 12/14/22 10:07:30.795
STEP: deleting the configmap 12/14/22 10:07:30.847
STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/14/22 10:07:30.875
Dec 14 10:07:30.875: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62044 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 10:07:30.875: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62045 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 10:07:30.875: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62046 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 10:07:30.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7904" for this suite. 12/14/22 10:07:30.924
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":353,"skipped":6561,"failed":0}
------------------------------
• [10.590 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:20.362
    Dec 14 10:07:20.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 10:07:20.363
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:20.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:20.487
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 12/14/22 10:07:20.535
    STEP: creating a new configmap 12/14/22 10:07:20.56
    STEP: modifying the configmap once 12/14/22 10:07:20.586
    STEP: changing the label value of the configmap 12/14/22 10:07:20.639
    STEP: Expecting to observe a delete notification for the watched object 12/14/22 10:07:20.69
    Dec 14 10:07:20.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61964 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 10:07:20.690: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61965 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 10:07:20.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 61967 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 12/14/22 10:07:20.69
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/14/22 10:07:20.742
    STEP: changing the label value of the configmap back 12/14/22 10:07:30.742
    STEP: modifying the configmap a third time 12/14/22 10:07:30.795
    STEP: deleting the configmap 12/14/22 10:07:30.847
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/14/22 10:07:30.875
    Dec 14 10:07:30.875: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62044 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 10:07:30.875: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62045 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 10:07:30.875: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7904  c3e7b2ac-19db-4f64-8741-b8c64773c435 62046 0 2022-12-14 10:07:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 10:07:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 10:07:30.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7904" for this suite. 12/14/22 10:07:30.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:30.952
Dec 14 10:07:30.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 10:07:30.954
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:31.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:31.079
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 12/14/22 10:07:31.128
Dec 14 10:07:31.160: INFO: Waiting up to 5m0s for pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644" in namespace "var-expansion-3953" to be "Succeeded or Failed"
Dec 14 10:07:31.185: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Pending", Reason="", readiness=false. Elapsed: 24.974413ms
Dec 14 10:07:33.212: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051708227s
Dec 14 10:07:35.213: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052691061s
STEP: Saw pod success 12/14/22 10:07:35.214
Dec 14 10:07:35.214: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644" satisfied condition "Succeeded or Failed"
Dec 14 10:07:35.240: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 container dapi-container: <nil>
STEP: delete the pod 12/14/22 10:07:35.31
Dec 14 10:07:35.343: INFO: Waiting for pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 to disappear
Dec 14 10:07:35.368: INFO: Pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 10:07:35.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3953" for this suite. 12/14/22 10:07:35.418
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":354,"skipped":6578,"failed":0}
------------------------------
• [4.492 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:30.952
    Dec 14 10:07:30.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 10:07:30.954
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:31.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:31.079
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 12/14/22 10:07:31.128
    Dec 14 10:07:31.160: INFO: Waiting up to 5m0s for pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644" in namespace "var-expansion-3953" to be "Succeeded or Failed"
    Dec 14 10:07:31.185: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Pending", Reason="", readiness=false. Elapsed: 24.974413ms
    Dec 14 10:07:33.212: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051708227s
    Dec 14 10:07:35.213: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052691061s
    STEP: Saw pod success 12/14/22 10:07:35.214
    Dec 14 10:07:35.214: INFO: Pod "var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644" satisfied condition "Succeeded or Failed"
    Dec 14 10:07:35.240: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 10:07:35.31
    Dec 14 10:07:35.343: INFO: Waiting for pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 to disappear
    Dec 14 10:07:35.368: INFO: Pod var-expansion-b786b14e-4af7-488b-bdaa-138b32b02644 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 10:07:35.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3953" for this suite. 12/14/22 10:07:35.418
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:35.445
Dec 14 10:07:35.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:07:35.446
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:35.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:35.57
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-3883 12/14/22 10:07:35.618
Dec 14 10:07:35.653: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3883" to be "running and ready"
Dec 14 10:07:35.678: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 25.376835ms
Dec 14 10:07:35.679: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:07:37.705: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.052013154s
Dec 14 10:07:37.705: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 14 10:07:37.705: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec 14 10:07:37.732: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 14 10:07:38.406: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 14 10:07:38.406: INFO: stdout: "iptables"
Dec 14 10:07:38.406: INFO: proxyMode: iptables
Dec 14 10:07:38.438: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 14 10:07:38.462: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-3883 12/14/22 10:07:38.462
STEP: creating replication controller affinity-clusterip-timeout in namespace services-3883 12/14/22 10:07:38.503
I1214 10:07:38.540750    6274 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3883, replica count: 3
I1214 10:07:41.592790    6274 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 10:07:41.643: INFO: Creating new exec pod
Dec 14 10:07:41.674: INFO: Waiting up to 5m0s for pod "execpod-affinityfrccl" in namespace "services-3883" to be "running"
Dec 14 10:07:41.699: INFO: Pod "execpod-affinityfrccl": Phase="Pending", Reason="", readiness=false. Elapsed: 25.211221ms
Dec 14 10:07:43.726: INFO: Pod "execpod-affinityfrccl": Phase="Running", Reason="", readiness=true. Elapsed: 2.051841119s
Dec 14 10:07:43.726: INFO: Pod "execpod-affinityfrccl" satisfied condition "running"
Dec 14 10:07:44.727: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Dec 14 10:07:45.377: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Dec 14 10:07:45.377: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:45.377: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.106.85.159 80'
Dec 14 10:07:46.059: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.106.85.159 80\nConnection to 100.106.85.159 80 port [tcp/http] succeeded!\n"
Dec 14 10:07:46.059: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:46.059: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.106.85.159:80/ ; done'
Dec 14 10:07:46.824: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:07:46.824: INFO: stdout: "\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9"
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
Dec 14 10:07:46.824: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:07:47.440: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:07:47.440: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:08:07.441: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:08:08.110: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:08:08.110: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:08:28.113: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:08:28.783: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:08:28.783: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:08:48.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:08:49.472: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:08:49.472: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:09:09.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:09:10.103: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:09:10.103: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:09:30.104: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:09:30.639: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:09:30.639: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
Dec 14 10:09:50.640: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
Dec 14 10:09:51.246: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
Dec 14 10:09:51.246: INFO: stdout: "affinity-clusterip-timeout-xjmhj"
Dec 14 10:09:51.246: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3883, will wait for the garbage collector to delete the pods 12/14/22 10:09:51.281
Dec 14 10:09:51.384: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 27.448289ms
Dec 14 10:09:51.485: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.705363ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:09:53.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3883" for this suite. 12/14/22 10:09:53.475
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":355,"skipped":6578,"failed":0}
------------------------------
• [138.056 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:35.445
    Dec 14 10:07:35.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:07:35.446
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:35.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:35.57
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-3883 12/14/22 10:07:35.618
    Dec 14 10:07:35.653: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3883" to be "running and ready"
    Dec 14 10:07:35.678: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 25.376835ms
    Dec 14 10:07:35.679: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:07:37.705: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.052013154s
    Dec 14 10:07:37.705: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec 14 10:07:37.705: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec 14 10:07:37.732: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec 14 10:07:38.406: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec 14 10:07:38.406: INFO: stdout: "iptables"
    Dec 14 10:07:38.406: INFO: proxyMode: iptables
    Dec 14 10:07:38.438: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec 14 10:07:38.462: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-3883 12/14/22 10:07:38.462
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-3883 12/14/22 10:07:38.503
    I1214 10:07:38.540750    6274 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3883, replica count: 3
    I1214 10:07:41.592790    6274 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 10:07:41.643: INFO: Creating new exec pod
    Dec 14 10:07:41.674: INFO: Waiting up to 5m0s for pod "execpod-affinityfrccl" in namespace "services-3883" to be "running"
    Dec 14 10:07:41.699: INFO: Pod "execpod-affinityfrccl": Phase="Pending", Reason="", readiness=false. Elapsed: 25.211221ms
    Dec 14 10:07:43.726: INFO: Pod "execpod-affinityfrccl": Phase="Running", Reason="", readiness=true. Elapsed: 2.051841119s
    Dec 14 10:07:43.726: INFO: Pod "execpod-affinityfrccl" satisfied condition "running"
    Dec 14 10:07:44.727: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Dec 14 10:07:45.377: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Dec 14 10:07:45.377: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:45.377: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.106.85.159 80'
    Dec 14 10:07:46.059: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.106.85.159 80\nConnection to 100.106.85.159 80 port [tcp/http] succeeded!\n"
    Dec 14 10:07:46.059: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:46.059: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.106.85.159:80/ ; done'
    Dec 14 10:07:46.824: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:07:46.824: INFO: stdout: "\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9\naffinity-clusterip-timeout-7xwq9"
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Received response from host: affinity-clusterip-timeout-7xwq9
    Dec 14 10:07:46.824: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:07:47.440: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:07:47.440: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:08:07.441: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:08:08.110: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:08:08.110: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:08:28.113: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:08:28.783: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:08:28.783: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:08:48.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:08:49.472: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:08:49.472: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:09:09.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:09:10.103: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:09:10.103: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:09:30.104: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:09:30.639: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:09:30.639: INFO: stdout: "affinity-clusterip-timeout-7xwq9"
    Dec 14 10:09:50.640: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3883 exec execpod-affinityfrccl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.106.85.159:80/'
    Dec 14 10:09:51.246: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.106.85.159:80/\n"
    Dec 14 10:09:51.246: INFO: stdout: "affinity-clusterip-timeout-xjmhj"
    Dec 14 10:09:51.246: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3883, will wait for the garbage collector to delete the pods 12/14/22 10:09:51.281
    Dec 14 10:09:51.384: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 27.448289ms
    Dec 14 10:09:51.485: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.705363ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:09:53.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3883" for this suite. 12/14/22 10:09:53.475
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:09:53.502
Dec 14 10:09:53.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 10:09:53.503
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:53.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:53.625
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 10:09:53.673
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-fcsb 12/14/22 10:09:53.725
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 10:09:53.725
Dec 14 10:09:53.770: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fcsb" in namespace "subpath-5726" to be "Succeeded or Failed"
Dec 14 10:09:53.795: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.685967ms
Dec 14 10:09:55.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 2.051434104s
Dec 14 10:09:57.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 4.052398454s
Dec 14 10:09:59.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 6.051357159s
Dec 14 10:10:01.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 8.052180543s
Dec 14 10:10:03.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 10.052135109s
Dec 14 10:10:05.825: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 12.054211476s
Dec 14 10:10:07.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 14.052141855s
Dec 14 10:10:09.821: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 16.050950938s
Dec 14 10:10:11.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 18.052154383s
Dec 14 10:10:13.821: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 20.050389722s
Dec 14 10:10:15.825: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=false. Elapsed: 22.054982621s
Dec 14 10:10:17.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052004256s
STEP: Saw pod success 12/14/22 10:10:17.822
Dec 14 10:10:17.823: INFO: Pod "pod-subpath-test-configmap-fcsb" satisfied condition "Succeeded or Failed"
Dec 14 10:10:17.849: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-configmap-fcsb container test-container-subpath-configmap-fcsb: <nil>
STEP: delete the pod 12/14/22 10:10:17.988
Dec 14 10:10:18.058: INFO: Waiting for pod pod-subpath-test-configmap-fcsb to disappear
Dec 14 10:10:18.109: INFO: Pod pod-subpath-test-configmap-fcsb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fcsb 12/14/22 10:10:18.109
Dec 14 10:10:18.109: INFO: Deleting pod "pod-subpath-test-configmap-fcsb" in namespace "subpath-5726"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 10:10:18.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5726" for this suite. 12/14/22 10:10:18.183
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":356,"skipped":6582,"failed":0}
------------------------------
• [24.708 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:09:53.502
    Dec 14 10:09:53.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 10:09:53.503
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:53.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:53.625
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 10:09:53.673
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-fcsb 12/14/22 10:09:53.725
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 10:09:53.725
    Dec 14 10:09:53.770: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fcsb" in namespace "subpath-5726" to be "Succeeded or Failed"
    Dec 14 10:09:53.795: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.685967ms
    Dec 14 10:09:55.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 2.051434104s
    Dec 14 10:09:57.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 4.052398454s
    Dec 14 10:09:59.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 6.051357159s
    Dec 14 10:10:01.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 8.052180543s
    Dec 14 10:10:03.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 10.052135109s
    Dec 14 10:10:05.825: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 12.054211476s
    Dec 14 10:10:07.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 14.052141855s
    Dec 14 10:10:09.821: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 16.050950938s
    Dec 14 10:10:11.823: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 18.052154383s
    Dec 14 10:10:13.821: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=true. Elapsed: 20.050389722s
    Dec 14 10:10:15.825: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Running", Reason="", readiness=false. Elapsed: 22.054982621s
    Dec 14 10:10:17.822: INFO: Pod "pod-subpath-test-configmap-fcsb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052004256s
    STEP: Saw pod success 12/14/22 10:10:17.822
    Dec 14 10:10:17.823: INFO: Pod "pod-subpath-test-configmap-fcsb" satisfied condition "Succeeded or Failed"
    Dec 14 10:10:17.849: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-subpath-test-configmap-fcsb container test-container-subpath-configmap-fcsb: <nil>
    STEP: delete the pod 12/14/22 10:10:17.988
    Dec 14 10:10:18.058: INFO: Waiting for pod pod-subpath-test-configmap-fcsb to disappear
    Dec 14 10:10:18.109: INFO: Pod pod-subpath-test-configmap-fcsb no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-fcsb 12/14/22 10:10:18.109
    Dec 14 10:10:18.109: INFO: Deleting pod "pod-subpath-test-configmap-fcsb" in namespace "subpath-5726"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 10:10:18.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5726" for this suite. 12/14/22 10:10:18.183
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:18.211
Dec 14 10:10:18.211: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 10:10:18.212
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:18.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:18.337
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Dec 14 10:10:18.461: INFO: Endpoints addresses: [10.243.138.137] , ports: [443]
Dec 14 10:10:18.461: INFO: EndpointSlices addresses: [10.243.138.137] , ports: [443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 10:10:18.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6041" for this suite. 12/14/22 10:10:18.488
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":357,"skipped":6594,"failed":0}
------------------------------
• [0.305 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:18.211
    Dec 14 10:10:18.211: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 10:10:18.212
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:18.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:18.337
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Dec 14 10:10:18.461: INFO: Endpoints addresses: [10.243.138.137] , ports: [443]
    Dec 14 10:10:18.461: INFO: EndpointSlices addresses: [10.243.138.137] , ports: [443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 10:10:18.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6041" for this suite. 12/14/22 10:10:18.488
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:18.516
Dec 14 10:10:18.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 10:10:18.517
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:18.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:18.643
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 12/14/22 10:10:18.692
Dec 14 10:10:18.725: INFO: Waiting up to 5m0s for pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000" in namespace "downward-api-3217" to be "Succeeded or Failed"
Dec 14 10:10:18.750: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Pending", Reason="", readiness=false. Elapsed: 25.138964ms
Dec 14 10:10:20.776: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051228095s
Dec 14 10:10:22.783: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058407741s
STEP: Saw pod success 12/14/22 10:10:22.784
Dec 14 10:10:22.784: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000" satisfied condition "Succeeded or Failed"
Dec 14 10:10:22.809: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 container dapi-container: <nil>
STEP: delete the pod 12/14/22 10:10:22.842
Dec 14 10:10:22.879: INFO: Waiting for pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 to disappear
Dec 14 10:10:22.904: INFO: Pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 10:10:22.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3217" for this suite. 12/14/22 10:10:22.953
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":358,"skipped":6608,"failed":0}
------------------------------
• [4.465 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:18.516
    Dec 14 10:10:18.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 10:10:18.517
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:18.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:18.643
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 12/14/22 10:10:18.692
    Dec 14 10:10:18.725: INFO: Waiting up to 5m0s for pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000" in namespace "downward-api-3217" to be "Succeeded or Failed"
    Dec 14 10:10:18.750: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Pending", Reason="", readiness=false. Elapsed: 25.138964ms
    Dec 14 10:10:20.776: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051228095s
    Dec 14 10:10:22.783: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058407741s
    STEP: Saw pod success 12/14/22 10:10:22.784
    Dec 14 10:10:22.784: INFO: Pod "downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000" satisfied condition "Succeeded or Failed"
    Dec 14 10:10:22.809: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 10:10:22.842
    Dec 14 10:10:22.879: INFO: Waiting for pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 to disappear
    Dec 14 10:10:22.904: INFO: Pod downward-api-52347b9e-c584-4a2a-b2e5-56d01b1f5000 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 10:10:22.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3217" for this suite. 12/14/22 10:10:22.953
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:22.982
Dec 14 10:10:22.982: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 10:10:22.982
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:23.058
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:23.107
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 10:10:23.312
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 10:10:23.339
Dec 14 10:10:23.396: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:10:23.396: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 10:10:24.472: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:10:24.472: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:10:25.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 10:10:25.471: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status 12/14/22 10:10:25.496
Dec 14 10:10:25.522: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 12/14/22 10:10:25.522
Dec 14 10:10:25.575: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 12/14/22 10:10:25.575
Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: ADDED
Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.601: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.601: INFO: Found daemon set daemon-set in namespace daemonsets-4017 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 10:10:25.601: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 12/14/22 10:10:25.601
STEP: watching for the daemon set status to be patched 12/14/22 10:10:25.627
Dec 14 10:10:25.651: INFO: Observed &DaemonSet event: ADDED
Dec 14 10:10:25.651: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.652: INFO: Observed daemon set daemon-set in namespace daemonsets-4017 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 10:10:25.652: INFO: Found daemon set daemon-set in namespace daemonsets-4017 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Dec 14 10:10:25.652: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:10:25.677
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4017, will wait for the garbage collector to delete the pods 12/14/22 10:10:25.677
Dec 14 10:10:25.783: INFO: Deleting DaemonSet.extensions daemon-set took: 29.632609ms
Dec 14 10:10:25.884: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.7246ms
Dec 14 10:10:28.108: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:10:28.109: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 10:10:28.133: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"63346"},"items":null}

Dec 14 10:10:28.158: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"63346"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:10:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4017" for this suite. 12/14/22 10:10:28.283
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":359,"skipped":6631,"failed":0}
------------------------------
• [5.328 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:22.982
    Dec 14 10:10:22.982: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 10:10:22.982
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:23.058
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:23.107
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 10:10:23.312
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 10:10:23.339
    Dec 14 10:10:23.396: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:10:23.396: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 10:10:24.472: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:10:24.472: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:10:25.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 10:10:25.471: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Getting /status 12/14/22 10:10:25.496
    Dec 14 10:10:25.522: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 12/14/22 10:10:25.522
    Dec 14 10:10:25.575: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 12/14/22 10:10:25.575
    Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: ADDED
    Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.600: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.601: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.601: INFO: Found daemon set daemon-set in namespace daemonsets-4017 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 10:10:25.601: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 12/14/22 10:10:25.601
    STEP: watching for the daemon set status to be patched 12/14/22 10:10:25.627
    Dec 14 10:10:25.651: INFO: Observed &DaemonSet event: ADDED
    Dec 14 10:10:25.651: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.652: INFO: Observed daemon set daemon-set in namespace daemonsets-4017 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 10:10:25.652: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 10:10:25.652: INFO: Found daemon set daemon-set in namespace daemonsets-4017 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Dec 14 10:10:25.652: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:10:25.677
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4017, will wait for the garbage collector to delete the pods 12/14/22 10:10:25.677
    Dec 14 10:10:25.783: INFO: Deleting DaemonSet.extensions daemon-set took: 29.632609ms
    Dec 14 10:10:25.884: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.7246ms
    Dec 14 10:10:28.108: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:10:28.109: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 10:10:28.133: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"63346"},"items":null}

    Dec 14 10:10:28.158: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"63346"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:10:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4017" for this suite. 12/14/22 10:10:28.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:28.311
Dec 14 10:10:28.311: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 10:10:28.311
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:28.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:28.434
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-6a370285-aef0-4d2c-9dd7-8d8af6496ac7 12/14/22 10:10:28.481
STEP: Creating a pod to test consume secrets 12/14/22 10:10:28.506
Dec 14 10:10:28.539: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c" in namespace "projected-529" to be "Succeeded or Failed"
Dec 14 10:10:28.571: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Pending", Reason="", readiness=false. Elapsed: 31.177071ms
Dec 14 10:10:30.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Running", Reason="", readiness=false. Elapsed: 2.057798588s
Dec 14 10:10:32.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057428884s
STEP: Saw pod success 12/14/22 10:10:32.597
Dec 14 10:10:32.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c" satisfied condition "Succeeded or Failed"
Dec 14 10:10:32.623: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 10:10:32.656
Dec 14 10:10:32.690: INFO: Waiting for pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c to disappear
Dec 14 10:10:32.716: INFO: Pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 10:10:32.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-529" for this suite. 12/14/22 10:10:32.765
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":360,"skipped":6662,"failed":0}
------------------------------
• [4.487 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:28.311
    Dec 14 10:10:28.311: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 10:10:28.311
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:28.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:28.434
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-6a370285-aef0-4d2c-9dd7-8d8af6496ac7 12/14/22 10:10:28.481
    STEP: Creating a pod to test consume secrets 12/14/22 10:10:28.506
    Dec 14 10:10:28.539: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c" in namespace "projected-529" to be "Succeeded or Failed"
    Dec 14 10:10:28.571: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Pending", Reason="", readiness=false. Elapsed: 31.177071ms
    Dec 14 10:10:30.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Running", Reason="", readiness=false. Elapsed: 2.057798588s
    Dec 14 10:10:32.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057428884s
    STEP: Saw pod success 12/14/22 10:10:32.597
    Dec 14 10:10:32.597: INFO: Pod "pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c" satisfied condition "Succeeded or Failed"
    Dec 14 10:10:32.623: INFO: Trying to get logs from node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 10:10:32.656
    Dec 14 10:10:32.690: INFO: Waiting for pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c to disappear
    Dec 14 10:10:32.716: INFO: Pod pod-projected-secrets-ee767c95-a32e-49d7-869a-432f97c2f68c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 10:10:32.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-529" for this suite. 12/14/22 10:10:32.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:32.799
Dec 14 10:10:32.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 10:10:32.8
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:32.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:32.924
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 12/14/22 10:10:32.981
Dec 14 10:10:32.982: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6771 create -f -'
Dec 14 10:10:33.672: INFO: stderr: ""
Dec 14 10:10:33.672: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 10:10:33.672
Dec 14 10:10:34.698: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:10:34.698: INFO: Found 0 / 1
Dec 14 10:10:35.699: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:10:35.699: INFO: Found 1 / 1
Dec 14 10:10:35.699: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 12/14/22 10:10:35.699
Dec 14 10:10:35.726: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:10:35.726: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 10:10:35.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6771 patch pod agnhost-primary-tnmsx -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 14 10:10:35.931: INFO: stderr: ""
Dec 14 10:10:35.931: INFO: stdout: "pod/agnhost-primary-tnmsx patched\n"
STEP: checking annotations 12/14/22 10:10:35.931
Dec 14 10:10:35.957: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:10:35.957: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 10:10:35.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6771" for this suite. 12/14/22 10:10:36.005
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":361,"skipped":6691,"failed":0}
------------------------------
• [3.234 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:32.799
    Dec 14 10:10:32.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 10:10:32.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:32.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:32.924
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 12/14/22 10:10:32.981
    Dec 14 10:10:32.982: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6771 create -f -'
    Dec 14 10:10:33.672: INFO: stderr: ""
    Dec 14 10:10:33.672: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 10:10:33.672
    Dec 14 10:10:34.698: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:10:34.698: INFO: Found 0 / 1
    Dec 14 10:10:35.699: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:10:35.699: INFO: Found 1 / 1
    Dec 14 10:10:35.699: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 12/14/22 10:10:35.699
    Dec 14 10:10:35.726: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:10:35.726: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 10:10:35.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm0ct-io0.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6771 patch pod agnhost-primary-tnmsx -p {"metadata":{"annotations":{"x":"y"}}}'
    Dec 14 10:10:35.931: INFO: stderr: ""
    Dec 14 10:10:35.931: INFO: stdout: "pod/agnhost-primary-tnmsx patched\n"
    STEP: checking annotations 12/14/22 10:10:35.931
    Dec 14 10:10:35.957: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:10:35.957: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 10:10:35.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6771" for this suite. 12/14/22 10:10:36.005
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:36.033
Dec 14 10:10:36.033: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 10:10:36.034
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:36.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:36.159
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 10:10:36.313
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 10:10:36.34
Dec 14 10:10:36.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:10:36.393: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
Dec 14 10:10:37.474: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:10:37.474: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
Dec 14 10:10:38.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 10:10:38.468: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets 12/14/22 10:10:38.495
STEP: DeleteCollection of the DaemonSets 12/14/22 10:10:38.524
STEP: Verify that ReplicaSets have been deleted 12/14/22 10:10:38.554
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Dec 14 10:10:38.645: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"63469"},"items":null}

Dec 14 10:10:38.674: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"63469"},"items":[{"metadata":{"name":"daemon-set-jl5mg","generateName":"daemon-set-","namespace":"daemonsets-4371","uid":"3ebad769-674d-4cae-9915-0c8ca1c2594d","resourceVersion":"63468","creationTimestamp":"2022-12-14T10:10:36Z","deletionTimestamp":"2022-12-14T10:11:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a11d1917a6b06afa25f2a76457aae562cdd1676d6f9a19942e47603156942cfa","cni.projectcalico.org/podIP":"100.64.1.253/32","cni.projectcalico.org/podIPs":"100.64.1.253/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6601c100-90e0-466d-ab88-d10cc799a9f0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6601c100-90e0-466d-ab88-d10cc799a9f0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:38Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mdlzg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mdlzg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--it--tm0ct-io0-worker-1-6f755-vb826","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--it--tm0ct-io0-worker-1-6f755-vb826"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:38Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:38Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"}],"hostIP":"10.250.0.4","podIP":"100.64.1.253","podIPs":[{"ip":"100.64.1.253"}],"startTime":"2022-12-14T10:10:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T10:10:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://ec93fc344ad43c8f88c8c37ba992e42eddf1b7feb055e1a77ff6d7d26e4631f8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tqkh5","generateName":"daemon-set-","namespace":"daemonsets-4371","uid":"d5726e1f-5ce8-471e-b9b1-336814607734","resourceVersion":"63469","creationTimestamp":"2022-12-14T10:10:36Z","deletionTimestamp":"2022-12-14T10:11:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"df7d819d003306ff3148d076096580fc8c4bb8d5002e6bcca3d11738dea3c98a","cni.projectcalico.org/podIP":"100.64.0.55/32","cni.projectcalico.org/podIPs":"100.64.0.55/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6601c100-90e0-466d-ab88-d10cc799a9f0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6601c100-90e0-466d-ab88-d10cc799a9f0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.55\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rtqvh","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rtqvh","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--it--tm0ct-io0-worker-1-6f755-hwmlx"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"}],"hostIP":"10.250.0.5","podIP":"100.64.0.55","podIPs":[{"ip":"100.64.0.55"}],"startTime":"2022-12-14T10:10:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T10:10:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1c051077c77bedec3bafed1cfa440fe681396a5ad4faf72b95118725f2dfa0a7","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:10:38.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4371" for this suite. 12/14/22 10:10:38.784
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":362,"skipped":6697,"failed":0}
------------------------------
• [2.778 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:36.033
    Dec 14 10:10:36.033: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 10:10:36.034
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:36.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:36.159
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 10:10:36.313
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 10:10:36.34
    Dec 14 10:10:36.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:10:36.393: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-hwmlx is running 0 daemon pod, expected 1
    Dec 14 10:10:37.474: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:10:37.474: INFO: Node shoot--it--tm0ct-io0-worker-1-6f755-vb826 is running 0 daemon pod, expected 1
    Dec 14 10:10:38.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 10:10:38.468: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: listing all DeamonSets 12/14/22 10:10:38.495
    STEP: DeleteCollection of the DaemonSets 12/14/22 10:10:38.524
    STEP: Verify that ReplicaSets have been deleted 12/14/22 10:10:38.554
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Dec 14 10:10:38.645: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"63469"},"items":null}

    Dec 14 10:10:38.674: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"63469"},"items":[{"metadata":{"name":"daemon-set-jl5mg","generateName":"daemon-set-","namespace":"daemonsets-4371","uid":"3ebad769-674d-4cae-9915-0c8ca1c2594d","resourceVersion":"63468","creationTimestamp":"2022-12-14T10:10:36Z","deletionTimestamp":"2022-12-14T10:11:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a11d1917a6b06afa25f2a76457aae562cdd1676d6f9a19942e47603156942cfa","cni.projectcalico.org/podIP":"100.64.1.253/32","cni.projectcalico.org/podIPs":"100.64.1.253/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6601c100-90e0-466d-ab88-d10cc799a9f0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6601c100-90e0-466d-ab88-d10cc799a9f0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:38Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.1.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mdlzg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mdlzg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--it--tm0ct-io0-worker-1-6f755-vb826","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--it--tm0ct-io0-worker-1-6f755-vb826"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:38Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:38Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"}],"hostIP":"10.250.0.4","podIP":"100.64.1.253","podIPs":[{"ip":"100.64.1.253"}],"startTime":"2022-12-14T10:10:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T10:10:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://ec93fc344ad43c8f88c8c37ba992e42eddf1b7feb055e1a77ff6d7d26e4631f8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tqkh5","generateName":"daemon-set-","namespace":"daemonsets-4371","uid":"d5726e1f-5ce8-471e-b9b1-336814607734","resourceVersion":"63469","creationTimestamp":"2022-12-14T10:10:36Z","deletionTimestamp":"2022-12-14T10:11:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"df7d819d003306ff3148d076096580fc8c4bb8d5002e6bcca3d11738dea3c98a","cni.projectcalico.org/podIP":"100.64.0.55/32","cni.projectcalico.org/podIPs":"100.64.0.55/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6601c100-90e0-466d-ab88-d10cc799a9f0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6601c100-90e0-466d-ab88-d10cc799a9f0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T10:10:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.64.0.55\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rtqvh","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tm0ct-io0.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rtqvh","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--it--tm0ct-io0-worker-1-6f755-hwmlx","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--it--tm0ct-io0-worker-1-6f755-hwmlx"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T10:10:36Z"}],"hostIP":"10.250.0.5","podIP":"100.64.0.55","podIPs":[{"ip":"100.64.0.55"}],"startTime":"2022-12-14T10:10:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T10:10:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1c051077c77bedec3bafed1cfa440fe681396a5ad4faf72b95118725f2dfa0a7","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:10:38.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4371" for this suite. 12/14/22 10:10:38.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Dec 14 10:10:38.812: INFO: Running AfterSuite actions on all nodes
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Dec 14 10:10:38.812: INFO: Running AfterSuite actions on node 1
Dec 14 10:10:38.812: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec 14 10:10:38.812: INFO: Running AfterSuite actions on all nodes
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Dec 14 10:10:38.812: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec 14 10:10:38.812: INFO: Running AfterSuite actions on node 1
    Dec 14 10:10:38.812: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.085 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 6374.943 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--ginkgo.dryRun is deprecated, use --ginkgo.dry-run instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m
  [38;5;11m--ginkgo.flakeAttempts is deprecated, use --ginkgo.flake-attempts instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m


Ginkgo ran 1 suite in 1h46m15.234085591s
Test Suite Passed
