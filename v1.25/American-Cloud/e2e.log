I0422 18:52:51.131169      20 e2e.go:116] Starting e2e run "7305ce57-647e-4d5d-807f-a37572b6ebbc" on Ginkgo node 1
Apr 22 18:52:51.153: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1682189570 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Apr 22 18:52:51.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 18:52:51.268: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 22 18:52:51.308: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 22 18:52:51.398: INFO: 19 / 19 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 22 18:52:51.398: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 22 18:52:51.399: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 22 18:52:51.412: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 22 18:52:51.412: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Apr 22 18:52:51.412: INFO: e2e test version: v1.25.0
Apr 22 18:52:51.414: INFO: kube-apiserver version: v1.25.0
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Apr 22 18:52:51.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 18:52:51.425: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.159 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 22 18:52:51.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 18:52:51.268: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 22 18:52:51.308: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 22 18:52:51.398: INFO: 19 / 19 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 22 18:52:51.398: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
    Apr 22 18:52:51.399: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 22 18:52:51.412: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Apr 22 18:52:51.412: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
    Apr 22 18:52:51.412: INFO: e2e test version: v1.25.0
    Apr 22 18:52:51.414: INFO: kube-apiserver version: v1.25.0
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 22 18:52:51.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 18:52:51.425: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:52:51.447
Apr 22 18:52:51.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 18:52:51.448
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:52:51.52
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:52:51.525
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Apr 22 18:52:51.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 18:52:55.096
Apr 22 18:52:55.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 create -f -'
Apr 22 18:52:56.010: INFO: stderr: ""
Apr 22 18:52:56.010: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 22 18:52:56.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 delete e2e-test-crd-publish-openapi-9764-crds test-cr'
Apr 22 18:52:56.155: INFO: stderr: ""
Apr 22 18:52:56.155: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 22 18:52:56.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 apply -f -'
Apr 22 18:52:56.424: INFO: stderr: ""
Apr 22 18:52:56.424: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 22 18:52:56.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 delete e2e-test-crd-publish-openapi-9764-crds test-cr'
Apr 22 18:52:56.593: INFO: stderr: ""
Apr 22 18:52:56.593: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/22/23 18:52:56.593
Apr 22 18:52:56.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 explain e2e-test-crd-publish-openapi-9764-crds'
Apr 22 18:52:56.906: INFO: stderr: ""
Apr 22 18:52:56.906: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9764-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 18:53:00.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9069" for this suite. 04/22/23 18:53:00.188
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":1,"skipped":6,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.748 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:52:51.447
    Apr 22 18:52:51.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 18:52:51.448
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:52:51.52
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:52:51.525
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Apr 22 18:52:51.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 18:52:55.096
    Apr 22 18:52:55.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 create -f -'
    Apr 22 18:52:56.010: INFO: stderr: ""
    Apr 22 18:52:56.010: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 22 18:52:56.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 delete e2e-test-crd-publish-openapi-9764-crds test-cr'
    Apr 22 18:52:56.155: INFO: stderr: ""
    Apr 22 18:52:56.155: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 22 18:52:56.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 apply -f -'
    Apr 22 18:52:56.424: INFO: stderr: ""
    Apr 22 18:52:56.424: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 22 18:52:56.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 --namespace=crd-publish-openapi-9069 delete e2e-test-crd-publish-openapi-9764-crds test-cr'
    Apr 22 18:52:56.593: INFO: stderr: ""
    Apr 22 18:52:56.593: INFO: stdout: "e2e-test-crd-publish-openapi-9764-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/22/23 18:52:56.593
    Apr 22 18:52:56.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-9069 explain e2e-test-crd-publish-openapi-9764-crds'
    Apr 22 18:52:56.906: INFO: stderr: ""
    Apr 22 18:52:56.906: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9764-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 18:53:00.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9069" for this suite. 04/22/23 18:53:00.188
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:00.22
Apr 22 18:53:00.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption 04/22/23 18:53:00.223
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:00.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:00.255
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:00.261
Apr 22 18:53:00.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption-2 04/22/23 18:53:00.263
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:00.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:00.316
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 04/22/23 18:53:00.337
STEP: Waiting for the pdb to be processed 04/22/23 18:53:02.371
STEP: Waiting for the pdb to be processed 04/22/23 18:53:04.41
STEP: listing a collection of PDBs across all namespaces 04/22/23 18:53:06.426
STEP: listing a collection of PDBs in namespace disruption-4396 04/22/23 18:53:06.434
STEP: deleting a collection of PDBs 04/22/23 18:53:06.444
STEP: Waiting for the PDB collection to be deleted 04/22/23 18:53:06.485
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Apr 22 18:53:06.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-602" for this suite. 04/22/23 18:53:06.521
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 22 18:53:06.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4396" for this suite. 04/22/23 18:53:06.544
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":2,"skipped":17,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.341 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:00.22
    Apr 22 18:53:00.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption 04/22/23 18:53:00.223
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:00.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:00.255
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:00.261
    Apr 22 18:53:00.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption-2 04/22/23 18:53:00.263
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:00.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:00.316
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 04/22/23 18:53:00.337
    STEP: Waiting for the pdb to be processed 04/22/23 18:53:02.371
    STEP: Waiting for the pdb to be processed 04/22/23 18:53:04.41
    STEP: listing a collection of PDBs across all namespaces 04/22/23 18:53:06.426
    STEP: listing a collection of PDBs in namespace disruption-4396 04/22/23 18:53:06.434
    STEP: deleting a collection of PDBs 04/22/23 18:53:06.444
    STEP: Waiting for the PDB collection to be deleted 04/22/23 18:53:06.485
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Apr 22 18:53:06.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-602" for this suite. 04/22/23 18:53:06.521
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 22 18:53:06.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4396" for this suite. 04/22/23 18:53:06.544
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:06.593
Apr 22 18:53:06.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 18:53:06.595
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:06.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:06.658
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-7150 04/22/23 18:53:06.669
STEP: creating service affinity-nodeport in namespace services-7150 04/22/23 18:53:06.67
STEP: creating replication controller affinity-nodeport in namespace services-7150 04/22/23 18:53:06.732
I0422 18:53:06.748802      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-7150, replica count: 3
I0422 18:53:09.803072      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0422 18:53:12.803523      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 18:53:12.832: INFO: Creating new exec pod
Apr 22 18:53:12.854: INFO: Waiting up to 5m0s for pod "execpod-affinitytzht2" in namespace "services-7150" to be "running"
Apr 22 18:53:12.866: INFO: Pod "execpod-affinitytzht2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.761183ms
Apr 22 18:53:14.878: INFO: Pod "execpod-affinitytzht2": Phase="Running", Reason="", readiness=true. Elapsed: 2.023587826s
Apr 22 18:53:14.878: INFO: Pod "execpod-affinitytzht2" satisfied condition "running"
Apr 22 18:53:15.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 22 18:53:16.231: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 22 18:53:16.231: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 18:53:16.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.46.234 80'
Apr 22 18:53:16.427: INFO: stderr: "+ nc -v -t -w 2 10.110.46.234 80\n+ echo hostName\nConnection to 10.110.46.234 80 port [tcp/http] succeeded!\n"
Apr 22 18:53:16.427: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 18:53:16.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 30327'
Apr 22 18:53:16.665: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 30327\n+ echo hostName\nConnection to 10.1.1.165 30327 port [tcp/*] succeeded!\n"
Apr 22 18:53:16.665: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 18:53:16.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 30327'
Apr 22 18:53:16.925: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 30327\n+ echo hostName\nConnection to 10.1.1.128 30327 port [tcp/*] succeeded!\n"
Apr 22 18:53:16.925: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 18:53:16.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:30327/ ; done'
Apr 22 18:53:17.273: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n"
Apr 22 18:53:17.273: INFO: stdout: "\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q"
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
Apr 22 18:53:17.273: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-7150, will wait for the garbage collector to delete the pods 04/22/23 18:53:17.305
Apr 22 18:53:17.380: INFO: Deleting ReplicationController affinity-nodeport took: 11.89452ms
Apr 22 18:53:17.481: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.186353ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 18:53:20.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7150" for this suite. 04/22/23 18:53:20.44
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":3,"skipped":46,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.861 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:06.593
    Apr 22 18:53:06.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 18:53:06.595
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:06.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:06.658
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-7150 04/22/23 18:53:06.669
    STEP: creating service affinity-nodeport in namespace services-7150 04/22/23 18:53:06.67
    STEP: creating replication controller affinity-nodeport in namespace services-7150 04/22/23 18:53:06.732
    I0422 18:53:06.748802      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-7150, replica count: 3
    I0422 18:53:09.803072      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0422 18:53:12.803523      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 18:53:12.832: INFO: Creating new exec pod
    Apr 22 18:53:12.854: INFO: Waiting up to 5m0s for pod "execpod-affinitytzht2" in namespace "services-7150" to be "running"
    Apr 22 18:53:12.866: INFO: Pod "execpod-affinitytzht2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.761183ms
    Apr 22 18:53:14.878: INFO: Pod "execpod-affinitytzht2": Phase="Running", Reason="", readiness=true. Elapsed: 2.023587826s
    Apr 22 18:53:14.878: INFO: Pod "execpod-affinitytzht2" satisfied condition "running"
    Apr 22 18:53:15.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Apr 22 18:53:16.231: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 22 18:53:16.231: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 18:53:16.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.46.234 80'
    Apr 22 18:53:16.427: INFO: stderr: "+ nc -v -t -w 2 10.110.46.234 80\n+ echo hostName\nConnection to 10.110.46.234 80 port [tcp/http] succeeded!\n"
    Apr 22 18:53:16.427: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 18:53:16.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 30327'
    Apr 22 18:53:16.665: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 30327\n+ echo hostName\nConnection to 10.1.1.165 30327 port [tcp/*] succeeded!\n"
    Apr 22 18:53:16.665: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 18:53:16.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 30327'
    Apr 22 18:53:16.925: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 30327\n+ echo hostName\nConnection to 10.1.1.128 30327 port [tcp/*] succeeded!\n"
    Apr 22 18:53:16.925: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 18:53:16.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7150 exec execpod-affinitytzht2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:30327/ ; done'
    Apr 22 18:53:17.273: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30327/\n"
    Apr 22 18:53:17.273: INFO: stdout: "\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q\naffinity-nodeport-k7c4q"
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Received response from host: affinity-nodeport-k7c4q
    Apr 22 18:53:17.273: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-7150, will wait for the garbage collector to delete the pods 04/22/23 18:53:17.305
    Apr 22 18:53:17.380: INFO: Deleting ReplicationController affinity-nodeport took: 11.89452ms
    Apr 22 18:53:17.481: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.186353ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 18:53:20.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7150" for this suite. 04/22/23 18:53:20.44
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:20.462
Apr 22 18:53:20.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 18:53:20.465
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:20.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:20.516
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 04/22/23 18:53:20.55
Apr 22 18:53:20.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789" in namespace "downward-api-8897" to be "Succeeded or Failed"
Apr 22 18:53:20.576: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Pending", Reason="", readiness=false. Elapsed: 8.380284ms
Apr 22 18:53:22.588: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020512018s
Apr 22 18:53:24.590: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022033896s
STEP: Saw pod success 04/22/23 18:53:24.59
Apr 22 18:53:24.590: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789" satisfied condition "Succeeded or Failed"
Apr 22 18:53:24.599: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 container client-container: <nil>
STEP: delete the pod 04/22/23 18:53:24.67
Apr 22 18:53:24.699: INFO: Waiting for pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 to disappear
Apr 22 18:53:24.709: INFO: Pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 18:53:24.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8897" for this suite. 04/22/23 18:53:24.722
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":4,"skipped":56,"failed":0}
------------------------------
â€¢ [4.279 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:20.462
    Apr 22 18:53:20.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 18:53:20.465
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:20.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:20.516
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 04/22/23 18:53:20.55
    Apr 22 18:53:20.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789" in namespace "downward-api-8897" to be "Succeeded or Failed"
    Apr 22 18:53:20.576: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Pending", Reason="", readiness=false. Elapsed: 8.380284ms
    Apr 22 18:53:22.588: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020512018s
    Apr 22 18:53:24.590: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022033896s
    STEP: Saw pod success 04/22/23 18:53:24.59
    Apr 22 18:53:24.590: INFO: Pod "downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789" satisfied condition "Succeeded or Failed"
    Apr 22 18:53:24.599: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 container client-container: <nil>
    STEP: delete the pod 04/22/23 18:53:24.67
    Apr 22 18:53:24.699: INFO: Waiting for pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 to disappear
    Apr 22 18:53:24.709: INFO: Pod downwardapi-volume-42256459-9451-48e6-aed1-48fbce36e789 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 18:53:24.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8897" for this suite. 04/22/23 18:53:24.722
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:24.752
Apr 22 18:53:24.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replication-controller 04/22/23 18:53:24.753
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:24.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:24.812
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Apr 22 18:53:24.820: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/22/23 18:53:25.844
STEP: Checking rc "condition-test" has the desired failure condition set 04/22/23 18:53:25.851
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/22/23 18:53:26.868
Apr 22 18:53:26.894: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/22/23 18:53:26.894
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 22 18:53:26.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1746" for this suite. 04/22/23 18:53:26.92
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":5,"skipped":75,"failed":0}
------------------------------
â€¢ [2.187 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:24.752
    Apr 22 18:53:24.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replication-controller 04/22/23 18:53:24.753
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:24.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:24.812
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Apr 22 18:53:24.820: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/22/23 18:53:25.844
    STEP: Checking rc "condition-test" has the desired failure condition set 04/22/23 18:53:25.851
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/22/23 18:53:26.868
    Apr 22 18:53:26.894: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/22/23 18:53:26.894
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 22 18:53:26.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1746" for this suite. 04/22/23 18:53:26.92
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:26.944
Apr 22 18:53:26.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-runtime 04/22/23 18:53:26.946
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:26.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:26.999
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/22/23 18:53:27.017
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/22/23 18:53:50.251
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/22/23 18:53:50.263
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/22/23 18:53:50.281
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/22/23 18:53:50.282
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/22/23 18:53:50.367
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/22/23 18:53:53.413
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/22/23 18:53:55.441
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/22/23 18:53:55.458
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/22/23 18:53:55.459
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/22/23 18:53:55.513
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/22/23 18:53:56.532
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/22/23 18:53:58.559
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/22/23 18:53:58.576
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/22/23 18:53:58.576
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 22 18:53:58.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9987" for this suite. 04/22/23 18:53:58.661
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":6,"skipped":82,"failed":0}
------------------------------
â€¢ [SLOW TEST] [31.736 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:26.944
    Apr 22 18:53:26.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-runtime 04/22/23 18:53:26.946
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:26.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:26.999
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/22/23 18:53:27.017
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/22/23 18:53:50.251
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/22/23 18:53:50.263
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/22/23 18:53:50.281
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/22/23 18:53:50.282
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/22/23 18:53:50.367
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/22/23 18:53:53.413
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/22/23 18:53:55.441
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/22/23 18:53:55.458
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/22/23 18:53:55.459
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/22/23 18:53:55.513
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/22/23 18:53:56.532
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/22/23 18:53:58.559
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/22/23 18:53:58.576
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/22/23 18:53:58.576
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 22 18:53:58.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9987" for this suite. 04/22/23 18:53:58.661
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:53:58.704
Apr 22 18:53:58.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 18:53:58.708
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:58.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:58.763
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be in namespace container-probe-9579 04/22/23 18:53:58.767
Apr 22 18:53:58.790: INFO: Waiting up to 5m0s for pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be" in namespace "container-probe-9579" to be "not pending"
Apr 22 18:53:58.799: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be": Phase="Pending", Reason="", readiness=false. Elapsed: 8.003797ms
Apr 22 18:54:00.808: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be": Phase="Running", Reason="", readiness=true. Elapsed: 2.017619336s
Apr 22 18:54:00.808: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be" satisfied condition "not pending"
Apr 22 18:54:00.808: INFO: Started pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be in namespace container-probe-9579
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 18:54:00.808
Apr 22 18:54:00.822: INFO: Initial restart count of pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is 0
Apr 22 18:54:20.937: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 1 (20.115153454s elapsed)
Apr 22 18:54:41.045: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 2 (40.223658854s elapsed)
Apr 22 18:55:01.151: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 3 (1m0.329039608s elapsed)
Apr 22 18:55:21.253: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 4 (1m20.431070968s elapsed)
Apr 22 18:56:25.594: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 5 (2m24.772394661s elapsed)
STEP: deleting the pod 04/22/23 18:56:25.594
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 18:56:25.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9579" for this suite. 04/22/23 18:56:25.648
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":7,"skipped":115,"failed":0}
------------------------------
â€¢ [SLOW TEST] [146.963 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:53:58.704
    Apr 22 18:53:58.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 18:53:58.708
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:53:58.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:53:58.763
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be in namespace container-probe-9579 04/22/23 18:53:58.767
    Apr 22 18:53:58.790: INFO: Waiting up to 5m0s for pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be" in namespace "container-probe-9579" to be "not pending"
    Apr 22 18:53:58.799: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be": Phase="Pending", Reason="", readiness=false. Elapsed: 8.003797ms
    Apr 22 18:54:00.808: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be": Phase="Running", Reason="", readiness=true. Elapsed: 2.017619336s
    Apr 22 18:54:00.808: INFO: Pod "liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be" satisfied condition "not pending"
    Apr 22 18:54:00.808: INFO: Started pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be in namespace container-probe-9579
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 18:54:00.808
    Apr 22 18:54:00.822: INFO: Initial restart count of pod liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is 0
    Apr 22 18:54:20.937: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 1 (20.115153454s elapsed)
    Apr 22 18:54:41.045: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 2 (40.223658854s elapsed)
    Apr 22 18:55:01.151: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 3 (1m0.329039608s elapsed)
    Apr 22 18:55:21.253: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 4 (1m20.431070968s elapsed)
    Apr 22 18:56:25.594: INFO: Restart count of pod container-probe-9579/liveness-99d99164-fd2a-4655-9a48-3e34d1bfa4be is now 5 (2m24.772394661s elapsed)
    STEP: deleting the pod 04/22/23 18:56:25.594
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 18:56:25.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9579" for this suite. 04/22/23 18:56:25.648
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:56:25.673
Apr 22 18:56:25.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename containers 04/22/23 18:56:25.677
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:25.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:25.75
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Apr 22 18:56:25.774: INFO: Waiting up to 5m0s for pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2" in namespace "containers-1118" to be "running"
Apr 22 18:56:25.786: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.4376ms
Apr 22 18:56:27.801: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026630359s
Apr 22 18:56:27.801: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 22 18:56:27.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1118" for this suite. 04/22/23 18:56:27.852
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":8,"skipped":138,"failed":0}
------------------------------
â€¢ [2.199 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:56:25.673
    Apr 22 18:56:25.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename containers 04/22/23 18:56:25.677
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:25.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:25.75
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Apr 22 18:56:25.774: INFO: Waiting up to 5m0s for pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2" in namespace "containers-1118" to be "running"
    Apr 22 18:56:25.786: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.4376ms
    Apr 22 18:56:27.801: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026630359s
    Apr 22 18:56:27.801: INFO: Pod "client-containers-5de029a1-7442-410c-8e1d-61cdfa902ed2" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 22 18:56:27.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1118" for this suite. 04/22/23 18:56:27.852
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:56:27.906
Apr 22 18:56:27.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 18:56:27.91
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:27.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:27.99
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 04/22/23 18:56:28.055
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 18:56:28.069
Apr 22 18:56:28.080: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 18:56:28.081: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 18:56:28.089: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 18:56:28.089: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 18:56:29.119: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 18:56:29.120: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 18:56:29.128: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 18:56:29.128: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status 04/22/23 18:56:29.138
Apr 22 18:56:29.158: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/22/23 18:56:29.158
Apr 22 18:56:29.217: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/22/23 18:56:29.217
Apr 22 18:56:29.224: INFO: Observed &DaemonSet event: ADDED
Apr 22 18:56:29.225: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.225: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.226: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.226: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.226: INFO: Found daemon set daemon-set in namespace daemonsets-7003 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 22 18:56:29.226: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/22/23 18:56:29.226
STEP: watching for the daemon set status to be patched 04/22/23 18:56:29.241
Apr 22 18:56:29.247: INFO: Observed &DaemonSet event: ADDED
Apr 22 18:56:29.248: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.248: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.249: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.250: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.250: INFO: Observed daemon set daemon-set in namespace daemonsets-7003 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 22 18:56:29.251: INFO: Observed &DaemonSet event: MODIFIED
Apr 22 18:56:29.252: INFO: Found daemon set daemon-set in namespace daemonsets-7003 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 22 18:56:29.252: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 18:56:29.262
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7003, will wait for the garbage collector to delete the pods 04/22/23 18:56:29.263
Apr 22 18:56:29.339: INFO: Deleting DaemonSet.extensions daemon-set took: 16.9118ms
Apr 22 18:56:29.439: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.301099ms
Apr 22 18:56:32.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 18:56:32.248: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 18:56:32.255: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2100"},"items":null}

Apr 22 18:56:32.263: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2100"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 18:56:32.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7003" for this suite. 04/22/23 18:56:32.303
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":9,"skipped":196,"failed":0}
------------------------------
â€¢ [4.415 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:56:27.906
    Apr 22 18:56:27.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 18:56:27.91
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:27.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:27.99
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 04/22/23 18:56:28.055
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 18:56:28.069
    Apr 22 18:56:28.080: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 18:56:28.081: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 18:56:28.089: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 18:56:28.089: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 18:56:29.119: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 18:56:29.120: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 18:56:29.128: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 18:56:29.128: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Getting /status 04/22/23 18:56:29.138
    Apr 22 18:56:29.158: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/22/23 18:56:29.158
    Apr 22 18:56:29.217: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/22/23 18:56:29.217
    Apr 22 18:56:29.224: INFO: Observed &DaemonSet event: ADDED
    Apr 22 18:56:29.225: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.225: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.226: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.226: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.226: INFO: Found daemon set daemon-set in namespace daemonsets-7003 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 22 18:56:29.226: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/22/23 18:56:29.226
    STEP: watching for the daemon set status to be patched 04/22/23 18:56:29.241
    Apr 22 18:56:29.247: INFO: Observed &DaemonSet event: ADDED
    Apr 22 18:56:29.248: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.248: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.249: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.250: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.250: INFO: Observed daemon set daemon-set in namespace daemonsets-7003 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 22 18:56:29.251: INFO: Observed &DaemonSet event: MODIFIED
    Apr 22 18:56:29.252: INFO: Found daemon set daemon-set in namespace daemonsets-7003 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 22 18:56:29.252: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 18:56:29.262
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7003, will wait for the garbage collector to delete the pods 04/22/23 18:56:29.263
    Apr 22 18:56:29.339: INFO: Deleting DaemonSet.extensions daemon-set took: 16.9118ms
    Apr 22 18:56:29.439: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.301099ms
    Apr 22 18:56:32.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 18:56:32.248: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 18:56:32.255: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2100"},"items":null}

    Apr 22 18:56:32.263: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2100"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 18:56:32.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7003" for this suite. 04/22/23 18:56:32.303
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:56:32.327
Apr 22 18:56:32.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 18:56:32.33
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:32.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:32.387
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 04/22/23 18:56:32.396
Apr 22 18:56:32.415: INFO: created test-pod-1
Apr 22 18:56:32.433: INFO: created test-pod-2
Apr 22 18:56:32.459: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/22/23 18:56:32.459
Apr 22 18:56:32.460: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6998' to be running and ready
Apr 22 18:56:32.493: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 22 18:56:32.493: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 22 18:56:32.494: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 22 18:56:32.494: INFO: 0 / 3 pods in namespace 'pods-6998' are running and ready (0 seconds elapsed)
Apr 22 18:56:32.494: INFO: expected 0 pod replicas in namespace 'pods-6998', 0 are Running and Ready.
Apr 22 18:56:32.494: INFO: POD         NODE                       PHASE    GRACE  CONDITIONS
Apr 22 18:56:32.494: INFO: test-pod-1  cncf25-2-node-187aa4c0d96  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
Apr 22 18:56:32.494: INFO: test-pod-2  cncf25-2-node-187aa4bdec5  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
Apr 22 18:56:32.494: INFO: test-pod-3  cncf25-2-node-187aa4bdec5  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
Apr 22 18:56:32.494: INFO: 
Apr 22 18:56:34.518: INFO: 3 / 3 pods in namespace 'pods-6998' are running and ready (2 seconds elapsed)
Apr 22 18:56:34.518: INFO: expected 0 pod replicas in namespace 'pods-6998', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/22/23 18:56:34.548
Apr 22 18:56:34.554: INFO: Pod quantity 3 is different from expected quantity 0
Apr 22 18:56:35.567: INFO: Pod quantity 3 is different from expected quantity 0
Apr 22 18:56:36.563: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 18:56:37.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6998" for this suite. 04/22/23 18:56:37.569
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":10,"skipped":208,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.253 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:56:32.327
    Apr 22 18:56:32.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 18:56:32.33
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:32.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:32.387
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 04/22/23 18:56:32.396
    Apr 22 18:56:32.415: INFO: created test-pod-1
    Apr 22 18:56:32.433: INFO: created test-pod-2
    Apr 22 18:56:32.459: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/22/23 18:56:32.459
    Apr 22 18:56:32.460: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6998' to be running and ready
    Apr 22 18:56:32.493: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 22 18:56:32.493: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 22 18:56:32.494: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 22 18:56:32.494: INFO: 0 / 3 pods in namespace 'pods-6998' are running and ready (0 seconds elapsed)
    Apr 22 18:56:32.494: INFO: expected 0 pod replicas in namespace 'pods-6998', 0 are Running and Ready.
    Apr 22 18:56:32.494: INFO: POD         NODE                       PHASE    GRACE  CONDITIONS
    Apr 22 18:56:32.494: INFO: test-pod-1  cncf25-2-node-187aa4c0d96  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
    Apr 22 18:56:32.494: INFO: test-pod-2  cncf25-2-node-187aa4bdec5  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
    Apr 22 18:56:32.494: INFO: test-pod-3  cncf25-2-node-187aa4bdec5  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 18:56:32 +0000 UTC  }]
    Apr 22 18:56:32.494: INFO: 
    Apr 22 18:56:34.518: INFO: 3 / 3 pods in namespace 'pods-6998' are running and ready (2 seconds elapsed)
    Apr 22 18:56:34.518: INFO: expected 0 pod replicas in namespace 'pods-6998', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/22/23 18:56:34.548
    Apr 22 18:56:34.554: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 22 18:56:35.567: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 22 18:56:36.563: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 18:56:37.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6998" for this suite. 04/22/23 18:56:37.569
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:56:37.609
Apr 22 18:56:37.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename endpointslice 04/22/23 18:56:37.611
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:37.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:37.647
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 22 18:56:39.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4811" for this suite. 04/22/23 18:56:39.792
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":11,"skipped":277,"failed":0}
------------------------------
â€¢ [2.196 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:56:37.609
    Apr 22 18:56:37.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename endpointslice 04/22/23 18:56:37.611
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:37.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:37.647
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 22 18:56:39.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4811" for this suite. 04/22/23 18:56:39.792
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:56:39.83
Apr 22 18:56:39.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 18:56:39.831
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:39.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:39.87
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 18:57:39.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7314" for this suite. 04/22/23 18:57:39.911
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":12,"skipped":308,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.100 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:56:39.83
    Apr 22 18:56:39.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 18:56:39.831
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:56:39.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:56:39.87
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 18:57:39.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7314" for this suite. 04/22/23 18:57:39.911
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:57:39.933
Apr 22 18:57:39.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 18:57:39.936
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:40.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:40.01
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 22 18:57:40.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 18:57:43.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2379" for this suite. 04/22/23 18:57:43.329
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":13,"skipped":325,"failed":0}
------------------------------
â€¢ [3.413 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:57:39.933
    Apr 22 18:57:39.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 18:57:39.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:40.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:40.01
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 22 18:57:40.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 18:57:43.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2379" for this suite. 04/22/23 18:57:43.329
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:57:43.353
Apr 22 18:57:43.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 18:57:43.356
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:43.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:43.432
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-8390/configmap-test-395567f0-1895-460e-8f26-25d686c6967f 04/22/23 18:57:43.438
STEP: Creating a pod to test consume configMaps 04/22/23 18:57:43.447
Apr 22 18:57:43.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede" in namespace "configmap-8390" to be "Succeeded or Failed"
Apr 22 18:57:43.472: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Pending", Reason="", readiness=false. Elapsed: 5.57984ms
Apr 22 18:57:45.482: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014889888s
Apr 22 18:57:47.483: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015686599s
STEP: Saw pod success 04/22/23 18:57:47.483
Apr 22 18:57:47.484: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede" satisfied condition "Succeeded or Failed"
Apr 22 18:57:47.493: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede container env-test: <nil>
STEP: delete the pod 04/22/23 18:57:47.514
Apr 22 18:57:47.545: INFO: Waiting for pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede to disappear
Apr 22 18:57:47.557: INFO: Pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 18:57:47.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8390" for this suite. 04/22/23 18:57:47.573
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":14,"skipped":334,"failed":0}
------------------------------
â€¢ [4.241 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:57:43.353
    Apr 22 18:57:43.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 18:57:43.356
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:43.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:43.432
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-8390/configmap-test-395567f0-1895-460e-8f26-25d686c6967f 04/22/23 18:57:43.438
    STEP: Creating a pod to test consume configMaps 04/22/23 18:57:43.447
    Apr 22 18:57:43.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede" in namespace "configmap-8390" to be "Succeeded or Failed"
    Apr 22 18:57:43.472: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Pending", Reason="", readiness=false. Elapsed: 5.57984ms
    Apr 22 18:57:45.482: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014889888s
    Apr 22 18:57:47.483: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015686599s
    STEP: Saw pod success 04/22/23 18:57:47.483
    Apr 22 18:57:47.484: INFO: Pod "pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede" satisfied condition "Succeeded or Failed"
    Apr 22 18:57:47.493: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede container env-test: <nil>
    STEP: delete the pod 04/22/23 18:57:47.514
    Apr 22 18:57:47.545: INFO: Waiting for pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede to disappear
    Apr 22 18:57:47.557: INFO: Pod pod-configmaps-9ff515c1-81f3-464c-90fb-85038af10ede no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 18:57:47.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8390" for this suite. 04/22/23 18:57:47.573
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:57:47.615
Apr 22 18:57:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 18:57:47.618
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:47.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:47.68
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3954 04/22/23 18:57:47.691
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/22/23 18:57:47.726
STEP: creating service externalsvc in namespace services-3954 04/22/23 18:57:47.727
STEP: creating replication controller externalsvc in namespace services-3954 04/22/23 18:57:47.786
I0422 18:57:47.802330      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3954, replica count: 2
I0422 18:57:50.854539      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/22/23 18:57:50.866
Apr 22 18:57:50.913: INFO: Creating new exec pod
Apr 22 18:57:50.942: INFO: Waiting up to 5m0s for pod "execpodrbcg5" in namespace "services-3954" to be "running"
Apr 22 18:57:50.953: INFO: Pod "execpodrbcg5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.645833ms
Apr 22 18:57:52.959: INFO: Pod "execpodrbcg5": Phase="Running", Reason="", readiness=true. Elapsed: 2.015595031s
Apr 22 18:57:52.959: INFO: Pod "execpodrbcg5" satisfied condition "running"
Apr 22 18:57:52.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3954 exec execpodrbcg5 -- /bin/sh -x -c nslookup clusterip-service.services-3954.svc.cluster.local'
Apr 22 18:57:53.309: INFO: stderr: "+ nslookup clusterip-service.services-3954.svc.cluster.local\n"
Apr 22 18:57:53.309: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3954.svc.cluster.local\tcanonical name = externalsvc.services-3954.svc.cluster.local.\nName:\texternalsvc.services-3954.svc.cluster.local\nAddress: 10.111.238.129\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3954, will wait for the garbage collector to delete the pods 04/22/23 18:57:53.309
Apr 22 18:57:53.391: INFO: Deleting ReplicationController externalsvc took: 18.80206ms
Apr 22 18:57:53.492: INFO: Terminating ReplicationController externalsvc pods took: 101.147043ms
Apr 22 18:57:55.621: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 18:57:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3954" for this suite. 04/22/23 18:57:55.648
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":15,"skipped":353,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.042 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:57:47.615
    Apr 22 18:57:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 18:57:47.618
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:47.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:47.68
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3954 04/22/23 18:57:47.691
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/22/23 18:57:47.726
    STEP: creating service externalsvc in namespace services-3954 04/22/23 18:57:47.727
    STEP: creating replication controller externalsvc in namespace services-3954 04/22/23 18:57:47.786
    I0422 18:57:47.802330      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3954, replica count: 2
    I0422 18:57:50.854539      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/22/23 18:57:50.866
    Apr 22 18:57:50.913: INFO: Creating new exec pod
    Apr 22 18:57:50.942: INFO: Waiting up to 5m0s for pod "execpodrbcg5" in namespace "services-3954" to be "running"
    Apr 22 18:57:50.953: INFO: Pod "execpodrbcg5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.645833ms
    Apr 22 18:57:52.959: INFO: Pod "execpodrbcg5": Phase="Running", Reason="", readiness=true. Elapsed: 2.015595031s
    Apr 22 18:57:52.959: INFO: Pod "execpodrbcg5" satisfied condition "running"
    Apr 22 18:57:52.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3954 exec execpodrbcg5 -- /bin/sh -x -c nslookup clusterip-service.services-3954.svc.cluster.local'
    Apr 22 18:57:53.309: INFO: stderr: "+ nslookup clusterip-service.services-3954.svc.cluster.local\n"
    Apr 22 18:57:53.309: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3954.svc.cluster.local\tcanonical name = externalsvc.services-3954.svc.cluster.local.\nName:\texternalsvc.services-3954.svc.cluster.local\nAddress: 10.111.238.129\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-3954, will wait for the garbage collector to delete the pods 04/22/23 18:57:53.309
    Apr 22 18:57:53.391: INFO: Deleting ReplicationController externalsvc took: 18.80206ms
    Apr 22 18:57:53.492: INFO: Terminating ReplicationController externalsvc pods took: 101.147043ms
    Apr 22 18:57:55.621: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 18:57:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3954" for this suite. 04/22/23 18:57:55.648
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 18:57:55.683
Apr 22 18:57:55.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 18:57:55.686
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:55.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:55.721
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 04/22/23 18:57:55.726
Apr 22 18:57:55.738: INFO: Waiting up to 2m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765" to be "running"
Apr 22 18:57:55.742: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769388ms
Apr 22 18:57:57.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013953131s
Apr 22 18:57:59.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013525446s
Apr 22 18:58:01.748: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010246468s
Apr 22 18:58:03.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012852721s
Apr 22 18:58:05.756: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017970572s
Apr 22 18:58:07.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.017583263s
Apr 22 18:58:09.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015000881s
Apr 22 18:58:11.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.014732889s
Apr 22 18:58:13.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0138389s
Apr 22 18:58:15.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.017178617s
Apr 22 18:58:17.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015166668s
Apr 22 18:58:19.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013409993s
Apr 22 18:58:21.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.017328454s
Apr 22 18:58:23.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014379766s
Apr 22 18:58:25.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015667096s
Apr 22 18:58:27.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.014183278s
Apr 22 18:58:29.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.016823846s
Apr 22 18:58:31.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01475345s
Apr 22 18:58:33.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.014750967s
Apr 22 18:58:35.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013192615s
Apr 22 18:58:37.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013370113s
Apr 22 18:58:39.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015194283s
Apr 22 18:58:41.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014252752s
Apr 22 18:58:43.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 48.016189873s
Apr 22 18:58:45.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013399684s
Apr 22 18:58:47.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 52.013014035s
Apr 22 18:58:49.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 54.014089656s
Apr 22 18:58:51.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013472906s
Apr 22 18:58:53.750: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 58.012609121s
Apr 22 18:58:55.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015043219s
Apr 22 18:58:57.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013012344s
Apr 22 18:58:59.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.015756391s
Apr 22 18:59:01.748: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010340687s
Apr 22 18:59:03.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017025996s
Apr 22 18:59:05.750: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.012562428s
Apr 22 18:59:07.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.016392818s
Apr 22 18:59:09.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014596172s
Apr 22 18:59:11.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014103931s
Apr 22 18:59:13.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015014552s
Apr 22 18:59:15.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013891479s
Apr 22 18:59:17.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.01480985s
Apr 22 18:59:19.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.013526385s
Apr 22 18:59:21.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012853869s
Apr 22 18:59:23.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.012883181s
Apr 22 18:59:25.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013356089s
Apr 22 18:59:27.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013155932s
Apr 22 18:59:29.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014700556s
Apr 22 18:59:31.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013954422s
Apr 22 18:59:33.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015007222s
Apr 22 18:59:35.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013121153s
Apr 22 18:59:37.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.01656926s
Apr 22 18:59:39.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013964897s
Apr 22 18:59:41.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.016523639s
Apr 22 18:59:43.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014081218s
Apr 22 18:59:45.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013757335s
Apr 22 18:59:47.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014034178s
Apr 22 18:59:49.756: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017810305s
Apr 22 18:59:51.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013427303s
Apr 22 18:59:53.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014993265s
Apr 22 18:59:55.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013503272s
Apr 22 18:59:55.760: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.021924106s
STEP: updating the pod 04/22/23 18:59:55.76
Apr 22 18:59:56.288: INFO: Successfully updated pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f"
STEP: waiting for pod running 04/22/23 18:59:56.289
Apr 22 18:59:56.290: INFO: Waiting up to 2m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765" to be "running"
Apr 22 18:59:56.302: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.297811ms
Apr 22 18:59:58.315: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Running", Reason="", readiness=true. Elapsed: 2.025199692s
Apr 22 18:59:58.315: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" satisfied condition "running"
STEP: deleting the pod gracefully 04/22/23 18:59:58.315
Apr 22 18:59:58.315: INFO: Deleting pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765"
Apr 22 18:59:58.331: INFO: Wait up to 5m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 19:00:30.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7765" for this suite. 04/22/23 19:00:30.373
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":16,"skipped":384,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.707 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 18:57:55.683
    Apr 22 18:57:55.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 18:57:55.686
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 18:57:55.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 18:57:55.721
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 04/22/23 18:57:55.726
    Apr 22 18:57:55.738: INFO: Waiting up to 2m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765" to be "running"
    Apr 22 18:57:55.742: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769388ms
    Apr 22 18:57:57.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013953131s
    Apr 22 18:57:59.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013525446s
    Apr 22 18:58:01.748: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010246468s
    Apr 22 18:58:03.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012852721s
    Apr 22 18:58:05.756: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017970572s
    Apr 22 18:58:07.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.017583263s
    Apr 22 18:58:09.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015000881s
    Apr 22 18:58:11.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.014732889s
    Apr 22 18:58:13.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0138389s
    Apr 22 18:58:15.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.017178617s
    Apr 22 18:58:17.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015166668s
    Apr 22 18:58:19.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013409993s
    Apr 22 18:58:21.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.017328454s
    Apr 22 18:58:23.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014379766s
    Apr 22 18:58:25.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015667096s
    Apr 22 18:58:27.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.014183278s
    Apr 22 18:58:29.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.016823846s
    Apr 22 18:58:31.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01475345s
    Apr 22 18:58:33.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.014750967s
    Apr 22 18:58:35.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013192615s
    Apr 22 18:58:37.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013370113s
    Apr 22 18:58:39.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015194283s
    Apr 22 18:58:41.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014252752s
    Apr 22 18:58:43.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 48.016189873s
    Apr 22 18:58:45.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013399684s
    Apr 22 18:58:47.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 52.013014035s
    Apr 22 18:58:49.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 54.014089656s
    Apr 22 18:58:51.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013472906s
    Apr 22 18:58:53.750: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 58.012609121s
    Apr 22 18:58:55.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015043219s
    Apr 22 18:58:57.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013012344s
    Apr 22 18:58:59.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.015756391s
    Apr 22 18:59:01.748: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010340687s
    Apr 22 18:59:03.755: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017025996s
    Apr 22 18:59:05.750: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.012562428s
    Apr 22 18:59:07.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.016392818s
    Apr 22 18:59:09.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014596172s
    Apr 22 18:59:11.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014103931s
    Apr 22 18:59:13.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015014552s
    Apr 22 18:59:15.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013891479s
    Apr 22 18:59:17.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.01480985s
    Apr 22 18:59:19.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.013526385s
    Apr 22 18:59:21.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012853869s
    Apr 22 18:59:23.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.012883181s
    Apr 22 18:59:25.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013356089s
    Apr 22 18:59:27.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013155932s
    Apr 22 18:59:29.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014700556s
    Apr 22 18:59:31.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013954422s
    Apr 22 18:59:33.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015007222s
    Apr 22 18:59:35.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013121153s
    Apr 22 18:59:37.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.01656926s
    Apr 22 18:59:39.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013964897s
    Apr 22 18:59:41.754: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.016523639s
    Apr 22 18:59:43.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014081218s
    Apr 22 18:59:45.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013757335s
    Apr 22 18:59:47.752: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014034178s
    Apr 22 18:59:49.756: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017810305s
    Apr 22 18:59:51.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013427303s
    Apr 22 18:59:53.753: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014993265s
    Apr 22 18:59:55.751: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013503272s
    Apr 22 18:59:55.760: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.021924106s
    STEP: updating the pod 04/22/23 18:59:55.76
    Apr 22 18:59:56.288: INFO: Successfully updated pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f"
    STEP: waiting for pod running 04/22/23 18:59:56.289
    Apr 22 18:59:56.290: INFO: Waiting up to 2m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765" to be "running"
    Apr 22 18:59:56.302: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.297811ms
    Apr 22 18:59:58.315: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f": Phase="Running", Reason="", readiness=true. Elapsed: 2.025199692s
    Apr 22 18:59:58.315: INFO: Pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" satisfied condition "running"
    STEP: deleting the pod gracefully 04/22/23 18:59:58.315
    Apr 22 18:59:58.315: INFO: Deleting pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" in namespace "var-expansion-7765"
    Apr 22 18:59:58.331: INFO: Wait up to 5m0s for pod "var-expansion-a0a9a494-7cef-4989-a55f-50ef8287ca8f" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 19:00:30.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7765" for this suite. 04/22/23 19:00:30.373
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:30.407
Apr 22 19:00:30.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 19:00:30.41
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:30.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:30.472
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 04/22/23 19:00:30.483
STEP: Ensure pods equal to paralellism count is attached to the job 04/22/23 19:00:30.501
STEP: patching /status 04/22/23 19:00:32.516
STEP: updating /status 04/22/23 19:00:32.537
STEP: get /status 04/22/23 19:00:32.599
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 19:00:32.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8980" for this suite. 04/22/23 19:00:32.62
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":17,"skipped":401,"failed":0}
------------------------------
â€¢ [2.229 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:30.407
    Apr 22 19:00:30.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 19:00:30.41
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:30.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:30.472
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 04/22/23 19:00:30.483
    STEP: Ensure pods equal to paralellism count is attached to the job 04/22/23 19:00:30.501
    STEP: patching /status 04/22/23 19:00:32.516
    STEP: updating /status 04/22/23 19:00:32.537
    STEP: get /status 04/22/23 19:00:32.599
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 19:00:32.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8980" for this suite. 04/22/23 19:00:32.62
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:32.642
Apr 22 19:00:32.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 19:00:32.645
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:32.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:32.701
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 04/22/23 19:00:32.749
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:00:32.762
Apr 22 19:00:32.774: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:32.775: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:32.795: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:00:32.795: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:00:33.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:33.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:33.816: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:00:33.816: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:00:34.806: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:34.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:00:34.816: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:00:34.816: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets 04/22/23 19:00:34.823
STEP: DeleteCollection of the DaemonSets 04/22/23 19:00:34.834
STEP: Verify that ReplicaSets have been deleted 04/22/23 19:00:34.854
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Apr 22 19:00:34.881: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3112"},"items":null}

Apr 22 19:00:34.899: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3112"},"items":[{"metadata":{"name":"daemon-set-77n62","generateName":"daemon-set-","namespace":"daemonsets-3593","uid":"29d66634-905b-4118-a7cd-281c2cba70e4","resourceVersion":"3106","creationTimestamp":"2023-04-22T19:00:32Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:32Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t54lw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t54lw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf25-2-node-187aa4bdec5","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf25-2-node-187aa4bdec5"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"}],"hostIP":"10.1.1.165","podIP":"10.44.0.4","podIPs":[{"ip":"10.44.0.4"}],"startTime":"2023-04-22T19:00:32Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-22T19:00:33Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7fdef52c033d6d389c4f60b15b50a00fbbc1c4ccd9491fb55dc1abf94e56e1ab","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-jf8k5","generateName":"daemon-set-","namespace":"daemonsets-3593","uid":"5bee2dff-acab-4ef6-831e-e3be034977d7","resourceVersion":"3107","creationTimestamp":"2023-04-22T19:00:32Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:32Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ctvkb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ctvkb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf25-2-node-187aa4c0d96","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf25-2-node-187aa4c0d96"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"}],"hostIP":"10.1.1.128","podIP":"10.36.0.5","podIPs":[{"ip":"10.36.0.5"}],"startTime":"2023-04-22T19:00:32Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-22T19:00:33Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a38cf4bef23602722ad82016e9631186294cb5a0b9ed9fab3f8ee80034996744","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:00:34.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3593" for this suite. 04/22/23 19:00:34.936
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":18,"skipped":413,"failed":0}
------------------------------
â€¢ [2.306 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:32.642
    Apr 22 19:00:32.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 19:00:32.645
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:32.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:32.701
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 04/22/23 19:00:32.749
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:00:32.762
    Apr 22 19:00:32.774: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:32.775: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:32.795: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:00:32.795: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:00:33.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:33.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:33.816: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:00:33.816: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:00:34.806: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:34.807: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:00:34.816: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:00:34.816: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: listing all DeamonSets 04/22/23 19:00:34.823
    STEP: DeleteCollection of the DaemonSets 04/22/23 19:00:34.834
    STEP: Verify that ReplicaSets have been deleted 04/22/23 19:00:34.854
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Apr 22 19:00:34.881: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3112"},"items":null}

    Apr 22 19:00:34.899: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3112"},"items":[{"metadata":{"name":"daemon-set-77n62","generateName":"daemon-set-","namespace":"daemonsets-3593","uid":"29d66634-905b-4118-a7cd-281c2cba70e4","resourceVersion":"3106","creationTimestamp":"2023-04-22T19:00:32Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:32Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t54lw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t54lw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf25-2-node-187aa4bdec5","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf25-2-node-187aa4bdec5"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"}],"hostIP":"10.1.1.165","podIP":"10.44.0.4","podIPs":[{"ip":"10.44.0.4"}],"startTime":"2023-04-22T19:00:32Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-22T19:00:33Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7fdef52c033d6d389c4f60b15b50a00fbbc1c4ccd9491fb55dc1abf94e56e1ab","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-jf8k5","generateName":"daemon-set-","namespace":"daemonsets-3593","uid":"5bee2dff-acab-4ef6-831e-e3be034977d7","resourceVersion":"3107","creationTimestamp":"2023-04-22T19:00:32Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:32Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b0e0c32-7bfe-4b73-9312-c0ca57aa1168\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-22T19:00:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ctvkb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ctvkb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf25-2-node-187aa4c0d96","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf25-2-node-187aa4c0d96"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:33Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-22T19:00:32Z"}],"hostIP":"10.1.1.128","podIP":"10.36.0.5","podIPs":[{"ip":"10.36.0.5"}],"startTime":"2023-04-22T19:00:32Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-22T19:00:33Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a38cf4bef23602722ad82016e9631186294cb5a0b9ed9fab3f8ee80034996744","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:00:34.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3593" for this suite. 04/22/23 19:00:34.936
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:34.97
Apr 22 19:00:34.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:00:34.974
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:35.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:35.012
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 04/22/23 19:00:35.018
STEP: Ensuring ResourceQuota status is calculated 04/22/23 19:00:35.024
STEP: Creating a ResourceQuota with not best effort scope 04/22/23 19:00:37.038
STEP: Ensuring ResourceQuota status is calculated 04/22/23 19:00:37.051
STEP: Creating a best-effort pod 04/22/23 19:00:39.062
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/22/23 19:00:39.093
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/22/23 19:00:41.103
STEP: Deleting the pod 04/22/23 19:00:43.11
STEP: Ensuring resource quota status released the pod usage 04/22/23 19:00:43.131
STEP: Creating a not best-effort pod 04/22/23 19:00:45.142
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/22/23 19:00:45.171
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/22/23 19:00:47.18
STEP: Deleting the pod 04/22/23 19:00:49.19
STEP: Ensuring resource quota status released the pod usage 04/22/23 19:00:49.227
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:00:51.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3155" for this suite. 04/22/23 19:00:51.247
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":19,"skipped":423,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.293 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:34.97
    Apr 22 19:00:34.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:00:34.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:35.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:35.012
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 04/22/23 19:00:35.018
    STEP: Ensuring ResourceQuota status is calculated 04/22/23 19:00:35.024
    STEP: Creating a ResourceQuota with not best effort scope 04/22/23 19:00:37.038
    STEP: Ensuring ResourceQuota status is calculated 04/22/23 19:00:37.051
    STEP: Creating a best-effort pod 04/22/23 19:00:39.062
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/22/23 19:00:39.093
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/22/23 19:00:41.103
    STEP: Deleting the pod 04/22/23 19:00:43.11
    STEP: Ensuring resource quota status released the pod usage 04/22/23 19:00:43.131
    STEP: Creating a not best-effort pod 04/22/23 19:00:45.142
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/22/23 19:00:45.171
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/22/23 19:00:47.18
    STEP: Deleting the pod 04/22/23 19:00:49.19
    STEP: Ensuring resource quota status released the pod usage 04/22/23 19:00:49.227
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:00:51.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3155" for this suite. 04/22/23 19:00:51.247
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:51.267
Apr 22 19:00:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:00:51.271
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:51.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:51.338
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 04/22/23 19:00:51.348
Apr 22 19:00:51.350: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-325 proxy --unix-socket=/tmp/kubectl-proxy-unix1952873137/test'
STEP: retrieving proxy /api/ output 04/22/23 19:00:51.452
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:00:51.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-325" for this suite. 04/22/23 19:00:51.464
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":20,"skipped":424,"failed":0}
------------------------------
â€¢ [0.213 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:51.267
    Apr 22 19:00:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:00:51.271
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:51.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:51.338
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 04/22/23 19:00:51.348
    Apr 22 19:00:51.350: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-325 proxy --unix-socket=/tmp/kubectl-proxy-unix1952873137/test'
    STEP: retrieving proxy /api/ output 04/22/23 19:00:51.452
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:00:51.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-325" for this suite. 04/22/23 19:00:51.464
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:51.49
Apr 22 19:00:51.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:00:51.492
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:51.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:51.551
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:00:51.574
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:00:52.311
STEP: Deploying the webhook pod 04/22/23 19:00:52.327
STEP: Wait for the deployment to be ready 04/22/23 19:00:52.353
Apr 22 19:00:52.389: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:00:54.422
STEP: Verifying the service has paired with the endpoint 04/22/23 19:00:54.459
Apr 22 19:00:55.460: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 04/22/23 19:00:55.611
STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 19:00:55.699
STEP: Deleting the collection of validation webhooks 04/22/23 19:00:55.742
STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 19:00:55.825
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:00:55.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8811" for this suite. 04/22/23 19:00:55.85
STEP: Destroying namespace "webhook-8811-markers" for this suite. 04/22/23 19:00:55.86
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":21,"skipped":472,"failed":0}
------------------------------
â€¢ [4.473 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:51.49
    Apr 22 19:00:51.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:00:51.492
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:51.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:51.551
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:00:51.574
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:00:52.311
    STEP: Deploying the webhook pod 04/22/23 19:00:52.327
    STEP: Wait for the deployment to be ready 04/22/23 19:00:52.353
    Apr 22 19:00:52.389: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:00:54.422
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:00:54.459
    Apr 22 19:00:55.460: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 04/22/23 19:00:55.611
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 19:00:55.699
    STEP: Deleting the collection of validation webhooks 04/22/23 19:00:55.742
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 19:00:55.825
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:00:55.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8811" for this suite. 04/22/23 19:00:55.85
    STEP: Destroying namespace "webhook-8811-markers" for this suite. 04/22/23 19:00:55.86
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:55.97
Apr 22 19:00:55.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename discovery 04/22/23 19:00:55.974
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:56.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:56.053
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/22/23 19:00:56.063
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 22 19:00:56.543: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 22 19:00:56.544: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 22 19:00:56.544: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 22 19:00:56.545: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 22 19:00:56.545: INFO: Checking APIGroup: apps
Apr 22 19:00:56.546: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 22 19:00:56.546: INFO: Versions found [{apps/v1 v1}]
Apr 22 19:00:56.546: INFO: apps/v1 matches apps/v1
Apr 22 19:00:56.546: INFO: Checking APIGroup: events.k8s.io
Apr 22 19:00:56.547: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 22 19:00:56.547: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 22 19:00:56.547: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 22 19:00:56.547: INFO: Checking APIGroup: authentication.k8s.io
Apr 22 19:00:56.549: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 22 19:00:56.549: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 22 19:00:56.549: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 22 19:00:56.549: INFO: Checking APIGroup: authorization.k8s.io
Apr 22 19:00:56.550: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 22 19:00:56.551: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 22 19:00:56.551: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 22 19:00:56.551: INFO: Checking APIGroup: autoscaling
Apr 22 19:00:56.552: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 22 19:00:56.553: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Apr 22 19:00:56.553: INFO: autoscaling/v2 matches autoscaling/v2
Apr 22 19:00:56.553: INFO: Checking APIGroup: batch
Apr 22 19:00:56.554: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 22 19:00:56.554: INFO: Versions found [{batch/v1 v1}]
Apr 22 19:00:56.554: INFO: batch/v1 matches batch/v1
Apr 22 19:00:56.554: INFO: Checking APIGroup: certificates.k8s.io
Apr 22 19:00:56.556: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 22 19:00:56.556: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 22 19:00:56.556: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 22 19:00:56.556: INFO: Checking APIGroup: networking.k8s.io
Apr 22 19:00:56.558: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 22 19:00:56.558: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 22 19:00:56.558: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 22 19:00:56.558: INFO: Checking APIGroup: policy
Apr 22 19:00:56.559: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 22 19:00:56.559: INFO: Versions found [{policy/v1 v1}]
Apr 22 19:00:56.559: INFO: policy/v1 matches policy/v1
Apr 22 19:00:56.559: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 22 19:00:56.561: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 22 19:00:56.561: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 22 19:00:56.561: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 22 19:00:56.561: INFO: Checking APIGroup: storage.k8s.io
Apr 22 19:00:56.563: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 22 19:00:56.563: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 22 19:00:56.563: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 22 19:00:56.564: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 22 19:00:56.565: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 22 19:00:56.565: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 22 19:00:56.565: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 22 19:00:56.565: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 22 19:00:56.567: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 22 19:00:56.567: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 22 19:00:56.567: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 22 19:00:56.567: INFO: Checking APIGroup: scheduling.k8s.io
Apr 22 19:00:56.569: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 22 19:00:56.569: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 22 19:00:56.569: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 22 19:00:56.569: INFO: Checking APIGroup: coordination.k8s.io
Apr 22 19:00:56.570: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 22 19:00:56.570: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 22 19:00:56.570: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 22 19:00:56.570: INFO: Checking APIGroup: node.k8s.io
Apr 22 19:00:56.571: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 22 19:00:56.571: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 22 19:00:56.572: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 22 19:00:56.572: INFO: Checking APIGroup: discovery.k8s.io
Apr 22 19:00:56.573: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 22 19:00:56.573: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 22 19:00:56.573: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 22 19:00:56.574: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 22 19:00:56.575: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr 22 19:00:56.575: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 22 19:00:56.576: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Apr 22 19:00:56.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3932" for this suite. 04/22/23 19:00:56.581
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":22,"skipped":478,"failed":0}
------------------------------
â€¢ [0.618 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:55.97
    Apr 22 19:00:55.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename discovery 04/22/23 19:00:55.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:56.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:56.053
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/22/23 19:00:56.063
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 22 19:00:56.543: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 22 19:00:56.544: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 22 19:00:56.544: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 22 19:00:56.545: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 22 19:00:56.545: INFO: Checking APIGroup: apps
    Apr 22 19:00:56.546: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 22 19:00:56.546: INFO: Versions found [{apps/v1 v1}]
    Apr 22 19:00:56.546: INFO: apps/v1 matches apps/v1
    Apr 22 19:00:56.546: INFO: Checking APIGroup: events.k8s.io
    Apr 22 19:00:56.547: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 22 19:00:56.547: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 22 19:00:56.547: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 22 19:00:56.547: INFO: Checking APIGroup: authentication.k8s.io
    Apr 22 19:00:56.549: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 22 19:00:56.549: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 22 19:00:56.549: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 22 19:00:56.549: INFO: Checking APIGroup: authorization.k8s.io
    Apr 22 19:00:56.550: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 22 19:00:56.551: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 22 19:00:56.551: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 22 19:00:56.551: INFO: Checking APIGroup: autoscaling
    Apr 22 19:00:56.552: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 22 19:00:56.553: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Apr 22 19:00:56.553: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 22 19:00:56.553: INFO: Checking APIGroup: batch
    Apr 22 19:00:56.554: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 22 19:00:56.554: INFO: Versions found [{batch/v1 v1}]
    Apr 22 19:00:56.554: INFO: batch/v1 matches batch/v1
    Apr 22 19:00:56.554: INFO: Checking APIGroup: certificates.k8s.io
    Apr 22 19:00:56.556: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 22 19:00:56.556: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 22 19:00:56.556: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 22 19:00:56.556: INFO: Checking APIGroup: networking.k8s.io
    Apr 22 19:00:56.558: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 22 19:00:56.558: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 22 19:00:56.558: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 22 19:00:56.558: INFO: Checking APIGroup: policy
    Apr 22 19:00:56.559: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 22 19:00:56.559: INFO: Versions found [{policy/v1 v1}]
    Apr 22 19:00:56.559: INFO: policy/v1 matches policy/v1
    Apr 22 19:00:56.559: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 22 19:00:56.561: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 22 19:00:56.561: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 22 19:00:56.561: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 22 19:00:56.561: INFO: Checking APIGroup: storage.k8s.io
    Apr 22 19:00:56.563: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 22 19:00:56.563: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 22 19:00:56.563: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 22 19:00:56.564: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 22 19:00:56.565: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 22 19:00:56.565: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 22 19:00:56.565: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 22 19:00:56.565: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 22 19:00:56.567: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 22 19:00:56.567: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 22 19:00:56.567: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 22 19:00:56.567: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 22 19:00:56.569: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 22 19:00:56.569: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 22 19:00:56.569: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 22 19:00:56.569: INFO: Checking APIGroup: coordination.k8s.io
    Apr 22 19:00:56.570: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 22 19:00:56.570: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 22 19:00:56.570: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 22 19:00:56.570: INFO: Checking APIGroup: node.k8s.io
    Apr 22 19:00:56.571: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 22 19:00:56.571: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 22 19:00:56.572: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 22 19:00:56.572: INFO: Checking APIGroup: discovery.k8s.io
    Apr 22 19:00:56.573: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 22 19:00:56.573: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 22 19:00:56.573: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 22 19:00:56.574: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 22 19:00:56.575: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Apr 22 19:00:56.575: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Apr 22 19:00:56.576: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Apr 22 19:00:56.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3932" for this suite. 04/22/23 19:00:56.581
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:00:56.594
Apr 22 19:00:56.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:00:56.596
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:56.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:56.625
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-0655e469-c114-4823-b573-ab0716e30bd0 04/22/23 19:00:56.628
STEP: Creating a pod to test consume secrets 04/22/23 19:00:56.635
Apr 22 19:00:56.645: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e" in namespace "projected-3633" to be "Succeeded or Failed"
Apr 22 19:00:56.651: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035613ms
Apr 22 19:00:58.660: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014865887s
Apr 22 19:01:00.661: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01647321s
STEP: Saw pod success 04/22/23 19:01:00.662
Apr 22 19:01:00.662: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e" satisfied condition "Succeeded or Failed"
Apr 22 19:01:00.670: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e container projected-secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:01:00.711
Apr 22 19:01:00.742: INFO: Waiting for pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e to disappear
Apr 22 19:01:00.749: INFO: Pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:01:00.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3633" for this suite. 04/22/23 19:01:00.761
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":23,"skipped":480,"failed":0}
------------------------------
â€¢ [4.182 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:00:56.594
    Apr 22 19:00:56.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:00:56.596
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:00:56.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:00:56.625
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-0655e469-c114-4823-b573-ab0716e30bd0 04/22/23 19:00:56.628
    STEP: Creating a pod to test consume secrets 04/22/23 19:00:56.635
    Apr 22 19:00:56.645: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e" in namespace "projected-3633" to be "Succeeded or Failed"
    Apr 22 19:00:56.651: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035613ms
    Apr 22 19:00:58.660: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014865887s
    Apr 22 19:01:00.661: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01647321s
    STEP: Saw pod success 04/22/23 19:01:00.662
    Apr 22 19:01:00.662: INFO: Pod "pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e" satisfied condition "Succeeded or Failed"
    Apr 22 19:01:00.670: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:01:00.711
    Apr 22 19:01:00.742: INFO: Waiting for pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e to disappear
    Apr 22 19:01:00.749: INFO: Pod pod-projected-secrets-7cb1bfc9-4aa0-45f8-bdce-0839a053c36e no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:01:00.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3633" for this suite. 04/22/23 19:01:00.761
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:01:00.78
Apr 22 19:01:00.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pod-network-test 04/22/23 19:01:00.784
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:00.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:00.844
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-6385 04/22/23 19:01:00.851
STEP: creating a selector 04/22/23 19:01:00.852
STEP: Creating the service pods in kubernetes 04/22/23 19:01:00.852
Apr 22 19:01:00.853: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 22 19:01:00.903: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6385" to be "running and ready"
Apr 22 19:01:00.922: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.602944ms
Apr 22 19:01:00.922: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:01:02.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.028914118s
Apr 22 19:01:02.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:01:04.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.02855037s
Apr 22 19:01:04.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:01:06.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028444762s
Apr 22 19:01:06.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:01:08.933: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.029356756s
Apr 22 19:01:08.933: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:01:10.931: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.027834317s
Apr 22 19:01:10.931: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:01:12.931: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.027403598s
Apr 22 19:01:12.931: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 22 19:01:12.931: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 22 19:01:12.939: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6385" to be "running and ready"
Apr 22 19:01:12.946: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 7.276655ms
Apr 22 19:01:12.946: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 22 19:01:12.946: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 04/22/23 19:01:12.954
Apr 22 19:01:12.968: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6385" to be "running"
Apr 22 19:01:12.976: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.583921ms
Apr 22 19:01:14.987: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018448424s
Apr 22 19:01:14.988: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 22 19:01:14.996: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr 22 19:01:14.996: INFO: Breadth first check of 10.44.0.4 on host 10.1.1.165...
Apr 22 19:01:15.004: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.3:9080/dial?request=hostname&protocol=http&host=10.44.0.4&port=8083&tries=1'] Namespace:pod-network-test-6385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:15.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:15.007: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:15.008: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.3%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.44.0.4%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 22 19:01:15.201: INFO: Waiting for responses: map[]
Apr 22 19:01:15.201: INFO: reached 10.44.0.4 after 0/1 tries
Apr 22 19:01:15.201: INFO: Breadth first check of 10.36.0.5 on host 10.1.1.128...
Apr 22 19:01:15.217: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.3:9080/dial?request=hostname&protocol=http&host=10.36.0.5&port=8083&tries=1'] Namespace:pod-network-test-6385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:15.219: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:15.219: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.3%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.36.0.5%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 22 19:01:15.367: INFO: Waiting for responses: map[]
Apr 22 19:01:15.367: INFO: reached 10.36.0.5 after 0/1 tries
Apr 22 19:01:15.368: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 22 19:01:15.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6385" for this suite. 04/22/23 19:01:15.38
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":24,"skipped":486,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.617 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:01:00.78
    Apr 22 19:01:00.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pod-network-test 04/22/23 19:01:00.784
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:00.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:00.844
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-6385 04/22/23 19:01:00.851
    STEP: creating a selector 04/22/23 19:01:00.852
    STEP: Creating the service pods in kubernetes 04/22/23 19:01:00.852
    Apr 22 19:01:00.853: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 22 19:01:00.903: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6385" to be "running and ready"
    Apr 22 19:01:00.922: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.602944ms
    Apr 22 19:01:00.922: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:01:02.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.028914118s
    Apr 22 19:01:02.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:01:04.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.02855037s
    Apr 22 19:01:04.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:01:06.932: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028444762s
    Apr 22 19:01:06.932: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:01:08.933: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.029356756s
    Apr 22 19:01:08.933: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:01:10.931: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.027834317s
    Apr 22 19:01:10.931: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:01:12.931: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.027403598s
    Apr 22 19:01:12.931: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 22 19:01:12.931: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 22 19:01:12.939: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6385" to be "running and ready"
    Apr 22 19:01:12.946: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 7.276655ms
    Apr 22 19:01:12.946: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 22 19:01:12.946: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 04/22/23 19:01:12.954
    Apr 22 19:01:12.968: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6385" to be "running"
    Apr 22 19:01:12.976: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.583921ms
    Apr 22 19:01:14.987: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018448424s
    Apr 22 19:01:14.988: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 22 19:01:14.996: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Apr 22 19:01:14.996: INFO: Breadth first check of 10.44.0.4 on host 10.1.1.165...
    Apr 22 19:01:15.004: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.3:9080/dial?request=hostname&protocol=http&host=10.44.0.4&port=8083&tries=1'] Namespace:pod-network-test-6385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:15.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:15.007: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:15.008: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.3%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.44.0.4%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 22 19:01:15.201: INFO: Waiting for responses: map[]
    Apr 22 19:01:15.201: INFO: reached 10.44.0.4 after 0/1 tries
    Apr 22 19:01:15.201: INFO: Breadth first check of 10.36.0.5 on host 10.1.1.128...
    Apr 22 19:01:15.217: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.3:9080/dial?request=hostname&protocol=http&host=10.36.0.5&port=8083&tries=1'] Namespace:pod-network-test-6385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:15.219: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:15.219: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.3%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.36.0.5%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 22 19:01:15.367: INFO: Waiting for responses: map[]
    Apr 22 19:01:15.367: INFO: reached 10.36.0.5 after 0/1 tries
    Apr 22 19:01:15.368: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 22 19:01:15.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6385" for this suite. 04/22/23 19:01:15.38
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:01:15.422
Apr 22 19:01:15.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/22/23 19:01:15.425
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:15.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:15.518
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/22/23 19:01:15.527
STEP: Creating hostNetwork=false pod 04/22/23 19:01:15.528
Apr 22 19:01:15.548: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9532" to be "running and ready"
Apr 22 19:01:15.565: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.591532ms
Apr 22 19:01:15.565: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:01:17.576: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027090564s
Apr 22 19:01:17.577: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 22 19:01:17.577: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/22/23 19:01:17.586
Apr 22 19:01:17.601: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9532" to be "running and ready"
Apr 22 19:01:17.612: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.357332ms
Apr 22 19:01:17.612: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:01:19.622: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.02107906s
Apr 22 19:01:19.622: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 22 19:01:19.622: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/22/23 19:01:19.63
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/22/23 19:01:19.63
Apr 22 19:01:19.630: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:19.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:19.633: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:19.633: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 22 19:01:19.812: INFO: Exec stderr: ""
Apr 22 19:01:19.813: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:19.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:19.815: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:19.815: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 22 19:01:19.939: INFO: Exec stderr: ""
Apr 22 19:01:19.939: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:19.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:19.940: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:19.940: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 22 19:01:20.079: INFO: Exec stderr: ""
Apr 22 19:01:20.079: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.080: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.080: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 22 19:01:20.242: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/22/23 19:01:20.242
Apr 22 19:01:20.242: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.244: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.244: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 22 19:01:20.416: INFO: Exec stderr: ""
Apr 22 19:01:20.416: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.418: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.418: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 22 19:01:20.572: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/22/23 19:01:20.572
Apr 22 19:01:20.573: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.575: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.575: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 22 19:01:20.755: INFO: Exec stderr: ""
Apr 22 19:01:20.756: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.759: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.759: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 22 19:01:20.883: INFO: Exec stderr: ""
Apr 22 19:01:20.883: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.883: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.884: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 22 19:01:20.978: INFO: Exec stderr: ""
Apr 22 19:01:20.978: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:01:20.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:01:20.980: INFO: ExecWithOptions: Clientset creation
Apr 22 19:01:20.980: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 22 19:01:21.060: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Apr 22 19:01:21.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9532" for this suite. 04/22/23 19:01:21.065
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":25,"skipped":501,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.649 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:01:15.422
    Apr 22 19:01:15.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/22/23 19:01:15.425
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:15.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:15.518
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/22/23 19:01:15.527
    STEP: Creating hostNetwork=false pod 04/22/23 19:01:15.528
    Apr 22 19:01:15.548: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9532" to be "running and ready"
    Apr 22 19:01:15.565: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.591532ms
    Apr 22 19:01:15.565: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:01:17.576: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027090564s
    Apr 22 19:01:17.577: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 22 19:01:17.577: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/22/23 19:01:17.586
    Apr 22 19:01:17.601: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9532" to be "running and ready"
    Apr 22 19:01:17.612: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.357332ms
    Apr 22 19:01:17.612: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:01:19.622: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.02107906s
    Apr 22 19:01:19.622: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 22 19:01:19.622: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/22/23 19:01:19.63
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/22/23 19:01:19.63
    Apr 22 19:01:19.630: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:19.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:19.633: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:19.633: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 22 19:01:19.812: INFO: Exec stderr: ""
    Apr 22 19:01:19.813: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:19.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:19.815: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:19.815: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 22 19:01:19.939: INFO: Exec stderr: ""
    Apr 22 19:01:19.939: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:19.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:19.940: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:19.940: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 22 19:01:20.079: INFO: Exec stderr: ""
    Apr 22 19:01:20.079: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.080: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.080: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 22 19:01:20.242: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/22/23 19:01:20.242
    Apr 22 19:01:20.242: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.244: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.244: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 22 19:01:20.416: INFO: Exec stderr: ""
    Apr 22 19:01:20.416: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.418: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.418: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 22 19:01:20.572: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/22/23 19:01:20.572
    Apr 22 19:01:20.573: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.575: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.575: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 22 19:01:20.755: INFO: Exec stderr: ""
    Apr 22 19:01:20.756: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.759: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.759: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 22 19:01:20.883: INFO: Exec stderr: ""
    Apr 22 19:01:20.883: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.883: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.884: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 22 19:01:20.978: INFO: Exec stderr: ""
    Apr 22 19:01:20.978: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9532 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:01:20.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:01:20.980: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:01:20.980: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9532/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 22 19:01:21.060: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Apr 22 19:01:21.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-9532" for this suite. 04/22/23 19:01:21.065
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:01:21.075
Apr 22 19:01:21.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption 04/22/23 19:01:21.077
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:21.101
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:21.123
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 22 19:01:21.164: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 19:02:21.241: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 04/22/23 19:02:21.253
Apr 22 19:02:21.358: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 22 19:02:21.368: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 22 19:02:21.406: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 22 19:02:21.423: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/22/23 19:02:21.423
Apr 22 19:02:21.424: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-6214" to be "running"
Apr 22 19:02:21.433: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.474463ms
Apr 22 19:02:23.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018183463s
Apr 22 19:02:25.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017687741s
Apr 22 19:02:27.443: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018611894s
Apr 22 19:02:29.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018402366s
Apr 22 19:02:31.444: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020513415s
Apr 22 19:02:33.448: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.024352764s
Apr 22 19:02:33.449: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 22 19:02:33.449: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
Apr 22 19:02:33.458: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.483628ms
Apr 22 19:02:33.458: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 22 19:02:33.458: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
Apr 22 19:02:33.467: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.30806ms
Apr 22 19:02:33.468: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 22 19:02:33.468: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
Apr 22 19:02:33.477: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.617014ms
Apr 22 19:02:33.477: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/22/23 19:02:33.478
Apr 22 19:02:33.513: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 22 19:02:33.527: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.034848ms
Apr 22 19:02:35.534: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02051134s
Apr 22 19:02:37.537: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.02392033s
Apr 22 19:02:37.537: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:02:37.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6214" for this suite. 04/22/23 19:02:37.639
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":26,"skipped":509,"failed":0}
------------------------------
â€¢ [SLOW TEST] [76.656 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:01:21.075
    Apr 22 19:01:21.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption 04/22/23 19:01:21.077
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:01:21.101
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:01:21.123
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 22 19:01:21.164: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 19:02:21.241: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 04/22/23 19:02:21.253
    Apr 22 19:02:21.358: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 22 19:02:21.368: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 22 19:02:21.406: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 22 19:02:21.423: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/22/23 19:02:21.423
    Apr 22 19:02:21.424: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-6214" to be "running"
    Apr 22 19:02:21.433: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.474463ms
    Apr 22 19:02:23.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018183463s
    Apr 22 19:02:25.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017687741s
    Apr 22 19:02:27.443: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018611894s
    Apr 22 19:02:29.442: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018402366s
    Apr 22 19:02:31.444: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020513415s
    Apr 22 19:02:33.448: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.024352764s
    Apr 22 19:02:33.449: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 22 19:02:33.449: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
    Apr 22 19:02:33.458: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.483628ms
    Apr 22 19:02:33.458: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 22 19:02:33.458: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
    Apr 22 19:02:33.467: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.30806ms
    Apr 22 19:02:33.468: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 22 19:02:33.468: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-6214" to be "running"
    Apr 22 19:02:33.477: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.617014ms
    Apr 22 19:02:33.477: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/22/23 19:02:33.478
    Apr 22 19:02:33.513: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 22 19:02:33.527: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.034848ms
    Apr 22 19:02:35.534: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02051134s
    Apr 22 19:02:37.537: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.02392033s
    Apr 22 19:02:37.537: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:02:37.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-6214" for this suite. 04/22/23 19:02:37.639
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:02:37.749
Apr 22 19:02:37.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:02:37.754
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:37.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:37.815
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 04/22/23 19:02:37.822
Apr 22 19:02:37.824: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 22 19:02:37.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:38.932: INFO: stderr: ""
Apr 22 19:02:38.932: INFO: stdout: "service/agnhost-replica created\n"
Apr 22 19:02:38.932: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 22 19:02:38.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:40.104: INFO: stderr: ""
Apr 22 19:02:40.104: INFO: stdout: "service/agnhost-primary created\n"
Apr 22 19:02:40.104: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 22 19:02:40.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:40.356: INFO: stderr: ""
Apr 22 19:02:40.356: INFO: stdout: "service/frontend created\n"
Apr 22 19:02:40.356: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 22 19:02:40.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:40.599: INFO: stderr: ""
Apr 22 19:02:40.599: INFO: stdout: "deployment.apps/frontend created\n"
Apr 22 19:02:40.600: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 22 19:02:40.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:40.953: INFO: stderr: ""
Apr 22 19:02:40.953: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 22 19:02:40.954: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 22 19:02:40.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
Apr 22 19:02:41.357: INFO: stderr: ""
Apr 22 19:02:41.357: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/22/23 19:02:41.357
Apr 22 19:02:41.358: INFO: Waiting for all frontend pods to be Running.
Apr 22 19:02:46.410: INFO: Waiting for frontend to serve content.
Apr 22 19:02:46.445: INFO: Trying to add a new entry to the guestbook.
Apr 22 19:02:46.490: INFO: Verifying that added entry can be retrieved.
Apr 22 19:02:46.523: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 04/22/23 19:02:51.546
Apr 22 19:02:51.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:51.784: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:51.784: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/22/23 19:02:51.784
Apr 22 19:02:51.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:51.904: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:51.904: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/22/23 19:02:51.904
Apr 22 19:02:51.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:52.072: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:52.072: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/22/23 19:02:52.073
Apr 22 19:02:52.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:52.236: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:52.236: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/22/23 19:02:52.237
Apr 22 19:02:52.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:52.393: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:52.393: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/22/23 19:02:52.393
Apr 22 19:02:52.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
Apr 22 19:02:52.550: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:02:52.550: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:02:52.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8243" for this suite. 04/22/23 19:02:52.561
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":27,"skipped":539,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.838 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:02:37.749
    Apr 22 19:02:37.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:02:37.754
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:37.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:37.815
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 04/22/23 19:02:37.822
    Apr 22 19:02:37.824: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 22 19:02:37.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:38.932: INFO: stderr: ""
    Apr 22 19:02:38.932: INFO: stdout: "service/agnhost-replica created\n"
    Apr 22 19:02:38.932: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 22 19:02:38.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:40.104: INFO: stderr: ""
    Apr 22 19:02:40.104: INFO: stdout: "service/agnhost-primary created\n"
    Apr 22 19:02:40.104: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 22 19:02:40.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:40.356: INFO: stderr: ""
    Apr 22 19:02:40.356: INFO: stdout: "service/frontend created\n"
    Apr 22 19:02:40.356: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 22 19:02:40.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:40.599: INFO: stderr: ""
    Apr 22 19:02:40.599: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 22 19:02:40.600: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 22 19:02:40.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:40.953: INFO: stderr: ""
    Apr 22 19:02:40.953: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 22 19:02:40.954: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 22 19:02:40.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 create -f -'
    Apr 22 19:02:41.357: INFO: stderr: ""
    Apr 22 19:02:41.357: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/22/23 19:02:41.357
    Apr 22 19:02:41.358: INFO: Waiting for all frontend pods to be Running.
    Apr 22 19:02:46.410: INFO: Waiting for frontend to serve content.
    Apr 22 19:02:46.445: INFO: Trying to add a new entry to the guestbook.
    Apr 22 19:02:46.490: INFO: Verifying that added entry can be retrieved.
    Apr 22 19:02:46.523: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 04/22/23 19:02:51.546
    Apr 22 19:02:51.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:51.784: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:51.784: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/22/23 19:02:51.784
    Apr 22 19:02:51.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:51.904: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:51.904: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/22/23 19:02:51.904
    Apr 22 19:02:51.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:52.072: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:52.072: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/22/23 19:02:52.073
    Apr 22 19:02:52.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:52.236: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:52.236: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/22/23 19:02:52.237
    Apr 22 19:02:52.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:52.393: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:52.393: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/22/23 19:02:52.393
    Apr 22 19:02:52.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8243 delete --grace-period=0 --force -f -'
    Apr 22 19:02:52.550: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:02:52.550: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:02:52.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8243" for this suite. 04/22/23 19:02:52.561
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:02:52.588
Apr 22 19:02:52.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename init-container 04/22/23 19:02:52.59
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:52.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:52.633
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 04/22/23 19:02:52.637
Apr 22 19:02:52.637: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 19:02:55.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9797" for this suite. 04/22/23 19:02:55.63
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":28,"skipped":572,"failed":0}
------------------------------
â€¢ [3.059 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:02:52.588
    Apr 22 19:02:52.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename init-container 04/22/23 19:02:52.59
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:52.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:52.633
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 04/22/23 19:02:52.637
    Apr 22 19:02:52.637: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 19:02:55.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9797" for this suite. 04/22/23 19:02:55.63
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:02:55.656
Apr 22 19:02:55.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename watch 04/22/23 19:02:55.659
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:55.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:55.719
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/22/23 19:02:55.731
STEP: creating a new configmap 04/22/23 19:02:55.735
STEP: modifying the configmap once 04/22/23 19:02:55.749
STEP: changing the label value of the configmap 04/22/23 19:02:55.768
STEP: Expecting to observe a delete notification for the watched object 04/22/23 19:02:55.798
Apr 22 19:02:55.799: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4114 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:02:55.800: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4115 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:02:55.801: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4116 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/22/23 19:02:55.802
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/22/23 19:02:55.819
STEP: changing the label value of the configmap back 04/22/23 19:03:05.821
STEP: modifying the configmap a third time 04/22/23 19:03:05.844
STEP: deleting the configmap 04/22/23 19:03:05.865
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/22/23 19:03:05.879
Apr 22 19:03:05.880: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4205 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:03:05.881: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4206 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:03:05.881: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4207 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 22 19:03:05.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2356" for this suite. 04/22/23 19:03:05.895
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":29,"skipped":584,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.263 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:02:55.656
    Apr 22 19:02:55.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename watch 04/22/23 19:02:55.659
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:02:55.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:02:55.719
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/22/23 19:02:55.731
    STEP: creating a new configmap 04/22/23 19:02:55.735
    STEP: modifying the configmap once 04/22/23 19:02:55.749
    STEP: changing the label value of the configmap 04/22/23 19:02:55.768
    STEP: Expecting to observe a delete notification for the watched object 04/22/23 19:02:55.798
    Apr 22 19:02:55.799: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4114 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:02:55.800: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4115 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:02:55.801: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4116 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:02:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/22/23 19:02:55.802
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/22/23 19:02:55.819
    STEP: changing the label value of the configmap back 04/22/23 19:03:05.821
    STEP: modifying the configmap a third time 04/22/23 19:03:05.844
    STEP: deleting the configmap 04/22/23 19:03:05.865
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/22/23 19:03:05.879
    Apr 22 19:03:05.880: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4205 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:03:05.881: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4206 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:03:05.881: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2356  542c226c-0cd4-48ed-8a1a-2e4c617252e8 4207 0 2023-04-22 19:02:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-22 19:03:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 22 19:03:05.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2356" for this suite. 04/22/23 19:03:05.895
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:05.938
Apr 22 19:03:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context 04/22/23 19:03:05.94
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:06.008
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/22/23 19:03:06.018
Apr 22 19:03:06.042: INFO: Waiting up to 5m0s for pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed" in namespace "security-context-7695" to be "Succeeded or Failed"
Apr 22 19:03:06.053: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.201851ms
Apr 22 19:03:08.062: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019181186s
Apr 22 19:03:10.064: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021248002s
STEP: Saw pod success 04/22/23 19:03:10.065
Apr 22 19:03:10.065: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed" satisfied condition "Succeeded or Failed"
Apr 22 19:03:10.074: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed container test-container: <nil>
STEP: delete the pod 04/22/23 19:03:10.125
Apr 22 19:03:10.156: INFO: Waiting for pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed to disappear
Apr 22 19:03:10.169: INFO: Pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 19:03:10.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7695" for this suite. 04/22/23 19:03:10.182
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":30,"skipped":603,"failed":0}
------------------------------
â€¢ [4.263 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:05.938
    Apr 22 19:03:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context 04/22/23 19:03:05.94
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:06.008
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/22/23 19:03:06.018
    Apr 22 19:03:06.042: INFO: Waiting up to 5m0s for pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed" in namespace "security-context-7695" to be "Succeeded or Failed"
    Apr 22 19:03:06.053: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.201851ms
    Apr 22 19:03:08.062: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019181186s
    Apr 22 19:03:10.064: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021248002s
    STEP: Saw pod success 04/22/23 19:03:10.065
    Apr 22 19:03:10.065: INFO: Pod "security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed" satisfied condition "Succeeded or Failed"
    Apr 22 19:03:10.074: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed container test-container: <nil>
    STEP: delete the pod 04/22/23 19:03:10.125
    Apr 22 19:03:10.156: INFO: Waiting for pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed to disappear
    Apr 22 19:03:10.169: INFO: Pod security-context-3ffb09ad-7f2b-4e0b-9262-273f14b5a7ed no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 19:03:10.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7695" for this suite. 04/22/23 19:03:10.182
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:10.225
Apr 22 19:03:10.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:03:10.228
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:10.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:10.285
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-03888c45-87e0-4b50-83f5-049fd28ad213 04/22/23 19:03:10.293
STEP: Creating a pod to test consume secrets 04/22/23 19:03:10.309
Apr 22 19:03:10.324: INFO: Waiting up to 5m0s for pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4" in namespace "secrets-5496" to be "Succeeded or Failed"
Apr 22 19:03:10.338: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.930955ms
Apr 22 19:03:12.352: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027165755s
Apr 22 19:03:14.349: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024051634s
STEP: Saw pod success 04/22/23 19:03:14.349
Apr 22 19:03:14.350: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4" satisfied condition "Succeeded or Failed"
Apr 22 19:03:14.363: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:03:14.382
Apr 22 19:03:14.416: INFO: Waiting for pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 to disappear
Apr 22 19:03:14.424: INFO: Pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:03:14.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5496" for this suite. 04/22/23 19:03:14.439
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":31,"skipped":616,"failed":0}
------------------------------
â€¢ [4.233 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:10.225
    Apr 22 19:03:10.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:03:10.228
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:10.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:10.285
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-03888c45-87e0-4b50-83f5-049fd28ad213 04/22/23 19:03:10.293
    STEP: Creating a pod to test consume secrets 04/22/23 19:03:10.309
    Apr 22 19:03:10.324: INFO: Waiting up to 5m0s for pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4" in namespace "secrets-5496" to be "Succeeded or Failed"
    Apr 22 19:03:10.338: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.930955ms
    Apr 22 19:03:12.352: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027165755s
    Apr 22 19:03:14.349: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024051634s
    STEP: Saw pod success 04/22/23 19:03:14.349
    Apr 22 19:03:14.350: INFO: Pod "pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4" satisfied condition "Succeeded or Failed"
    Apr 22 19:03:14.363: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:03:14.382
    Apr 22 19:03:14.416: INFO: Waiting for pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 to disappear
    Apr 22 19:03:14.424: INFO: Pod pod-secrets-e4f4a4e4-d594-418c-8609-85b792a11ea4 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:03:14.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5496" for this suite. 04/22/23 19:03:14.439
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:14.478
Apr 22 19:03:14.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:03:14.482
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:14.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:14.563
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-9551 04/22/23 19:03:14.571
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[] 04/22/23 19:03:14.615
Apr 22 19:03:14.627: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Apr 22 19:03:15.639: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9551 04/22/23 19:03:15.639
Apr 22 19:03:15.653: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9551" to be "running and ready"
Apr 22 19:03:15.660: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400143ms
Apr 22 19:03:15.660: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:03:17.670: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.016651088s
Apr 22 19:03:17.670: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 22 19:03:17.671: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod1:[100]] 04/22/23 19:03:17.678
Apr 22 19:03:17.708: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-9551 04/22/23 19:03:17.708
Apr 22 19:03:17.725: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9551" to be "running and ready"
Apr 22 19:03:17.733: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.004684ms
Apr 22 19:03:17.733: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:03:19.748: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.022681419s
Apr 22 19:03:19.748: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 22 19:03:19.748: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod1:[100] pod2:[101]] 04/22/23 19:03:19.754
Apr 22 19:03:19.796: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/22/23 19:03:19.797
Apr 22 19:03:19.798: INFO: Creating new exec pod
Apr 22 19:03:19.824: INFO: Waiting up to 5m0s for pod "execpodnfhr7" in namespace "services-9551" to be "running"
Apr 22 19:03:19.832: INFO: Pod "execpodnfhr7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.725006ms
Apr 22 19:03:21.843: INFO: Pod "execpodnfhr7": Phase="Running", Reason="", readiness=true. Elapsed: 2.018240011s
Apr 22 19:03:21.843: INFO: Pod "execpodnfhr7" satisfied condition "running"
Apr 22 19:03:22.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 22 19:03:23.157: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 22 19:03:23.157: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:03:23.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.74.121 80'
Apr 22 19:03:23.478: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.74.121 80\nConnection to 10.97.74.121 80 port [tcp/http] succeeded!\n"
Apr 22 19:03:23.478: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:03:23.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 22 19:03:23.788: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 22 19:03:23.788: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:03:23.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.74.121 81'
Apr 22 19:03:24.133: INFO: stderr: "+ nc -v -t -w 2 10.97.74.121 81\n+ echo hostName\nConnection to 10.97.74.121 81 port [tcp/*] succeeded!\n"
Apr 22 19:03:24.133: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9551 04/22/23 19:03:24.134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod2:[101]] 04/22/23 19:03:24.172
Apr 22 19:03:24.221: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-9551 04/22/23 19:03:24.221
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[] 04/22/23 19:03:24.255
Apr 22 19:03:24.279: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 19:03:24.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9551" for this suite. 04/22/23 19:03:24.338
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":32,"skipped":622,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.871 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:14.478
    Apr 22 19:03:14.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:03:14.482
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:14.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:14.563
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-9551 04/22/23 19:03:14.571
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[] 04/22/23 19:03:14.615
    Apr 22 19:03:14.627: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Apr 22 19:03:15.639: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9551 04/22/23 19:03:15.639
    Apr 22 19:03:15.653: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9551" to be "running and ready"
    Apr 22 19:03:15.660: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400143ms
    Apr 22 19:03:15.660: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:03:17.670: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.016651088s
    Apr 22 19:03:17.670: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 22 19:03:17.671: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod1:[100]] 04/22/23 19:03:17.678
    Apr 22 19:03:17.708: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-9551 04/22/23 19:03:17.708
    Apr 22 19:03:17.725: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9551" to be "running and ready"
    Apr 22 19:03:17.733: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.004684ms
    Apr 22 19:03:17.733: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:03:19.748: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.022681419s
    Apr 22 19:03:19.748: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 22 19:03:19.748: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod1:[100] pod2:[101]] 04/22/23 19:03:19.754
    Apr 22 19:03:19.796: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/22/23 19:03:19.797
    Apr 22 19:03:19.798: INFO: Creating new exec pod
    Apr 22 19:03:19.824: INFO: Waiting up to 5m0s for pod "execpodnfhr7" in namespace "services-9551" to be "running"
    Apr 22 19:03:19.832: INFO: Pod "execpodnfhr7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.725006ms
    Apr 22 19:03:21.843: INFO: Pod "execpodnfhr7": Phase="Running", Reason="", readiness=true. Elapsed: 2.018240011s
    Apr 22 19:03:21.843: INFO: Pod "execpodnfhr7" satisfied condition "running"
    Apr 22 19:03:22.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Apr 22 19:03:23.157: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 22 19:03:23.157: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:03:23.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.74.121 80'
    Apr 22 19:03:23.478: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.74.121 80\nConnection to 10.97.74.121 80 port [tcp/http] succeeded!\n"
    Apr 22 19:03:23.478: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:03:23.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Apr 22 19:03:23.788: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 22 19:03:23.788: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:03:23.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-9551 exec execpodnfhr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.74.121 81'
    Apr 22 19:03:24.133: INFO: stderr: "+ nc -v -t -w 2 10.97.74.121 81\n+ echo hostName\nConnection to 10.97.74.121 81 port [tcp/*] succeeded!\n"
    Apr 22 19:03:24.133: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-9551 04/22/23 19:03:24.134
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[pod2:[101]] 04/22/23 19:03:24.172
    Apr 22 19:03:24.221: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-9551 04/22/23 19:03:24.221
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9551 to expose endpoints map[] 04/22/23 19:03:24.255
    Apr 22 19:03:24.279: INFO: successfully validated that service multi-endpoint-test in namespace services-9551 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 19:03:24.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9551" for this suite. 04/22/23 19:03:24.338
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:24.37
Apr 22 19:03:24.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:03:24.371
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:24.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:24.406
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 22 19:03:24.410: INFO: Creating deployment "webserver-deployment"
Apr 22 19:03:24.419: INFO: Waiting for observed generation 1
Apr 22 19:03:26.434: INFO: Waiting for all required pods to come up
Apr 22 19:03:26.449: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/22/23 19:03:26.449
Apr 22 19:03:26.450: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2g585" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.450: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vct48" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.451: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-5hvkw" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.451: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-clqv4" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.452: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fj9lv" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.452: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fwmkn" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.453: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q5bxj" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.453: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-r4jtg" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.454: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-s64cn" in namespace "deployment-7148" to be "running"
Apr 22 19:03:26.463: INFO: Pod "webserver-deployment-845c8977d9-vct48": Phase="Pending", Reason="", readiness=false. Elapsed: 12.846163ms
Apr 22 19:03:26.477: INFO: Pod "webserver-deployment-845c8977d9-2g585": Phase="Pending", Reason="", readiness=false. Elapsed: 27.302415ms
Apr 22 19:03:26.500: INFO: Pod "webserver-deployment-845c8977d9-r4jtg": Phase="Pending", Reason="", readiness=false. Elapsed: 46.711853ms
Apr 22 19:03:26.500: INFO: Pod "webserver-deployment-845c8977d9-fj9lv": Phase="Pending", Reason="", readiness=false. Elapsed: 48.299502ms
Apr 22 19:03:26.502: INFO: Pod "webserver-deployment-845c8977d9-fwmkn": Phase="Pending", Reason="", readiness=false. Elapsed: 49.690713ms
Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-clqv4": Phase="Pending", Reason="", readiness=false. Elapsed: 51.394981ms
Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-5hvkw": Phase="Running", Reason="", readiness=true. Elapsed: 51.921006ms
Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-5hvkw" satisfied condition "running"
Apr 22 19:03:26.506: INFO: Pod "webserver-deployment-845c8977d9-s64cn": Phase="Pending", Reason="", readiness=false. Elapsed: 51.426069ms
Apr 22 19:03:26.506: INFO: Pod "webserver-deployment-845c8977d9-q5bxj": Phase="Pending", Reason="", readiness=false. Elapsed: 53.224543ms
Apr 22 19:03:28.474: INFO: Pod "webserver-deployment-845c8977d9-vct48": Phase="Running", Reason="", readiness=true. Elapsed: 2.023094969s
Apr 22 19:03:28.474: INFO: Pod "webserver-deployment-845c8977d9-vct48" satisfied condition "running"
Apr 22 19:03:28.486: INFO: Pod "webserver-deployment-845c8977d9-2g585": Phase="Running", Reason="", readiness=true. Elapsed: 2.036265159s
Apr 22 19:03:28.486: INFO: Pod "webserver-deployment-845c8977d9-2g585" satisfied condition "running"
Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-r4jtg": Phase="Running", Reason="", readiness=true. Elapsed: 2.063198369s
Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-r4jtg" satisfied condition "running"
Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-fj9lv": Phase="Running", Reason="", readiness=true. Elapsed: 2.065168723s
Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-fj9lv" satisfied condition "running"
Apr 22 19:03:28.523: INFO: Pod "webserver-deployment-845c8977d9-q5bxj": Phase="Running", Reason="", readiness=true. Elapsed: 2.070724269s
Apr 22 19:03:28.523: INFO: Pod "webserver-deployment-845c8977d9-q5bxj" satisfied condition "running"
Apr 22 19:03:28.524: INFO: Pod "webserver-deployment-845c8977d9-clqv4": Phase="Running", Reason="", readiness=true. Elapsed: 2.072799129s
Apr 22 19:03:28.524: INFO: Pod "webserver-deployment-845c8977d9-clqv4" satisfied condition "running"
Apr 22 19:03:28.526: INFO: Pod "webserver-deployment-845c8977d9-fwmkn": Phase="Running", Reason="", readiness=true. Elapsed: 2.073557839s
Apr 22 19:03:28.526: INFO: Pod "webserver-deployment-845c8977d9-fwmkn" satisfied condition "running"
Apr 22 19:03:28.528: INFO: Pod "webserver-deployment-845c8977d9-s64cn": Phase="Running", Reason="", readiness=true. Elapsed: 2.074132533s
Apr 22 19:03:28.529: INFO: Pod "webserver-deployment-845c8977d9-s64cn" satisfied condition "running"
Apr 22 19:03:28.529: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 22 19:03:28.547: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 22 19:03:28.585: INFO: Updating deployment webserver-deployment
Apr 22 19:03:28.585: INFO: Waiting for observed generation 2
Apr 22 19:03:30.606: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 22 19:03:30.615: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 22 19:03:30.625: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 22 19:03:30.655: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 22 19:03:30.655: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 22 19:03:30.667: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 22 19:03:30.686: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 22 19:03:30.686: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 22 19:03:30.717: INFO: Updating deployment webserver-deployment
Apr 22 19:03:30.717: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 22 19:03:30.749: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 22 19:03:30.756: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:03:32.791: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7148  45a25c6c-d1e0-4ead-baaf-7d322e021ca6 4664 3 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:03:30 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-22 19:03:30 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 22 19:03:32.805: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-7148  9ffa1861-c3e9-4aaa-b0e8-2e611961053f 4656 3 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 45a25c6c-d1e0-4ead-baaf-7d322e021ca6 0xc003a82d07 0xc003a82d08}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"45a25c6c-d1e0-4ead-baaf-7d322e021ca6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:03:32.805: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 22 19:03:32.805: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-7148  58a019e7-a0bb-428d-8aa0-1d2433237236 4657 3 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 45a25c6c-d1e0-4ead-baaf-7d322e021ca6 0xc003a82e17 0xc003a82e18}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"45a25c6c-d1e0-4ead-baaf-7d322e021ca6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82ea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:03:32.821: INFO: Pod "webserver-deployment-69b7448995-5j7nk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5j7nk webserver-deployment-69b7448995- deployment-7148  a35c3afa-5f5d-4723-a767-880e7aecfb5c 4647 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc003c1be50 0xc003c1be51}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sg5xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sg5xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-7nmp6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7nmp6 webserver-deployment-69b7448995- deployment-7148  145c43de-49b4-45aa-9227-c0178d9320c9 4644 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc003c1bfb0 0xc003c1bfb1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hrdp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hrdp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-9qplj" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9qplj webserver-deployment-69b7448995- deployment-7148  cb523788-35e0-4be2-b75b-2801ba9983de 4528 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2110 0xc0037e2111}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jbqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jbqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-gqjd8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-gqjd8 webserver-deployment-69b7448995- deployment-7148  0b5a2701-d6ac-4cd0-9e66-5265f3433eae 4596 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e22e0 0xc0037e22e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.9\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hvnsq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hvnsq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.9,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-j5r95" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-j5r95 webserver-deployment-69b7448995- deployment-7148  79d995d3-8cc0-4ca2-968e-872a922cb318 4645 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e24e0 0xc0037e24e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xrgkx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xrgkx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-lncns" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lncns webserver-deployment-69b7448995- deployment-7148  123ae0e7-4058-483d-9b61-266106bf4828 4682 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2640 0xc0037e2641}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qtmpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qtmpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.3,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-lrg46" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lrg46 webserver-deployment-69b7448995- deployment-7148  97091e6c-4f91-4569-8a81-c3cadf96d5e4 4623 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2840 0xc0037e2841}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-scm8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-scm8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-np2nc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-np2nc webserver-deployment-69b7448995- deployment-7148  ac41b102-35f3-4fb9-b5d7-54138177eba4 4553 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e29a0 0xc0037e29a1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qgszq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qgszq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-pd6wd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pd6wd webserver-deployment-69b7448995- deployment-7148  b8a3d4aa-9a37-4bbe-875f-8853cdef67d1 4652 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2b80 0xc0037e2b81}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-62jdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-62jdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-sx7xr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sx7xr webserver-deployment-69b7448995- deployment-7148  30fa4d0f-6e82-40af-9ea6-593a3c3a7845 4684 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2ce0 0xc0037e2ce1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7f76j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7f76j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:03:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-sxbqn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sxbqn webserver-deployment-69b7448995- deployment-7148  0755a2c8-4264-4fed-873f-a4469174a499 4620 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2ec0 0xc0037e2ec1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkbbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkbbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-twxh7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-twxh7 webserver-deployment-69b7448995- deployment-7148  a8880f01-7948-4bf1-8b15-b2dc905922ae 4589 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e3030 0xc0037e3031}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtqmv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtqmv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.6,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-wqf7r" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wqf7r webserver-deployment-69b7448995- deployment-7148  ffd8d10c-ace6-4ba2-bcb0-50c8ea708b19 4646 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e3230 0xc0037e3231}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g9v77,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g9v77,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-845c8977d9-46hsj" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-46hsj webserver-deployment-845c8977d9- deployment-7148  c6d81260-2511-4f3a-b389-7c0d5781cb0e 4641 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3390 0xc0037e3391}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2qs8w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2qs8w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-4gsqc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4gsqc webserver-deployment-845c8977d9- deployment-7148  c4934f77-b688-4734-9375-707fa6acc163 4640 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e34e0 0xc0037e34e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6t9zl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6t9zl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-5hvkw" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5hvkw webserver-deployment-845c8977d9- deployment-7148  46cbe312-e756-4cd4-bb6d-54f5f303c5ed 4467 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3660 0xc0037e3661}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q6gsx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q6gsx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.4,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://56be32b01395679a8cf015f584327ee191508574deed71519d8c62ab8e0243d0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-6862s" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6862s webserver-deployment-845c8977d9- deployment-7148  6075722f-4b42-456e-9a82-fdef313dad40 4629 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3890 0xc0037e3891}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2vccc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2vccc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-bpmbl" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bpmbl webserver-deployment-845c8977d9- deployment-7148  c22b2596-3bb8-46ea-b58c-aba378eb1ecc 4643 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e39e0 0xc0037e39e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2wmkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2wmkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-btf9z" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-btf9z webserver-deployment-845c8977d9- deployment-7148  c6bfee94-5946-4ff1-9539-b224605e7f2f 4456 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3b40 0xc0037e3b41}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fmfn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fmfn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.5,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8f9c68ec12ada4e9b18a3bf4905a22d7caaf37c351c61e1229b0a4ba4f575788,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-cbtl2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cbtl2 webserver-deployment-845c8977d9- deployment-7148  50ffe79c-094d-4cdb-b04c-e9665c8ae732 4616 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3d20 0xc0037e3d21}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57l4w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57l4w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-clqv4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-clqv4 webserver-deployment-845c8977d9- deployment-7148  6347933e-27d6-4629-b65e-6c0dcd6f9528 4492 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3e70 0xc0037e3e71}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4rzk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4rzk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.8,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd3669a4d60f85f04a50bffbef6719e249df22095cd70f4b59bf5dc118494c59,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-csz4w" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-csz4w webserver-deployment-845c8977d9- deployment-7148  398f7837-1211-498a-a0eb-6ea6dc59f3c2 4633 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c040 0xc00378c041}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-72ccc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-72ccc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-d66jg" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-d66jg webserver-deployment-845c8977d9- deployment-7148  b58f8540-8b6c-43af-943e-bd415565ecd8 4608 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c190 0xc00378c191}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gj5wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gj5wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-fj9lv" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fj9lv webserver-deployment-845c8977d9- deployment-7148  bfaa5367-f7b7-4786-9ae6-21b79d038e69 4480 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c2e0 0xc00378c2e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sl5mw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sl5mw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.6,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7ab1df1c633f6fe8a3e90f520fdb4a89ade0d84cd6e186e885b384062df99887,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-fwmkn" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fwmkn webserver-deployment-845c8977d9- deployment-7148  04755b71-8099-4ba9-a1ba-9cb994ed3428 4486 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c4b0 0xc00378c4b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-66pf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-66pf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.8,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2e2089cf8c2653e8b9af7bed577e880648da6050f9db387b596bdc38f2d349c8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-gxnrb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gxnrb webserver-deployment-845c8977d9- deployment-7148  a3926050-c6c7-4f84-9140-3a9fcc7c5f29 4638 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c680 0xc00378c681}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xdhlq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xdhlq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-jmc2t" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jmc2t webserver-deployment-845c8977d9- deployment-7148  13f28467-9c92-4d8a-90ab-8da7a974d55f 4639 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c7d0 0xc00378c7d1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xbzc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xbzc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-lmvpq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lmvpq webserver-deployment-845c8977d9- deployment-7148  59b184dc-766b-4b94-9710-fc11fc291332 4636 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c920 0xc00378c921}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h49v4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h49v4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-n5z99" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n5z99 webserver-deployment-845c8977d9- deployment-7148  1496687b-5ec6-4994-8fd9-41639b9d14cf 4637 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378ca70 0xc00378ca71}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pxhv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pxhv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-q5bxj" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-q5bxj webserver-deployment-845c8977d9- deployment-7148  b51c8999-ab07-4d4f-b959-3bceafe20185 4473 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cbc0 0xc00378cbc1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4s6wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4s6wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.5,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://23b6b612cb547018af74c695eb6edbf2209ff7636463e48ee2a0b56260320f05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-r4jtg" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-r4jtg webserver-deployment-845c8977d9- deployment-7148  605fbb34-6fca-4363-80eb-de3ce56284c5 4472 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cd90 0xc00378cd91}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hbns6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hbns6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.7,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6daf0165b6858c1c34f1a7b411b1328f61e7356aa9c085f266a6fef036125828,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-rf7wm" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rf7wm webserver-deployment-845c8977d9- deployment-7148  920ae10c-fbf3-4aca-980d-c131ffc0fe7b 4618 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cf60 0xc00378cf61}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27428,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27428,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:03:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:03:32.832: INFO: Pod "webserver-deployment-845c8977d9-vct48" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vct48 webserver-deployment-845c8977d9- deployment-7148  ead3d9f5-26f2-42f6-8171-4689906367b5 4481 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378d110 0xc00378d111}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-68bwz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68bwz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.7,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8ed64319a5d8d061b14e789d770b87e4bfa64cd55fc6cd17bdd4b8983ed241f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:03:32.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7148" for this suite. 04/22/23 19:03:32.84
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":33,"skipped":653,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.486 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:24.37
    Apr 22 19:03:24.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:03:24.371
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:24.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:24.406
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 22 19:03:24.410: INFO: Creating deployment "webserver-deployment"
    Apr 22 19:03:24.419: INFO: Waiting for observed generation 1
    Apr 22 19:03:26.434: INFO: Waiting for all required pods to come up
    Apr 22 19:03:26.449: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/22/23 19:03:26.449
    Apr 22 19:03:26.450: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2g585" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.450: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vct48" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.451: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-5hvkw" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.451: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-clqv4" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.452: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fj9lv" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.452: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fwmkn" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.453: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q5bxj" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.453: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-r4jtg" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.454: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-s64cn" in namespace "deployment-7148" to be "running"
    Apr 22 19:03:26.463: INFO: Pod "webserver-deployment-845c8977d9-vct48": Phase="Pending", Reason="", readiness=false. Elapsed: 12.846163ms
    Apr 22 19:03:26.477: INFO: Pod "webserver-deployment-845c8977d9-2g585": Phase="Pending", Reason="", readiness=false. Elapsed: 27.302415ms
    Apr 22 19:03:26.500: INFO: Pod "webserver-deployment-845c8977d9-r4jtg": Phase="Pending", Reason="", readiness=false. Elapsed: 46.711853ms
    Apr 22 19:03:26.500: INFO: Pod "webserver-deployment-845c8977d9-fj9lv": Phase="Pending", Reason="", readiness=false. Elapsed: 48.299502ms
    Apr 22 19:03:26.502: INFO: Pod "webserver-deployment-845c8977d9-fwmkn": Phase="Pending", Reason="", readiness=false. Elapsed: 49.690713ms
    Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-clqv4": Phase="Pending", Reason="", readiness=false. Elapsed: 51.394981ms
    Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-5hvkw": Phase="Running", Reason="", readiness=true. Elapsed: 51.921006ms
    Apr 22 19:03:26.503: INFO: Pod "webserver-deployment-845c8977d9-5hvkw" satisfied condition "running"
    Apr 22 19:03:26.506: INFO: Pod "webserver-deployment-845c8977d9-s64cn": Phase="Pending", Reason="", readiness=false. Elapsed: 51.426069ms
    Apr 22 19:03:26.506: INFO: Pod "webserver-deployment-845c8977d9-q5bxj": Phase="Pending", Reason="", readiness=false. Elapsed: 53.224543ms
    Apr 22 19:03:28.474: INFO: Pod "webserver-deployment-845c8977d9-vct48": Phase="Running", Reason="", readiness=true. Elapsed: 2.023094969s
    Apr 22 19:03:28.474: INFO: Pod "webserver-deployment-845c8977d9-vct48" satisfied condition "running"
    Apr 22 19:03:28.486: INFO: Pod "webserver-deployment-845c8977d9-2g585": Phase="Running", Reason="", readiness=true. Elapsed: 2.036265159s
    Apr 22 19:03:28.486: INFO: Pod "webserver-deployment-845c8977d9-2g585" satisfied condition "running"
    Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-r4jtg": Phase="Running", Reason="", readiness=true. Elapsed: 2.063198369s
    Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-r4jtg" satisfied condition "running"
    Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-fj9lv": Phase="Running", Reason="", readiness=true. Elapsed: 2.065168723s
    Apr 22 19:03:28.517: INFO: Pod "webserver-deployment-845c8977d9-fj9lv" satisfied condition "running"
    Apr 22 19:03:28.523: INFO: Pod "webserver-deployment-845c8977d9-q5bxj": Phase="Running", Reason="", readiness=true. Elapsed: 2.070724269s
    Apr 22 19:03:28.523: INFO: Pod "webserver-deployment-845c8977d9-q5bxj" satisfied condition "running"
    Apr 22 19:03:28.524: INFO: Pod "webserver-deployment-845c8977d9-clqv4": Phase="Running", Reason="", readiness=true. Elapsed: 2.072799129s
    Apr 22 19:03:28.524: INFO: Pod "webserver-deployment-845c8977d9-clqv4" satisfied condition "running"
    Apr 22 19:03:28.526: INFO: Pod "webserver-deployment-845c8977d9-fwmkn": Phase="Running", Reason="", readiness=true. Elapsed: 2.073557839s
    Apr 22 19:03:28.526: INFO: Pod "webserver-deployment-845c8977d9-fwmkn" satisfied condition "running"
    Apr 22 19:03:28.528: INFO: Pod "webserver-deployment-845c8977d9-s64cn": Phase="Running", Reason="", readiness=true. Elapsed: 2.074132533s
    Apr 22 19:03:28.529: INFO: Pod "webserver-deployment-845c8977d9-s64cn" satisfied condition "running"
    Apr 22 19:03:28.529: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 22 19:03:28.547: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 22 19:03:28.585: INFO: Updating deployment webserver-deployment
    Apr 22 19:03:28.585: INFO: Waiting for observed generation 2
    Apr 22 19:03:30.606: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 22 19:03:30.615: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 22 19:03:30.625: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 22 19:03:30.655: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 22 19:03:30.655: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 22 19:03:30.667: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 22 19:03:30.686: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 22 19:03:30.686: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 22 19:03:30.717: INFO: Updating deployment webserver-deployment
    Apr 22 19:03:30.717: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 22 19:03:30.749: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 22 19:03:30.756: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:03:32.791: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-7148  45a25c6c-d1e0-4ead-baaf-7d322e021ca6 4664 3 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:03:30 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-22 19:03:30 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Apr 22 19:03:32.805: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-7148  9ffa1861-c3e9-4aaa-b0e8-2e611961053f 4656 3 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 45a25c6c-d1e0-4ead-baaf-7d322e021ca6 0xc003a82d07 0xc003a82d08}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"45a25c6c-d1e0-4ead-baaf-7d322e021ca6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:03:32.805: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 22 19:03:32.805: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-7148  58a019e7-a0bb-428d-8aa0-1d2433237236 4657 3 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 45a25c6c-d1e0-4ead-baaf-7d322e021ca6 0xc003a82e17 0xc003a82e18}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"45a25c6c-d1e0-4ead-baaf-7d322e021ca6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a82ea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:03:32.821: INFO: Pod "webserver-deployment-69b7448995-5j7nk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5j7nk webserver-deployment-69b7448995- deployment-7148  a35c3afa-5f5d-4723-a767-880e7aecfb5c 4647 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc003c1be50 0xc003c1be51}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sg5xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sg5xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-7nmp6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7nmp6 webserver-deployment-69b7448995- deployment-7148  145c43de-49b4-45aa-9227-c0178d9320c9 4644 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc003c1bfb0 0xc003c1bfb1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hrdp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hrdp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-9qplj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9qplj webserver-deployment-69b7448995- deployment-7148  cb523788-35e0-4be2-b75b-2801ba9983de 4528 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2110 0xc0037e2111}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jbqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jbqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.823: INFO: Pod "webserver-deployment-69b7448995-gqjd8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-gqjd8 webserver-deployment-69b7448995- deployment-7148  0b5a2701-d6ac-4cd0-9e66-5265f3433eae 4596 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e22e0 0xc0037e22e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.9\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hvnsq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hvnsq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.9,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-j5r95" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-j5r95 webserver-deployment-69b7448995- deployment-7148  79d995d3-8cc0-4ca2-968e-872a922cb318 4645 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e24e0 0xc0037e24e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xrgkx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xrgkx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-lncns" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lncns webserver-deployment-69b7448995- deployment-7148  123ae0e7-4058-483d-9b61-266106bf4828 4682 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2640 0xc0037e2641}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qtmpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qtmpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.3,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.824: INFO: Pod "webserver-deployment-69b7448995-lrg46" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lrg46 webserver-deployment-69b7448995- deployment-7148  97091e6c-4f91-4569-8a81-c3cadf96d5e4 4623 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2840 0xc0037e2841}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-scm8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-scm8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-np2nc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-np2nc webserver-deployment-69b7448995- deployment-7148  ac41b102-35f3-4fb9-b5d7-54138177eba4 4553 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e29a0 0xc0037e29a1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qgszq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qgszq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-pd6wd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pd6wd webserver-deployment-69b7448995- deployment-7148  b8a3d4aa-9a37-4bbe-875f-8853cdef67d1 4652 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2b80 0xc0037e2b81}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-62jdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-62jdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.825: INFO: Pod "webserver-deployment-69b7448995-sx7xr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sx7xr webserver-deployment-69b7448995- deployment-7148  30fa4d0f-6e82-40af-9ea6-593a3c3a7845 4684 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2ce0 0xc0037e2ce1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7f76j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7f76j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:03:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-sxbqn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sxbqn webserver-deployment-69b7448995- deployment-7148  0755a2c8-4264-4fed-873f-a4469174a499 4620 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e2ec0 0xc0037e2ec1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkbbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkbbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-twxh7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-twxh7 webserver-deployment-69b7448995- deployment-7148  a8880f01-7948-4bf1-8b15-b2dc905922ae 4589 0 2023-04-22 19:03:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e3030 0xc0037e3031}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtqmv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtqmv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.6,StartTime:2023-04-22 19:03:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-69b7448995-wqf7r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wqf7r webserver-deployment-69b7448995- deployment-7148  ffd8d10c-ace6-4ba2-bcb0-50c8ea708b19 4646 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9ffa1861-c3e9-4aaa-b0e8-2e611961053f 0xc0037e3230 0xc0037e3231}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ffa1861-c3e9-4aaa-b0e8-2e611961053f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g9v77,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g9v77,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.826: INFO: Pod "webserver-deployment-845c8977d9-46hsj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-46hsj webserver-deployment-845c8977d9- deployment-7148  c6d81260-2511-4f3a-b389-7c0d5781cb0e 4641 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3390 0xc0037e3391}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2qs8w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2qs8w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-4gsqc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4gsqc webserver-deployment-845c8977d9- deployment-7148  c4934f77-b688-4734-9375-707fa6acc163 4640 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e34e0 0xc0037e34e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6t9zl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6t9zl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-5hvkw" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5hvkw webserver-deployment-845c8977d9- deployment-7148  46cbe312-e756-4cd4-bb6d-54f5f303c5ed 4467 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3660 0xc0037e3661}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q6gsx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q6gsx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.4,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://56be32b01395679a8cf015f584327ee191508574deed71519d8c62ab8e0243d0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-6862s" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6862s webserver-deployment-845c8977d9- deployment-7148  6075722f-4b42-456e-9a82-fdef313dad40 4629 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3890 0xc0037e3891}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2vccc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2vccc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.827: INFO: Pod "webserver-deployment-845c8977d9-bpmbl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bpmbl webserver-deployment-845c8977d9- deployment-7148  c22b2596-3bb8-46ea-b58c-aba378eb1ecc 4643 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e39e0 0xc0037e39e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2wmkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2wmkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-btf9z" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-btf9z webserver-deployment-845c8977d9- deployment-7148  c6bfee94-5946-4ff1-9539-b224605e7f2f 4456 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3b40 0xc0037e3b41}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fmfn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fmfn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.5,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8f9c68ec12ada4e9b18a3bf4905a22d7caaf37c351c61e1229b0a4ba4f575788,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-cbtl2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cbtl2 webserver-deployment-845c8977d9- deployment-7148  50ffe79c-094d-4cdb-b04c-e9665c8ae732 4616 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3d20 0xc0037e3d21}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57l4w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57l4w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.828: INFO: Pod "webserver-deployment-845c8977d9-clqv4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-clqv4 webserver-deployment-845c8977d9- deployment-7148  6347933e-27d6-4629-b65e-6c0dcd6f9528 4492 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc0037e3e70 0xc0037e3e71}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4rzk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4rzk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.8,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd3669a4d60f85f04a50bffbef6719e249df22095cd70f4b59bf5dc118494c59,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-csz4w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-csz4w webserver-deployment-845c8977d9- deployment-7148  398f7837-1211-498a-a0eb-6ea6dc59f3c2 4633 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c040 0xc00378c041}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-72ccc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-72ccc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-d66jg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-d66jg webserver-deployment-845c8977d9- deployment-7148  b58f8540-8b6c-43af-943e-bd415565ecd8 4608 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c190 0xc00378c191}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gj5wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gj5wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-fj9lv" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fj9lv webserver-deployment-845c8977d9- deployment-7148  bfaa5367-f7b7-4786-9ae6-21b79d038e69 4480 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c2e0 0xc00378c2e1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sl5mw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sl5mw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.6,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7ab1df1c633f6fe8a3e90f520fdb4a89ade0d84cd6e186e885b384062df99887,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.829: INFO: Pod "webserver-deployment-845c8977d9-fwmkn" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fwmkn webserver-deployment-845c8977d9- deployment-7148  04755b71-8099-4ba9-a1ba-9cb994ed3428 4486 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c4b0 0xc00378c4b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-66pf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-66pf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.8,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2e2089cf8c2653e8b9af7bed577e880648da6050f9db387b596bdc38f2d349c8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-gxnrb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gxnrb webserver-deployment-845c8977d9- deployment-7148  a3926050-c6c7-4f84-9140-3a9fcc7c5f29 4638 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c680 0xc00378c681}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xdhlq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xdhlq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-jmc2t" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jmc2t webserver-deployment-845c8977d9- deployment-7148  13f28467-9c92-4d8a-90ab-8da7a974d55f 4639 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c7d0 0xc00378c7d1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xbzc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xbzc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-lmvpq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lmvpq webserver-deployment-845c8977d9- deployment-7148  59b184dc-766b-4b94-9710-fc11fc291332 4636 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378c920 0xc00378c921}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h49v4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h49v4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.830: INFO: Pod "webserver-deployment-845c8977d9-n5z99" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n5z99 webserver-deployment-845c8977d9- deployment-7148  1496687b-5ec6-4994-8fd9-41639b9d14cf 4637 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378ca70 0xc00378ca71}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pxhv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pxhv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-q5bxj" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-q5bxj webserver-deployment-845c8977d9- deployment-7148  b51c8999-ab07-4d4f-b959-3bceafe20185 4473 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cbc0 0xc00378cbc1}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4s6wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4s6wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.5,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://23b6b612cb547018af74c695eb6edbf2209ff7636463e48ee2a0b56260320f05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-r4jtg" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-r4jtg webserver-deployment-845c8977d9- deployment-7148  605fbb34-6fca-4363-80eb-de3ce56284c5 4472 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cd90 0xc00378cd91}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hbns6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hbns6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.7,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6daf0165b6858c1c34f1a7b411b1328f61e7356aa9c085f266a6fef036125828,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.831: INFO: Pod "webserver-deployment-845c8977d9-rf7wm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rf7wm webserver-deployment-845c8977d9- deployment-7148  920ae10c-fbf3-4aca-980d-c131ffc0fe7b 4618 0 2023-04-22 19:03:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378cf60 0xc00378cf61}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27428,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27428,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:03:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:03:32.832: INFO: Pod "webserver-deployment-845c8977d9-vct48" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vct48 webserver-deployment-845c8977d9- deployment-7148  ead3d9f5-26f2-42f6-8171-4689906367b5 4481 0 2023-04-22 19:03:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 58a019e7-a0bb-428d-8aa0-1d2433237236 0xc00378d110 0xc00378d111}] [] [{kube-controller-manager Update v1 2023-04-22 19:03:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"58a019e7-a0bb-428d-8aa0-1d2433237236\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:03:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-68bwz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68bwz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:03:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.7,StartTime:2023-04-22 19:03:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:03:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8ed64319a5d8d061b14e789d770b87e4bfa64cd55fc6cd17bdd4b8983ed241f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:03:32.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7148" for this suite. 04/22/23 19:03:32.84
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:32.863
Apr 22 19:03:32.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:03:32.864
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:32.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:32.892
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 04/22/23 19:03:32.899
STEP: fetching the ConfigMap 04/22/23 19:03:32.906
STEP: patching the ConfigMap 04/22/23 19:03:32.911
STEP: listing all ConfigMaps in all namespaces with a label selector 04/22/23 19:03:32.918
STEP: deleting the ConfigMap by collection with a label selector 04/22/23 19:03:32.923
STEP: listing all ConfigMaps in test namespace 04/22/23 19:03:32.933
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:03:32.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8761" for this suite. 04/22/23 19:03:32.942
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":34,"skipped":666,"failed":0}
------------------------------
â€¢ [0.091 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:32.863
    Apr 22 19:03:32.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:03:32.864
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:32.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:32.892
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 04/22/23 19:03:32.899
    STEP: fetching the ConfigMap 04/22/23 19:03:32.906
    STEP: patching the ConfigMap 04/22/23 19:03:32.911
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/22/23 19:03:32.918
    STEP: deleting the ConfigMap by collection with a label selector 04/22/23 19:03:32.923
    STEP: listing all ConfigMaps in test namespace 04/22/23 19:03:32.933
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:03:32.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8761" for this suite. 04/22/23 19:03:32.942
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:32.97
Apr 22 19:03:32.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:03:32.974
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:32.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:33.002
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-9d183b56-9961-41ba-9c0b-99de79d62914 04/22/23 19:03:33.006
STEP: Creating a pod to test consume secrets 04/22/23 19:03:33.012
Apr 22 19:03:33.021: INFO: Waiting up to 5m0s for pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a" in namespace "secrets-879" to be "Succeeded or Failed"
Apr 22 19:03:33.026: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.664168ms
Apr 22 19:03:35.035: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014266343s
Apr 22 19:03:37.034: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013438738s
Apr 22 19:03:39.035: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014439269s
Apr 22 19:03:41.034: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013037973s
Apr 22 19:03:43.036: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.014606931s
STEP: Saw pod success 04/22/23 19:03:43.036
Apr 22 19:03:43.036: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a" satisfied condition "Succeeded or Failed"
Apr 22 19:03:43.046: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a container secret-env-test: <nil>
STEP: delete the pod 04/22/23 19:03:43.086
Apr 22 19:03:43.134: INFO: Waiting for pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a to disappear
Apr 22 19:03:43.142: INFO: Pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:03:43.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-879" for this suite. 04/22/23 19:03:43.155
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":35,"skipped":693,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.207 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:32.97
    Apr 22 19:03:32.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:03:32.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:32.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:33.002
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-9d183b56-9961-41ba-9c0b-99de79d62914 04/22/23 19:03:33.006
    STEP: Creating a pod to test consume secrets 04/22/23 19:03:33.012
    Apr 22 19:03:33.021: INFO: Waiting up to 5m0s for pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a" in namespace "secrets-879" to be "Succeeded or Failed"
    Apr 22 19:03:33.026: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.664168ms
    Apr 22 19:03:35.035: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014266343s
    Apr 22 19:03:37.034: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013438738s
    Apr 22 19:03:39.035: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014439269s
    Apr 22 19:03:41.034: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013037973s
    Apr 22 19:03:43.036: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.014606931s
    STEP: Saw pod success 04/22/23 19:03:43.036
    Apr 22 19:03:43.036: INFO: Pod "pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a" satisfied condition "Succeeded or Failed"
    Apr 22 19:03:43.046: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a container secret-env-test: <nil>
    STEP: delete the pod 04/22/23 19:03:43.086
    Apr 22 19:03:43.134: INFO: Waiting for pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a to disappear
    Apr 22 19:03:43.142: INFO: Pod pod-secrets-01d7f186-efaa-4362-85bc-6a0b05c6645a no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:03:43.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-879" for this suite. 04/22/23 19:03:43.155
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:43.19
Apr 22 19:03:43.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:03:43.193
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:43.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:43.242
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 04/22/23 19:03:43.254
Apr 22 19:03:43.271: INFO: Waiting up to 5m0s for pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50" in namespace "emptydir-6816" to be "Succeeded or Failed"
Apr 22 19:03:43.282: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 10.214595ms
Apr 22 19:03:45.292: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020224044s
Apr 22 19:03:47.290: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018398561s
Apr 22 19:03:49.292: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020335499s
STEP: Saw pod success 04/22/23 19:03:49.293
Apr 22 19:03:49.294: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50" satisfied condition "Succeeded or Failed"
Apr 22 19:03:49.303: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 container test-container: <nil>
STEP: delete the pod 04/22/23 19:03:49.322
Apr 22 19:03:49.383: INFO: Waiting for pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 to disappear
Apr 22 19:03:49.390: INFO: Pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:03:49.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6816" for this suite. 04/22/23 19:03:49.403
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":36,"skipped":704,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.229 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:43.19
    Apr 22 19:03:43.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:03:43.193
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:43.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:43.242
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/22/23 19:03:43.254
    Apr 22 19:03:43.271: INFO: Waiting up to 5m0s for pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50" in namespace "emptydir-6816" to be "Succeeded or Failed"
    Apr 22 19:03:43.282: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 10.214595ms
    Apr 22 19:03:45.292: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020224044s
    Apr 22 19:03:47.290: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018398561s
    Apr 22 19:03:49.292: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020335499s
    STEP: Saw pod success 04/22/23 19:03:49.293
    Apr 22 19:03:49.294: INFO: Pod "pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50" satisfied condition "Succeeded or Failed"
    Apr 22 19:03:49.303: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:03:49.322
    Apr 22 19:03:49.383: INFO: Waiting for pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 to disappear
    Apr 22 19:03:49.390: INFO: Pod pod-3b91eead-9709-4b93-9c9d-8f1ad4b82d50 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:03:49.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6816" for this suite. 04/22/23 19:03:49.403
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:03:49.445
Apr 22 19:03:49.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-watch 04/22/23 19:03:49.448
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:49.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:49.529
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 22 19:03:49.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Creating first CR  04/22/23 19:03:52.167
Apr 22 19:03:52.180: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:03:52Z]] name:name1 resourceVersion:5085 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/22/23 19:04:02.181
Apr 22 19:04:02.197: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:02Z]] name:name2 resourceVersion:5121 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/22/23 19:04:12.198
Apr 22 19:04:12.217: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:12Z]] name:name1 resourceVersion:5145 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/22/23 19:04:22.217
Apr 22 19:04:22.247: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:22Z]] name:name2 resourceVersion:5172 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/22/23 19:04:32.248
Apr 22 19:04:32.270: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:12Z]] name:name1 resourceVersion:5199 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/22/23 19:04:42.271
Apr 22 19:04:42.291: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:22Z]] name:name2 resourceVersion:5226 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:04:52.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6480" for this suite. 04/22/23 19:04:52.852
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":37,"skipped":719,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.425 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:03:49.445
    Apr 22 19:03:49.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-watch 04/22/23 19:03:49.448
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:03:49.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:03:49.529
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 22 19:03:49.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Creating first CR  04/22/23 19:03:52.167
    Apr 22 19:03:52.180: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:03:52Z]] name:name1 resourceVersion:5085 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/22/23 19:04:02.181
    Apr 22 19:04:02.197: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:02Z]] name:name2 resourceVersion:5121 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/22/23 19:04:12.198
    Apr 22 19:04:12.217: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:12Z]] name:name1 resourceVersion:5145 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/22/23 19:04:22.217
    Apr 22 19:04:22.247: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:22Z]] name:name2 resourceVersion:5172 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/22/23 19:04:32.248
    Apr 22 19:04:32.270: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:03:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:12Z]] name:name1 resourceVersion:5199 uid:a69ff3d6-5bbc-4a0b-a208-85bd5612794e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/22/23 19:04:42.271
    Apr 22 19:04:42.291: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-22T19:04:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-22T19:04:22Z]] name:name2 resourceVersion:5226 uid:cf520f52-3f2f-4e67-aa44-dacdf0a2cda9] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:04:52.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-6480" for this suite. 04/22/23 19:04:52.852
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:04:52.881
Apr 22 19:04:52.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:04:52.885
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:04:52.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:04:52.932
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/22/23 19:04:52.942
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local;sleep 1; done
 04/22/23 19:04:52.95
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local;sleep 1; done
 04/22/23 19:04:52.95
STEP: creating a pod to probe DNS 04/22/23 19:04:52.95
STEP: submitting the pod to kubernetes 04/22/23 19:04:52.951
Apr 22 19:04:52.967: INFO: Waiting up to 15m0s for pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d" in namespace "dns-5878" to be "running"
Apr 22 19:04:52.975: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.926905ms
Apr 22 19:04:54.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018020737s
Apr 22 19:04:56.984: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017097249s
Apr 22 19:04:58.986: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019138745s
Apr 22 19:05:00.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017873634s
Apr 22 19:05:02.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Running", Reason="", readiness=true. Elapsed: 10.01794819s
Apr 22 19:05:02.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:05:02.985
STEP: looking for the results for each expected name from probers 04/22/23 19:05:02.994
Apr 22 19:05:03.017: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.027: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.038: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.050: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.061: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.071: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.080: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.093: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:03.094: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

Apr 22 19:05:08.110: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.120: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.130: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.139: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.149: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.159: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.167: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.179: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:08.179: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

Apr 22 19:05:13.108: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.119: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.129: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.141: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.150: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.160: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.171: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.182: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:13.183: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

Apr 22 19:05:18.106: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.114: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.122: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.130: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.138: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.156: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.167: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:18.168: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

Apr 22 19:05:23.109: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.120: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.132: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.141: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.150: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.165: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.175: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.186: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
Apr 22 19:05:23.187: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

Apr 22 19:05:28.188: INFO: DNS probes using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d succeeded

STEP: deleting the pod 04/22/23 19:05:28.188
STEP: deleting the test headless service 04/22/23 19:05:28.224
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:05:28.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5878" for this suite. 04/22/23 19:05:28.267
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":38,"skipped":730,"failed":0}
------------------------------
â€¢ [SLOW TEST] [35.397 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:04:52.881
    Apr 22 19:04:52.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:04:52.885
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:04:52.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:04:52.932
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/22/23 19:04:52.942
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local;sleep 1; done
     04/22/23 19:04:52.95
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5878.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local;sleep 1; done
     04/22/23 19:04:52.95
    STEP: creating a pod to probe DNS 04/22/23 19:04:52.95
    STEP: submitting the pod to kubernetes 04/22/23 19:04:52.951
    Apr 22 19:04:52.967: INFO: Waiting up to 15m0s for pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d" in namespace "dns-5878" to be "running"
    Apr 22 19:04:52.975: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.926905ms
    Apr 22 19:04:54.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018020737s
    Apr 22 19:04:56.984: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017097249s
    Apr 22 19:04:58.986: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019138745s
    Apr 22 19:05:00.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017873634s
    Apr 22 19:05:02.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d": Phase="Running", Reason="", readiness=true. Elapsed: 10.01794819s
    Apr 22 19:05:02.985: INFO: Pod "dns-test-a9757ac8-cb03-49c8-8255-563257519a9d" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:05:02.985
    STEP: looking for the results for each expected name from probers 04/22/23 19:05:02.994
    Apr 22 19:05:03.017: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.027: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.038: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.050: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.061: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.071: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.080: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.093: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:03.094: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

    Apr 22 19:05:08.110: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.120: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.130: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.139: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.149: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.159: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.167: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.179: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:08.179: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

    Apr 22 19:05:13.108: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.119: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.129: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.141: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.150: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.160: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.171: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.182: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:13.183: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

    Apr 22 19:05:18.106: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.114: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.122: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.130: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.138: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.156: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.167: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:18.168: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

    Apr 22 19:05:23.109: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.120: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.132: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.141: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.150: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.165: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.175: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.186: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local from pod dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d: the server could not find the requested resource (get pods dns-test-a9757ac8-cb03-49c8-8255-563257519a9d)
    Apr 22 19:05:23.187: INFO: Lookups using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5878.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5878.svc.cluster.local jessie_udp@dns-test-service-2.dns-5878.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5878.svc.cluster.local]

    Apr 22 19:05:28.188: INFO: DNS probes using dns-5878/dns-test-a9757ac8-cb03-49c8-8255-563257519a9d succeeded

    STEP: deleting the pod 04/22/23 19:05:28.188
    STEP: deleting the test headless service 04/22/23 19:05:28.224
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:05:28.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5878" for this suite. 04/22/23 19:05:28.267
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:05:28.299
Apr 22 19:05:28.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:05:28.303
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:28.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:28.348
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-b0a01a5b-a519-4960-829b-9b2b0994fcf9 04/22/23 19:05:28.366
STEP: Creating the pod 04/22/23 19:05:28.374
Apr 22 19:05:28.394: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb" in namespace "projected-185" to be "running and ready"
Apr 22 19:05:28.402: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00869ms
Apr 22 19:05:28.402: INFO: The phase of Pod pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:05:30.411: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb": Phase="Running", Reason="", readiness=true. Elapsed: 2.017023791s
Apr 22 19:05:30.411: INFO: The phase of Pod pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb is Running (Ready = true)
Apr 22 19:05:30.411: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-b0a01a5b-a519-4960-829b-9b2b0994fcf9 04/22/23 19:05:30.454
STEP: waiting to observe update in volume 04/22/23 19:05:30.467
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:05:32.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-185" for this suite. 04/22/23 19:05:32.522
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":39,"skipped":769,"failed":0}
------------------------------
â€¢ [4.247 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:05:28.299
    Apr 22 19:05:28.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:05:28.303
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:28.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:28.348
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-b0a01a5b-a519-4960-829b-9b2b0994fcf9 04/22/23 19:05:28.366
    STEP: Creating the pod 04/22/23 19:05:28.374
    Apr 22 19:05:28.394: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb" in namespace "projected-185" to be "running and ready"
    Apr 22 19:05:28.402: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00869ms
    Apr 22 19:05:28.402: INFO: The phase of Pod pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:05:30.411: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb": Phase="Running", Reason="", readiness=true. Elapsed: 2.017023791s
    Apr 22 19:05:30.411: INFO: The phase of Pod pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb is Running (Ready = true)
    Apr 22 19:05:30.411: INFO: Pod "pod-projected-configmaps-08f89f42-083c-4177-8ae6-5948fb7b56fb" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-b0a01a5b-a519-4960-829b-9b2b0994fcf9 04/22/23 19:05:30.454
    STEP: waiting to observe update in volume 04/22/23 19:05:30.467
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:05:32.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-185" for this suite. 04/22/23 19:05:32.522
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:05:32.553
Apr 22 19:05:32.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:05:32.555
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:32.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:32.61
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:05:32.646
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:05:33.021
STEP: Deploying the webhook pod 04/22/23 19:05:33.036
STEP: Wait for the deployment to be ready 04/22/23 19:05:33.064
Apr 22 19:05:33.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 22 19:05:35.115: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/22/23 19:05:37.125
STEP: Verifying the service has paired with the endpoint 04/22/23 19:05:37.177
Apr 22 19:05:38.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 04/22/23 19:05:38.187
STEP: create a pod that should be denied by the webhook 04/22/23 19:05:38.241
STEP: create a pod that causes the webhook to hang 04/22/23 19:05:38.281
STEP: create a configmap that should be denied by the webhook 04/22/23 19:05:48.301
STEP: create a configmap that should be admitted by the webhook 04/22/23 19:05:48.678
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/22/23 19:05:48.697
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/22/23 19:05:48.712
STEP: create a namespace that bypass the webhook 04/22/23 19:05:48.721
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/22/23 19:05:48.732
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:05:48.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2503" for this suite. 04/22/23 19:05:48.791
STEP: Destroying namespace "webhook-2503-markers" for this suite. 04/22/23 19:05:48.8
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":40,"skipped":774,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.319 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:05:32.553
    Apr 22 19:05:32.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:05:32.555
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:32.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:32.61
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:05:32.646
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:05:33.021
    STEP: Deploying the webhook pod 04/22/23 19:05:33.036
    STEP: Wait for the deployment to be ready 04/22/23 19:05:33.064
    Apr 22 19:05:33.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 22 19:05:35.115: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 5, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/22/23 19:05:37.125
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:05:37.177
    Apr 22 19:05:38.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 04/22/23 19:05:38.187
    STEP: create a pod that should be denied by the webhook 04/22/23 19:05:38.241
    STEP: create a pod that causes the webhook to hang 04/22/23 19:05:38.281
    STEP: create a configmap that should be denied by the webhook 04/22/23 19:05:48.301
    STEP: create a configmap that should be admitted by the webhook 04/22/23 19:05:48.678
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/22/23 19:05:48.697
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/22/23 19:05:48.712
    STEP: create a namespace that bypass the webhook 04/22/23 19:05:48.721
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/22/23 19:05:48.732
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:05:48.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2503" for this suite. 04/22/23 19:05:48.791
    STEP: Destroying namespace "webhook-2503-markers" for this suite. 04/22/23 19:05:48.8
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:05:48.874
Apr 22 19:05:48.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename prestop 04/22/23 19:05:48.878
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:48.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:48.92
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-2193 04/22/23 19:05:48.973
STEP: Waiting for pods to come up. 04/22/23 19:05:48.982
Apr 22 19:05:48.982: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2193" to be "running"
Apr 22 19:05:48.990: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 7.937153ms
Apr 22 19:05:51.001: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.018371577s
Apr 22 19:05:51.001: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-2193 04/22/23 19:05:51.009
Apr 22 19:05:51.024: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2193" to be "running"
Apr 22 19:05:51.033: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 8.800811ms
Apr 22 19:05:53.054: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.029802505s
Apr 22 19:05:53.054: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/22/23 19:05:53.054
Apr 22 19:05:58.088: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/22/23 19:05:58.088
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Apr 22 19:05:58.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2193" for this suite. 04/22/23 19:05:58.147
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":41,"skipped":779,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.293 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:05:48.874
    Apr 22 19:05:48.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename prestop 04/22/23 19:05:48.878
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:48.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:48.92
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-2193 04/22/23 19:05:48.973
    STEP: Waiting for pods to come up. 04/22/23 19:05:48.982
    Apr 22 19:05:48.982: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2193" to be "running"
    Apr 22 19:05:48.990: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 7.937153ms
    Apr 22 19:05:51.001: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.018371577s
    Apr 22 19:05:51.001: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-2193 04/22/23 19:05:51.009
    Apr 22 19:05:51.024: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2193" to be "running"
    Apr 22 19:05:51.033: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 8.800811ms
    Apr 22 19:05:53.054: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.029802505s
    Apr 22 19:05:53.054: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/22/23 19:05:53.054
    Apr 22 19:05:58.088: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/22/23 19:05:58.088
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Apr 22 19:05:58.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-2193" for this suite. 04/22/23 19:05:58.147
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:05:58.169
Apr 22 19:05:58.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:05:58.172
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:58.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:58.231
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-3e852cde-9c96-4180-8eff-ed246319e578 04/22/23 19:05:58.24
STEP: Creating a pod to test consume secrets 04/22/23 19:05:58.249
Apr 22 19:05:58.268: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b" in namespace "projected-8320" to be "Succeeded or Failed"
Apr 22 19:05:58.284: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.666122ms
Apr 22 19:06:00.297: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027853177s
Apr 22 19:06:02.295: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026076535s
STEP: Saw pod success 04/22/23 19:06:02.295
Apr 22 19:06:02.296: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b" satisfied condition "Succeeded or Failed"
Apr 22 19:06:02.305: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:06:02.324
Apr 22 19:06:02.361: INFO: Waiting for pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b to disappear
Apr 22 19:06:02.372: INFO: Pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:06:02.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8320" for this suite. 04/22/23 19:06:02.384
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":42,"skipped":783,"failed":0}
------------------------------
â€¢ [4.235 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:05:58.169
    Apr 22 19:05:58.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:05:58.172
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:05:58.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:05:58.231
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-3e852cde-9c96-4180-8eff-ed246319e578 04/22/23 19:05:58.24
    STEP: Creating a pod to test consume secrets 04/22/23 19:05:58.249
    Apr 22 19:05:58.268: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b" in namespace "projected-8320" to be "Succeeded or Failed"
    Apr 22 19:05:58.284: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.666122ms
    Apr 22 19:06:00.297: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027853177s
    Apr 22 19:06:02.295: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026076535s
    STEP: Saw pod success 04/22/23 19:06:02.295
    Apr 22 19:06:02.296: INFO: Pod "pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b" satisfied condition "Succeeded or Failed"
    Apr 22 19:06:02.305: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:06:02.324
    Apr 22 19:06:02.361: INFO: Waiting for pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b to disappear
    Apr 22 19:06:02.372: INFO: Pod pod-projected-secrets-33b38792-a330-42aa-acb4-79d9a576792b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:06:02.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8320" for this suite. 04/22/23 19:06:02.384
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:06:02.41
Apr 22 19:06:02.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:06:02.413
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:06:02.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:06:02.455
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:06:02.487
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:06:02.897
STEP: Deploying the webhook pod 04/22/23 19:06:02.908
STEP: Wait for the deployment to be ready 04/22/23 19:06:02.937
Apr 22 19:06:02.955: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/22/23 19:06:04.988
STEP: Verifying the service has paired with the endpoint 04/22/23 19:06:05.022
Apr 22 19:06:06.023: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Apr 22 19:06:06.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/22/23 19:06:06.564
STEP: Creating a custom resource that should be denied by the webhook 04/22/23 19:06:06.608
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/22/23 19:06:08.691
STEP: Updating the custom resource with disallowed data should be denied 04/22/23 19:06:08.708
STEP: Deleting the custom resource should be denied 04/22/23 19:06:08.723
STEP: Remove the offending key and value from the custom resource data 04/22/23 19:06:08.735
STEP: Deleting the updated custom resource should be successful 04/22/23 19:06:08.751
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:06:09.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2175" for this suite. 04/22/23 19:06:09.311
STEP: Destroying namespace "webhook-2175-markers" for this suite. 04/22/23 19:06:09.33
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":43,"skipped":797,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.050 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:06:02.41
    Apr 22 19:06:02.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:06:02.413
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:06:02.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:06:02.455
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:06:02.487
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:06:02.897
    STEP: Deploying the webhook pod 04/22/23 19:06:02.908
    STEP: Wait for the deployment to be ready 04/22/23 19:06:02.937
    Apr 22 19:06:02.955: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/22/23 19:06:04.988
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:06:05.022
    Apr 22 19:06:06.023: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Apr 22 19:06:06.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/22/23 19:06:06.564
    STEP: Creating a custom resource that should be denied by the webhook 04/22/23 19:06:06.608
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/22/23 19:06:08.691
    STEP: Updating the custom resource with disallowed data should be denied 04/22/23 19:06:08.708
    STEP: Deleting the custom resource should be denied 04/22/23 19:06:08.723
    STEP: Remove the offending key and value from the custom resource data 04/22/23 19:06:08.735
    STEP: Deleting the updated custom resource should be successful 04/22/23 19:06:08.751
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:06:09.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2175" for this suite. 04/22/23 19:06:09.311
    STEP: Destroying namespace "webhook-2175-markers" for this suite. 04/22/23 19:06:09.33
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:06:09.471
Apr 22 19:06:09.471: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename taint-multiple-pods 04/22/23 19:06:09.475
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:06:09.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:06:09.518
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Apr 22 19:06:09.524: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 19:07:09.585: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Apr 22 19:07:09.595: INFO: Starting informer...
STEP: Starting pods... 04/22/23 19:07:09.595
Apr 22 19:07:09.846: INFO: Pod1 is running on cncf25-2-node-187aa4c0d96. Tainting Node
Apr 22 19:07:10.075: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8867" to be "running"
Apr 22 19:07:10.084: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.609689ms
Apr 22 19:07:12.093: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.017550908s
Apr 22 19:07:12.093: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 22 19:07:12.094: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8867" to be "running"
Apr 22 19:07:12.104: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.534112ms
Apr 22 19:07:12.104: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 22 19:07:12.104: INFO: Pod2 is running on cncf25-2-node-187aa4c0d96. Tainting Node
STEP: Trying to apply a taint on the Node 04/22/23 19:07:12.104
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:07:12.142
STEP: Waiting for Pod1 and Pod2 to be deleted 04/22/23 19:07:12.153
Apr 22 19:07:18.066: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 22 19:07:38.154: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:07:38.197
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:07:38.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8867" for this suite. 04/22/23 19:07:38.215
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":44,"skipped":810,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.762 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:06:09.471
    Apr 22 19:06:09.471: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename taint-multiple-pods 04/22/23 19:06:09.475
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:06:09.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:06:09.518
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Apr 22 19:06:09.524: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 19:07:09.585: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Apr 22 19:07:09.595: INFO: Starting informer...
    STEP: Starting pods... 04/22/23 19:07:09.595
    Apr 22 19:07:09.846: INFO: Pod1 is running on cncf25-2-node-187aa4c0d96. Tainting Node
    Apr 22 19:07:10.075: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8867" to be "running"
    Apr 22 19:07:10.084: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.609689ms
    Apr 22 19:07:12.093: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.017550908s
    Apr 22 19:07:12.093: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 22 19:07:12.094: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8867" to be "running"
    Apr 22 19:07:12.104: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.534112ms
    Apr 22 19:07:12.104: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 22 19:07:12.104: INFO: Pod2 is running on cncf25-2-node-187aa4c0d96. Tainting Node
    STEP: Trying to apply a taint on the Node 04/22/23 19:07:12.104
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:07:12.142
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/22/23 19:07:12.153
    Apr 22 19:07:18.066: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 22 19:07:38.154: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:07:38.197
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:07:38.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-8867" for this suite. 04/22/23 19:07:38.215
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:07:38.26
Apr 22 19:07:38.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:07:38.263
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:07:38.313
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:07:38.326
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/22/23 19:07:38.333
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_udp@PTR;check="$$(dig +tcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_tcp@PTR;sleep 1; done
 04/22/23 19:07:38.378
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_udp@PTR;check="$$(dig +tcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_tcp@PTR;sleep 1; done
 04/22/23 19:07:38.379
STEP: creating a pod to probe DNS 04/22/23 19:07:38.379
STEP: submitting the pod to kubernetes 04/22/23 19:07:38.38
Apr 22 19:07:38.394: INFO: Waiting up to 15m0s for pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184" in namespace "dns-5434" to be "running"
Apr 22 19:07:38.410: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184": Phase="Pending", Reason="", readiness=false. Elapsed: 10.327589ms
Apr 22 19:07:40.425: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184": Phase="Running", Reason="", readiness=true. Elapsed: 2.025003583s
Apr 22 19:07:40.426: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:07:40.427
STEP: looking for the results for each expected name from probers 04/22/23 19:07:40.436
Apr 22 19:07:40.453: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.463: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.473: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.483: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.554: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.583: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.596: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:40.637: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:07:45.655: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.665: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.690: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.756: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.768: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.779: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.789: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:45.831: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:07:50.652: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.662: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.673: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.684: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.736: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.757: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.768: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:50.810: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:07:55.651: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.661: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.670: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.680: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.740: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.751: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.763: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.774: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:07:55.828: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:08:00.650: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.665: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.678: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.692: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.748: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.760: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.772: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.785: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:00.829: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:08:05.659: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.668: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.678: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.687: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.746: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.756: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.768: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
Apr 22 19:08:05.828: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

Apr 22 19:08:10.820: INFO: DNS probes using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 succeeded

STEP: deleting the pod 04/22/23 19:08:10.82
STEP: deleting the test service 04/22/23 19:08:10.881
STEP: deleting the test headless service 04/22/23 19:08:10.947
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:08:10.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5434" for this suite. 04/22/23 19:08:10.978
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":45,"skipped":830,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.727 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:07:38.26
    Apr 22 19:07:38.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:07:38.263
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:07:38.313
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:07:38.326
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/22/23 19:07:38.333
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_udp@PTR;check="$$(dig +tcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_tcp@PTR;sleep 1; done
     04/22/23 19:07:38.378
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5434.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5434.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5434.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_udp@PTR;check="$$(dig +tcp +noall +answer +search 194.27.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.27.194_tcp@PTR;sleep 1; done
     04/22/23 19:07:38.379
    STEP: creating a pod to probe DNS 04/22/23 19:07:38.379
    STEP: submitting the pod to kubernetes 04/22/23 19:07:38.38
    Apr 22 19:07:38.394: INFO: Waiting up to 15m0s for pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184" in namespace "dns-5434" to be "running"
    Apr 22 19:07:38.410: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184": Phase="Pending", Reason="", readiness=false. Elapsed: 10.327589ms
    Apr 22 19:07:40.425: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184": Phase="Running", Reason="", readiness=true. Elapsed: 2.025003583s
    Apr 22 19:07:40.426: INFO: Pod "dns-test-cfc190b0-5154-4fef-8adf-704d829a7184" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:07:40.427
    STEP: looking for the results for each expected name from probers 04/22/23 19:07:40.436
    Apr 22 19:07:40.453: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.463: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.473: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.483: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.554: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.583: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.596: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:40.637: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:07:45.655: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.665: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.690: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.756: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.768: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.779: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.789: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:45.831: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:07:50.652: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.662: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.673: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.684: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.736: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.757: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.768: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:50.810: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:07:55.651: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.661: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.670: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.680: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.740: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.751: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.763: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.774: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:07:55.828: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:08:00.650: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.665: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.678: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.692: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.748: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.760: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.772: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.785: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:00.829: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:08:05.659: INFO: Unable to read wheezy_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.668: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.678: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.687: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.746: INFO: Unable to read jessie_udp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.756: INFO: Unable to read jessie_tcp@dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.768: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local from pod dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184: the server could not find the requested resource (get pods dns-test-cfc190b0-5154-4fef-8adf-704d829a7184)
    Apr 22 19:08:05.828: INFO: Lookups using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 failed for: [wheezy_udp@dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@dns-test-service.dns-5434.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_udp@dns-test-service.dns-5434.svc.cluster.local jessie_tcp@dns-test-service.dns-5434.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5434.svc.cluster.local]

    Apr 22 19:08:10.820: INFO: DNS probes using dns-5434/dns-test-cfc190b0-5154-4fef-8adf-704d829a7184 succeeded

    STEP: deleting the pod 04/22/23 19:08:10.82
    STEP: deleting the test service 04/22/23 19:08:10.881
    STEP: deleting the test headless service 04/22/23 19:08:10.947
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:08:10.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5434" for this suite. 04/22/23 19:08:10.978
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:08:11.006
Apr 22 19:08:11.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 19:08:11.007
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:08:11.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:08:11.035
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c in namespace container-probe-5694 04/22/23 19:08:11.039
Apr 22 19:08:11.050: INFO: Waiting up to 5m0s for pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c" in namespace "container-probe-5694" to be "not pending"
Apr 22 19:08:11.058: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.940854ms
Apr 22 19:08:13.070: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c": Phase="Running", Reason="", readiness=true. Elapsed: 2.020446158s
Apr 22 19:08:13.070: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c" satisfied condition "not pending"
Apr 22 19:08:13.070: INFO: Started pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c in namespace container-probe-5694
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:08:13.071
Apr 22 19:08:13.085: INFO: Initial restart count of pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c is 0
STEP: deleting the pod 04/22/23 19:12:14.348
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 19:12:14.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5694" for this suite. 04/22/23 19:12:14.421
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":46,"skipped":853,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.431 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:08:11.006
    Apr 22 19:08:11.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 19:08:11.007
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:08:11.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:08:11.035
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c in namespace container-probe-5694 04/22/23 19:08:11.039
    Apr 22 19:08:11.050: INFO: Waiting up to 5m0s for pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c" in namespace "container-probe-5694" to be "not pending"
    Apr 22 19:08:11.058: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.940854ms
    Apr 22 19:08:13.070: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c": Phase="Running", Reason="", readiness=true. Elapsed: 2.020446158s
    Apr 22 19:08:13.070: INFO: Pod "busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c" satisfied condition "not pending"
    Apr 22 19:08:13.070: INFO: Started pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c in namespace container-probe-5694
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:08:13.071
    Apr 22 19:08:13.085: INFO: Initial restart count of pod busybox-d77e6b2d-3bc6-4031-8708-4d445f172c5c is 0
    STEP: deleting the pod 04/22/23 19:12:14.348
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 19:12:14.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5694" for this suite. 04/22/23 19:12:14.421
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:14.478
Apr 22 19:12:14.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:12:14.481
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:14.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:14.56
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-0791c730-c815-48bb-81d7-8051d0738859 04/22/23 19:12:14.574
STEP: Creating secret with name s-test-opt-upd-0a439d54-da0d-49c7-a1e1-05269c167612 04/22/23 19:12:14.585
STEP: Creating the pod 04/22/23 19:12:14.594
Apr 22 19:12:14.615: INFO: Waiting up to 5m0s for pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744" in namespace "secrets-6985" to be "running and ready"
Apr 22 19:12:14.628: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744": Phase="Pending", Reason="", readiness=false. Elapsed: 13.41708ms
Apr 22 19:12:14.629: INFO: The phase of Pod pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:12:16.639: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744": Phase="Running", Reason="", readiness=true. Elapsed: 2.024375081s
Apr 22 19:12:16.640: INFO: The phase of Pod pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744 is Running (Ready = true)
Apr 22 19:12:16.640: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-0791c730-c815-48bb-81d7-8051d0738859 04/22/23 19:12:16.732
STEP: Updating secret s-test-opt-upd-0a439d54-da0d-49c7-a1e1-05269c167612 04/22/23 19:12:16.748
STEP: Creating secret with name s-test-opt-create-55d82685-4bd7-4442-815f-4417da8e4aab 04/22/23 19:12:16.768
STEP: waiting to observe update in volume 04/22/23 19:12:16.783
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:12:18.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6985" for this suite. 04/22/23 19:12:18.872
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":47,"skipped":898,"failed":0}
------------------------------
â€¢ [4.420 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:14.478
    Apr 22 19:12:14.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:12:14.481
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:14.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:14.56
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-0791c730-c815-48bb-81d7-8051d0738859 04/22/23 19:12:14.574
    STEP: Creating secret with name s-test-opt-upd-0a439d54-da0d-49c7-a1e1-05269c167612 04/22/23 19:12:14.585
    STEP: Creating the pod 04/22/23 19:12:14.594
    Apr 22 19:12:14.615: INFO: Waiting up to 5m0s for pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744" in namespace "secrets-6985" to be "running and ready"
    Apr 22 19:12:14.628: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744": Phase="Pending", Reason="", readiness=false. Elapsed: 13.41708ms
    Apr 22 19:12:14.629: INFO: The phase of Pod pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:12:16.639: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744": Phase="Running", Reason="", readiness=true. Elapsed: 2.024375081s
    Apr 22 19:12:16.640: INFO: The phase of Pod pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744 is Running (Ready = true)
    Apr 22 19:12:16.640: INFO: Pod "pod-secrets-6e484852-c36e-4947-83fc-e3cc66d3a744" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-0791c730-c815-48bb-81d7-8051d0738859 04/22/23 19:12:16.732
    STEP: Updating secret s-test-opt-upd-0a439d54-da0d-49c7-a1e1-05269c167612 04/22/23 19:12:16.748
    STEP: Creating secret with name s-test-opt-create-55d82685-4bd7-4442-815f-4417da8e4aab 04/22/23 19:12:16.768
    STEP: waiting to observe update in volume 04/22/23 19:12:16.783
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:12:18.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6985" for this suite. 04/22/23 19:12:18.872
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:18.908
Apr 22 19:12:18.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:12:18.91
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:18.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:18.963
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-24cc805f-c2cb-429a-9bd5-b964f849de6f 04/22/23 19:12:18.972
STEP: Creating a pod to test consume secrets 04/22/23 19:12:18.984
Apr 22 19:12:19.007: INFO: Waiting up to 5m0s for pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2" in namespace "secrets-9986" to be "Succeeded or Failed"
Apr 22 19:12:19.022: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.722147ms
Apr 22 19:12:21.031: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023270505s
Apr 22 19:12:23.035: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027626567s
STEP: Saw pod success 04/22/23 19:12:23.036
Apr 22 19:12:23.037: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2" satisfied condition "Succeeded or Failed"
Apr 22 19:12:23.047: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:12:23.066
Apr 22 19:12:23.101: INFO: Waiting for pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 to disappear
Apr 22 19:12:23.110: INFO: Pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:12:23.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9986" for this suite. 04/22/23 19:12:23.123
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":48,"skipped":906,"failed":0}
------------------------------
â€¢ [4.234 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:18.908
    Apr 22 19:12:18.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:12:18.91
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:18.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:18.963
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-24cc805f-c2cb-429a-9bd5-b964f849de6f 04/22/23 19:12:18.972
    STEP: Creating a pod to test consume secrets 04/22/23 19:12:18.984
    Apr 22 19:12:19.007: INFO: Waiting up to 5m0s for pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2" in namespace "secrets-9986" to be "Succeeded or Failed"
    Apr 22 19:12:19.022: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.722147ms
    Apr 22 19:12:21.031: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023270505s
    Apr 22 19:12:23.035: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027626567s
    STEP: Saw pod success 04/22/23 19:12:23.036
    Apr 22 19:12:23.037: INFO: Pod "pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2" satisfied condition "Succeeded or Failed"
    Apr 22 19:12:23.047: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:12:23.066
    Apr 22 19:12:23.101: INFO: Waiting for pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 to disappear
    Apr 22 19:12:23.110: INFO: Pod pod-secrets-3e05fd9b-395f-4e14-871c-913e919ae7b2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:12:23.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9986" for this suite. 04/22/23 19:12:23.123
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:23.163
Apr 22 19:12:23.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:12:23.166
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:23.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:23.238
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-52ad45f8-e139-4e0f-bc72-79bf8e1ded7e 04/22/23 19:12:23.251
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:12:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7023" for this suite. 04/22/23 19:12:23.267
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":49,"skipped":939,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:23.163
    Apr 22 19:12:23.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:12:23.166
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:23.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:23.238
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-52ad45f8-e139-4e0f-bc72-79bf8e1ded7e 04/22/23 19:12:23.251
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:12:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7023" for this suite. 04/22/23 19:12:23.267
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:23.283
Apr 22 19:12:23.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption 04/22/23 19:12:23.287
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:23.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:23.331
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 04/22/23 19:12:23.353
STEP: Updating PodDisruptionBudget status 04/22/23 19:12:25.381
STEP: Waiting for all pods to be running 04/22/23 19:12:25.399
Apr 22 19:12:25.413: INFO: running pods: 0 < 1
STEP: locating a running pod 04/22/23 19:12:27.422
STEP: Waiting for the pdb to be processed 04/22/23 19:12:27.455
STEP: Patching PodDisruptionBudget status 04/22/23 19:12:27.476
STEP: Waiting for the pdb to be processed 04/22/23 19:12:27.499
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 22 19:12:27.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9090" for this suite. 04/22/23 19:12:27.522
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":50,"skipped":946,"failed":0}
------------------------------
â€¢ [4.258 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:23.283
    Apr 22 19:12:23.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption 04/22/23 19:12:23.287
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:23.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:23.331
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 04/22/23 19:12:23.353
    STEP: Updating PodDisruptionBudget status 04/22/23 19:12:25.381
    STEP: Waiting for all pods to be running 04/22/23 19:12:25.399
    Apr 22 19:12:25.413: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/22/23 19:12:27.422
    STEP: Waiting for the pdb to be processed 04/22/23 19:12:27.455
    STEP: Patching PodDisruptionBudget status 04/22/23 19:12:27.476
    STEP: Waiting for the pdb to be processed 04/22/23 19:12:27.499
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 22 19:12:27.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9090" for this suite. 04/22/23 19:12:27.522
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:27.547
Apr 22 19:12:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:12:27.55
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:27.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:27.61
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:12:27.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2260" for this suite. 04/22/23 19:12:27.706
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":51,"skipped":953,"failed":0}
------------------------------
â€¢ [0.172 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:27.547
    Apr 22 19:12:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:12:27.55
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:27.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:27.61
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:12:27.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2260" for this suite. 04/22/23 19:12:27.706
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:27.723
Apr 22 19:12:27.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:12:27.727
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:27.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:27.774
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-3a2b7b93-b9ea-4d83-91c8-538044447f3f 04/22/23 19:12:27.782
STEP: Creating a pod to test consume configMaps 04/22/23 19:12:27.794
Apr 22 19:12:27.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7" in namespace "configmap-9843" to be "Succeeded or Failed"
Apr 22 19:12:27.824: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.863742ms
Apr 22 19:12:29.834: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018944051s
Apr 22 19:12:31.833: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017597673s
STEP: Saw pod success 04/22/23 19:12:31.833
Apr 22 19:12:31.833: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7" satisfied condition "Succeeded or Failed"
Apr 22 19:12:31.843: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:12:31.862
Apr 22 19:12:31.895: INFO: Waiting for pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 to disappear
Apr 22 19:12:31.902: INFO: Pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:12:31.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9843" for this suite. 04/22/23 19:12:31.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":52,"skipped":954,"failed":0}
------------------------------
â€¢ [4.206 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:27.723
    Apr 22 19:12:27.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:12:27.727
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:27.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:27.774
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-3a2b7b93-b9ea-4d83-91c8-538044447f3f 04/22/23 19:12:27.782
    STEP: Creating a pod to test consume configMaps 04/22/23 19:12:27.794
    Apr 22 19:12:27.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7" in namespace "configmap-9843" to be "Succeeded or Failed"
    Apr 22 19:12:27.824: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.863742ms
    Apr 22 19:12:29.834: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018944051s
    Apr 22 19:12:31.833: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017597673s
    STEP: Saw pod success 04/22/23 19:12:31.833
    Apr 22 19:12:31.833: INFO: Pod "pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7" satisfied condition "Succeeded or Failed"
    Apr 22 19:12:31.843: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:12:31.862
    Apr 22 19:12:31.895: INFO: Waiting for pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 to disappear
    Apr 22 19:12:31.902: INFO: Pod pod-configmaps-d5f0d1f1-bc54-4f85-abdf-462e899d72b7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:12:31.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9843" for this suite. 04/22/23 19:12:31.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:12:31.948
Apr 22 19:12:31.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir-wrapper 04/22/23 19:12:31.951
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:31.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:32.005
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/22/23 19:12:32.013
STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:12:32.399
Apr 22 19:12:32.428: INFO: Pod name wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4: Found 0 pods out of 5
Apr 22 19:12:37.450: INFO: Pod name wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/22/23 19:12:37.45
Apr 22 19:12:37.451: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:37.466: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.850549ms
Apr 22 19:12:39.477: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026196525s
Apr 22 19:12:41.480: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029226853s
Apr 22 19:12:43.474: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023392811s
Apr 22 19:12:45.479: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027697923s
Apr 22 19:12:47.476: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Running", Reason="", readiness=true. Elapsed: 10.025598581s
Apr 22 19:12:47.477: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv" satisfied condition "running"
Apr 22 19:12:47.477: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:47.488: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk": Phase="Running", Reason="", readiness=true. Elapsed: 11.409342ms
Apr 22 19:12:47.488: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk" satisfied condition "running"
Apr 22 19:12:47.488: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:47.497: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq": Phase="Running", Reason="", readiness=true. Elapsed: 8.939502ms
Apr 22 19:12:47.497: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq" satisfied condition "running"
Apr 22 19:12:47.497: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:47.506: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv": Phase="Running", Reason="", readiness=true. Elapsed: 8.958851ms
Apr 22 19:12:47.506: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv" satisfied condition "running"
Apr 22 19:12:47.506: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:47.515: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt": Phase="Running", Reason="", readiness=true. Elapsed: 9.037388ms
Apr 22 19:12:47.515: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:12:47.515
Apr 22 19:12:47.609: INFO: Deleting ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 took: 34.100787ms
Apr 22 19:12:47.809: INFO: Terminating ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 pods took: 200.719162ms
STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:12:51.019
Apr 22 19:12:51.049: INFO: Pod name wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5: Found 0 pods out of 5
Apr 22 19:12:56.067: INFO: Pod name wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/22/23 19:12:56.067
Apr 22 19:12:56.068: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:12:56.076: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 8.079997ms
Apr 22 19:12:58.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020152023s
Apr 22 19:13:00.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01979876s
Apr 22 19:13:02.093: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025411502s
Apr 22 19:13:04.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019747984s
Apr 22 19:13:06.090: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Running", Reason="", readiness=true. Elapsed: 10.021956956s
Apr 22 19:13:06.090: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws" satisfied condition "running"
Apr 22 19:13:06.090: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:06.110: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n": Phase="Running", Reason="", readiness=true. Elapsed: 20.304762ms
Apr 22 19:13:06.110: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n" satisfied condition "running"
Apr 22 19:13:06.110: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:06.125: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b": Phase="Running", Reason="", readiness=true. Elapsed: 15.012776ms
Apr 22 19:13:06.126: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b" satisfied condition "running"
Apr 22 19:13:06.126: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:06.142: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006054ms
Apr 22 19:13:08.155: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8": Phase="Running", Reason="", readiness=true. Elapsed: 2.029229175s
Apr 22 19:13:08.155: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8" satisfied condition "running"
Apr 22 19:13:08.156: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:08.166: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd": Phase="Running", Reason="", readiness=true. Elapsed: 10.284315ms
Apr 22 19:13:08.166: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:13:08.166
Apr 22 19:13:08.243: INFO: Deleting ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 took: 15.52526ms
Apr 22 19:13:08.444: INFO: Terminating ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 pods took: 201.043101ms
STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:13:11.254
Apr 22 19:13:11.299: INFO: Pod name wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28: Found 0 pods out of 5
Apr 22 19:13:16.326: INFO: Pod name wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/22/23 19:13:16.327
Apr 22 19:13:16.327: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:16.337: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.303777ms
Apr 22 19:13:18.356: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028992458s
Apr 22 19:13:20.352: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02489346s
Apr 22 19:13:22.348: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021516822s
Apr 22 19:13:24.373: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.046000214s
Apr 22 19:13:26.348: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021103875s
Apr 22 19:13:28.359: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Running", Reason="", readiness=true. Elapsed: 12.031900927s
Apr 22 19:13:28.359: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2" satisfied condition "running"
Apr 22 19:13:28.359: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:28.370: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8": Phase="Running", Reason="", readiness=true. Elapsed: 10.494143ms
Apr 22 19:13:28.370: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8" satisfied condition "running"
Apr 22 19:13:28.370: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:28.384: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4": Phase="Running", Reason="", readiness=true. Elapsed: 13.821182ms
Apr 22 19:13:28.384: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4" satisfied condition "running"
Apr 22 19:13:28.385: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:28.396: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q": Phase="Running", Reason="", readiness=true. Elapsed: 11.366876ms
Apr 22 19:13:28.396: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q" satisfied condition "running"
Apr 22 19:13:28.396: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs" in namespace "emptydir-wrapper-5273" to be "running"
Apr 22 19:13:28.408: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs": Phase="Running", Reason="", readiness=true. Elapsed: 10.677948ms
Apr 22 19:13:28.408: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:13:28.408
Apr 22 19:13:28.519: INFO: Deleting ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 took: 47.658654ms
Apr 22 19:13:28.721: INFO: Terminating ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 pods took: 202.302786ms
STEP: Cleaning up the configMaps 04/22/23 19:13:31.722
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 22 19:13:32.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5273" for this suite. 04/22/23 19:13:32.291
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":53,"skipped":997,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.354 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:12:31.948
    Apr 22 19:12:31.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir-wrapper 04/22/23 19:12:31.951
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:12:31.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:12:32.005
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/22/23 19:12:32.013
    STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:12:32.399
    Apr 22 19:12:32.428: INFO: Pod name wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4: Found 0 pods out of 5
    Apr 22 19:12:37.450: INFO: Pod name wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/22/23 19:12:37.45
    Apr 22 19:12:37.451: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:37.466: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.850549ms
    Apr 22 19:12:39.477: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026196525s
    Apr 22 19:12:41.480: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029226853s
    Apr 22 19:12:43.474: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023392811s
    Apr 22 19:12:45.479: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027697923s
    Apr 22 19:12:47.476: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv": Phase="Running", Reason="", readiness=true. Elapsed: 10.025598581s
    Apr 22 19:12:47.477: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-4qjbv" satisfied condition "running"
    Apr 22 19:12:47.477: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:47.488: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk": Phase="Running", Reason="", readiness=true. Elapsed: 11.409342ms
    Apr 22 19:12:47.488: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-g44wk" satisfied condition "running"
    Apr 22 19:12:47.488: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:47.497: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq": Phase="Running", Reason="", readiness=true. Elapsed: 8.939502ms
    Apr 22 19:12:47.497: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-lvpgq" satisfied condition "running"
    Apr 22 19:12:47.497: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:47.506: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv": Phase="Running", Reason="", readiness=true. Elapsed: 8.958851ms
    Apr 22 19:12:47.506: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-nnzqv" satisfied condition "running"
    Apr 22 19:12:47.506: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:47.515: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt": Phase="Running", Reason="", readiness=true. Elapsed: 9.037388ms
    Apr 22 19:12:47.515: INFO: Pod "wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4-wpstt" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:12:47.515
    Apr 22 19:12:47.609: INFO: Deleting ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 took: 34.100787ms
    Apr 22 19:12:47.809: INFO: Terminating ReplicationController wrapped-volume-race-a1abb1b2-750a-42bc-91fe-17fea80906c4 pods took: 200.719162ms
    STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:12:51.019
    Apr 22 19:12:51.049: INFO: Pod name wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5: Found 0 pods out of 5
    Apr 22 19:12:56.067: INFO: Pod name wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/22/23 19:12:56.067
    Apr 22 19:12:56.068: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:12:56.076: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 8.079997ms
    Apr 22 19:12:58.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020152023s
    Apr 22 19:13:00.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01979876s
    Apr 22 19:13:02.093: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025411502s
    Apr 22 19:13:04.088: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019747984s
    Apr 22 19:13:06.090: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws": Phase="Running", Reason="", readiness=true. Elapsed: 10.021956956s
    Apr 22 19:13:06.090: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-4jmws" satisfied condition "running"
    Apr 22 19:13:06.090: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:06.110: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n": Phase="Running", Reason="", readiness=true. Elapsed: 20.304762ms
    Apr 22 19:13:06.110: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-5qg8n" satisfied condition "running"
    Apr 22 19:13:06.110: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:06.125: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b": Phase="Running", Reason="", readiness=true. Elapsed: 15.012776ms
    Apr 22 19:13:06.126: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-jv97b" satisfied condition "running"
    Apr 22 19:13:06.126: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:06.142: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006054ms
    Apr 22 19:13:08.155: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8": Phase="Running", Reason="", readiness=true. Elapsed: 2.029229175s
    Apr 22 19:13:08.155: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-mwpm8" satisfied condition "running"
    Apr 22 19:13:08.156: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:08.166: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd": Phase="Running", Reason="", readiness=true. Elapsed: 10.284315ms
    Apr 22 19:13:08.166: INFO: Pod "wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5-qlbfd" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:13:08.166
    Apr 22 19:13:08.243: INFO: Deleting ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 took: 15.52526ms
    Apr 22 19:13:08.444: INFO: Terminating ReplicationController wrapped-volume-race-0a332d91-519a-481e-9a12-7b56713ed4d5 pods took: 201.043101ms
    STEP: Creating RC which spawns configmap-volume pods 04/22/23 19:13:11.254
    Apr 22 19:13:11.299: INFO: Pod name wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28: Found 0 pods out of 5
    Apr 22 19:13:16.326: INFO: Pod name wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/22/23 19:13:16.327
    Apr 22 19:13:16.327: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:16.337: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.303777ms
    Apr 22 19:13:18.356: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028992458s
    Apr 22 19:13:20.352: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02489346s
    Apr 22 19:13:22.348: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021516822s
    Apr 22 19:13:24.373: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.046000214s
    Apr 22 19:13:26.348: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021103875s
    Apr 22 19:13:28.359: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2": Phase="Running", Reason="", readiness=true. Elapsed: 12.031900927s
    Apr 22 19:13:28.359: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-6grk2" satisfied condition "running"
    Apr 22 19:13:28.359: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:28.370: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8": Phase="Running", Reason="", readiness=true. Elapsed: 10.494143ms
    Apr 22 19:13:28.370: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-bwcn8" satisfied condition "running"
    Apr 22 19:13:28.370: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:28.384: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4": Phase="Running", Reason="", readiness=true. Elapsed: 13.821182ms
    Apr 22 19:13:28.384: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-dh8v4" satisfied condition "running"
    Apr 22 19:13:28.385: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:28.396: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q": Phase="Running", Reason="", readiness=true. Elapsed: 11.366876ms
    Apr 22 19:13:28.396: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-gs29q" satisfied condition "running"
    Apr 22 19:13:28.396: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs" in namespace "emptydir-wrapper-5273" to be "running"
    Apr 22 19:13:28.408: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs": Phase="Running", Reason="", readiness=true. Elapsed: 10.677948ms
    Apr 22 19:13:28.408: INFO: Pod "wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28-klgbs" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 in namespace emptydir-wrapper-5273, will wait for the garbage collector to delete the pods 04/22/23 19:13:28.408
    Apr 22 19:13:28.519: INFO: Deleting ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 took: 47.658654ms
    Apr 22 19:13:28.721: INFO: Terminating ReplicationController wrapped-volume-race-7d3b5ead-7e41-4854-9028-c368684f4f28 pods took: 202.302786ms
    STEP: Cleaning up the configMaps 04/22/23 19:13:31.722
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:13:32.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5273" for this suite. 04/22/23 19:13:32.291
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:13:32.311
Apr 22 19:13:32.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 19:13:32.319
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:13:32.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:13:32.377
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/22/23 19:13:32.393
STEP: delete the rc 04/22/23 19:13:37.411
STEP: wait for the rc to be deleted 04/22/23 19:13:37.419
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/22/23 19:13:42.431
STEP: Gathering metrics 04/22/23 19:14:12.477
Apr 22 19:14:12.556: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 19:14:12.565: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 9.168451ms
Apr 22 19:14:12.565: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 19:14:12.566: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 19:14:12.752: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 22 19:14:12.753: INFO: Deleting pod "simpletest.rc-28jpc" in namespace "gc-8045"
Apr 22 19:14:12.792: INFO: Deleting pod "simpletest.rc-2hdf8" in namespace "gc-8045"
Apr 22 19:14:12.824: INFO: Deleting pod "simpletest.rc-2km92" in namespace "gc-8045"
Apr 22 19:14:12.845: INFO: Deleting pod "simpletest.rc-2l8w6" in namespace "gc-8045"
Apr 22 19:14:12.866: INFO: Deleting pod "simpletest.rc-2ns67" in namespace "gc-8045"
Apr 22 19:14:12.883: INFO: Deleting pod "simpletest.rc-2nzm8" in namespace "gc-8045"
Apr 22 19:14:12.902: INFO: Deleting pod "simpletest.rc-4k8nm" in namespace "gc-8045"
Apr 22 19:14:12.918: INFO: Deleting pod "simpletest.rc-4nnv5" in namespace "gc-8045"
Apr 22 19:14:12.935: INFO: Deleting pod "simpletest.rc-4tltd" in namespace "gc-8045"
Apr 22 19:14:12.955: INFO: Deleting pod "simpletest.rc-55j7l" in namespace "gc-8045"
Apr 22 19:14:12.969: INFO: Deleting pod "simpletest.rc-56g95" in namespace "gc-8045"
Apr 22 19:14:12.982: INFO: Deleting pod "simpletest.rc-5fp6g" in namespace "gc-8045"
Apr 22 19:14:12.996: INFO: Deleting pod "simpletest.rc-5hrvb" in namespace "gc-8045"
Apr 22 19:14:13.008: INFO: Deleting pod "simpletest.rc-5qjkz" in namespace "gc-8045"
Apr 22 19:14:13.021: INFO: Deleting pod "simpletest.rc-5wb9c" in namespace "gc-8045"
Apr 22 19:14:13.038: INFO: Deleting pod "simpletest.rc-6rrdr" in namespace "gc-8045"
Apr 22 19:14:13.055: INFO: Deleting pod "simpletest.rc-6wdh2" in namespace "gc-8045"
Apr 22 19:14:13.068: INFO: Deleting pod "simpletest.rc-746k6" in namespace "gc-8045"
Apr 22 19:14:13.085: INFO: Deleting pod "simpletest.rc-78v6z" in namespace "gc-8045"
Apr 22 19:14:13.107: INFO: Deleting pod "simpletest.rc-7dfxm" in namespace "gc-8045"
Apr 22 19:14:13.121: INFO: Deleting pod "simpletest.rc-7s7vz" in namespace "gc-8045"
Apr 22 19:14:13.141: INFO: Deleting pod "simpletest.rc-852j2" in namespace "gc-8045"
Apr 22 19:14:13.160: INFO: Deleting pod "simpletest.rc-87lk6" in namespace "gc-8045"
Apr 22 19:14:13.177: INFO: Deleting pod "simpletest.rc-87x6p" in namespace "gc-8045"
Apr 22 19:14:13.199: INFO: Deleting pod "simpletest.rc-8cllz" in namespace "gc-8045"
Apr 22 19:14:13.218: INFO: Deleting pod "simpletest.rc-8pgmf" in namespace "gc-8045"
Apr 22 19:14:13.242: INFO: Deleting pod "simpletest.rc-8rlrw" in namespace "gc-8045"
Apr 22 19:14:13.256: INFO: Deleting pod "simpletest.rc-9477m" in namespace "gc-8045"
Apr 22 19:14:13.272: INFO: Deleting pod "simpletest.rc-9j92k" in namespace "gc-8045"
Apr 22 19:14:13.295: INFO: Deleting pod "simpletest.rc-9z2hx" in namespace "gc-8045"
Apr 22 19:14:13.326: INFO: Deleting pod "simpletest.rc-b8zt2" in namespace "gc-8045"
Apr 22 19:14:13.347: INFO: Deleting pod "simpletest.rc-bbcqp" in namespace "gc-8045"
Apr 22 19:14:13.372: INFO: Deleting pod "simpletest.rc-bhk6n" in namespace "gc-8045"
Apr 22 19:14:13.390: INFO: Deleting pod "simpletest.rc-bq6b4" in namespace "gc-8045"
Apr 22 19:14:13.411: INFO: Deleting pod "simpletest.rc-cm8rl" in namespace "gc-8045"
Apr 22 19:14:13.429: INFO: Deleting pod "simpletest.rc-cvmmv" in namespace "gc-8045"
Apr 22 19:14:13.444: INFO: Deleting pod "simpletest.rc-cxlqf" in namespace "gc-8045"
Apr 22 19:14:13.465: INFO: Deleting pod "simpletest.rc-cxwzw" in namespace "gc-8045"
Apr 22 19:14:13.481: INFO: Deleting pod "simpletest.rc-d9z2g" in namespace "gc-8045"
Apr 22 19:14:13.508: INFO: Deleting pod "simpletest.rc-dmrh9" in namespace "gc-8045"
Apr 22 19:14:13.525: INFO: Deleting pod "simpletest.rc-fmcrx" in namespace "gc-8045"
Apr 22 19:14:13.541: INFO: Deleting pod "simpletest.rc-fq866" in namespace "gc-8045"
Apr 22 19:14:13.563: INFO: Deleting pod "simpletest.rc-ftz2c" in namespace "gc-8045"
Apr 22 19:14:13.580: INFO: Deleting pod "simpletest.rc-fx5wm" in namespace "gc-8045"
Apr 22 19:14:13.595: INFO: Deleting pod "simpletest.rc-fxh7k" in namespace "gc-8045"
Apr 22 19:14:13.615: INFO: Deleting pod "simpletest.rc-g78hl" in namespace "gc-8045"
Apr 22 19:14:13.638: INFO: Deleting pod "simpletest.rc-h7bxs" in namespace "gc-8045"
Apr 22 19:14:13.651: INFO: Deleting pod "simpletest.rc-hdjxs" in namespace "gc-8045"
Apr 22 19:14:13.662: INFO: Deleting pod "simpletest.rc-hk5s4" in namespace "gc-8045"
Apr 22 19:14:13.681: INFO: Deleting pod "simpletest.rc-hk7zf" in namespace "gc-8045"
Apr 22 19:14:13.692: INFO: Deleting pod "simpletest.rc-htbcg" in namespace "gc-8045"
Apr 22 19:14:13.705: INFO: Deleting pod "simpletest.rc-htf5s" in namespace "gc-8045"
Apr 22 19:14:13.727: INFO: Deleting pod "simpletest.rc-jnqfc" in namespace "gc-8045"
Apr 22 19:14:13.742: INFO: Deleting pod "simpletest.rc-jqr7p" in namespace "gc-8045"
Apr 22 19:14:13.754: INFO: Deleting pod "simpletest.rc-jtdwl" in namespace "gc-8045"
Apr 22 19:14:13.768: INFO: Deleting pod "simpletest.rc-k7sg8" in namespace "gc-8045"
Apr 22 19:14:13.783: INFO: Deleting pod "simpletest.rc-k7wmb" in namespace "gc-8045"
Apr 22 19:14:13.808: INFO: Deleting pod "simpletest.rc-khszq" in namespace "gc-8045"
Apr 22 19:14:13.829: INFO: Deleting pod "simpletest.rc-kq5n2" in namespace "gc-8045"
Apr 22 19:14:13.841: INFO: Deleting pod "simpletest.rc-kqb4l" in namespace "gc-8045"
Apr 22 19:14:13.858: INFO: Deleting pod "simpletest.rc-ktfhh" in namespace "gc-8045"
Apr 22 19:14:13.879: INFO: Deleting pod "simpletest.rc-l69mn" in namespace "gc-8045"
Apr 22 19:14:13.892: INFO: Deleting pod "simpletest.rc-lfk8z" in namespace "gc-8045"
Apr 22 19:14:13.915: INFO: Deleting pod "simpletest.rc-lg9zb" in namespace "gc-8045"
Apr 22 19:14:13.942: INFO: Deleting pod "simpletest.rc-ljgkh" in namespace "gc-8045"
Apr 22 19:14:13.972: INFO: Deleting pod "simpletest.rc-lmfvf" in namespace "gc-8045"
Apr 22 19:14:13.987: INFO: Deleting pod "simpletest.rc-lncqr" in namespace "gc-8045"
Apr 22 19:14:14.005: INFO: Deleting pod "simpletest.rc-m28cp" in namespace "gc-8045"
Apr 22 19:14:14.018: INFO: Deleting pod "simpletest.rc-mfzl2" in namespace "gc-8045"
Apr 22 19:14:14.031: INFO: Deleting pod "simpletest.rc-nhx2j" in namespace "gc-8045"
Apr 22 19:14:14.049: INFO: Deleting pod "simpletest.rc-psqqv" in namespace "gc-8045"
Apr 22 19:14:14.063: INFO: Deleting pod "simpletest.rc-pt8fj" in namespace "gc-8045"
Apr 22 19:14:14.079: INFO: Deleting pod "simpletest.rc-ptj8x" in namespace "gc-8045"
Apr 22 19:14:14.095: INFO: Deleting pod "simpletest.rc-qxwdg" in namespace "gc-8045"
Apr 22 19:14:14.108: INFO: Deleting pod "simpletest.rc-qzzxw" in namespace "gc-8045"
Apr 22 19:14:14.121: INFO: Deleting pod "simpletest.rc-r2hnc" in namespace "gc-8045"
Apr 22 19:14:14.138: INFO: Deleting pod "simpletest.rc-r9646" in namespace "gc-8045"
Apr 22 19:14:14.155: INFO: Deleting pod "simpletest.rc-rmgzf" in namespace "gc-8045"
Apr 22 19:14:14.181: INFO: Deleting pod "simpletest.rc-rmvcb" in namespace "gc-8045"
Apr 22 19:14:14.216: INFO: Deleting pod "simpletest.rc-rts9z" in namespace "gc-8045"
Apr 22 19:14:14.264: INFO: Deleting pod "simpletest.rc-rvkrz" in namespace "gc-8045"
Apr 22 19:14:14.321: INFO: Deleting pod "simpletest.rc-s44gd" in namespace "gc-8045"
Apr 22 19:14:14.368: INFO: Deleting pod "simpletest.rc-sv8b8" in namespace "gc-8045"
Apr 22 19:14:14.417: INFO: Deleting pod "simpletest.rc-t9lzd" in namespace "gc-8045"
Apr 22 19:14:14.469: INFO: Deleting pod "simpletest.rc-tdhwj" in namespace "gc-8045"
Apr 22 19:14:14.518: INFO: Deleting pod "simpletest.rc-tp6zg" in namespace "gc-8045"
Apr 22 19:14:14.568: INFO: Deleting pod "simpletest.rc-tqq6n" in namespace "gc-8045"
Apr 22 19:14:14.619: INFO: Deleting pod "simpletest.rc-vpxq4" in namespace "gc-8045"
Apr 22 19:14:14.670: INFO: Deleting pod "simpletest.rc-wb85z" in namespace "gc-8045"
Apr 22 19:14:14.721: INFO: Deleting pod "simpletest.rc-wdv4z" in namespace "gc-8045"
Apr 22 19:14:14.765: INFO: Deleting pod "simpletest.rc-wqhwm" in namespace "gc-8045"
Apr 22 19:14:14.847: INFO: Deleting pod "simpletest.rc-ww2f5" in namespace "gc-8045"
Apr 22 19:14:14.878: INFO: Deleting pod "simpletest.rc-x228b" in namespace "gc-8045"
Apr 22 19:14:14.933: INFO: Deleting pod "simpletest.rc-xbbkn" in namespace "gc-8045"
Apr 22 19:14:14.981: INFO: Deleting pod "simpletest.rc-xxppv" in namespace "gc-8045"
Apr 22 19:14:15.032: INFO: Deleting pod "simpletest.rc-z5648" in namespace "gc-8045"
Apr 22 19:14:15.078: INFO: Deleting pod "simpletest.rc-zfvrp" in namespace "gc-8045"
Apr 22 19:14:15.138: INFO: Deleting pod "simpletest.rc-zgjfb" in namespace "gc-8045"
Apr 22 19:14:15.175: INFO: Deleting pod "simpletest.rc-zgljs" in namespace "gc-8045"
Apr 22 19:14:15.234: INFO: Deleting pod "simpletest.rc-zmrjn" in namespace "gc-8045"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 19:14:15.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8045" for this suite. 04/22/23 19:14:15.314
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":54,"skipped":1007,"failed":0}
------------------------------
â€¢ [SLOW TEST] [43.091 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:13:32.311
    Apr 22 19:13:32.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 19:13:32.319
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:13:32.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:13:32.377
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/22/23 19:13:32.393
    STEP: delete the rc 04/22/23 19:13:37.411
    STEP: wait for the rc to be deleted 04/22/23 19:13:37.419
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/22/23 19:13:42.431
    STEP: Gathering metrics 04/22/23 19:14:12.477
    Apr 22 19:14:12.556: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 19:14:12.565: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 9.168451ms
    Apr 22 19:14:12.565: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 19:14:12.566: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 19:14:12.752: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 22 19:14:12.753: INFO: Deleting pod "simpletest.rc-28jpc" in namespace "gc-8045"
    Apr 22 19:14:12.792: INFO: Deleting pod "simpletest.rc-2hdf8" in namespace "gc-8045"
    Apr 22 19:14:12.824: INFO: Deleting pod "simpletest.rc-2km92" in namespace "gc-8045"
    Apr 22 19:14:12.845: INFO: Deleting pod "simpletest.rc-2l8w6" in namespace "gc-8045"
    Apr 22 19:14:12.866: INFO: Deleting pod "simpletest.rc-2ns67" in namespace "gc-8045"
    Apr 22 19:14:12.883: INFO: Deleting pod "simpletest.rc-2nzm8" in namespace "gc-8045"
    Apr 22 19:14:12.902: INFO: Deleting pod "simpletest.rc-4k8nm" in namespace "gc-8045"
    Apr 22 19:14:12.918: INFO: Deleting pod "simpletest.rc-4nnv5" in namespace "gc-8045"
    Apr 22 19:14:12.935: INFO: Deleting pod "simpletest.rc-4tltd" in namespace "gc-8045"
    Apr 22 19:14:12.955: INFO: Deleting pod "simpletest.rc-55j7l" in namespace "gc-8045"
    Apr 22 19:14:12.969: INFO: Deleting pod "simpletest.rc-56g95" in namespace "gc-8045"
    Apr 22 19:14:12.982: INFO: Deleting pod "simpletest.rc-5fp6g" in namespace "gc-8045"
    Apr 22 19:14:12.996: INFO: Deleting pod "simpletest.rc-5hrvb" in namespace "gc-8045"
    Apr 22 19:14:13.008: INFO: Deleting pod "simpletest.rc-5qjkz" in namespace "gc-8045"
    Apr 22 19:14:13.021: INFO: Deleting pod "simpletest.rc-5wb9c" in namespace "gc-8045"
    Apr 22 19:14:13.038: INFO: Deleting pod "simpletest.rc-6rrdr" in namespace "gc-8045"
    Apr 22 19:14:13.055: INFO: Deleting pod "simpletest.rc-6wdh2" in namespace "gc-8045"
    Apr 22 19:14:13.068: INFO: Deleting pod "simpletest.rc-746k6" in namespace "gc-8045"
    Apr 22 19:14:13.085: INFO: Deleting pod "simpletest.rc-78v6z" in namespace "gc-8045"
    Apr 22 19:14:13.107: INFO: Deleting pod "simpletest.rc-7dfxm" in namespace "gc-8045"
    Apr 22 19:14:13.121: INFO: Deleting pod "simpletest.rc-7s7vz" in namespace "gc-8045"
    Apr 22 19:14:13.141: INFO: Deleting pod "simpletest.rc-852j2" in namespace "gc-8045"
    Apr 22 19:14:13.160: INFO: Deleting pod "simpletest.rc-87lk6" in namespace "gc-8045"
    Apr 22 19:14:13.177: INFO: Deleting pod "simpletest.rc-87x6p" in namespace "gc-8045"
    Apr 22 19:14:13.199: INFO: Deleting pod "simpletest.rc-8cllz" in namespace "gc-8045"
    Apr 22 19:14:13.218: INFO: Deleting pod "simpletest.rc-8pgmf" in namespace "gc-8045"
    Apr 22 19:14:13.242: INFO: Deleting pod "simpletest.rc-8rlrw" in namespace "gc-8045"
    Apr 22 19:14:13.256: INFO: Deleting pod "simpletest.rc-9477m" in namespace "gc-8045"
    Apr 22 19:14:13.272: INFO: Deleting pod "simpletest.rc-9j92k" in namespace "gc-8045"
    Apr 22 19:14:13.295: INFO: Deleting pod "simpletest.rc-9z2hx" in namespace "gc-8045"
    Apr 22 19:14:13.326: INFO: Deleting pod "simpletest.rc-b8zt2" in namespace "gc-8045"
    Apr 22 19:14:13.347: INFO: Deleting pod "simpletest.rc-bbcqp" in namespace "gc-8045"
    Apr 22 19:14:13.372: INFO: Deleting pod "simpletest.rc-bhk6n" in namespace "gc-8045"
    Apr 22 19:14:13.390: INFO: Deleting pod "simpletest.rc-bq6b4" in namespace "gc-8045"
    Apr 22 19:14:13.411: INFO: Deleting pod "simpletest.rc-cm8rl" in namespace "gc-8045"
    Apr 22 19:14:13.429: INFO: Deleting pod "simpletest.rc-cvmmv" in namespace "gc-8045"
    Apr 22 19:14:13.444: INFO: Deleting pod "simpletest.rc-cxlqf" in namespace "gc-8045"
    Apr 22 19:14:13.465: INFO: Deleting pod "simpletest.rc-cxwzw" in namespace "gc-8045"
    Apr 22 19:14:13.481: INFO: Deleting pod "simpletest.rc-d9z2g" in namespace "gc-8045"
    Apr 22 19:14:13.508: INFO: Deleting pod "simpletest.rc-dmrh9" in namespace "gc-8045"
    Apr 22 19:14:13.525: INFO: Deleting pod "simpletest.rc-fmcrx" in namespace "gc-8045"
    Apr 22 19:14:13.541: INFO: Deleting pod "simpletest.rc-fq866" in namespace "gc-8045"
    Apr 22 19:14:13.563: INFO: Deleting pod "simpletest.rc-ftz2c" in namespace "gc-8045"
    Apr 22 19:14:13.580: INFO: Deleting pod "simpletest.rc-fx5wm" in namespace "gc-8045"
    Apr 22 19:14:13.595: INFO: Deleting pod "simpletest.rc-fxh7k" in namespace "gc-8045"
    Apr 22 19:14:13.615: INFO: Deleting pod "simpletest.rc-g78hl" in namespace "gc-8045"
    Apr 22 19:14:13.638: INFO: Deleting pod "simpletest.rc-h7bxs" in namespace "gc-8045"
    Apr 22 19:14:13.651: INFO: Deleting pod "simpletest.rc-hdjxs" in namespace "gc-8045"
    Apr 22 19:14:13.662: INFO: Deleting pod "simpletest.rc-hk5s4" in namespace "gc-8045"
    Apr 22 19:14:13.681: INFO: Deleting pod "simpletest.rc-hk7zf" in namespace "gc-8045"
    Apr 22 19:14:13.692: INFO: Deleting pod "simpletest.rc-htbcg" in namespace "gc-8045"
    Apr 22 19:14:13.705: INFO: Deleting pod "simpletest.rc-htf5s" in namespace "gc-8045"
    Apr 22 19:14:13.727: INFO: Deleting pod "simpletest.rc-jnqfc" in namespace "gc-8045"
    Apr 22 19:14:13.742: INFO: Deleting pod "simpletest.rc-jqr7p" in namespace "gc-8045"
    Apr 22 19:14:13.754: INFO: Deleting pod "simpletest.rc-jtdwl" in namespace "gc-8045"
    Apr 22 19:14:13.768: INFO: Deleting pod "simpletest.rc-k7sg8" in namespace "gc-8045"
    Apr 22 19:14:13.783: INFO: Deleting pod "simpletest.rc-k7wmb" in namespace "gc-8045"
    Apr 22 19:14:13.808: INFO: Deleting pod "simpletest.rc-khszq" in namespace "gc-8045"
    Apr 22 19:14:13.829: INFO: Deleting pod "simpletest.rc-kq5n2" in namespace "gc-8045"
    Apr 22 19:14:13.841: INFO: Deleting pod "simpletest.rc-kqb4l" in namespace "gc-8045"
    Apr 22 19:14:13.858: INFO: Deleting pod "simpletest.rc-ktfhh" in namespace "gc-8045"
    Apr 22 19:14:13.879: INFO: Deleting pod "simpletest.rc-l69mn" in namespace "gc-8045"
    Apr 22 19:14:13.892: INFO: Deleting pod "simpletest.rc-lfk8z" in namespace "gc-8045"
    Apr 22 19:14:13.915: INFO: Deleting pod "simpletest.rc-lg9zb" in namespace "gc-8045"
    Apr 22 19:14:13.942: INFO: Deleting pod "simpletest.rc-ljgkh" in namespace "gc-8045"
    Apr 22 19:14:13.972: INFO: Deleting pod "simpletest.rc-lmfvf" in namespace "gc-8045"
    Apr 22 19:14:13.987: INFO: Deleting pod "simpletest.rc-lncqr" in namespace "gc-8045"
    Apr 22 19:14:14.005: INFO: Deleting pod "simpletest.rc-m28cp" in namespace "gc-8045"
    Apr 22 19:14:14.018: INFO: Deleting pod "simpletest.rc-mfzl2" in namespace "gc-8045"
    Apr 22 19:14:14.031: INFO: Deleting pod "simpletest.rc-nhx2j" in namespace "gc-8045"
    Apr 22 19:14:14.049: INFO: Deleting pod "simpletest.rc-psqqv" in namespace "gc-8045"
    Apr 22 19:14:14.063: INFO: Deleting pod "simpletest.rc-pt8fj" in namespace "gc-8045"
    Apr 22 19:14:14.079: INFO: Deleting pod "simpletest.rc-ptj8x" in namespace "gc-8045"
    Apr 22 19:14:14.095: INFO: Deleting pod "simpletest.rc-qxwdg" in namespace "gc-8045"
    Apr 22 19:14:14.108: INFO: Deleting pod "simpletest.rc-qzzxw" in namespace "gc-8045"
    Apr 22 19:14:14.121: INFO: Deleting pod "simpletest.rc-r2hnc" in namespace "gc-8045"
    Apr 22 19:14:14.138: INFO: Deleting pod "simpletest.rc-r9646" in namespace "gc-8045"
    Apr 22 19:14:14.155: INFO: Deleting pod "simpletest.rc-rmgzf" in namespace "gc-8045"
    Apr 22 19:14:14.181: INFO: Deleting pod "simpletest.rc-rmvcb" in namespace "gc-8045"
    Apr 22 19:14:14.216: INFO: Deleting pod "simpletest.rc-rts9z" in namespace "gc-8045"
    Apr 22 19:14:14.264: INFO: Deleting pod "simpletest.rc-rvkrz" in namespace "gc-8045"
    Apr 22 19:14:14.321: INFO: Deleting pod "simpletest.rc-s44gd" in namespace "gc-8045"
    Apr 22 19:14:14.368: INFO: Deleting pod "simpletest.rc-sv8b8" in namespace "gc-8045"
    Apr 22 19:14:14.417: INFO: Deleting pod "simpletest.rc-t9lzd" in namespace "gc-8045"
    Apr 22 19:14:14.469: INFO: Deleting pod "simpletest.rc-tdhwj" in namespace "gc-8045"
    Apr 22 19:14:14.518: INFO: Deleting pod "simpletest.rc-tp6zg" in namespace "gc-8045"
    Apr 22 19:14:14.568: INFO: Deleting pod "simpletest.rc-tqq6n" in namespace "gc-8045"
    Apr 22 19:14:14.619: INFO: Deleting pod "simpletest.rc-vpxq4" in namespace "gc-8045"
    Apr 22 19:14:14.670: INFO: Deleting pod "simpletest.rc-wb85z" in namespace "gc-8045"
    Apr 22 19:14:14.721: INFO: Deleting pod "simpletest.rc-wdv4z" in namespace "gc-8045"
    Apr 22 19:14:14.765: INFO: Deleting pod "simpletest.rc-wqhwm" in namespace "gc-8045"
    Apr 22 19:14:14.847: INFO: Deleting pod "simpletest.rc-ww2f5" in namespace "gc-8045"
    Apr 22 19:14:14.878: INFO: Deleting pod "simpletest.rc-x228b" in namespace "gc-8045"
    Apr 22 19:14:14.933: INFO: Deleting pod "simpletest.rc-xbbkn" in namespace "gc-8045"
    Apr 22 19:14:14.981: INFO: Deleting pod "simpletest.rc-xxppv" in namespace "gc-8045"
    Apr 22 19:14:15.032: INFO: Deleting pod "simpletest.rc-z5648" in namespace "gc-8045"
    Apr 22 19:14:15.078: INFO: Deleting pod "simpletest.rc-zfvrp" in namespace "gc-8045"
    Apr 22 19:14:15.138: INFO: Deleting pod "simpletest.rc-zgjfb" in namespace "gc-8045"
    Apr 22 19:14:15.175: INFO: Deleting pod "simpletest.rc-zgljs" in namespace "gc-8045"
    Apr 22 19:14:15.234: INFO: Deleting pod "simpletest.rc-zmrjn" in namespace "gc-8045"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 19:14:15.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8045" for this suite. 04/22/23 19:14:15.314
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:15.405
Apr 22 19:14:15.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 19:14:15.407
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:15.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:15.452
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9731 04/22/23 19:14:15.46
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-9731 04/22/23 19:14:15.473
Apr 22 19:14:15.489: INFO: Found 0 stateful pods, waiting for 1
Apr 22 19:14:25.503: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/22/23 19:14:25.523
STEP: Getting /status 04/22/23 19:14:25.554
Apr 22 19:14:25.567: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/22/23 19:14:25.568
Apr 22 19:14:25.596: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/22/23 19:14:25.597
Apr 22 19:14:25.603: INFO: Observed &StatefulSet event: ADDED
Apr 22 19:14:25.604: INFO: Found Statefulset ss in namespace statefulset-9731 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 22 19:14:25.604: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/22/23 19:14:25.604
Apr 22 19:14:25.605: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 22 19:14:25.621: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/22/23 19:14:25.621
Apr 22 19:14:25.626: INFO: Observed &StatefulSet event: ADDED
Apr 22 19:14:25.627: INFO: Observed Statefulset ss in namespace statefulset-9731 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 22 19:14:25.627: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 19:14:25.628: INFO: Deleting all statefulset in ns statefulset-9731
Apr 22 19:14:25.637: INFO: Scaling statefulset ss to 0
Apr 22 19:14:35.695: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 19:14:35.703: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 19:14:35.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9731" for this suite. 04/22/23 19:14:35.76
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":55,"skipped":1010,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.367 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:15.405
    Apr 22 19:14:15.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 19:14:15.407
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:15.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:15.452
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9731 04/22/23 19:14:15.46
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-9731 04/22/23 19:14:15.473
    Apr 22 19:14:15.489: INFO: Found 0 stateful pods, waiting for 1
    Apr 22 19:14:25.503: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/22/23 19:14:25.523
    STEP: Getting /status 04/22/23 19:14:25.554
    Apr 22 19:14:25.567: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/22/23 19:14:25.568
    Apr 22 19:14:25.596: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/22/23 19:14:25.597
    Apr 22 19:14:25.603: INFO: Observed &StatefulSet event: ADDED
    Apr 22 19:14:25.604: INFO: Found Statefulset ss in namespace statefulset-9731 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 22 19:14:25.604: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/22/23 19:14:25.604
    Apr 22 19:14:25.605: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 22 19:14:25.621: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/22/23 19:14:25.621
    Apr 22 19:14:25.626: INFO: Observed &StatefulSet event: ADDED
    Apr 22 19:14:25.627: INFO: Observed Statefulset ss in namespace statefulset-9731 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 22 19:14:25.627: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 19:14:25.628: INFO: Deleting all statefulset in ns statefulset-9731
    Apr 22 19:14:25.637: INFO: Scaling statefulset ss to 0
    Apr 22 19:14:35.695: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 19:14:35.703: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 19:14:35.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9731" for this suite. 04/22/23 19:14:35.76
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:35.785
Apr 22 19:14:35.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 19:14:35.788
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:35.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:35.842
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 22 19:14:35.930: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"12bb9fe9-c2ee-40c3-9c50-9798e6850ee9", Controller:(*bool)(0xc003e2e776), BlockOwnerDeletion:(*bool)(0xc003e2e777)}}
Apr 22 19:14:35.937: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e18e4214-c18e-44a1-8846-582f7a2fbc69", Controller:(*bool)(0xc003e2ea06), BlockOwnerDeletion:(*bool)(0xc003e2ea07)}}
Apr 22 19:14:35.945: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"473b84bc-cb57-4cf2-a126-e887733ed6a9", Controller:(*bool)(0xc003cf93ba), BlockOwnerDeletion:(*bool)(0xc003cf93bb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 19:14:40.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6414" for this suite. 04/22/23 19:14:40.974
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":56,"skipped":1031,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.200 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:35.785
    Apr 22 19:14:35.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 19:14:35.788
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:35.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:35.842
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 22 19:14:35.930: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"12bb9fe9-c2ee-40c3-9c50-9798e6850ee9", Controller:(*bool)(0xc003e2e776), BlockOwnerDeletion:(*bool)(0xc003e2e777)}}
    Apr 22 19:14:35.937: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e18e4214-c18e-44a1-8846-582f7a2fbc69", Controller:(*bool)(0xc003e2ea06), BlockOwnerDeletion:(*bool)(0xc003e2ea07)}}
    Apr 22 19:14:35.945: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"473b84bc-cb57-4cf2-a126-e887733ed6a9", Controller:(*bool)(0xc003cf93ba), BlockOwnerDeletion:(*bool)(0xc003cf93bb)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 19:14:40.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6414" for this suite. 04/22/23 19:14:40.974
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:40.995
Apr 22 19:14:40.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename proxy 04/22/23 19:14:40.998
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:41.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:41.034
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/22/23 19:14:41.059
STEP: creating replication controller proxy-service-m6xlg in namespace proxy-2488 04/22/23 19:14:41.059
I0422 19:14:41.068830      20 runners.go:193] Created replication controller with name: proxy-service-m6xlg, namespace: proxy-2488, replica count: 1
I0422 19:14:42.121051      20 runners.go:193] proxy-service-m6xlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0422 19:14:43.121294      20 runners.go:193] proxy-service-m6xlg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:14:43.130: INFO: setup took 2.08930755s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/22/23 19:14:43.13
Apr 22 19:14:43.174: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 41.88953ms)
Apr 22 19:14:43.174: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 40.26633ms)
Apr 22 19:14:43.175: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 43.02291ms)
Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 41.851407ms)
Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 42.740693ms)
Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 44.799258ms)
Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 42.10055ms)
Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 42.578706ms)
Apr 22 19:14:43.186: INFO: (0) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 52.7512ms)
Apr 22 19:14:43.186: INFO: (0) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 53.725486ms)
Apr 22 19:14:43.187: INFO: (0) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 52.642329ms)
Apr 22 19:14:43.187: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 53.858904ms)
Apr 22 19:14:43.188: INFO: (0) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 54.503147ms)
Apr 22 19:14:43.188: INFO: (0) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 56.775526ms)
Apr 22 19:14:43.189: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 54.764416ms)
Apr 22 19:14:43.190: INFO: (0) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 55.622287ms)
Apr 22 19:14:43.220: INFO: (1) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 29.322194ms)
Apr 22 19:14:43.220: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 28.24553ms)
Apr 22 19:14:43.221: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 28.710983ms)
Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 30.248268ms)
Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 30.69361ms)
Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 31.248195ms)
Apr 22 19:14:43.223: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 30.710356ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 31.711572ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 31.540358ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 31.060644ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 31.189341ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 32.0031ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 31.481304ms)
Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 31.995189ms)
Apr 22 19:14:43.228: INFO: (1) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 35.173378ms)
Apr 22 19:14:43.228: INFO: (1) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 36.113381ms)
Apr 22 19:14:43.241: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.554784ms)
Apr 22 19:14:43.248: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 18.081727ms)
Apr 22 19:14:43.248: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.478698ms)
Apr 22 19:14:43.250: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.650124ms)
Apr 22 19:14:43.250: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.970325ms)
Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 20.904073ms)
Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 20.958624ms)
Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 21.646757ms)
Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 21.897582ms)
Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 21.30185ms)
Apr 22 19:14:43.255: INFO: (2) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 26.272081ms)
Apr 22 19:14:43.255: INFO: (2) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 25.475789ms)
Apr 22 19:14:43.257: INFO: (2) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 27.670953ms)
Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 28.01814ms)
Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 28.281986ms)
Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 28.11374ms)
Apr 22 19:14:43.273: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.043744ms)
Apr 22 19:14:43.275: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.205515ms)
Apr 22 19:14:43.275: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.150542ms)
Apr 22 19:14:43.276: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.177578ms)
Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 15.792562ms)
Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 16.850789ms)
Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 17.338271ms)
Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 17.981024ms)
Apr 22 19:14:43.279: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 19.701265ms)
Apr 22 19:14:43.280: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.303549ms)
Apr 22 19:14:43.283: INFO: (3) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 23.551948ms)
Apr 22 19:14:43.284: INFO: (3) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 22.60845ms)
Apr 22 19:14:43.284: INFO: (3) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 25.236869ms)
Apr 22 19:14:43.285: INFO: (3) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 25.894682ms)
Apr 22 19:14:43.286: INFO: (3) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 24.874771ms)
Apr 22 19:14:43.287: INFO: (3) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.143264ms)
Apr 22 19:14:43.307: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 15.715863ms)
Apr 22 19:14:43.308: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.222474ms)
Apr 22 19:14:43.308: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 19.408119ms)
Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 21.256557ms)
Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 18.196004ms)
Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 20.405901ms)
Apr 22 19:14:43.310: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 21.502826ms)
Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 22.889708ms)
Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.723574ms)
Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 21.338691ms)
Apr 22 19:14:43.314: INFO: (4) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.593867ms)
Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 27.4244ms)
Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 24.819798ms)
Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 26.369453ms)
Apr 22 19:14:43.317: INFO: (4) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 27.363116ms)
Apr 22 19:14:43.317: INFO: (4) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 26.659506ms)
Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 13.040321ms)
Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 13.276264ms)
Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.032482ms)
Apr 22 19:14:43.333: INFO: (5) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 15.052258ms)
Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.826702ms)
Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 15.066661ms)
Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.120073ms)
Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.015274ms)
Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 15.734143ms)
Apr 22 19:14:43.336: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.230331ms)
Apr 22 19:14:43.335: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 15.800242ms)
Apr 22 19:14:43.339: INFO: (5) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 20.250358ms)
Apr 22 19:14:43.339: INFO: (5) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 19.806534ms)
Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 20.657151ms)
Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 20.525694ms)
Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 21.415182ms)
Apr 22 19:14:43.359: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.597947ms)
Apr 22 19:14:43.360: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.691569ms)
Apr 22 19:14:43.361: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 16.13822ms)
Apr 22 19:14:43.361: INFO: (6) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 19.385822ms)
Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.337617ms)
Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 18.942331ms)
Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.242822ms)
Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.822408ms)
Apr 22 19:14:43.363: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 19.253575ms)
Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 22.772081ms)
Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.012596ms)
Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.063513ms)
Apr 22 19:14:43.365: INFO: (6) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 20.311733ms)
Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 22.931447ms)
Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 22.693298ms)
Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 21.869176ms)
Apr 22 19:14:43.378: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 11.597596ms)
Apr 22 19:14:43.379: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.024336ms)
Apr 22 19:14:43.380: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.047365ms)
Apr 22 19:14:43.381: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.056755ms)
Apr 22 19:14:43.381: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.06854ms)
Apr 22 19:14:43.382: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.652366ms)
Apr 22 19:14:43.382: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.031659ms)
Apr 22 19:14:43.383: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 11.644144ms)
Apr 22 19:14:43.384: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 11.973382ms)
Apr 22 19:14:43.385: INFO: (7) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.215966ms)
Apr 22 19:14:43.388: INFO: (7) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 20.470587ms)
Apr 22 19:14:43.388: INFO: (7) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.642968ms)
Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.115859ms)
Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 16.988112ms)
Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 22.098941ms)
Apr 22 19:14:43.390: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 22.418364ms)
Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.441812ms)
Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 13.225794ms)
Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.080137ms)
Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.057168ms)
Apr 22 19:14:43.406: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 14.291663ms)
Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.118064ms)
Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.974331ms)
Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 17.142212ms)
Apr 22 19:14:43.408: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.400785ms)
Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 15.519882ms)
Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.631304ms)
Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 15.267644ms)
Apr 22 19:14:43.410: INFO: (8) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 18.482845ms)
Apr 22 19:14:43.410: INFO: (8) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 16.230529ms)
Apr 22 19:14:43.415: INFO: (8) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 20.364395ms)
Apr 22 19:14:43.415: INFO: (8) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 20.376821ms)
Apr 22 19:14:43.423: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 7.150809ms)
Apr 22 19:14:43.429: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 10.900063ms)
Apr 22 19:14:43.429: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.94253ms)
Apr 22 19:14:43.433: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 16.6232ms)
Apr 22 19:14:43.434: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.979119ms)
Apr 22 19:14:43.435: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.727635ms)
Apr 22 19:14:43.436: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.607546ms)
Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.178798ms)
Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.812478ms)
Apr 22 19:14:43.439: INFO: (9) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 22.94077ms)
Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 20.965109ms)
Apr 22 19:14:43.440: INFO: (9) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 23.729716ms)
Apr 22 19:14:43.441: INFO: (9) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 23.747071ms)
Apr 22 19:14:43.442: INFO: (9) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 26.27721ms)
Apr 22 19:14:43.442: INFO: (9) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.480609ms)
Apr 22 19:14:43.443: INFO: (9) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 25.807ms)
Apr 22 19:14:43.450: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 5.900637ms)
Apr 22 19:14:43.454: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 8.266895ms)
Apr 22 19:14:43.455: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 10.400244ms)
Apr 22 19:14:43.456: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 10.924185ms)
Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.024005ms)
Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.050005ms)
Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 13.376448ms)
Apr 22 19:14:43.458: INFO: (10) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.133743ms)
Apr 22 19:14:43.458: INFO: (10) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 14.743621ms)
Apr 22 19:14:43.459: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.1697ms)
Apr 22 19:14:43.460: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.069002ms)
Apr 22 19:14:43.460: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.816731ms)
Apr 22 19:14:43.461: INFO: (10) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 16.768444ms)
Apr 22 19:14:43.462: INFO: (10) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 16.574234ms)
Apr 22 19:14:43.462: INFO: (10) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 16.568576ms)
Apr 22 19:14:43.464: INFO: (10) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.619124ms)
Apr 22 19:14:43.473: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 8.986386ms)
Apr 22 19:14:43.474: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 9.744071ms)
Apr 22 19:14:43.474: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 9.841259ms)
Apr 22 19:14:43.475: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 10.440774ms)
Apr 22 19:14:43.476: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.221703ms)
Apr 22 19:14:43.477: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.036966ms)
Apr 22 19:14:43.478: INFO: (11) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 13.600295ms)
Apr 22 19:14:43.478: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.412455ms)
Apr 22 19:14:43.479: INFO: (11) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 14.111462ms)
Apr 22 19:14:43.479: INFO: (11) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.657946ms)
Apr 22 19:14:43.480: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.239145ms)
Apr 22 19:14:43.480: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.447759ms)
Apr 22 19:14:43.481: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.901242ms)
Apr 22 19:14:43.481: INFO: (11) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 15.987893ms)
Apr 22 19:14:43.482: INFO: (11) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 16.652787ms)
Apr 22 19:14:43.482: INFO: (11) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 16.999956ms)
Apr 22 19:14:43.492: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 9.027681ms)
Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.114421ms)
Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 11.502906ms)
Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 11.422773ms)
Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 11.939496ms)
Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 11.940722ms)
Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 13.086565ms)
Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 12.437522ms)
Apr 22 19:14:43.497: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.973824ms)
Apr 22 19:14:43.497: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.96243ms)
Apr 22 19:14:43.501: INFO: (12) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 17.266658ms)
Apr 22 19:14:43.501: INFO: (12) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.887006ms)
Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 19.082263ms)
Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 18.696044ms)
Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 18.022134ms)
Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 19.166483ms)
Apr 22 19:14:43.512: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 9.693406ms)
Apr 22 19:14:43.516: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 11.193158ms)
Apr 22 19:14:43.516: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.727291ms)
Apr 22 19:14:43.517: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.75595ms)
Apr 22 19:14:43.518: INFO: (13) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 13.965097ms)
Apr 22 19:14:43.519: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 15.652022ms)
Apr 22 19:14:43.519: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.518209ms)
Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 16.924747ms)
Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.644628ms)
Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 15.41123ms)
Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 17.210538ms)
Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 17.361903ms)
Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 18.221033ms)
Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 17.005728ms)
Apr 22 19:14:43.522: INFO: (13) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 19.331587ms)
Apr 22 19:14:43.522: INFO: (13) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.971197ms)
Apr 22 19:14:43.533: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 9.212049ms)
Apr 22 19:14:43.535: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 10.922727ms)
Apr 22 19:14:43.538: INFO: (14) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.439652ms)
Apr 22 19:14:43.538: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.057026ms)
Apr 22 19:14:43.539: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.680627ms)
Apr 22 19:14:43.539: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.626809ms)
Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.159701ms)
Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.406495ms)
Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 17.793585ms)
Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 16.009683ms)
Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.125725ms)
Apr 22 19:14:43.541: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 16.214398ms)
Apr 22 19:14:43.541: INFO: (14) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.188918ms)
Apr 22 19:14:43.542: INFO: (14) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 17.943247ms)
Apr 22 19:14:43.544: INFO: (14) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 19.562768ms)
Apr 22 19:14:43.545: INFO: (14) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 20.055334ms)
Apr 22 19:14:43.559: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.598802ms)
Apr 22 19:14:43.561: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.832452ms)
Apr 22 19:14:43.561: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.880203ms)
Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 14.423774ms)
Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.119191ms)
Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.869095ms)
Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 15.315841ms)
Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.184454ms)
Apr 22 19:14:43.563: INFO: (15) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 17.635087ms)
Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.261615ms)
Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 17.136969ms)
Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 17.828502ms)
Apr 22 19:14:43.566: INFO: (15) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 19.833861ms)
Apr 22 19:14:43.569: INFO: (15) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 22.38638ms)
Apr 22 19:14:43.569: INFO: (15) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 23.255882ms)
Apr 22 19:14:43.576: INFO: (15) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 28.894068ms)
Apr 22 19:14:43.597: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.302877ms)
Apr 22 19:14:43.598: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 21.500553ms)
Apr 22 19:14:43.598: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 20.308734ms)
Apr 22 19:14:43.599: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 22.063739ms)
Apr 22 19:14:43.600: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 22.03629ms)
Apr 22 19:14:43.600: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.433669ms)
Apr 22 19:14:43.601: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 22.97307ms)
Apr 22 19:14:43.602: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 23.724552ms)
Apr 22 19:14:43.602: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 24.602412ms)
Apr 22 19:14:43.603: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 25.177228ms)
Apr 22 19:14:43.603: INFO: (16) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 26.40518ms)
Apr 22 19:14:43.607: INFO: (16) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 29.886311ms)
Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 32.20381ms)
Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 32.286864ms)
Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 32.126427ms)
Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 32.794203ms)
Apr 22 19:14:43.620: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 9.303189ms)
Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 19.023305ms)
Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 20.606097ms)
Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.303505ms)
Apr 22 19:14:43.633: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.635112ms)
Apr 22 19:14:43.634: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 22.884364ms)
Apr 22 19:14:43.634: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 23.168371ms)
Apr 22 19:14:43.635: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.677252ms)
Apr 22 19:14:43.636: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 24.533582ms)
Apr 22 19:14:43.636: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 24.64182ms)
Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 43.279784ms)
Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 44.288407ms)
Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 43.011693ms)
Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 43.132131ms)
Apr 22 19:14:43.655: INFO: (17) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 44.45509ms)
Apr 22 19:14:43.655: INFO: (17) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 44.025179ms)
Apr 22 19:14:43.676: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.89739ms)
Apr 22 19:14:43.676: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.505114ms)
Apr 22 19:14:43.678: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 21.685353ms)
Apr 22 19:14:43.678: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 22.879268ms)
Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 22.040482ms)
Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 22.722368ms)
Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 23.26323ms)
Apr 22 19:14:43.680: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 24.798493ms)
Apr 22 19:14:43.681: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 24.350409ms)
Apr 22 19:14:43.681: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 26.373499ms)
Apr 22 19:14:43.682: INFO: (18) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 26.789566ms)
Apr 22 19:14:43.683: INFO: (18) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 26.400735ms)
Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 27.763665ms)
Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 27.495912ms)
Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 27.70792ms)
Apr 22 19:14:43.685: INFO: (18) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 29.134147ms)
Apr 22 19:14:43.695: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 8.577168ms)
Apr 22 19:14:43.702: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.41604ms)
Apr 22 19:14:43.703: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 17.115512ms)
Apr 22 19:14:43.704: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.16539ms)
Apr 22 19:14:43.704: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.682824ms)
Apr 22 19:14:43.705: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 16.336288ms)
Apr 22 19:14:43.705: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 15.371556ms)
Apr 22 19:14:43.706: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.213453ms)
Apr 22 19:14:43.707: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.239025ms)
Apr 22 19:14:43.708: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.760563ms)
Apr 22 19:14:43.709: INFO: (19) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 22.975181ms)
Apr 22 19:14:43.709: INFO: (19) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 19.204958ms)
Apr 22 19:14:43.710: INFO: (19) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 21.227534ms)
Apr 22 19:14:43.710: INFO: (19) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 22.566569ms)
Apr 22 19:14:43.711: INFO: (19) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 23.169195ms)
Apr 22 19:14:43.711: INFO: (19) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 22.480539ms)
STEP: deleting ReplicationController proxy-service-m6xlg in namespace proxy-2488, will wait for the garbage collector to delete the pods 04/22/23 19:14:43.712
Apr 22 19:14:43.777: INFO: Deleting ReplicationController proxy-service-m6xlg took: 8.142174ms
Apr 22 19:14:43.880: INFO: Terminating ReplicationController proxy-service-m6xlg pods took: 102.918352ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 22 19:14:45.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2488" for this suite. 04/22/23 19:14:45.892
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":57,"skipped":1038,"failed":0}
------------------------------
â€¢ [4.916 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:40.995
    Apr 22 19:14:40.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename proxy 04/22/23 19:14:40.998
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:41.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:41.034
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/22/23 19:14:41.059
    STEP: creating replication controller proxy-service-m6xlg in namespace proxy-2488 04/22/23 19:14:41.059
    I0422 19:14:41.068830      20 runners.go:193] Created replication controller with name: proxy-service-m6xlg, namespace: proxy-2488, replica count: 1
    I0422 19:14:42.121051      20 runners.go:193] proxy-service-m6xlg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0422 19:14:43.121294      20 runners.go:193] proxy-service-m6xlg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:14:43.130: INFO: setup took 2.08930755s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/22/23 19:14:43.13
    Apr 22 19:14:43.174: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 41.88953ms)
    Apr 22 19:14:43.174: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 40.26633ms)
    Apr 22 19:14:43.175: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 43.02291ms)
    Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 41.851407ms)
    Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 42.740693ms)
    Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 44.799258ms)
    Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 42.10055ms)
    Apr 22 19:14:43.176: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 42.578706ms)
    Apr 22 19:14:43.186: INFO: (0) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 52.7512ms)
    Apr 22 19:14:43.186: INFO: (0) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 53.725486ms)
    Apr 22 19:14:43.187: INFO: (0) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 52.642329ms)
    Apr 22 19:14:43.187: INFO: (0) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 53.858904ms)
    Apr 22 19:14:43.188: INFO: (0) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 54.503147ms)
    Apr 22 19:14:43.188: INFO: (0) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 56.775526ms)
    Apr 22 19:14:43.189: INFO: (0) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 54.764416ms)
    Apr 22 19:14:43.190: INFO: (0) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 55.622287ms)
    Apr 22 19:14:43.220: INFO: (1) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 29.322194ms)
    Apr 22 19:14:43.220: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 28.24553ms)
    Apr 22 19:14:43.221: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 28.710983ms)
    Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 30.248268ms)
    Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 30.69361ms)
    Apr 22 19:14:43.222: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 31.248195ms)
    Apr 22 19:14:43.223: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 30.710356ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 31.711572ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 31.540358ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 31.060644ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 31.189341ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 32.0031ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 31.481304ms)
    Apr 22 19:14:43.224: INFO: (1) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 31.995189ms)
    Apr 22 19:14:43.228: INFO: (1) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 35.173378ms)
    Apr 22 19:14:43.228: INFO: (1) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 36.113381ms)
    Apr 22 19:14:43.241: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.554784ms)
    Apr 22 19:14:43.248: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 18.081727ms)
    Apr 22 19:14:43.248: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.478698ms)
    Apr 22 19:14:43.250: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.650124ms)
    Apr 22 19:14:43.250: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.970325ms)
    Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 20.904073ms)
    Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 20.958624ms)
    Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 21.646757ms)
    Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 21.897582ms)
    Apr 22 19:14:43.251: INFO: (2) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 21.30185ms)
    Apr 22 19:14:43.255: INFO: (2) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 26.272081ms)
    Apr 22 19:14:43.255: INFO: (2) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 25.475789ms)
    Apr 22 19:14:43.257: INFO: (2) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 27.670953ms)
    Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 28.01814ms)
    Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 28.281986ms)
    Apr 22 19:14:43.258: INFO: (2) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 28.11374ms)
    Apr 22 19:14:43.273: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.043744ms)
    Apr 22 19:14:43.275: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.205515ms)
    Apr 22 19:14:43.275: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.150542ms)
    Apr 22 19:14:43.276: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.177578ms)
    Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 15.792562ms)
    Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 16.850789ms)
    Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 17.338271ms)
    Apr 22 19:14:43.277: INFO: (3) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 17.981024ms)
    Apr 22 19:14:43.279: INFO: (3) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 19.701265ms)
    Apr 22 19:14:43.280: INFO: (3) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.303549ms)
    Apr 22 19:14:43.283: INFO: (3) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 23.551948ms)
    Apr 22 19:14:43.284: INFO: (3) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 22.60845ms)
    Apr 22 19:14:43.284: INFO: (3) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 25.236869ms)
    Apr 22 19:14:43.285: INFO: (3) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 25.894682ms)
    Apr 22 19:14:43.286: INFO: (3) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 24.874771ms)
    Apr 22 19:14:43.287: INFO: (3) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.143264ms)
    Apr 22 19:14:43.307: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 15.715863ms)
    Apr 22 19:14:43.308: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.222474ms)
    Apr 22 19:14:43.308: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 19.408119ms)
    Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 21.256557ms)
    Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 18.196004ms)
    Apr 22 19:14:43.309: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 20.405901ms)
    Apr 22 19:14:43.310: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 21.502826ms)
    Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 22.889708ms)
    Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.723574ms)
    Apr 22 19:14:43.311: INFO: (4) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 21.338691ms)
    Apr 22 19:14:43.314: INFO: (4) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.593867ms)
    Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 27.4244ms)
    Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 24.819798ms)
    Apr 22 19:14:43.316: INFO: (4) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 26.369453ms)
    Apr 22 19:14:43.317: INFO: (4) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 27.363116ms)
    Apr 22 19:14:43.317: INFO: (4) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 26.659506ms)
    Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 13.040321ms)
    Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 13.276264ms)
    Apr 22 19:14:43.332: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.032482ms)
    Apr 22 19:14:43.333: INFO: (5) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 15.052258ms)
    Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.826702ms)
    Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 15.066661ms)
    Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.120073ms)
    Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.015274ms)
    Apr 22 19:14:43.334: INFO: (5) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 15.734143ms)
    Apr 22 19:14:43.336: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.230331ms)
    Apr 22 19:14:43.335: INFO: (5) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 15.800242ms)
    Apr 22 19:14:43.339: INFO: (5) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 20.250358ms)
    Apr 22 19:14:43.339: INFO: (5) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 19.806534ms)
    Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 20.657151ms)
    Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 20.525694ms)
    Apr 22 19:14:43.340: INFO: (5) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 21.415182ms)
    Apr 22 19:14:43.359: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.597947ms)
    Apr 22 19:14:43.360: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.691569ms)
    Apr 22 19:14:43.361: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 16.13822ms)
    Apr 22 19:14:43.361: INFO: (6) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 19.385822ms)
    Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.337617ms)
    Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 18.942331ms)
    Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.242822ms)
    Apr 22 19:14:43.362: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.822408ms)
    Apr 22 19:14:43.363: INFO: (6) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 19.253575ms)
    Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 22.772081ms)
    Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.012596ms)
    Apr 22 19:14:43.364: INFO: (6) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.063513ms)
    Apr 22 19:14:43.365: INFO: (6) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 20.311733ms)
    Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 22.931447ms)
    Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 22.693298ms)
    Apr 22 19:14:43.366: INFO: (6) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 21.869176ms)
    Apr 22 19:14:43.378: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 11.597596ms)
    Apr 22 19:14:43.379: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.024336ms)
    Apr 22 19:14:43.380: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.047365ms)
    Apr 22 19:14:43.381: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.056755ms)
    Apr 22 19:14:43.381: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.06854ms)
    Apr 22 19:14:43.382: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.652366ms)
    Apr 22 19:14:43.382: INFO: (7) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.031659ms)
    Apr 22 19:14:43.383: INFO: (7) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 11.644144ms)
    Apr 22 19:14:43.384: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 11.973382ms)
    Apr 22 19:14:43.385: INFO: (7) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.215966ms)
    Apr 22 19:14:43.388: INFO: (7) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 20.470587ms)
    Apr 22 19:14:43.388: INFO: (7) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.642968ms)
    Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.115859ms)
    Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 16.988112ms)
    Apr 22 19:14:43.389: INFO: (7) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 22.098941ms)
    Apr 22 19:14:43.390: INFO: (7) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 22.418364ms)
    Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.441812ms)
    Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 13.225794ms)
    Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.080137ms)
    Apr 22 19:14:43.404: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.057168ms)
    Apr 22 19:14:43.406: INFO: (8) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 14.291663ms)
    Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.118064ms)
    Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.974331ms)
    Apr 22 19:14:43.407: INFO: (8) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 17.142212ms)
    Apr 22 19:14:43.408: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.400785ms)
    Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 15.519882ms)
    Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.631304ms)
    Apr 22 19:14:43.409: INFO: (8) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 15.267644ms)
    Apr 22 19:14:43.410: INFO: (8) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 18.482845ms)
    Apr 22 19:14:43.410: INFO: (8) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 16.230529ms)
    Apr 22 19:14:43.415: INFO: (8) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 20.364395ms)
    Apr 22 19:14:43.415: INFO: (8) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 20.376821ms)
    Apr 22 19:14:43.423: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 7.150809ms)
    Apr 22 19:14:43.429: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 10.900063ms)
    Apr 22 19:14:43.429: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.94253ms)
    Apr 22 19:14:43.433: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 16.6232ms)
    Apr 22 19:14:43.434: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.979119ms)
    Apr 22 19:14:43.435: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 18.727635ms)
    Apr 22 19:14:43.436: INFO: (9) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.607546ms)
    Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.178798ms)
    Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.812478ms)
    Apr 22 19:14:43.439: INFO: (9) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 22.94077ms)
    Apr 22 19:14:43.438: INFO: (9) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 20.965109ms)
    Apr 22 19:14:43.440: INFO: (9) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 23.729716ms)
    Apr 22 19:14:43.441: INFO: (9) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 23.747071ms)
    Apr 22 19:14:43.442: INFO: (9) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 26.27721ms)
    Apr 22 19:14:43.442: INFO: (9) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 26.480609ms)
    Apr 22 19:14:43.443: INFO: (9) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 25.807ms)
    Apr 22 19:14:43.450: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 5.900637ms)
    Apr 22 19:14:43.454: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 8.266895ms)
    Apr 22 19:14:43.455: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 10.400244ms)
    Apr 22 19:14:43.456: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 10.924185ms)
    Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.024005ms)
    Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 13.050005ms)
    Apr 22 19:14:43.457: INFO: (10) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 13.376448ms)
    Apr 22 19:14:43.458: INFO: (10) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.133743ms)
    Apr 22 19:14:43.458: INFO: (10) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 14.743621ms)
    Apr 22 19:14:43.459: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.1697ms)
    Apr 22 19:14:43.460: INFO: (10) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.069002ms)
    Apr 22 19:14:43.460: INFO: (10) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.816731ms)
    Apr 22 19:14:43.461: INFO: (10) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 16.768444ms)
    Apr 22 19:14:43.462: INFO: (10) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 16.574234ms)
    Apr 22 19:14:43.462: INFO: (10) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 16.568576ms)
    Apr 22 19:14:43.464: INFO: (10) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.619124ms)
    Apr 22 19:14:43.473: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 8.986386ms)
    Apr 22 19:14:43.474: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 9.744071ms)
    Apr 22 19:14:43.474: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 9.841259ms)
    Apr 22 19:14:43.475: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 10.440774ms)
    Apr 22 19:14:43.476: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.221703ms)
    Apr 22 19:14:43.477: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 12.036966ms)
    Apr 22 19:14:43.478: INFO: (11) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 13.600295ms)
    Apr 22 19:14:43.478: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 13.412455ms)
    Apr 22 19:14:43.479: INFO: (11) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 14.111462ms)
    Apr 22 19:14:43.479: INFO: (11) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.657946ms)
    Apr 22 19:14:43.480: INFO: (11) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.239145ms)
    Apr 22 19:14:43.480: INFO: (11) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.447759ms)
    Apr 22 19:14:43.481: INFO: (11) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.901242ms)
    Apr 22 19:14:43.481: INFO: (11) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 15.987893ms)
    Apr 22 19:14:43.482: INFO: (11) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 16.652787ms)
    Apr 22 19:14:43.482: INFO: (11) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 16.999956ms)
    Apr 22 19:14:43.492: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 9.027681ms)
    Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.114421ms)
    Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 11.502906ms)
    Apr 22 19:14:43.495: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 11.422773ms)
    Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 11.939496ms)
    Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 11.940722ms)
    Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 13.086565ms)
    Apr 22 19:14:43.496: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 12.437522ms)
    Apr 22 19:14:43.497: INFO: (12) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 12.973824ms)
    Apr 22 19:14:43.497: INFO: (12) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.96243ms)
    Apr 22 19:14:43.501: INFO: (12) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 17.266658ms)
    Apr 22 19:14:43.501: INFO: (12) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.887006ms)
    Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 19.082263ms)
    Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 18.696044ms)
    Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 18.022134ms)
    Apr 22 19:14:43.502: INFO: (12) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 19.166483ms)
    Apr 22 19:14:43.512: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 9.693406ms)
    Apr 22 19:14:43.516: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 11.193158ms)
    Apr 22 19:14:43.516: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 11.727291ms)
    Apr 22 19:14:43.517: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 14.75595ms)
    Apr 22 19:14:43.518: INFO: (13) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 13.965097ms)
    Apr 22 19:14:43.519: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 15.652022ms)
    Apr 22 19:14:43.519: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.518209ms)
    Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 16.924747ms)
    Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 17.644628ms)
    Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 15.41123ms)
    Apr 22 19:14:43.520: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 17.210538ms)
    Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 17.361903ms)
    Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 18.221033ms)
    Apr 22 19:14:43.521: INFO: (13) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 17.005728ms)
    Apr 22 19:14:43.522: INFO: (13) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 19.331587ms)
    Apr 22 19:14:43.522: INFO: (13) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.971197ms)
    Apr 22 19:14:43.533: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 9.212049ms)
    Apr 22 19:14:43.535: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 10.922727ms)
    Apr 22 19:14:43.538: INFO: (14) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 14.439652ms)
    Apr 22 19:14:43.538: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 13.057026ms)
    Apr 22 19:14:43.539: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.680627ms)
    Apr 22 19:14:43.539: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 14.626809ms)
    Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.159701ms)
    Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 17.406495ms)
    Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 17.793585ms)
    Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 16.009683ms)
    Apr 22 19:14:43.540: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.125725ms)
    Apr 22 19:14:43.541: INFO: (14) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 16.214398ms)
    Apr 22 19:14:43.541: INFO: (14) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 18.188918ms)
    Apr 22 19:14:43.542: INFO: (14) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 17.943247ms)
    Apr 22 19:14:43.544: INFO: (14) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 19.562768ms)
    Apr 22 19:14:43.545: INFO: (14) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 20.055334ms)
    Apr 22 19:14:43.559: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 13.598802ms)
    Apr 22 19:14:43.561: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 14.832452ms)
    Apr 22 19:14:43.561: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 14.880203ms)
    Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 14.423774ms)
    Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 15.119191ms)
    Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.869095ms)
    Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 15.315841ms)
    Apr 22 19:14:43.562: INFO: (15) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 16.184454ms)
    Apr 22 19:14:43.563: INFO: (15) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 17.635087ms)
    Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 16.261615ms)
    Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 17.136969ms)
    Apr 22 19:14:43.564: INFO: (15) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 17.828502ms)
    Apr 22 19:14:43.566: INFO: (15) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 19.833861ms)
    Apr 22 19:14:43.569: INFO: (15) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 22.38638ms)
    Apr 22 19:14:43.569: INFO: (15) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 23.255882ms)
    Apr 22 19:14:43.576: INFO: (15) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 28.894068ms)
    Apr 22 19:14:43.597: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.302877ms)
    Apr 22 19:14:43.598: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 21.500553ms)
    Apr 22 19:14:43.598: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 20.308734ms)
    Apr 22 19:14:43.599: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 22.063739ms)
    Apr 22 19:14:43.600: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 22.03629ms)
    Apr 22 19:14:43.600: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.433669ms)
    Apr 22 19:14:43.601: INFO: (16) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 22.97307ms)
    Apr 22 19:14:43.602: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 23.724552ms)
    Apr 22 19:14:43.602: INFO: (16) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 24.602412ms)
    Apr 22 19:14:43.603: INFO: (16) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 25.177228ms)
    Apr 22 19:14:43.603: INFO: (16) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 26.40518ms)
    Apr 22 19:14:43.607: INFO: (16) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 29.886311ms)
    Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 32.20381ms)
    Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 32.286864ms)
    Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 32.126427ms)
    Apr 22 19:14:43.610: INFO: (16) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 32.794203ms)
    Apr 22 19:14:43.620: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 9.303189ms)
    Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 19.023305ms)
    Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 20.606097ms)
    Apr 22 19:14:43.631: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.303505ms)
    Apr 22 19:14:43.633: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.635112ms)
    Apr 22 19:14:43.634: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 22.884364ms)
    Apr 22 19:14:43.634: INFO: (17) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 23.168371ms)
    Apr 22 19:14:43.635: INFO: (17) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 22.677252ms)
    Apr 22 19:14:43.636: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 24.533582ms)
    Apr 22 19:14:43.636: INFO: (17) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 24.64182ms)
    Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 43.279784ms)
    Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 44.288407ms)
    Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 43.011693ms)
    Apr 22 19:14:43.654: INFO: (17) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 43.132131ms)
    Apr 22 19:14:43.655: INFO: (17) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 44.45509ms)
    Apr 22 19:14:43.655: INFO: (17) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 44.025179ms)
    Apr 22 19:14:43.676: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 19.89739ms)
    Apr 22 19:14:43.676: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 20.505114ms)
    Apr 22 19:14:43.678: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 21.685353ms)
    Apr 22 19:14:43.678: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 22.879268ms)
    Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 22.040482ms)
    Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 22.722368ms)
    Apr 22 19:14:43.679: INFO: (18) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 23.26323ms)
    Apr 22 19:14:43.680: INFO: (18) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 24.798493ms)
    Apr 22 19:14:43.681: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 24.350409ms)
    Apr 22 19:14:43.681: INFO: (18) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 26.373499ms)
    Apr 22 19:14:43.682: INFO: (18) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 26.789566ms)
    Apr 22 19:14:43.683: INFO: (18) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 26.400735ms)
    Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 27.763665ms)
    Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 27.495912ms)
    Apr 22 19:14:43.684: INFO: (18) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 27.70792ms)
    Apr 22 19:14:43.685: INFO: (18) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 29.134147ms)
    Apr 22 19:14:43.695: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">... (200; 8.577168ms)
    Apr 22 19:14:43.702: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 15.41604ms)
    Apr 22 19:14:43.703: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:1080/proxy/rewriteme">test<... (200; 17.115512ms)
    Apr 22 19:14:43.704: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln/proxy/rewriteme">test</a> (200; 14.16539ms)
    Apr 22 19:14:43.704: INFO: (19) /api/v1/namespaces/proxy-2488/pods/proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 14.682824ms)
    Apr 22 19:14:43.705: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:462/proxy/: tls qux (200; 16.336288ms)
    Apr 22 19:14:43.705: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:460/proxy/: tls baz (200; 15.371556ms)
    Apr 22 19:14:43.706: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:160/proxy/: foo (200; 19.213453ms)
    Apr 22 19:14:43.707: INFO: (19) /api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/: <a href="/api/v1/namespaces/proxy-2488/pods/https:proxy-service-m6xlg-zlmln:443/proxy/tlsrewritem... (200; 19.239025ms)
    Apr 22 19:14:43.708: INFO: (19) /api/v1/namespaces/proxy-2488/pods/http:proxy-service-m6xlg-zlmln:162/proxy/: bar (200; 20.760563ms)
    Apr 22 19:14:43.709: INFO: (19) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname1/proxy/: foo (200; 22.975181ms)
    Apr 22 19:14:43.709: INFO: (19) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname2/proxy/: tls qux (200; 19.204958ms)
    Apr 22 19:14:43.710: INFO: (19) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname1/proxy/: foo (200; 21.227534ms)
    Apr 22 19:14:43.710: INFO: (19) /api/v1/namespaces/proxy-2488/services/http:proxy-service-m6xlg:portname2/proxy/: bar (200; 22.566569ms)
    Apr 22 19:14:43.711: INFO: (19) /api/v1/namespaces/proxy-2488/services/proxy-service-m6xlg:portname2/proxy/: bar (200; 23.169195ms)
    Apr 22 19:14:43.711: INFO: (19) /api/v1/namespaces/proxy-2488/services/https:proxy-service-m6xlg:tlsportname1/proxy/: tls baz (200; 22.480539ms)
    STEP: deleting ReplicationController proxy-service-m6xlg in namespace proxy-2488, will wait for the garbage collector to delete the pods 04/22/23 19:14:43.712
    Apr 22 19:14:43.777: INFO: Deleting ReplicationController proxy-service-m6xlg took: 8.142174ms
    Apr 22 19:14:43.880: INFO: Terminating ReplicationController proxy-service-m6xlg pods took: 102.918352ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 22 19:14:45.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2488" for this suite. 04/22/23 19:14:45.892
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:45.914
Apr 22 19:14:45.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:14:45.918
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:45.944
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:45.95
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-c60f1e97-edc0-4704-af41-09ac256a0c9a 04/22/23 19:14:45.961
STEP: Creating configMap with name cm-test-opt-upd-dff2a544-7295-4389-b9b3-1d1b3c29d22d 04/22/23 19:14:45.966
STEP: Creating the pod 04/22/23 19:14:45.972
Apr 22 19:14:45.983: INFO: Waiting up to 5m0s for pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67" in namespace "configmap-6765" to be "running and ready"
Apr 22 19:14:45.989: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67": Phase="Pending", Reason="", readiness=false. Elapsed: 5.817521ms
Apr 22 19:14:45.989: INFO: The phase of Pod pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:14:47.998: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67": Phase="Running", Reason="", readiness=true. Elapsed: 2.015494637s
Apr 22 19:14:47.999: INFO: The phase of Pod pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67 is Running (Ready = true)
Apr 22 19:14:47.999: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-c60f1e97-edc0-4704-af41-09ac256a0c9a 04/22/23 19:14:48.085
STEP: Updating configmap cm-test-opt-upd-dff2a544-7295-4389-b9b3-1d1b3c29d22d 04/22/23 19:14:48.102
STEP: Creating configMap with name cm-test-opt-create-00e2f123-48bf-420b-84f1-86d4711948f3 04/22/23 19:14:48.118
STEP: waiting to observe update in volume 04/22/23 19:14:48.13
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:14:52.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6765" for this suite. 04/22/23 19:14:52.237
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":58,"skipped":1044,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.341 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:45.914
    Apr 22 19:14:45.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:14:45.918
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:45.944
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:45.95
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-c60f1e97-edc0-4704-af41-09ac256a0c9a 04/22/23 19:14:45.961
    STEP: Creating configMap with name cm-test-opt-upd-dff2a544-7295-4389-b9b3-1d1b3c29d22d 04/22/23 19:14:45.966
    STEP: Creating the pod 04/22/23 19:14:45.972
    Apr 22 19:14:45.983: INFO: Waiting up to 5m0s for pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67" in namespace "configmap-6765" to be "running and ready"
    Apr 22 19:14:45.989: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67": Phase="Pending", Reason="", readiness=false. Elapsed: 5.817521ms
    Apr 22 19:14:45.989: INFO: The phase of Pod pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:14:47.998: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67": Phase="Running", Reason="", readiness=true. Elapsed: 2.015494637s
    Apr 22 19:14:47.999: INFO: The phase of Pod pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67 is Running (Ready = true)
    Apr 22 19:14:47.999: INFO: Pod "pod-configmaps-959a3f0e-708d-44be-a616-4af1fd084b67" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-c60f1e97-edc0-4704-af41-09ac256a0c9a 04/22/23 19:14:48.085
    STEP: Updating configmap cm-test-opt-upd-dff2a544-7295-4389-b9b3-1d1b3c29d22d 04/22/23 19:14:48.102
    STEP: Creating configMap with name cm-test-opt-create-00e2f123-48bf-420b-84f1-86d4711948f3 04/22/23 19:14:48.118
    STEP: waiting to observe update in volume 04/22/23 19:14:48.13
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:14:52.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6765" for this suite. 04/22/23 19:14:52.237
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:52.29
Apr 22 19:14:52.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:14:52.292
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:52.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:52.36
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:14:52.371
Apr 22 19:14:52.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce" in namespace "downward-api-9885" to be "Succeeded or Failed"
Apr 22 19:14:52.398: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Pending", Reason="", readiness=false. Elapsed: 7.235201ms
Apr 22 19:14:54.410: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019035989s
Apr 22 19:14:56.407: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016381762s
STEP: Saw pod success 04/22/23 19:14:56.407
Apr 22 19:14:56.408: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce" satisfied condition "Succeeded or Failed"
Apr 22 19:14:56.418: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce container client-container: <nil>
STEP: delete the pod 04/22/23 19:14:56.434
Apr 22 19:14:56.464: INFO: Waiting for pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce to disappear
Apr 22 19:14:56.472: INFO: Pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:14:56.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9885" for this suite. 04/22/23 19:14:56.485
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":59,"skipped":1075,"failed":0}
------------------------------
â€¢ [4.214 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:52.29
    Apr 22 19:14:52.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:14:52.292
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:52.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:52.36
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:14:52.371
    Apr 22 19:14:52.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce" in namespace "downward-api-9885" to be "Succeeded or Failed"
    Apr 22 19:14:52.398: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Pending", Reason="", readiness=false. Elapsed: 7.235201ms
    Apr 22 19:14:54.410: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019035989s
    Apr 22 19:14:56.407: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016381762s
    STEP: Saw pod success 04/22/23 19:14:56.407
    Apr 22 19:14:56.408: INFO: Pod "downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce" satisfied condition "Succeeded or Failed"
    Apr 22 19:14:56.418: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce container client-container: <nil>
    STEP: delete the pod 04/22/23 19:14:56.434
    Apr 22 19:14:56.464: INFO: Waiting for pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce to disappear
    Apr 22 19:14:56.472: INFO: Pod downwardapi-volume-c6d6b716-a978-49d3-a874-df0d9fbac0ce no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:14:56.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9885" for this suite. 04/22/23 19:14:56.485
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:14:56.514
Apr 22 19:14:56.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 19:14:56.517
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:56.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:56.57
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 04/22/23 19:14:56.577
Apr 22 19:14:56.592: INFO: Waiting up to 5m0s for pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536" in namespace "var-expansion-4939" to be "Succeeded or Failed"
Apr 22 19:14:56.601: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720381ms
Apr 22 19:14:58.609: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017624595s
Apr 22 19:15:00.613: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020938593s
STEP: Saw pod success 04/22/23 19:15:00.613
Apr 22 19:15:00.614: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536" satisfied condition "Succeeded or Failed"
Apr 22 19:15:00.623: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 container dapi-container: <nil>
STEP: delete the pod 04/22/23 19:15:00.642
Apr 22 19:15:00.700: INFO: Waiting for pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 to disappear
Apr 22 19:15:00.707: INFO: Pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 19:15:00.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4939" for this suite. 04/22/23 19:15:00.721
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":60,"skipped":1079,"failed":0}
------------------------------
â€¢ [4.224 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:14:56.514
    Apr 22 19:14:56.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 19:14:56.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:14:56.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:14:56.57
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 04/22/23 19:14:56.577
    Apr 22 19:14:56.592: INFO: Waiting up to 5m0s for pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536" in namespace "var-expansion-4939" to be "Succeeded or Failed"
    Apr 22 19:14:56.601: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720381ms
    Apr 22 19:14:58.609: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017624595s
    Apr 22 19:15:00.613: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020938593s
    STEP: Saw pod success 04/22/23 19:15:00.613
    Apr 22 19:15:00.614: INFO: Pod "var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536" satisfied condition "Succeeded or Failed"
    Apr 22 19:15:00.623: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 19:15:00.642
    Apr 22 19:15:00.700: INFO: Waiting for pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 to disappear
    Apr 22 19:15:00.707: INFO: Pod var-expansion-f69c0f5f-6f8a-4650-84ad-a663e257f536 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 19:15:00.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4939" for this suite. 04/22/23 19:15:00.721
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:00.743
Apr 22 19:15:00.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 19:15:00.746
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:00.797
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:00.805
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 22 19:15:00.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:15:01.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-538" for this suite. 04/22/23 19:15:01.446
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":61,"skipped":1092,"failed":0}
------------------------------
â€¢ [0.725 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:00.743
    Apr 22 19:15:00.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 19:15:00.746
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:00.797
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:00.805
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 22 19:15:00.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:15:01.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-538" for this suite. 04/22/23 19:15:01.446
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:01.484
Apr 22 19:15:01.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:15:01.486
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:01.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:01.562
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/22/23 19:15:01.57
Apr 22 19:15:01.588: INFO: Waiting up to 5m0s for pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4" in namespace "emptydir-3512" to be "Succeeded or Failed"
Apr 22 19:15:01.593: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661864ms
Apr 22 19:15:03.603: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015320243s
Apr 22 19:15:05.603: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014914578s
STEP: Saw pod success 04/22/23 19:15:05.603
Apr 22 19:15:05.604: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4" satisfied condition "Succeeded or Failed"
Apr 22 19:15:05.613: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 container test-container: <nil>
STEP: delete the pod 04/22/23 19:15:05.634
Apr 22 19:15:05.664: INFO: Waiting for pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 to disappear
Apr 22 19:15:05.671: INFO: Pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:15:05.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3512" for this suite. 04/22/23 19:15:05.687
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":62,"skipped":1095,"failed":0}
------------------------------
â€¢ [4.219 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:01.484
    Apr 22 19:15:01.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:15:01.486
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:01.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:01.562
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/22/23 19:15:01.57
    Apr 22 19:15:01.588: INFO: Waiting up to 5m0s for pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4" in namespace "emptydir-3512" to be "Succeeded or Failed"
    Apr 22 19:15:01.593: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661864ms
    Apr 22 19:15:03.603: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015320243s
    Apr 22 19:15:05.603: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014914578s
    STEP: Saw pod success 04/22/23 19:15:05.603
    Apr 22 19:15:05.604: INFO: Pod "pod-93d47a8c-baef-4b0e-831d-fa61986c27e4" satisfied condition "Succeeded or Failed"
    Apr 22 19:15:05.613: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:15:05.634
    Apr 22 19:15:05.664: INFO: Waiting for pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 to disappear
    Apr 22 19:15:05.671: INFO: Pod pod-93d47a8c-baef-4b0e-831d-fa61986c27e4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:15:05.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3512" for this suite. 04/22/23 19:15:05.687
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:05.741
Apr 22 19:15:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:15:05.743
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:05.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:05.808
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-e21e1687-1f61-4dd0-a62d-c2a109ef8167 04/22/23 19:15:05.822
STEP: Creating the pod 04/22/23 19:15:05.83
Apr 22 19:15:05.845: INFO: Waiting up to 5m0s for pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650" in namespace "configmap-7402" to be "running"
Apr 22 19:15:05.851: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79129ms
Apr 22 19:15:07.864: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650": Phase="Running", Reason="", readiness=false. Elapsed: 2.019307273s
Apr 22 19:15:07.864: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650" satisfied condition "running"
STEP: Waiting for pod with text data 04/22/23 19:15:07.864
STEP: Waiting for pod with binary data 04/22/23 19:15:07.886
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:15:07.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7402" for this suite. 04/22/23 19:15:07.915
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":63,"skipped":1136,"failed":0}
------------------------------
â€¢ [2.198 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:05.741
    Apr 22 19:15:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:15:05.743
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:05.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:05.808
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-e21e1687-1f61-4dd0-a62d-c2a109ef8167 04/22/23 19:15:05.822
    STEP: Creating the pod 04/22/23 19:15:05.83
    Apr 22 19:15:05.845: INFO: Waiting up to 5m0s for pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650" in namespace "configmap-7402" to be "running"
    Apr 22 19:15:05.851: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79129ms
    Apr 22 19:15:07.864: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650": Phase="Running", Reason="", readiness=false. Elapsed: 2.019307273s
    Apr 22 19:15:07.864: INFO: Pod "pod-configmaps-093639ac-ff41-4e36-b68f-e42052bcb650" satisfied condition "running"
    STEP: Waiting for pod with text data 04/22/23 19:15:07.864
    STEP: Waiting for pod with binary data 04/22/23 19:15:07.886
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:15:07.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7402" for this suite. 04/22/23 19:15:07.915
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:07.952
Apr 22 19:15:07.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:15:07.954
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:08.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:08.038
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-2fa3bc69-fa0b-44fe-8777-ea84418fd0f9 04/22/23 19:15:08.047
STEP: Creating a pod to test consume configMaps 04/22/23 19:15:08.059
Apr 22 19:15:08.080: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c" in namespace "projected-2466" to be "Succeeded or Failed"
Apr 22 19:15:08.087: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.060276ms
Apr 22 19:15:10.098: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01781551s
Apr 22 19:15:12.097: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016452916s
STEP: Saw pod success 04/22/23 19:15:12.097
Apr 22 19:15:12.098: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c" satisfied condition "Succeeded or Failed"
Apr 22 19:15:12.106: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:15:12.126
Apr 22 19:15:12.161: INFO: Waiting for pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c to disappear
Apr 22 19:15:12.174: INFO: Pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:15:12.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2466" for this suite. 04/22/23 19:15:12.185
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":64,"skipped":1150,"failed":0}
------------------------------
â€¢ [4.251 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:07.952
    Apr 22 19:15:07.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:15:07.954
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:08.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:08.038
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-2fa3bc69-fa0b-44fe-8777-ea84418fd0f9 04/22/23 19:15:08.047
    STEP: Creating a pod to test consume configMaps 04/22/23 19:15:08.059
    Apr 22 19:15:08.080: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c" in namespace "projected-2466" to be "Succeeded or Failed"
    Apr 22 19:15:08.087: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.060276ms
    Apr 22 19:15:10.098: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01781551s
    Apr 22 19:15:12.097: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016452916s
    STEP: Saw pod success 04/22/23 19:15:12.097
    Apr 22 19:15:12.098: INFO: Pod "pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c" satisfied condition "Succeeded or Failed"
    Apr 22 19:15:12.106: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:15:12.126
    Apr 22 19:15:12.161: INFO: Waiting for pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c to disappear
    Apr 22 19:15:12.174: INFO: Pod pod-projected-configmaps-06195e25-08a8-4947-ab0a-0edfb8463d6c no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:15:12.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2466" for this suite. 04/22/23 19:15:12.185
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:12.204
Apr 22 19:15:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename watch 04/22/23 19:15:12.209
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:12.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:12.265
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/22/23 19:15:12.274
STEP: creating a watch on configmaps with label B 04/22/23 19:15:12.278
STEP: creating a watch on configmaps with label A or B 04/22/23 19:15:12.281
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.284
Apr 22 19:15:12.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10007 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:12.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10007 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.296
Apr 22 19:15:12.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10008 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:12.316: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10008 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/22/23 19:15:12.316
Apr 22 19:15:12.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10009 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:12.340: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10009 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.341
Apr 22 19:15:12.366: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10010 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:12.367: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10010 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/22/23 19:15:12.368
Apr 22 19:15:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10011 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10011 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/22/23 19:15:22.379
Apr 22 19:15:22.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10060 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:15:22.392: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10060 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 22 19:15:32.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5291" for this suite. 04/22/23 19:15:32.41
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":65,"skipped":1182,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.223 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:12.204
    Apr 22 19:15:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename watch 04/22/23 19:15:12.209
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:12.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:12.265
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/22/23 19:15:12.274
    STEP: creating a watch on configmaps with label B 04/22/23 19:15:12.278
    STEP: creating a watch on configmaps with label A or B 04/22/23 19:15:12.281
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.284
    Apr 22 19:15:12.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10007 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:12.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10007 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.296
    Apr 22 19:15:12.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10008 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:12.316: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10008 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/22/23 19:15:12.316
    Apr 22 19:15:12.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10009 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:12.340: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10009 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/22/23 19:15:12.341
    Apr 22 19:15:12.366: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10010 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:12.367: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5291  cb33c44e-244b-4bb6-a37f-57152e10be07 10010 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/22/23 19:15:12.368
    Apr 22 19:15:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10011 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10011 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/22/23 19:15:22.379
    Apr 22 19:15:22.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10060 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:15:22.392: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5291  56ccb9ef-d2fa-4ec8-b7be-17b17f1e9deb 10060 0 2023-04-22 19:15:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-22 19:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 22 19:15:32.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5291" for this suite. 04/22/23 19:15:32.41
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:32.434
Apr 22 19:15:32.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename ingressclass 04/22/23 19:15:32.44
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:32.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:32.518
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/22/23 19:15:32.527
STEP: getting /apis/networking.k8s.io 04/22/23 19:15:32.534
STEP: getting /apis/networking.k8s.iov1 04/22/23 19:15:32.538
STEP: creating 04/22/23 19:15:32.542
STEP: getting 04/22/23 19:15:32.575
STEP: listing 04/22/23 19:15:32.582
STEP: watching 04/22/23 19:15:32.59
Apr 22 19:15:32.590: INFO: starting watch
STEP: patching 04/22/23 19:15:32.593
STEP: updating 04/22/23 19:15:32.605
Apr 22 19:15:32.617: INFO: waiting for watch events with expected annotations
Apr 22 19:15:32.618: INFO: saw patched and updated annotations
STEP: deleting 04/22/23 19:15:32.62
STEP: deleting a collection 04/22/23 19:15:32.649
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Apr 22 19:15:32.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-8354" for this suite. 04/22/23 19:15:32.702
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":66,"skipped":1183,"failed":0}
------------------------------
â€¢ [0.284 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:32.434
    Apr 22 19:15:32.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename ingressclass 04/22/23 19:15:32.44
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:32.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:32.518
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/22/23 19:15:32.527
    STEP: getting /apis/networking.k8s.io 04/22/23 19:15:32.534
    STEP: getting /apis/networking.k8s.iov1 04/22/23 19:15:32.538
    STEP: creating 04/22/23 19:15:32.542
    STEP: getting 04/22/23 19:15:32.575
    STEP: listing 04/22/23 19:15:32.582
    STEP: watching 04/22/23 19:15:32.59
    Apr 22 19:15:32.590: INFO: starting watch
    STEP: patching 04/22/23 19:15:32.593
    STEP: updating 04/22/23 19:15:32.605
    Apr 22 19:15:32.617: INFO: waiting for watch events with expected annotations
    Apr 22 19:15:32.618: INFO: saw patched and updated annotations
    STEP: deleting 04/22/23 19:15:32.62
    STEP: deleting a collection 04/22/23 19:15:32.649
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Apr 22 19:15:32.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-8354" for this suite. 04/22/23 19:15:32.702
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:32.747
Apr 22 19:15:32.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:15:32.75
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:32.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:32.816
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:15:32.831
Apr 22 19:15:32.848: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3301" to be "running and ready"
Apr 22 19:15:32.860: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.968334ms
Apr 22 19:15:32.860: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:15:34.870: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021417384s
Apr 22 19:15:34.870: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 22 19:15:34.870: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 04/22/23 19:15:34.877
Apr 22 19:15:34.894: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3301" to be "running and ready"
Apr 22 19:15:34.908: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.841773ms
Apr 22 19:15:34.908: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:15:36.922: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.027976793s
Apr 22 19:15:36.922: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 22 19:15:36.922: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/22/23 19:15:36.931
STEP: delete the pod with lifecycle hook 04/22/23 19:15:36.95
Apr 22 19:15:36.984: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 22 19:15:37.007: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 22 19:15:39.009: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 22 19:15:39.021: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 22 19:15:41.008: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 22 19:15:41.022: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 22 19:15:41.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3301" for this suite. 04/22/23 19:15:41.036
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":67,"skipped":1206,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.304 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:32.747
    Apr 22 19:15:32.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:15:32.75
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:32.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:32.816
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:15:32.831
    Apr 22 19:15:32.848: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3301" to be "running and ready"
    Apr 22 19:15:32.860: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.968334ms
    Apr 22 19:15:32.860: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:15:34.870: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021417384s
    Apr 22 19:15:34.870: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 22 19:15:34.870: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 04/22/23 19:15:34.877
    Apr 22 19:15:34.894: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3301" to be "running and ready"
    Apr 22 19:15:34.908: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.841773ms
    Apr 22 19:15:34.908: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:15:36.922: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.027976793s
    Apr 22 19:15:36.922: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 22 19:15:36.922: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/22/23 19:15:36.931
    STEP: delete the pod with lifecycle hook 04/22/23 19:15:36.95
    Apr 22 19:15:36.984: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 22 19:15:37.007: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 22 19:15:39.009: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 22 19:15:39.021: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 22 19:15:41.008: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 22 19:15:41.022: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 22 19:15:41.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3301" for this suite. 04/22/23 19:15:41.036
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:15:41.087
Apr 22 19:15:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename subpath 04/22/23 19:15:41.091
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:41.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:41.147
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/22/23 19:15:41.158
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-z9hb 04/22/23 19:15:41.177
STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:15:41.177
Apr 22 19:15:41.193: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-z9hb" in namespace "subpath-5911" to be "Succeeded or Failed"
Apr 22 19:15:41.203: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.197066ms
Apr 22 19:15:43.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 2.019383892s
Apr 22 19:15:45.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 4.018406708s
Apr 22 19:15:47.214: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 6.020378832s
Apr 22 19:15:49.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 8.018817492s
Apr 22 19:15:51.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 10.019195383s
Apr 22 19:15:53.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 12.018956269s
Apr 22 19:15:55.214: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 14.020199561s
Apr 22 19:15:57.211: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 16.017461104s
Apr 22 19:15:59.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 18.019234046s
Apr 22 19:16:01.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 20.018290967s
Apr 22 19:16:03.211: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=false. Elapsed: 22.017737951s
Apr 22 19:16:05.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.019518924s
STEP: Saw pod success 04/22/23 19:16:05.213
Apr 22 19:16:05.214: INFO: Pod "pod-subpath-test-secret-z9hb" satisfied condition "Succeeded or Failed"
Apr 22 19:16:05.223: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-secret-z9hb container test-container-subpath-secret-z9hb: <nil>
STEP: delete the pod 04/22/23 19:16:05.244
Apr 22 19:16:05.272: INFO: Waiting for pod pod-subpath-test-secret-z9hb to disappear
Apr 22 19:16:05.281: INFO: Pod pod-subpath-test-secret-z9hb no longer exists
STEP: Deleting pod pod-subpath-test-secret-z9hb 04/22/23 19:16:05.281
Apr 22 19:16:05.282: INFO: Deleting pod "pod-subpath-test-secret-z9hb" in namespace "subpath-5911"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 22 19:16:05.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5911" for this suite. 04/22/23 19:16:05.308
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":68,"skipped":1239,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.239 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:15:41.087
    Apr 22 19:15:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename subpath 04/22/23 19:15:41.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:15:41.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:15:41.147
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/22/23 19:15:41.158
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-z9hb 04/22/23 19:15:41.177
    STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:15:41.177
    Apr 22 19:15:41.193: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-z9hb" in namespace "subpath-5911" to be "Succeeded or Failed"
    Apr 22 19:15:41.203: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.197066ms
    Apr 22 19:15:43.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 2.019383892s
    Apr 22 19:15:45.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 4.018406708s
    Apr 22 19:15:47.214: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 6.020378832s
    Apr 22 19:15:49.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 8.018817492s
    Apr 22 19:15:51.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 10.019195383s
    Apr 22 19:15:53.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 12.018956269s
    Apr 22 19:15:55.214: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 14.020199561s
    Apr 22 19:15:57.211: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 16.017461104s
    Apr 22 19:15:59.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 18.019234046s
    Apr 22 19:16:01.212: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=true. Elapsed: 20.018290967s
    Apr 22 19:16:03.211: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Running", Reason="", readiness=false. Elapsed: 22.017737951s
    Apr 22 19:16:05.213: INFO: Pod "pod-subpath-test-secret-z9hb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.019518924s
    STEP: Saw pod success 04/22/23 19:16:05.213
    Apr 22 19:16:05.214: INFO: Pod "pod-subpath-test-secret-z9hb" satisfied condition "Succeeded or Failed"
    Apr 22 19:16:05.223: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-secret-z9hb container test-container-subpath-secret-z9hb: <nil>
    STEP: delete the pod 04/22/23 19:16:05.244
    Apr 22 19:16:05.272: INFO: Waiting for pod pod-subpath-test-secret-z9hb to disappear
    Apr 22 19:16:05.281: INFO: Pod pod-subpath-test-secret-z9hb no longer exists
    STEP: Deleting pod pod-subpath-test-secret-z9hb 04/22/23 19:16:05.281
    Apr 22 19:16:05.282: INFO: Deleting pod "pod-subpath-test-secret-z9hb" in namespace "subpath-5911"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 22 19:16:05.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5911" for this suite. 04/22/23 19:16:05.308
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:16:05.353
Apr 22 19:16:05.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:16:05.356
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:05.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:05.421
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 22 19:16:05.449: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 22 19:16:10.459: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 19:16:10.459
Apr 22 19:16:10.461: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 22 19:16:12.471: INFO: Creating deployment "test-rollover-deployment"
Apr 22 19:16:12.496: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 22 19:16:14.516: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 22 19:16:14.535: INFO: Ensure that both replica sets have 1 created replica
Apr 22 19:16:14.551: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 22 19:16:14.574: INFO: Updating deployment test-rollover-deployment
Apr 22 19:16:14.575: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 22 19:16:16.598: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 22 19:16:16.614: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 22 19:16:16.632: INFO: all replica sets need to contain the pod-template-hash label
Apr 22 19:16:16.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 19:16:18.655: INFO: all replica sets need to contain the pod-template-hash label
Apr 22 19:16:18.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 19:16:20.653: INFO: all replica sets need to contain the pod-template-hash label
Apr 22 19:16:20.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 19:16:22.653: INFO: all replica sets need to contain the pod-template-hash label
Apr 22 19:16:22.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 19:16:24.654: INFO: all replica sets need to contain the pod-template-hash label
Apr 22 19:16:24.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 19:16:26.652: INFO: 
Apr 22 19:16:26.653: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:16:26.680: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8065  9d285630-2f0b-4e8d-a07f-ef13eec72d4a 10392 2 2023-04-22 19:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f07178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-22 19:16:12 +0000 UTC,LastTransitionTime:2023-04-22 19:16:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-22 19:16:26 +0000 UTC,LastTransitionTime:2023-04-22 19:16:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 22 19:16:26.691: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8065  4e37bea3-0a08-401b-bf12-15e152fc157a 10382 2 2023-04-22 19:16:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07757 0xc003f07758}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f07808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:16:26.692: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 22 19:16:26.692: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8065  3085942f-0791-48f0-80e9-2ab44c057225 10391 2 2023-04-22 19:16:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07507 0xc003f07508}] [] [{e2e.test Update apps/v1 2023-04-22 19:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003f075c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:16:26.693: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8065  88bd073c-abe7-4825-9a14-20510ef8bf25 10340 2 2023-04-22 19:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07637 0xc003f07638}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f076e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:16:26.704: INFO: Pod "test-rollover-deployment-6d45fd857b-p2l7x" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-p2l7x test-rollover-deployment-6d45fd857b- deployment-8065  5ba68a4b-179c-463e-8c8e-644c1a8997a6 10353 0 2023-04-22 19:16:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 4e37bea3-0a08-401b-bf12-15e152fc157a 0xc003eb39c7 0xc003eb39c8}] [] [{kube-controller-manager Update v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e37bea3-0a08-401b-bf12-15e152fc157a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:16:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4bcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4bcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.3,StartTime:2023-04-22 19:16:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:16:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://b6126872369e453d7b5c25f4550b9ef35e568374003aba500562a70a8b494b5a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:16:26.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8065" for this suite. 04/22/23 19:16:26.717
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":69,"skipped":1259,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.385 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:16:05.353
    Apr 22 19:16:05.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:16:05.356
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:05.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:05.421
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 22 19:16:05.449: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 22 19:16:10.459: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 19:16:10.459
    Apr 22 19:16:10.461: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 22 19:16:12.471: INFO: Creating deployment "test-rollover-deployment"
    Apr 22 19:16:12.496: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 22 19:16:14.516: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 22 19:16:14.535: INFO: Ensure that both replica sets have 1 created replica
    Apr 22 19:16:14.551: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 22 19:16:14.574: INFO: Updating deployment test-rollover-deployment
    Apr 22 19:16:14.575: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 22 19:16:16.598: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 22 19:16:16.614: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 22 19:16:16.632: INFO: all replica sets need to contain the pod-template-hash label
    Apr 22 19:16:16.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 19:16:18.655: INFO: all replica sets need to contain the pod-template-hash label
    Apr 22 19:16:18.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 19:16:20.653: INFO: all replica sets need to contain the pod-template-hash label
    Apr 22 19:16:20.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 19:16:22.653: INFO: all replica sets need to contain the pod-template-hash label
    Apr 22 19:16:22.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 19:16:24.654: INFO: all replica sets need to contain the pod-template-hash label
    Apr 22 19:16:24.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 19, 16, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 19, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 19:16:26.652: INFO: 
    Apr 22 19:16:26.653: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:16:26.680: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-8065  9d285630-2f0b-4e8d-a07f-ef13eec72d4a 10392 2 2023-04-22 19:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f07178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-22 19:16:12 +0000 UTC,LastTransitionTime:2023-04-22 19:16:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-22 19:16:26 +0000 UTC,LastTransitionTime:2023-04-22 19:16:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 22 19:16:26.691: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8065  4e37bea3-0a08-401b-bf12-15e152fc157a 10382 2 2023-04-22 19:16:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07757 0xc003f07758}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f07808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:16:26.692: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 22 19:16:26.692: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8065  3085942f-0791-48f0-80e9-2ab44c057225 10391 2 2023-04-22 19:16:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07507 0xc003f07508}] [] [{e2e.test Update apps/v1 2023-04-22 19:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:26 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003f075c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:16:26.693: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8065  88bd073c-abe7-4825-9a14-20510ef8bf25 10340 2 2023-04-22 19:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9d285630-2f0b-4e8d-a07f-ef13eec72d4a 0xc003f07637 0xc003f07638}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d285630-2f0b-4e8d-a07f-ef13eec72d4a\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f076e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:16:26.704: INFO: Pod "test-rollover-deployment-6d45fd857b-p2l7x" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-p2l7x test-rollover-deployment-6d45fd857b- deployment-8065  5ba68a4b-179c-463e-8c8e-644c1a8997a6 10353 0 2023-04-22 19:16:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 4e37bea3-0a08-401b-bf12-15e152fc157a 0xc003eb39c7 0xc003eb39c8}] [] [{kube-controller-manager Update v1 2023-04-22 19:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e37bea3-0a08-401b-bf12-15e152fc157a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:16:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4bcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4bcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:16:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.3,StartTime:2023-04-22 19:16:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:16:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://b6126872369e453d7b5c25f4550b9ef35e568374003aba500562a70a8b494b5a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:16:26.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8065" for this suite. 04/22/23 19:16:26.717
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:16:26.751
Apr 22 19:16:26.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:16:26.754
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:26.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:26.82
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-e919733b-2577-4219-952d-62d7d14f1e94 04/22/23 19:16:26.836
STEP: Creating configMap with name cm-test-opt-upd-5ac37e36-fb53-4c09-9cda-606e54d88aaa 04/22/23 19:16:26.844
STEP: Creating the pod 04/22/23 19:16:26.851
Apr 22 19:16:26.876: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3" in namespace "projected-7113" to be "running and ready"
Apr 22 19:16:26.885: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.342715ms
Apr 22 19:16:26.885: INFO: The phase of Pod pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:16:28.896: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019334006s
Apr 22 19:16:28.896: INFO: The phase of Pod pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3 is Running (Ready = true)
Apr 22 19:16:28.896: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-e919733b-2577-4219-952d-62d7d14f1e94 04/22/23 19:16:28.954
STEP: Updating configmap cm-test-opt-upd-5ac37e36-fb53-4c09-9cda-606e54d88aaa 04/22/23 19:16:28.972
STEP: Creating configMap with name cm-test-opt-create-36daa0c8-0686-4103-ab89-b447d1d78757 04/22/23 19:16:28.986
STEP: waiting to observe update in volume 04/22/23 19:16:28.998
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:16:31.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7113" for this suite. 04/22/23 19:16:31.08
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":70,"skipped":1263,"failed":0}
------------------------------
â€¢ [4.346 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:16:26.751
    Apr 22 19:16:26.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:16:26.754
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:26.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:26.82
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-e919733b-2577-4219-952d-62d7d14f1e94 04/22/23 19:16:26.836
    STEP: Creating configMap with name cm-test-opt-upd-5ac37e36-fb53-4c09-9cda-606e54d88aaa 04/22/23 19:16:26.844
    STEP: Creating the pod 04/22/23 19:16:26.851
    Apr 22 19:16:26.876: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3" in namespace "projected-7113" to be "running and ready"
    Apr 22 19:16:26.885: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.342715ms
    Apr 22 19:16:26.885: INFO: The phase of Pod pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:16:28.896: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019334006s
    Apr 22 19:16:28.896: INFO: The phase of Pod pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3 is Running (Ready = true)
    Apr 22 19:16:28.896: INFO: Pod "pod-projected-configmaps-4443b635-828c-4cb6-9fb8-56a8c693a5c3" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-e919733b-2577-4219-952d-62d7d14f1e94 04/22/23 19:16:28.954
    STEP: Updating configmap cm-test-opt-upd-5ac37e36-fb53-4c09-9cda-606e54d88aaa 04/22/23 19:16:28.972
    STEP: Creating configMap with name cm-test-opt-create-36daa0c8-0686-4103-ab89-b447d1d78757 04/22/23 19:16:28.986
    STEP: waiting to observe update in volume 04/22/23 19:16:28.998
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:16:31.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7113" for this suite. 04/22/23 19:16:31.08
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:16:31.13
Apr 22 19:16:31.131: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:16:31.134
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:31.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:31.201
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 04/22/23 19:16:31.209
Apr 22 19:16:31.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 create -f -'
Apr 22 19:16:32.637: INFO: stderr: ""
Apr 22 19:16:32.637: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/22/23 19:16:32.637
Apr 22 19:16:32.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 diff -f -'
Apr 22 19:16:32.936: INFO: rc: 1
Apr 22 19:16:32.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 delete -f -'
Apr 22 19:16:33.065: INFO: stderr: ""
Apr 22 19:16:33.065: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:16:33.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4376" for this suite. 04/22/23 19:16:33.082
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":71,"skipped":1288,"failed":0}
------------------------------
â€¢ [1.980 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:16:31.13
    Apr 22 19:16:31.131: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:16:31.134
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:31.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:31.201
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 04/22/23 19:16:31.209
    Apr 22 19:16:31.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 create -f -'
    Apr 22 19:16:32.637: INFO: stderr: ""
    Apr 22 19:16:32.637: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/22/23 19:16:32.637
    Apr 22 19:16:32.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 diff -f -'
    Apr 22 19:16:32.936: INFO: rc: 1
    Apr 22 19:16:32.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4376 delete -f -'
    Apr 22 19:16:33.065: INFO: stderr: ""
    Apr 22 19:16:33.065: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:16:33.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4376" for this suite. 04/22/23 19:16:33.082
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:16:33.115
Apr 22 19:16:33.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:16:33.117
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:33.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:33.164
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 04/22/23 19:16:33.173
STEP: submitting the pod to kubernetes 04/22/23 19:16:33.174
Apr 22 19:16:33.187: INFO: Waiting up to 5m0s for pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" in namespace "pods-7033" to be "running and ready"
Apr 22 19:16:33.193: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12842ms
Apr 22 19:16:33.193: INFO: The phase of Pod pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:16:35.203: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Running", Reason="", readiness=true. Elapsed: 2.016183546s
Apr 22 19:16:35.203: INFO: The phase of Pod pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae is Running (Ready = true)
Apr 22 19:16:35.203: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/22/23 19:16:35.211
STEP: updating the pod 04/22/23 19:16:35.222
Apr 22 19:16:35.751: INFO: Successfully updated pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae"
Apr 22 19:16:35.752: INFO: Waiting up to 5m0s for pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" in namespace "pods-7033" to be "running"
Apr 22 19:16:35.760: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Running", Reason="", readiness=true. Elapsed: 8.184951ms
Apr 22 19:16:35.760: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/22/23 19:16:35.76
Apr 22 19:16:35.769: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:16:35.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7033" for this suite. 04/22/23 19:16:35.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":72,"skipped":1324,"failed":0}
------------------------------
â€¢ [2.686 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:16:33.115
    Apr 22 19:16:33.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:16:33.117
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:33.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:33.164
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 04/22/23 19:16:33.173
    STEP: submitting the pod to kubernetes 04/22/23 19:16:33.174
    Apr 22 19:16:33.187: INFO: Waiting up to 5m0s for pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" in namespace "pods-7033" to be "running and ready"
    Apr 22 19:16:33.193: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12842ms
    Apr 22 19:16:33.193: INFO: The phase of Pod pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:16:35.203: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Running", Reason="", readiness=true. Elapsed: 2.016183546s
    Apr 22 19:16:35.203: INFO: The phase of Pod pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae is Running (Ready = true)
    Apr 22 19:16:35.203: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/22/23 19:16:35.211
    STEP: updating the pod 04/22/23 19:16:35.222
    Apr 22 19:16:35.751: INFO: Successfully updated pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae"
    Apr 22 19:16:35.752: INFO: Waiting up to 5m0s for pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" in namespace "pods-7033" to be "running"
    Apr 22 19:16:35.760: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae": Phase="Running", Reason="", readiness=true. Elapsed: 8.184951ms
    Apr 22 19:16:35.760: INFO: Pod "pod-update-f461af4b-90b0-4cd5-a5f9-cde7c5598eae" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/22/23 19:16:35.76
    Apr 22 19:16:35.769: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:16:35.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7033" for this suite. 04/22/23 19:16:35.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:16:35.859
Apr 22 19:16:35.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:16:35.861
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:35.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:35.92
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/22/23 19:16:35.927
Apr 22 19:16:35.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/22/23 19:16:49.249
Apr 22 19:16:49.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:16:52.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:17:05.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1670" for this suite. 04/22/23 19:17:05.398
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":73,"skipped":1422,"failed":0}
------------------------------
â€¢ [SLOW TEST] [29.546 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:16:35.859
    Apr 22 19:16:35.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:16:35.861
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:16:35.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:16:35.92
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/22/23 19:16:35.927
    Apr 22 19:16:35.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/22/23 19:16:49.249
    Apr 22 19:16:49.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:16:52.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:17:05.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1670" for this suite. 04/22/23 19:17:05.398
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:05.416
Apr 22 19:17:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename subpath 04/22/23 19:17:05.417
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:05.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:05.447
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/22/23 19:17:05.451
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-ph22 04/22/23 19:17:05.462
STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:17:05.462
Apr 22 19:17:05.470: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ph22" in namespace "subpath-5641" to be "Succeeded or Failed"
Apr 22 19:17:05.478: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Pending", Reason="", readiness=false. Elapsed: 8.374224ms
Apr 22 19:17:07.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 2.017361477s
Apr 22 19:17:09.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 4.017181091s
Apr 22 19:17:11.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 6.016939617s
Apr 22 19:17:13.489: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 8.01924901s
Apr 22 19:17:15.488: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 10.018103574s
Apr 22 19:17:17.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 12.017345175s
Apr 22 19:17:19.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 14.017424279s
Apr 22 19:17:21.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 16.016949509s
Apr 22 19:17:23.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 18.016752454s
Apr 22 19:17:25.488: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 20.0175791s
Apr 22 19:17:27.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=false. Elapsed: 22.017148439s
Apr 22 19:17:29.484: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013752071s
STEP: Saw pod success 04/22/23 19:17:29.484
Apr 22 19:17:29.485: INFO: Pod "pod-subpath-test-configmap-ph22" satisfied condition "Succeeded or Failed"
Apr 22 19:17:29.489: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-configmap-ph22 container test-container-subpath-configmap-ph22: <nil>
STEP: delete the pod 04/22/23 19:17:29.508
Apr 22 19:17:29.531: INFO: Waiting for pod pod-subpath-test-configmap-ph22 to disappear
Apr 22 19:17:29.537: INFO: Pod pod-subpath-test-configmap-ph22 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ph22 04/22/23 19:17:29.537
Apr 22 19:17:29.537: INFO: Deleting pod "pod-subpath-test-configmap-ph22" in namespace "subpath-5641"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 22 19:17:29.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5641" for this suite. 04/22/23 19:17:29.548
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":74,"skipped":1487,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.139 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:05.416
    Apr 22 19:17:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename subpath 04/22/23 19:17:05.417
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:05.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:05.447
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/22/23 19:17:05.451
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-ph22 04/22/23 19:17:05.462
    STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:17:05.462
    Apr 22 19:17:05.470: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ph22" in namespace "subpath-5641" to be "Succeeded or Failed"
    Apr 22 19:17:05.478: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Pending", Reason="", readiness=false. Elapsed: 8.374224ms
    Apr 22 19:17:07.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 2.017361477s
    Apr 22 19:17:09.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 4.017181091s
    Apr 22 19:17:11.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 6.016939617s
    Apr 22 19:17:13.489: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 8.01924901s
    Apr 22 19:17:15.488: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 10.018103574s
    Apr 22 19:17:17.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 12.017345175s
    Apr 22 19:17:19.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 14.017424279s
    Apr 22 19:17:21.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 16.016949509s
    Apr 22 19:17:23.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 18.016752454s
    Apr 22 19:17:25.488: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=true. Elapsed: 20.0175791s
    Apr 22 19:17:27.487: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Running", Reason="", readiness=false. Elapsed: 22.017148439s
    Apr 22 19:17:29.484: INFO: Pod "pod-subpath-test-configmap-ph22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013752071s
    STEP: Saw pod success 04/22/23 19:17:29.484
    Apr 22 19:17:29.485: INFO: Pod "pod-subpath-test-configmap-ph22" satisfied condition "Succeeded or Failed"
    Apr 22 19:17:29.489: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-configmap-ph22 container test-container-subpath-configmap-ph22: <nil>
    STEP: delete the pod 04/22/23 19:17:29.508
    Apr 22 19:17:29.531: INFO: Waiting for pod pod-subpath-test-configmap-ph22 to disappear
    Apr 22 19:17:29.537: INFO: Pod pod-subpath-test-configmap-ph22 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-ph22 04/22/23 19:17:29.537
    Apr 22 19:17:29.537: INFO: Deleting pod "pod-subpath-test-configmap-ph22" in namespace "subpath-5641"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 22 19:17:29.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5641" for this suite. 04/22/23 19:17:29.548
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:29.571
Apr 22 19:17:29.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-runtime 04/22/23 19:17:29.574
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:29.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:29.613
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 04/22/23 19:17:29.619
STEP: wait for the container to reach Succeeded 04/22/23 19:17:29.633
STEP: get the container status 04/22/23 19:17:32.668
STEP: the container should be terminated 04/22/23 19:17:32.677
STEP: the termination message should be set 04/22/23 19:17:32.678
Apr 22 19:17:32.679: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/22/23 19:17:32.679
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 22 19:17:32.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6022" for this suite. 04/22/23 19:17:32.755
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":75,"skipped":1502,"failed":0}
------------------------------
â€¢ [3.198 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:29.571
    Apr 22 19:17:29.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-runtime 04/22/23 19:17:29.574
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:29.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:29.613
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 04/22/23 19:17:29.619
    STEP: wait for the container to reach Succeeded 04/22/23 19:17:29.633
    STEP: get the container status 04/22/23 19:17:32.668
    STEP: the container should be terminated 04/22/23 19:17:32.677
    STEP: the termination message should be set 04/22/23 19:17:32.678
    Apr 22 19:17:32.679: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/22/23 19:17:32.679
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 22 19:17:32.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6022" for this suite. 04/22/23 19:17:32.755
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:32.792
Apr 22 19:17:32.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:17:32.795
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:32.851
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:32.858
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 22 19:17:32.872: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 22 19:17:32.887: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 22 19:17:37.895: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 19:17:37.895
Apr 22 19:17:37.896: INFO: Creating deployment "test-rolling-update-deployment"
Apr 22 19:17:37.910: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 22 19:17:37.921: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 22 19:17:39.940: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 22 19:17:39.948: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:17:39.971: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3307  b26a805b-b5c5-4b51-82a3-39aeb26f310c 10849 1 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00432b5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-22 19:17:37 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-22 19:17:39 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 22 19:17:39.980: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3307  6f95e964-ca29-4b24-acc5-5c9e4715d6a8 10839 1 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b26a805b-b5c5-4b51-82a3-39aeb26f310c 0xc0042f0b67 0xc0042f0b68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b26a805b-b5c5-4b51-82a3-39aeb26f310c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042f0c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:17:39.981: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 22 19:17:39.982: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3307  bbd7d2c4-2a52-4188-afcb-9eacdcf4c756 10848 2 2023-04-22 19:17:32 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b26a805b-b5c5-4b51-82a3-39aeb26f310c 0xc0042f09c7 0xc0042f09c8}] [] [{e2e.test Update apps/v1 2023-04-22 19:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b26a805b-b5c5-4b51-82a3-39aeb26f310c\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0042f0ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:17:39.994: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pprhq" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pprhq test-rolling-update-deployment-78f575d8ff- deployment-3307  4efebdbc-7dcb-4798-853b-589b301041df 10838 0 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 6f95e964-ca29-4b24-acc5-5c9e4715d6a8 0xc00432ba67 0xc00432ba68}] [] [{kube-controller-manager Update v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6f95e964-ca29-4b24-acc5-5c9e4715d6a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l9djh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l9djh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.2,StartTime:2023-04-22 19:17:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:17:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://618011e8dad386fad55bebac9e855f702c61b70cf7a00f978633a4de9565e7e7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:17:39.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3307" for this suite. 04/22/23 19:17:40.009
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":76,"skipped":1530,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.234 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:32.792
    Apr 22 19:17:32.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:17:32.795
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:32.851
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:32.858
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 22 19:17:32.872: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 22 19:17:32.887: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 22 19:17:37.895: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 19:17:37.895
    Apr 22 19:17:37.896: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 22 19:17:37.910: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 22 19:17:37.921: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 22 19:17:39.940: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 22 19:17:39.948: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:17:39.971: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3307  b26a805b-b5c5-4b51-82a3-39aeb26f310c 10849 1 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00432b5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-22 19:17:37 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-22 19:17:39 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 22 19:17:39.980: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3307  6f95e964-ca29-4b24-acc5-5c9e4715d6a8 10839 1 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b26a805b-b5c5-4b51-82a3-39aeb26f310c 0xc0042f0b67 0xc0042f0b68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b26a805b-b5c5-4b51-82a3-39aeb26f310c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042f0c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:17:39.981: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 22 19:17:39.982: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3307  bbd7d2c4-2a52-4188-afcb-9eacdcf4c756 10848 2 2023-04-22 19:17:32 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b26a805b-b5c5-4b51-82a3-39aeb26f310c 0xc0042f09c7 0xc0042f09c8}] [] [{e2e.test Update apps/v1 2023-04-22 19:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b26a805b-b5c5-4b51-82a3-39aeb26f310c\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0042f0ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:17:39.994: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pprhq" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pprhq test-rolling-update-deployment-78f575d8ff- deployment-3307  4efebdbc-7dcb-4798-853b-589b301041df 10838 0 2023-04-22 19:17:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 6f95e964-ca29-4b24-acc5-5c9e4715d6a8 0xc00432ba67 0xc00432ba68}] [] [{kube-controller-manager Update v1 2023-04-22 19:17:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6f95e964-ca29-4b24-acc5-5c9e4715d6a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:17:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l9djh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l9djh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:17:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.2,StartTime:2023-04-22 19:17:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:17:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://618011e8dad386fad55bebac9e855f702c61b70cf7a00f978633a4de9565e7e7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:17:39.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3307" for this suite. 04/22/23 19:17:40.009
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:40.032
Apr 22 19:17:40.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:17:40.036
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:40.087
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:40.097
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:17:40.108
Apr 22 19:17:40.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787" in namespace "projected-6188" to be "Succeeded or Failed"
Apr 22 19:17:40.142: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Pending", Reason="", readiness=false. Elapsed: 13.25131ms
Apr 22 19:17:42.154: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024831582s
Apr 22 19:17:44.152: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023136936s
STEP: Saw pod success 04/22/23 19:17:44.152
Apr 22 19:17:44.153: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787" satisfied condition "Succeeded or Failed"
Apr 22 19:17:44.160: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 container client-container: <nil>
STEP: delete the pod 04/22/23 19:17:44.178
Apr 22 19:17:44.220: INFO: Waiting for pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 to disappear
Apr 22 19:17:44.229: INFO: Pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 19:17:44.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6188" for this suite. 04/22/23 19:17:44.241
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":77,"skipped":1537,"failed":0}
------------------------------
â€¢ [4.230 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:40.032
    Apr 22 19:17:40.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:17:40.036
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:40.087
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:40.097
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:17:40.108
    Apr 22 19:17:40.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787" in namespace "projected-6188" to be "Succeeded or Failed"
    Apr 22 19:17:40.142: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Pending", Reason="", readiness=false. Elapsed: 13.25131ms
    Apr 22 19:17:42.154: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024831582s
    Apr 22 19:17:44.152: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023136936s
    STEP: Saw pod success 04/22/23 19:17:44.152
    Apr 22 19:17:44.153: INFO: Pod "downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787" satisfied condition "Succeeded or Failed"
    Apr 22 19:17:44.160: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:17:44.178
    Apr 22 19:17:44.220: INFO: Waiting for pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 to disappear
    Apr 22 19:17:44.229: INFO: Pod downwardapi-volume-fa229ea5-463d-4b9b-9005-65dabf984787 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 19:17:44.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6188" for this suite. 04/22/23 19:17:44.241
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:44.273
Apr 22 19:17:44.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:17:44.276
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:44.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:44.327
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-65eaf446-cf7c-49bc-af6c-dfad7c566cc5 04/22/23 19:17:44.339
STEP: Creating a pod to test consume configMaps 04/22/23 19:17:44.357
Apr 22 19:17:44.376: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe" in namespace "projected-29" to be "Succeeded or Failed"
Apr 22 19:17:44.385: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.945653ms
Apr 22 19:17:46.395: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018722136s
Apr 22 19:17:48.394: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018205219s
STEP: Saw pod success 04/22/23 19:17:48.394
Apr 22 19:17:48.395: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe" satisfied condition "Succeeded or Failed"
Apr 22 19:17:48.403: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:17:48.42
Apr 22 19:17:48.452: INFO: Waiting for pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe to disappear
Apr 22 19:17:48.460: INFO: Pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:17:48.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-29" for this suite. 04/22/23 19:17:48.472
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":78,"skipped":1544,"failed":0}
------------------------------
â€¢ [4.233 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:44.273
    Apr 22 19:17:44.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:17:44.276
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:44.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:44.327
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-65eaf446-cf7c-49bc-af6c-dfad7c566cc5 04/22/23 19:17:44.339
    STEP: Creating a pod to test consume configMaps 04/22/23 19:17:44.357
    Apr 22 19:17:44.376: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe" in namespace "projected-29" to be "Succeeded or Failed"
    Apr 22 19:17:44.385: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.945653ms
    Apr 22 19:17:46.395: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018722136s
    Apr 22 19:17:48.394: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018205219s
    STEP: Saw pod success 04/22/23 19:17:48.394
    Apr 22 19:17:48.395: INFO: Pod "pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe" satisfied condition "Succeeded or Failed"
    Apr 22 19:17:48.403: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:17:48.42
    Apr 22 19:17:48.452: INFO: Waiting for pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe to disappear
    Apr 22 19:17:48.460: INFO: Pod pod-projected-configmaps-62325651-dab5-40c6-b17b-c820e5585bbe no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:17:48.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-29" for this suite. 04/22/23 19:17:48.472
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:17:48.515
Apr 22 19:17:48.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pod-network-test 04/22/23 19:17:48.517
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:48.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:48.564
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-1703 04/22/23 19:17:48.571
STEP: creating a selector 04/22/23 19:17:48.572
STEP: Creating the service pods in kubernetes 04/22/23 19:17:48.573
Apr 22 19:17:48.574: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 22 19:17:48.616: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1703" to be "running and ready"
Apr 22 19:17:48.627: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.144757ms
Apr 22 19:17:48.628: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:17:50.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.021187776s
Apr 22 19:17:50.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:17:52.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022027404s
Apr 22 19:17:52.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:17:54.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.021767124s
Apr 22 19:17:54.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:17:56.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.021925531s
Apr 22 19:17:56.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:17:58.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021119951s
Apr 22 19:17:58.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:00.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0220397s
Apr 22 19:18:00.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:02.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021363399s
Apr 22 19:18:02.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:04.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02246782s
Apr 22 19:18:04.640: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:06.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022356517s
Apr 22 19:18:06.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:08.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021804471s
Apr 22 19:18:08.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 19:18:10.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022460571s
Apr 22 19:18:10.639: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 22 19:18:10.639: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 22 19:18:10.649: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1703" to be "running and ready"
Apr 22 19:18:10.658: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 9.472016ms
Apr 22 19:18:10.658: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 22 19:18:10.658: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 04/22/23 19:18:10.666
Apr 22 19:18:10.707: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1703" to be "running"
Apr 22 19:18:10.722: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.286512ms
Apr 22 19:18:12.730: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022777022s
Apr 22 19:18:12.730: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 22 19:18:12.742: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1703" to be "running"
Apr 22 19:18:12.750: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.009773ms
Apr 22 19:18:12.750: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 22 19:18:12.761: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr 22 19:18:12.762: INFO: Going to poll 10.44.0.6 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Apr 22 19:18:12.781: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.44.0.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1703 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:18:12.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:18:12.785: INFO: ExecWithOptions: Clientset creation
Apr 22 19:18:12.786: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1703/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.44.0.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 22 19:18:13.931: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 22 19:18:13.931: INFO: Going to poll 10.36.0.1 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Apr 22 19:18:13.940: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.36.0.1 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1703 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:18:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:18:13.943: INFO: ExecWithOptions: Clientset creation
Apr 22 19:18:13.943: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1703/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.36.0.1+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 22 19:18:15.123: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 22 19:18:15.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1703" for this suite. 04/22/23 19:18:15.135
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":79,"skipped":1556,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.636 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:17:48.515
    Apr 22 19:17:48.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pod-network-test 04/22/23 19:17:48.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:17:48.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:17:48.564
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-1703 04/22/23 19:17:48.571
    STEP: creating a selector 04/22/23 19:17:48.572
    STEP: Creating the service pods in kubernetes 04/22/23 19:17:48.573
    Apr 22 19:17:48.574: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 22 19:17:48.616: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1703" to be "running and ready"
    Apr 22 19:17:48.627: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.144757ms
    Apr 22 19:17:48.628: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:17:50.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.021187776s
    Apr 22 19:17:50.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:17:52.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022027404s
    Apr 22 19:17:52.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:17:54.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.021767124s
    Apr 22 19:17:54.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:17:56.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.021925531s
    Apr 22 19:17:56.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:17:58.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021119951s
    Apr 22 19:17:58.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:00.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0220397s
    Apr 22 19:18:00.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:02.638: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021363399s
    Apr 22 19:18:02.638: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:04.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02246782s
    Apr 22 19:18:04.640: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:06.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022356517s
    Apr 22 19:18:06.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:08.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021804471s
    Apr 22 19:18:08.639: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 19:18:10.639: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022460571s
    Apr 22 19:18:10.639: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 22 19:18:10.639: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 22 19:18:10.649: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1703" to be "running and ready"
    Apr 22 19:18:10.658: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 9.472016ms
    Apr 22 19:18:10.658: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 22 19:18:10.658: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 04/22/23 19:18:10.666
    Apr 22 19:18:10.707: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1703" to be "running"
    Apr 22 19:18:10.722: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.286512ms
    Apr 22 19:18:12.730: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022777022s
    Apr 22 19:18:12.730: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 22 19:18:12.742: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1703" to be "running"
    Apr 22 19:18:12.750: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.009773ms
    Apr 22 19:18:12.750: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 22 19:18:12.761: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Apr 22 19:18:12.762: INFO: Going to poll 10.44.0.6 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Apr 22 19:18:12.781: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.44.0.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1703 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:18:12.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:18:12.785: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:18:12.786: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1703/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.44.0.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 22 19:18:13.931: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 22 19:18:13.931: INFO: Going to poll 10.36.0.1 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Apr 22 19:18:13.940: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.36.0.1 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1703 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:18:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:18:13.943: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:18:13.943: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1703/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.36.0.1+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 22 19:18:15.123: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 22 19:18:15.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1703" for this suite. 04/22/23 19:18:15.135
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:18:15.166
Apr 22 19:18:15.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svc-latency 04/22/23 19:18:15.168
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:15.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:15.226
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 22 19:18:15.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3198 04/22/23 19:18:15.239
I0422 19:18:15.255209      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3198, replica count: 1
I0422 19:18:16.307974      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0422 19:18:17.308882      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:18:17.448: INFO: Created: latency-svc-cmq2z
Apr 22 19:18:17.472: INFO: Got endpoints: latency-svc-cmq2z [61.884833ms]
Apr 22 19:18:17.515: INFO: Created: latency-svc-bqpdh
Apr 22 19:18:17.531: INFO: Got endpoints: latency-svc-bqpdh [56.479755ms]
Apr 22 19:18:17.541: INFO: Created: latency-svc-8lw5d
Apr 22 19:18:17.549: INFO: Got endpoints: latency-svc-8lw5d [74.390209ms]
Apr 22 19:18:17.565: INFO: Created: latency-svc-25xgf
Apr 22 19:18:17.579: INFO: Got endpoints: latency-svc-25xgf [105.643587ms]
Apr 22 19:18:17.585: INFO: Created: latency-svc-m827h
Apr 22 19:18:17.596: INFO: Got endpoints: latency-svc-m827h [120.553407ms]
Apr 22 19:18:17.619: INFO: Created: latency-svc-dk9cl
Apr 22 19:18:17.624: INFO: Got endpoints: latency-svc-dk9cl [148.011899ms]
Apr 22 19:18:17.629: INFO: Created: latency-svc-rjtqp
Apr 22 19:18:17.645: INFO: Got endpoints: latency-svc-rjtqp [167.45819ms]
Apr 22 19:18:17.656: INFO: Created: latency-svc-l9j77
Apr 22 19:18:17.664: INFO: Got endpoints: latency-svc-l9j77 [187.751207ms]
Apr 22 19:18:17.670: INFO: Created: latency-svc-qsphb
Apr 22 19:18:17.680: INFO: Got endpoints: latency-svc-qsphb [201.692615ms]
Apr 22 19:18:17.691: INFO: Created: latency-svc-6sxqj
Apr 22 19:18:17.693: INFO: Got endpoints: latency-svc-6sxqj [213.896212ms]
Apr 22 19:18:17.708: INFO: Created: latency-svc-7rkn6
Apr 22 19:18:17.716: INFO: Got endpoints: latency-svc-7rkn6 [235.459206ms]
Apr 22 19:18:17.726: INFO: Created: latency-svc-w8nth
Apr 22 19:18:17.742: INFO: Created: latency-svc-gqspn
Apr 22 19:18:17.745: INFO: Got endpoints: latency-svc-w8nth [265.255778ms]
Apr 22 19:18:17.763: INFO: Got endpoints: latency-svc-gqspn [281.735286ms]
Apr 22 19:18:17.773: INFO: Created: latency-svc-tvknd
Apr 22 19:18:17.781: INFO: Got endpoints: latency-svc-tvknd [299.903215ms]
Apr 22 19:18:17.788: INFO: Created: latency-svc-b58sz
Apr 22 19:18:17.797: INFO: Got endpoints: latency-svc-b58sz [314.985056ms]
Apr 22 19:18:17.804: INFO: Created: latency-svc-fglvn
Apr 22 19:18:17.809: INFO: Got endpoints: latency-svc-fglvn [332.463834ms]
Apr 22 19:18:17.837: INFO: Created: latency-svc-dc65p
Apr 22 19:18:17.848: INFO: Got endpoints: latency-svc-dc65p [316.956446ms]
Apr 22 19:18:17.855: INFO: Created: latency-svc-9jxpr
Apr 22 19:18:17.862: INFO: Got endpoints: latency-svc-9jxpr [312.109621ms]
Apr 22 19:18:17.871: INFO: Created: latency-svc-qn2gq
Apr 22 19:18:17.879: INFO: Got endpoints: latency-svc-qn2gq [299.758897ms]
Apr 22 19:18:17.895: INFO: Created: latency-svc-zljnm
Apr 22 19:18:17.904: INFO: Got endpoints: latency-svc-zljnm [307.737838ms]
Apr 22 19:18:17.910: INFO: Created: latency-svc-szh8t
Apr 22 19:18:17.919: INFO: Got endpoints: latency-svc-szh8t [294.489841ms]
Apr 22 19:18:17.928: INFO: Created: latency-svc-smzz9
Apr 22 19:18:17.931: INFO: Got endpoints: latency-svc-smzz9 [286.423046ms]
Apr 22 19:18:17.941: INFO: Created: latency-svc-jwmld
Apr 22 19:18:17.947: INFO: Got endpoints: latency-svc-jwmld [283.058774ms]
Apr 22 19:18:17.954: INFO: Created: latency-svc-r9q6q
Apr 22 19:18:17.967: INFO: Got endpoints: latency-svc-r9q6q [286.542385ms]
Apr 22 19:18:17.972: INFO: Created: latency-svc-4lkwb
Apr 22 19:18:17.978: INFO: Got endpoints: latency-svc-4lkwb [284.455561ms]
Apr 22 19:18:17.985: INFO: Created: latency-svc-4bnmc
Apr 22 19:18:17.991: INFO: Got endpoints: latency-svc-4bnmc [274.807854ms]
Apr 22 19:18:18.003: INFO: Created: latency-svc-ss62n
Apr 22 19:18:18.005: INFO: Got endpoints: latency-svc-ss62n [258.766703ms]
Apr 22 19:18:18.018: INFO: Created: latency-svc-6tkh6
Apr 22 19:18:18.024: INFO: Got endpoints: latency-svc-6tkh6 [260.825576ms]
Apr 22 19:18:18.042: INFO: Created: latency-svc-c5lzf
Apr 22 19:18:18.044: INFO: Got endpoints: latency-svc-c5lzf [261.808681ms]
Apr 22 19:18:18.054: INFO: Created: latency-svc-n6t42
Apr 22 19:18:18.062: INFO: Got endpoints: latency-svc-n6t42 [264.815837ms]
Apr 22 19:18:18.092: INFO: Created: latency-svc-8zzgf
Apr 22 19:18:18.106: INFO: Got endpoints: latency-svc-8zzgf [296.234685ms]
Apr 22 19:18:18.130: INFO: Created: latency-svc-sxbzc
Apr 22 19:18:18.134: INFO: Got endpoints: latency-svc-sxbzc [285.512735ms]
Apr 22 19:18:18.159: INFO: Created: latency-svc-8w2fv
Apr 22 19:18:18.167: INFO: Got endpoints: latency-svc-8w2fv [304.518635ms]
Apr 22 19:18:18.176: INFO: Created: latency-svc-pcd27
Apr 22 19:18:18.189: INFO: Got endpoints: latency-svc-pcd27 [309.96399ms]
Apr 22 19:18:18.200: INFO: Created: latency-svc-xpjbl
Apr 22 19:18:18.209: INFO: Got endpoints: latency-svc-xpjbl [304.508543ms]
Apr 22 19:18:18.214: INFO: Created: latency-svc-zdqfh
Apr 22 19:18:18.221: INFO: Got endpoints: latency-svc-zdqfh [302.41994ms]
Apr 22 19:18:18.230: INFO: Created: latency-svc-pq5bb
Apr 22 19:18:18.258: INFO: Got endpoints: latency-svc-pq5bb [326.020049ms]
Apr 22 19:18:18.263: INFO: Created: latency-svc-pc4rl
Apr 22 19:18:18.268: INFO: Got endpoints: latency-svc-pc4rl [319.516457ms]
Apr 22 19:18:18.278: INFO: Created: latency-svc-zlqvr
Apr 22 19:18:18.285: INFO: Got endpoints: latency-svc-zlqvr [318.1154ms]
Apr 22 19:18:18.292: INFO: Created: latency-svc-465qj
Apr 22 19:18:18.300: INFO: Got endpoints: latency-svc-465qj [322.195372ms]
Apr 22 19:18:18.311: INFO: Created: latency-svc-x25jl
Apr 22 19:18:18.317: INFO: Got endpoints: latency-svc-x25jl [325.790772ms]
Apr 22 19:18:18.322: INFO: Created: latency-svc-xn4pz
Apr 22 19:18:18.327: INFO: Got endpoints: latency-svc-xn4pz [322.100611ms]
Apr 22 19:18:18.338: INFO: Created: latency-svc-ttpfz
Apr 22 19:18:18.340: INFO: Got endpoints: latency-svc-ttpfz [316.271891ms]
Apr 22 19:18:18.355: INFO: Created: latency-svc-lj8vx
Apr 22 19:18:18.365: INFO: Got endpoints: latency-svc-lj8vx [321.350173ms]
Apr 22 19:18:18.379: INFO: Created: latency-svc-h9smb
Apr 22 19:18:18.387: INFO: Got endpoints: latency-svc-h9smb [325.300821ms]
Apr 22 19:18:18.394: INFO: Created: latency-svc-dw29w
Apr 22 19:18:18.406: INFO: Created: latency-svc-k7llg
Apr 22 19:18:18.413: INFO: Got endpoints: latency-svc-dw29w [307.087407ms]
Apr 22 19:18:18.417: INFO: Got endpoints: latency-svc-k7llg [282.014156ms]
Apr 22 19:18:18.424: INFO: Created: latency-svc-jz5x8
Apr 22 19:18:18.432: INFO: Got endpoints: latency-svc-jz5x8 [265.086339ms]
Apr 22 19:18:18.437: INFO: Created: latency-svc-6dlqm
Apr 22 19:18:18.446: INFO: Got endpoints: latency-svc-6dlqm [256.109816ms]
Apr 22 19:18:18.454: INFO: Created: latency-svc-h57gj
Apr 22 19:18:18.476: INFO: Got endpoints: latency-svc-h57gj [267.19474ms]
Apr 22 19:18:18.477: INFO: Created: latency-svc-nnchp
Apr 22 19:18:18.487: INFO: Created: latency-svc-src4d
Apr 22 19:18:18.507: INFO: Created: latency-svc-8hw9x
Apr 22 19:18:18.526: INFO: Got endpoints: latency-svc-nnchp [304.371717ms]
Apr 22 19:18:18.532: INFO: Created: latency-svc-mhl8m
Apr 22 19:18:18.550: INFO: Created: latency-svc-4rjnl
Apr 22 19:18:18.560: INFO: Created: latency-svc-gvg4n
Apr 22 19:18:18.577: INFO: Got endpoints: latency-svc-src4d [317.252348ms]
Apr 22 19:18:18.581: INFO: Created: latency-svc-mzgkd
Apr 22 19:18:18.606: INFO: Created: latency-svc-ls2k8
Apr 22 19:18:18.622: INFO: Created: latency-svc-w4v8c
Apr 22 19:18:18.626: INFO: Got endpoints: latency-svc-8hw9x [358.276173ms]
Apr 22 19:18:18.635: INFO: Created: latency-svc-p7pwl
Apr 22 19:18:18.646: INFO: Created: latency-svc-ktxgn
Apr 22 19:18:18.657: INFO: Created: latency-svc-rbd49
Apr 22 19:18:18.678: INFO: Got endpoints: latency-svc-mhl8m [393.529622ms]
Apr 22 19:18:18.680: INFO: Created: latency-svc-nbjrv
Apr 22 19:18:18.694: INFO: Created: latency-svc-g87nz
Apr 22 19:18:18.716: INFO: Created: latency-svc-dp7hp
Apr 22 19:18:18.725: INFO: Got endpoints: latency-svc-4rjnl [425.184646ms]
Apr 22 19:18:18.731: INFO: Created: latency-svc-lsb7c
Apr 22 19:18:18.748: INFO: Created: latency-svc-72t9d
Apr 22 19:18:18.765: INFO: Created: latency-svc-ghrmp
Apr 22 19:18:18.776: INFO: Got endpoints: latency-svc-gvg4n [458.527257ms]
Apr 22 19:18:18.812: INFO: Created: latency-svc-7t8dt
Apr 22 19:18:18.830: INFO: Got endpoints: latency-svc-mzgkd [502.525805ms]
Apr 22 19:18:18.841: INFO: Created: latency-svc-ttbgt
Apr 22 19:18:18.843: INFO: Created: latency-svc-zkwbn
Apr 22 19:18:18.856: INFO: Created: latency-svc-ckvxz
Apr 22 19:18:18.870: INFO: Got endpoints: latency-svc-ls2k8 [529.33757ms]
Apr 22 19:18:18.891: INFO: Created: latency-svc-7qn6h
Apr 22 19:18:18.921: INFO: Got endpoints: latency-svc-w4v8c [554.826719ms]
Apr 22 19:18:18.948: INFO: Created: latency-svc-b8hfh
Apr 22 19:18:18.971: INFO: Got endpoints: latency-svc-p7pwl [582.655137ms]
Apr 22 19:18:18.992: INFO: Created: latency-svc-k9pwr
Apr 22 19:18:19.027: INFO: Got endpoints: latency-svc-ktxgn [613.842547ms]
Apr 22 19:18:19.046: INFO: Created: latency-svc-4f9fj
Apr 22 19:18:19.070: INFO: Got endpoints: latency-svc-rbd49 [652.826887ms]
Apr 22 19:18:19.090: INFO: Created: latency-svc-sf6lj
Apr 22 19:18:19.122: INFO: Got endpoints: latency-svc-nbjrv [689.863563ms]
Apr 22 19:18:19.152: INFO: Created: latency-svc-z52mf
Apr 22 19:18:19.170: INFO: Got endpoints: latency-svc-g87nz [724.046073ms]
Apr 22 19:18:19.191: INFO: Created: latency-svc-gc2r7
Apr 22 19:18:19.220: INFO: Got endpoints: latency-svc-dp7hp [743.449386ms]
Apr 22 19:18:19.242: INFO: Created: latency-svc-47vm9
Apr 22 19:18:19.271: INFO: Got endpoints: latency-svc-lsb7c [745.414193ms]
Apr 22 19:18:19.313: INFO: Created: latency-svc-sk6t9
Apr 22 19:18:19.326: INFO: Got endpoints: latency-svc-72t9d [748.062466ms]
Apr 22 19:18:19.361: INFO: Created: latency-svc-g96lz
Apr 22 19:18:19.374: INFO: Got endpoints: latency-svc-ghrmp [747.869222ms]
Apr 22 19:18:19.396: INFO: Created: latency-svc-lvzgv
Apr 22 19:18:19.428: INFO: Got endpoints: latency-svc-7t8dt [701.759163ms]
Apr 22 19:18:19.451: INFO: Created: latency-svc-584jm
Apr 22 19:18:19.473: INFO: Got endpoints: latency-svc-ttbgt [696.814826ms]
Apr 22 19:18:19.502: INFO: Created: latency-svc-vkl6g
Apr 22 19:18:19.522: INFO: Got endpoints: latency-svc-zkwbn [843.386906ms]
Apr 22 19:18:19.559: INFO: Created: latency-svc-pw474
Apr 22 19:18:19.571: INFO: Got endpoints: latency-svc-ckvxz [740.169675ms]
Apr 22 19:18:19.593: INFO: Created: latency-svc-t27nq
Apr 22 19:18:19.621: INFO: Got endpoints: latency-svc-7qn6h [750.589476ms]
Apr 22 19:18:19.643: INFO: Created: latency-svc-27rj2
Apr 22 19:18:19.684: INFO: Got endpoints: latency-svc-b8hfh [763.548518ms]
Apr 22 19:18:19.706: INFO: Created: latency-svc-xm7gh
Apr 22 19:18:19.723: INFO: Got endpoints: latency-svc-k9pwr [752.239211ms]
Apr 22 19:18:19.748: INFO: Created: latency-svc-6gnqk
Apr 22 19:18:19.773: INFO: Got endpoints: latency-svc-4f9fj [744.725251ms]
Apr 22 19:18:19.829: INFO: Created: latency-svc-zbqlm
Apr 22 19:18:19.831: INFO: Got endpoints: latency-svc-sf6lj [760.075211ms]
Apr 22 19:18:19.874: INFO: Got endpoints: latency-svc-z52mf [751.812927ms]
Apr 22 19:18:19.881: INFO: Created: latency-svc-8fvqk
Apr 22 19:18:19.894: INFO: Created: latency-svc-ltz84
Apr 22 19:18:19.921: INFO: Got endpoints: latency-svc-gc2r7 [750.733618ms]
Apr 22 19:18:19.939: INFO: Created: latency-svc-lkbdk
Apr 22 19:18:19.973: INFO: Got endpoints: latency-svc-47vm9 [752.240351ms]
Apr 22 19:18:19.989: INFO: Created: latency-svc-gvfjs
Apr 22 19:18:20.023: INFO: Got endpoints: latency-svc-sk6t9 [751.752873ms]
Apr 22 19:18:20.047: INFO: Created: latency-svc-njkn7
Apr 22 19:18:20.073: INFO: Got endpoints: latency-svc-g96lz [746.577338ms]
Apr 22 19:18:20.099: INFO: Created: latency-svc-kmwfn
Apr 22 19:18:20.124: INFO: Got endpoints: latency-svc-lvzgv [749.196858ms]
Apr 22 19:18:20.152: INFO: Created: latency-svc-xd4bz
Apr 22 19:18:20.187: INFO: Got endpoints: latency-svc-584jm [758.456532ms]
Apr 22 19:18:20.214: INFO: Created: latency-svc-m9dgs
Apr 22 19:18:20.229: INFO: Got endpoints: latency-svc-vkl6g [755.943284ms]
Apr 22 19:18:20.250: INFO: Created: latency-svc-q55k7
Apr 22 19:18:20.274: INFO: Got endpoints: latency-svc-pw474 [751.506731ms]
Apr 22 19:18:20.310: INFO: Created: latency-svc-kvzcp
Apr 22 19:18:20.326: INFO: Got endpoints: latency-svc-t27nq [755.038634ms]
Apr 22 19:18:20.346: INFO: Created: latency-svc-pjzkf
Apr 22 19:18:20.372: INFO: Got endpoints: latency-svc-27rj2 [751.199065ms]
Apr 22 19:18:20.394: INFO: Created: latency-svc-9lgwp
Apr 22 19:18:20.422: INFO: Got endpoints: latency-svc-xm7gh [737.358429ms]
Apr 22 19:18:20.447: INFO: Created: latency-svc-vv74c
Apr 22 19:18:20.474: INFO: Got endpoints: latency-svc-6gnqk [749.793715ms]
Apr 22 19:18:20.506: INFO: Created: latency-svc-cf7tv
Apr 22 19:18:20.525: INFO: Got endpoints: latency-svc-zbqlm [751.840178ms]
Apr 22 19:18:20.549: INFO: Created: latency-svc-5rsxs
Apr 22 19:18:20.572: INFO: Got endpoints: latency-svc-8fvqk [740.400382ms]
Apr 22 19:18:20.593: INFO: Created: latency-svc-9zmft
Apr 22 19:18:20.622: INFO: Got endpoints: latency-svc-ltz84 [747.092096ms]
Apr 22 19:18:20.640: INFO: Created: latency-svc-skdv6
Apr 22 19:18:20.670: INFO: Got endpoints: latency-svc-lkbdk [748.447208ms]
Apr 22 19:18:20.690: INFO: Created: latency-svc-msnq9
Apr 22 19:18:20.724: INFO: Got endpoints: latency-svc-gvfjs [751.26434ms]
Apr 22 19:18:20.741: INFO: Created: latency-svc-p5krt
Apr 22 19:18:20.775: INFO: Got endpoints: latency-svc-njkn7 [752.407956ms]
Apr 22 19:18:20.802: INFO: Created: latency-svc-9qhcm
Apr 22 19:18:20.820: INFO: Got endpoints: latency-svc-kmwfn [747.327219ms]
Apr 22 19:18:20.842: INFO: Created: latency-svc-vwx68
Apr 22 19:18:20.871: INFO: Got endpoints: latency-svc-xd4bz [747.051123ms]
Apr 22 19:18:20.892: INFO: Created: latency-svc-88s9p
Apr 22 19:18:20.921: INFO: Got endpoints: latency-svc-m9dgs [734.152161ms]
Apr 22 19:18:20.939: INFO: Created: latency-svc-9p25w
Apr 22 19:18:20.972: INFO: Got endpoints: latency-svc-q55k7 [742.839498ms]
Apr 22 19:18:20.992: INFO: Created: latency-svc-hgsvr
Apr 22 19:18:21.021: INFO: Got endpoints: latency-svc-kvzcp [746.36155ms]
Apr 22 19:18:21.040: INFO: Created: latency-svc-sz779
Apr 22 19:18:21.073: INFO: Got endpoints: latency-svc-pjzkf [746.618892ms]
Apr 22 19:18:21.099: INFO: Created: latency-svc-qnmds
Apr 22 19:18:21.125: INFO: Got endpoints: latency-svc-9lgwp [753.297699ms]
Apr 22 19:18:21.151: INFO: Created: latency-svc-bmc96
Apr 22 19:18:21.171: INFO: Got endpoints: latency-svc-vv74c [749.66974ms]
Apr 22 19:18:21.200: INFO: Created: latency-svc-bdz55
Apr 22 19:18:21.222: INFO: Got endpoints: latency-svc-cf7tv [747.939497ms]
Apr 22 19:18:21.241: INFO: Created: latency-svc-4cvhx
Apr 22 19:18:21.272: INFO: Got endpoints: latency-svc-5rsxs [746.556822ms]
Apr 22 19:18:21.316: INFO: Created: latency-svc-vslnn
Apr 22 19:18:21.338: INFO: Got endpoints: latency-svc-9zmft [766.082637ms]
Apr 22 19:18:21.383: INFO: Got endpoints: latency-svc-skdv6 [760.9811ms]
Apr 22 19:18:21.400: INFO: Created: latency-svc-bz8r5
Apr 22 19:18:21.438: INFO: Got endpoints: latency-svc-msnq9 [767.35446ms]
Apr 22 19:18:21.454: INFO: Created: latency-svc-pnrmq
Apr 22 19:18:21.482: INFO: Got endpoints: latency-svc-p5krt [758.09148ms]
Apr 22 19:18:21.514: INFO: Created: latency-svc-lvn86
Apr 22 19:18:21.542: INFO: Got endpoints: latency-svc-9qhcm [766.112908ms]
Apr 22 19:18:21.558: INFO: Created: latency-svc-2mcsj
Apr 22 19:18:21.586: INFO: Got endpoints: latency-svc-vwx68 [765.048399ms]
Apr 22 19:18:21.604: INFO: Created: latency-svc-ds48w
Apr 22 19:18:21.647: INFO: Got endpoints: latency-svc-88s9p [776.126666ms]
Apr 22 19:18:21.658: INFO: Created: latency-svc-8dtfc
Apr 22 19:18:21.680: INFO: Got endpoints: latency-svc-9p25w [758.995253ms]
Apr 22 19:18:21.726: INFO: Created: latency-svc-gbqg8
Apr 22 19:18:21.735: INFO: Got endpoints: latency-svc-hgsvr [762.256836ms]
Apr 22 19:18:21.766: INFO: Created: latency-svc-vvs9l
Apr 22 19:18:21.793: INFO: Got endpoints: latency-svc-sz779 [771.960946ms]
Apr 22 19:18:21.800: INFO: Created: latency-svc-9d9q8
Apr 22 19:18:21.826: INFO: Got endpoints: latency-svc-qnmds [752.178725ms]
Apr 22 19:18:21.833: INFO: Created: latency-svc-np75z
Apr 22 19:18:21.890: INFO: Created: latency-svc-cqjc5
Apr 22 19:18:21.899: INFO: Got endpoints: latency-svc-bmc96 [772.782525ms]
Apr 22 19:18:21.924: INFO: Got endpoints: latency-svc-bdz55 [752.61399ms]
Apr 22 19:18:21.930: INFO: Created: latency-svc-6j4c5
Apr 22 19:18:21.957: INFO: Created: latency-svc-6pd56
Apr 22 19:18:21.975: INFO: Got endpoints: latency-svc-4cvhx [752.406723ms]
Apr 22 19:18:22.004: INFO: Created: latency-svc-wkdp6
Apr 22 19:18:22.023: INFO: Got endpoints: latency-svc-vslnn [750.780525ms]
Apr 22 19:18:22.051: INFO: Created: latency-svc-56fkq
Apr 22 19:18:22.077: INFO: Got endpoints: latency-svc-bz8r5 [738.670765ms]
Apr 22 19:18:22.106: INFO: Created: latency-svc-pfjsf
Apr 22 19:18:22.124: INFO: Got endpoints: latency-svc-pnrmq [740.510935ms]
Apr 22 19:18:22.155: INFO: Created: latency-svc-nggl4
Apr 22 19:18:22.176: INFO: Got endpoints: latency-svc-lvn86 [737.944058ms]
Apr 22 19:18:22.201: INFO: Created: latency-svc-m5t7b
Apr 22 19:18:22.223: INFO: Got endpoints: latency-svc-2mcsj [740.898135ms]
Apr 22 19:18:22.266: INFO: Created: latency-svc-g499b
Apr 22 19:18:22.274: INFO: Got endpoints: latency-svc-ds48w [731.01943ms]
Apr 22 19:18:22.310: INFO: Created: latency-svc-g5v7l
Apr 22 19:18:22.323: INFO: Got endpoints: latency-svc-8dtfc [737.698436ms]
Apr 22 19:18:22.354: INFO: Created: latency-svc-f6cqv
Apr 22 19:18:22.373: INFO: Got endpoints: latency-svc-gbqg8 [725.730497ms]
Apr 22 19:18:22.405: INFO: Created: latency-svc-vtn2l
Apr 22 19:18:22.423: INFO: Got endpoints: latency-svc-vvs9l [742.667027ms]
Apr 22 19:18:22.505: INFO: Got endpoints: latency-svc-9d9q8 [769.962935ms]
Apr 22 19:18:22.518: INFO: Created: latency-svc-v7bw4
Apr 22 19:18:22.529: INFO: Got endpoints: latency-svc-np75z [735.03197ms]
Apr 22 19:18:22.545: INFO: Created: latency-svc-f655t
Apr 22 19:18:22.558: INFO: Created: latency-svc-q9c8j
Apr 22 19:18:22.571: INFO: Got endpoints: latency-svc-cqjc5 [745.396947ms]
Apr 22 19:18:22.590: INFO: Created: latency-svc-mbqdw
Apr 22 19:18:22.623: INFO: Got endpoints: latency-svc-6j4c5 [724.06485ms]
Apr 22 19:18:22.639: INFO: Created: latency-svc-ttgxt
Apr 22 19:18:22.671: INFO: Got endpoints: latency-svc-6pd56 [746.26386ms]
Apr 22 19:18:22.689: INFO: Created: latency-svc-wgvwh
Apr 22 19:18:22.723: INFO: Got endpoints: latency-svc-wkdp6 [747.858178ms]
Apr 22 19:18:22.744: INFO: Created: latency-svc-srptg
Apr 22 19:18:22.771: INFO: Got endpoints: latency-svc-56fkq [747.275894ms]
Apr 22 19:18:22.797: INFO: Created: latency-svc-qgdvl
Apr 22 19:18:22.832: INFO: Got endpoints: latency-svc-pfjsf [753.986539ms]
Apr 22 19:18:22.860: INFO: Created: latency-svc-q48rh
Apr 22 19:18:22.875: INFO: Got endpoints: latency-svc-nggl4 [750.73392ms]
Apr 22 19:18:22.906: INFO: Created: latency-svc-85c7f
Apr 22 19:18:22.926: INFO: Got endpoints: latency-svc-m5t7b [749.164869ms]
Apr 22 19:18:22.953: INFO: Created: latency-svc-j9jtc
Apr 22 19:18:22.971: INFO: Got endpoints: latency-svc-g499b [746.934064ms]
Apr 22 19:18:22.994: INFO: Created: latency-svc-nxjhf
Apr 22 19:18:23.024: INFO: Got endpoints: latency-svc-g5v7l [749.961951ms]
Apr 22 19:18:23.058: INFO: Created: latency-svc-jc9dr
Apr 22 19:18:23.076: INFO: Got endpoints: latency-svc-f6cqv [752.717494ms]
Apr 22 19:18:23.111: INFO: Created: latency-svc-cptss
Apr 22 19:18:23.124: INFO: Got endpoints: latency-svc-vtn2l [750.94972ms]
Apr 22 19:18:23.156: INFO: Created: latency-svc-sfb8l
Apr 22 19:18:23.177: INFO: Got endpoints: latency-svc-v7bw4 [752.996397ms]
Apr 22 19:18:23.207: INFO: Created: latency-svc-m85ht
Apr 22 19:18:23.227: INFO: Got endpoints: latency-svc-f655t [721.438324ms]
Apr 22 19:18:23.263: INFO: Created: latency-svc-hpp7s
Apr 22 19:18:23.284: INFO: Got endpoints: latency-svc-q9c8j [755.263499ms]
Apr 22 19:18:23.323: INFO: Got endpoints: latency-svc-mbqdw [751.561847ms]
Apr 22 19:18:23.325: INFO: Created: latency-svc-zttcd
Apr 22 19:18:23.352: INFO: Created: latency-svc-pjs65
Apr 22 19:18:23.383: INFO: Got endpoints: latency-svc-ttgxt [759.604322ms]
Apr 22 19:18:23.409: INFO: Created: latency-svc-4t5k5
Apr 22 19:18:23.425: INFO: Got endpoints: latency-svc-wgvwh [753.54102ms]
Apr 22 19:18:23.449: INFO: Created: latency-svc-t7ncq
Apr 22 19:18:23.474: INFO: Got endpoints: latency-svc-srptg [750.252178ms]
Apr 22 19:18:23.500: INFO: Created: latency-svc-qqkqc
Apr 22 19:18:23.525: INFO: Got endpoints: latency-svc-qgdvl [753.340646ms]
Apr 22 19:18:23.558: INFO: Created: latency-svc-qdcqk
Apr 22 19:18:23.578: INFO: Got endpoints: latency-svc-q48rh [745.863911ms]
Apr 22 19:18:23.596: INFO: Created: latency-svc-sz5gg
Apr 22 19:18:23.622: INFO: Got endpoints: latency-svc-85c7f [747.333059ms]
Apr 22 19:18:23.637: INFO: Created: latency-svc-67qgm
Apr 22 19:18:23.672: INFO: Got endpoints: latency-svc-j9jtc [746.311258ms]
Apr 22 19:18:23.697: INFO: Created: latency-svc-9p9sp
Apr 22 19:18:23.721: INFO: Got endpoints: latency-svc-nxjhf [749.852763ms]
Apr 22 19:18:23.738: INFO: Created: latency-svc-kbgpm
Apr 22 19:18:23.777: INFO: Got endpoints: latency-svc-jc9dr [752.500871ms]
Apr 22 19:18:23.806: INFO: Created: latency-svc-lpf8p
Apr 22 19:18:23.827: INFO: Got endpoints: latency-svc-cptss [750.700081ms]
Apr 22 19:18:23.854: INFO: Created: latency-svc-2xt8r
Apr 22 19:18:23.875: INFO: Got endpoints: latency-svc-sfb8l [750.186819ms]
Apr 22 19:18:23.901: INFO: Created: latency-svc-ckbqw
Apr 22 19:18:23.926: INFO: Got endpoints: latency-svc-m85ht [748.226493ms]
Apr 22 19:18:23.955: INFO: Created: latency-svc-gg6tk
Apr 22 19:18:23.979: INFO: Got endpoints: latency-svc-hpp7s [751.391976ms]
Apr 22 19:18:24.009: INFO: Created: latency-svc-pfwqk
Apr 22 19:18:24.032: INFO: Got endpoints: latency-svc-zttcd [748.157943ms]
Apr 22 19:18:24.065: INFO: Created: latency-svc-v9hhg
Apr 22 19:18:24.073: INFO: Got endpoints: latency-svc-pjs65 [749.524328ms]
Apr 22 19:18:24.102: INFO: Created: latency-svc-bjlk5
Apr 22 19:18:24.128: INFO: Got endpoints: latency-svc-4t5k5 [744.570035ms]
Apr 22 19:18:24.162: INFO: Created: latency-svc-6xrj2
Apr 22 19:18:24.175: INFO: Got endpoints: latency-svc-t7ncq [750.105959ms]
Apr 22 19:18:24.208: INFO: Created: latency-svc-bw622
Apr 22 19:18:24.230: INFO: Got endpoints: latency-svc-qqkqc [755.86236ms]
Apr 22 19:18:24.264: INFO: Created: latency-svc-s2js8
Apr 22 19:18:24.273: INFO: Got endpoints: latency-svc-qdcqk [748.026416ms]
Apr 22 19:18:24.302: INFO: Created: latency-svc-6dvjt
Apr 22 19:18:24.326: INFO: Got endpoints: latency-svc-sz5gg [748.097337ms]
Apr 22 19:18:24.366: INFO: Created: latency-svc-dvxgh
Apr 22 19:18:24.375: INFO: Got endpoints: latency-svc-67qgm [752.211491ms]
Apr 22 19:18:24.415: INFO: Created: latency-svc-7hrpb
Apr 22 19:18:24.424: INFO: Got endpoints: latency-svc-9p9sp [751.609912ms]
Apr 22 19:18:24.449: INFO: Created: latency-svc-jkqh6
Apr 22 19:18:24.474: INFO: Got endpoints: latency-svc-kbgpm [753.094725ms]
Apr 22 19:18:24.510: INFO: Created: latency-svc-5pq5q
Apr 22 19:18:24.526: INFO: Got endpoints: latency-svc-lpf8p [749.33407ms]
Apr 22 19:18:24.548: INFO: Created: latency-svc-hh2r2
Apr 22 19:18:24.571: INFO: Got endpoints: latency-svc-2xt8r [743.9736ms]
Apr 22 19:18:24.598: INFO: Created: latency-svc-s27pr
Apr 22 19:18:24.623: INFO: Got endpoints: latency-svc-ckbqw [748.457942ms]
Apr 22 19:18:24.643: INFO: Created: latency-svc-t5vv2
Apr 22 19:18:24.680: INFO: Got endpoints: latency-svc-gg6tk [753.888888ms]
Apr 22 19:18:24.702: INFO: Created: latency-svc-vhkv8
Apr 22 19:18:24.722: INFO: Got endpoints: latency-svc-pfwqk [743.277247ms]
Apr 22 19:18:24.739: INFO: Created: latency-svc-7gfbz
Apr 22 19:18:24.771: INFO: Got endpoints: latency-svc-v9hhg [738.695774ms]
Apr 22 19:18:24.846: INFO: Got endpoints: latency-svc-bjlk5 [772.414452ms]
Apr 22 19:18:24.847: INFO: Created: latency-svc-jp9v6
Apr 22 19:18:24.871: INFO: Got endpoints: latency-svc-6xrj2 [743.314ms]
Apr 22 19:18:24.877: INFO: Created: latency-svc-z6jw2
Apr 22 19:18:24.889: INFO: Created: latency-svc-k5mjh
Apr 22 19:18:24.922: INFO: Got endpoints: latency-svc-bw622 [746.655149ms]
Apr 22 19:18:24.945: INFO: Created: latency-svc-sv7kf
Apr 22 19:18:24.977: INFO: Got endpoints: latency-svc-s2js8 [746.952178ms]
Apr 22 19:18:25.010: INFO: Created: latency-svc-5fssl
Apr 22 19:18:25.020: INFO: Got endpoints: latency-svc-6dvjt [746.898074ms]
Apr 22 19:18:25.037: INFO: Created: latency-svc-nv2x6
Apr 22 19:18:25.070: INFO: Got endpoints: latency-svc-dvxgh [742.889822ms]
Apr 22 19:18:25.089: INFO: Created: latency-svc-8c7qw
Apr 22 19:18:25.124: INFO: Got endpoints: latency-svc-7hrpb [748.782991ms]
Apr 22 19:18:25.154: INFO: Created: latency-svc-wbnqt
Apr 22 19:18:25.173: INFO: Got endpoints: latency-svc-jkqh6 [748.025395ms]
Apr 22 19:18:25.196: INFO: Created: latency-svc-rpcnw
Apr 22 19:18:25.224: INFO: Got endpoints: latency-svc-5pq5q [748.40077ms]
Apr 22 19:18:25.248: INFO: Created: latency-svc-v4rm4
Apr 22 19:18:25.273: INFO: Got endpoints: latency-svc-hh2r2 [746.052741ms]
Apr 22 19:18:25.339: INFO: Got endpoints: latency-svc-s27pr [767.766656ms]
Apr 22 19:18:25.345: INFO: Created: latency-svc-bpznw
Apr 22 19:18:25.374: INFO: Got endpoints: latency-svc-t5vv2 [750.597786ms]
Apr 22 19:18:25.424: INFO: Got endpoints: latency-svc-vhkv8 [743.60405ms]
Apr 22 19:18:25.473: INFO: Got endpoints: latency-svc-7gfbz [750.401918ms]
Apr 22 19:18:25.526: INFO: Got endpoints: latency-svc-jp9v6 [755.004946ms]
Apr 22 19:18:25.579: INFO: Got endpoints: latency-svc-z6jw2 [733.364111ms]
Apr 22 19:18:25.623: INFO: Got endpoints: latency-svc-k5mjh [751.968272ms]
Apr 22 19:18:25.673: INFO: Got endpoints: latency-svc-sv7kf [751.072672ms]
Apr 22 19:18:25.722: INFO: Got endpoints: latency-svc-5fssl [744.004017ms]
Apr 22 19:18:25.771: INFO: Got endpoints: latency-svc-nv2x6 [750.704705ms]
Apr 22 19:18:25.833: INFO: Got endpoints: latency-svc-8c7qw [762.467171ms]
Apr 22 19:18:25.881: INFO: Got endpoints: latency-svc-wbnqt [756.156487ms]
Apr 22 19:18:25.931: INFO: Got endpoints: latency-svc-rpcnw [757.584164ms]
Apr 22 19:18:25.978: INFO: Got endpoints: latency-svc-v4rm4 [753.647299ms]
Apr 22 19:18:26.023: INFO: Got endpoints: latency-svc-bpznw [750.00884ms]
Apr 22 19:18:26.023: INFO: Latencies: [56.479755ms 74.390209ms 105.643587ms 120.553407ms 148.011899ms 167.45819ms 187.751207ms 201.692615ms 213.896212ms 235.459206ms 256.109816ms 258.766703ms 260.825576ms 261.808681ms 264.815837ms 265.086339ms 265.255778ms 267.19474ms 274.807854ms 281.735286ms 282.014156ms 283.058774ms 284.455561ms 285.512735ms 286.423046ms 286.542385ms 294.489841ms 296.234685ms 299.758897ms 299.903215ms 302.41994ms 304.371717ms 304.508543ms 304.518635ms 307.087407ms 307.737838ms 309.96399ms 312.109621ms 314.985056ms 316.271891ms 316.956446ms 317.252348ms 318.1154ms 319.516457ms 321.350173ms 322.100611ms 322.195372ms 325.300821ms 325.790772ms 326.020049ms 332.463834ms 358.276173ms 393.529622ms 425.184646ms 458.527257ms 502.525805ms 529.33757ms 554.826719ms 582.655137ms 613.842547ms 652.826887ms 689.863563ms 696.814826ms 701.759163ms 721.438324ms 724.046073ms 724.06485ms 725.730497ms 731.01943ms 733.364111ms 734.152161ms 735.03197ms 737.358429ms 737.698436ms 737.944058ms 738.670765ms 738.695774ms 740.169675ms 740.400382ms 740.510935ms 740.898135ms 742.667027ms 742.839498ms 742.889822ms 743.277247ms 743.314ms 743.449386ms 743.60405ms 743.9736ms 744.004017ms 744.570035ms 744.725251ms 745.396947ms 745.414193ms 745.863911ms 746.052741ms 746.26386ms 746.311258ms 746.36155ms 746.556822ms 746.577338ms 746.618892ms 746.655149ms 746.898074ms 746.934064ms 746.952178ms 747.051123ms 747.092096ms 747.275894ms 747.327219ms 747.333059ms 747.858178ms 747.869222ms 747.939497ms 748.025395ms 748.026416ms 748.062466ms 748.097337ms 748.157943ms 748.226493ms 748.40077ms 748.447208ms 748.457942ms 748.782991ms 749.164869ms 749.196858ms 749.33407ms 749.524328ms 749.66974ms 749.793715ms 749.852763ms 749.961951ms 750.00884ms 750.105959ms 750.186819ms 750.252178ms 750.401918ms 750.589476ms 750.597786ms 750.700081ms 750.704705ms 750.733618ms 750.73392ms 750.780525ms 750.94972ms 751.072672ms 751.199065ms 751.26434ms 751.391976ms 751.506731ms 751.561847ms 751.609912ms 751.752873ms 751.812927ms 751.840178ms 751.968272ms 752.178725ms 752.211491ms 752.239211ms 752.240351ms 752.406723ms 752.407956ms 752.500871ms 752.61399ms 752.717494ms 752.996397ms 753.094725ms 753.297699ms 753.340646ms 753.54102ms 753.647299ms 753.888888ms 753.986539ms 755.004946ms 755.038634ms 755.263499ms 755.86236ms 755.943284ms 756.156487ms 757.584164ms 758.09148ms 758.456532ms 758.995253ms 759.604322ms 760.075211ms 760.9811ms 762.256836ms 762.467171ms 763.548518ms 765.048399ms 766.082637ms 766.112908ms 767.35446ms 767.766656ms 769.962935ms 771.960946ms 772.414452ms 772.782525ms 776.126666ms 843.386906ms]
Apr 22 19:18:26.024: INFO: 50 %ile: 746.577338ms
Apr 22 19:18:26.024: INFO: 90 %ile: 758.09148ms
Apr 22 19:18:26.025: INFO: 99 %ile: 776.126666ms
Apr 22 19:18:26.025: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Apr 22 19:18:26.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3198" for this suite. 04/22/23 19:18:26.046
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":80,"skipped":1578,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.890 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:18:15.166
    Apr 22 19:18:15.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svc-latency 04/22/23 19:18:15.168
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:15.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:15.226
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 22 19:18:15.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-3198 04/22/23 19:18:15.239
    I0422 19:18:15.255209      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3198, replica count: 1
    I0422 19:18:16.307974      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0422 19:18:17.308882      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:18:17.448: INFO: Created: latency-svc-cmq2z
    Apr 22 19:18:17.472: INFO: Got endpoints: latency-svc-cmq2z [61.884833ms]
    Apr 22 19:18:17.515: INFO: Created: latency-svc-bqpdh
    Apr 22 19:18:17.531: INFO: Got endpoints: latency-svc-bqpdh [56.479755ms]
    Apr 22 19:18:17.541: INFO: Created: latency-svc-8lw5d
    Apr 22 19:18:17.549: INFO: Got endpoints: latency-svc-8lw5d [74.390209ms]
    Apr 22 19:18:17.565: INFO: Created: latency-svc-25xgf
    Apr 22 19:18:17.579: INFO: Got endpoints: latency-svc-25xgf [105.643587ms]
    Apr 22 19:18:17.585: INFO: Created: latency-svc-m827h
    Apr 22 19:18:17.596: INFO: Got endpoints: latency-svc-m827h [120.553407ms]
    Apr 22 19:18:17.619: INFO: Created: latency-svc-dk9cl
    Apr 22 19:18:17.624: INFO: Got endpoints: latency-svc-dk9cl [148.011899ms]
    Apr 22 19:18:17.629: INFO: Created: latency-svc-rjtqp
    Apr 22 19:18:17.645: INFO: Got endpoints: latency-svc-rjtqp [167.45819ms]
    Apr 22 19:18:17.656: INFO: Created: latency-svc-l9j77
    Apr 22 19:18:17.664: INFO: Got endpoints: latency-svc-l9j77 [187.751207ms]
    Apr 22 19:18:17.670: INFO: Created: latency-svc-qsphb
    Apr 22 19:18:17.680: INFO: Got endpoints: latency-svc-qsphb [201.692615ms]
    Apr 22 19:18:17.691: INFO: Created: latency-svc-6sxqj
    Apr 22 19:18:17.693: INFO: Got endpoints: latency-svc-6sxqj [213.896212ms]
    Apr 22 19:18:17.708: INFO: Created: latency-svc-7rkn6
    Apr 22 19:18:17.716: INFO: Got endpoints: latency-svc-7rkn6 [235.459206ms]
    Apr 22 19:18:17.726: INFO: Created: latency-svc-w8nth
    Apr 22 19:18:17.742: INFO: Created: latency-svc-gqspn
    Apr 22 19:18:17.745: INFO: Got endpoints: latency-svc-w8nth [265.255778ms]
    Apr 22 19:18:17.763: INFO: Got endpoints: latency-svc-gqspn [281.735286ms]
    Apr 22 19:18:17.773: INFO: Created: latency-svc-tvknd
    Apr 22 19:18:17.781: INFO: Got endpoints: latency-svc-tvknd [299.903215ms]
    Apr 22 19:18:17.788: INFO: Created: latency-svc-b58sz
    Apr 22 19:18:17.797: INFO: Got endpoints: latency-svc-b58sz [314.985056ms]
    Apr 22 19:18:17.804: INFO: Created: latency-svc-fglvn
    Apr 22 19:18:17.809: INFO: Got endpoints: latency-svc-fglvn [332.463834ms]
    Apr 22 19:18:17.837: INFO: Created: latency-svc-dc65p
    Apr 22 19:18:17.848: INFO: Got endpoints: latency-svc-dc65p [316.956446ms]
    Apr 22 19:18:17.855: INFO: Created: latency-svc-9jxpr
    Apr 22 19:18:17.862: INFO: Got endpoints: latency-svc-9jxpr [312.109621ms]
    Apr 22 19:18:17.871: INFO: Created: latency-svc-qn2gq
    Apr 22 19:18:17.879: INFO: Got endpoints: latency-svc-qn2gq [299.758897ms]
    Apr 22 19:18:17.895: INFO: Created: latency-svc-zljnm
    Apr 22 19:18:17.904: INFO: Got endpoints: latency-svc-zljnm [307.737838ms]
    Apr 22 19:18:17.910: INFO: Created: latency-svc-szh8t
    Apr 22 19:18:17.919: INFO: Got endpoints: latency-svc-szh8t [294.489841ms]
    Apr 22 19:18:17.928: INFO: Created: latency-svc-smzz9
    Apr 22 19:18:17.931: INFO: Got endpoints: latency-svc-smzz9 [286.423046ms]
    Apr 22 19:18:17.941: INFO: Created: latency-svc-jwmld
    Apr 22 19:18:17.947: INFO: Got endpoints: latency-svc-jwmld [283.058774ms]
    Apr 22 19:18:17.954: INFO: Created: latency-svc-r9q6q
    Apr 22 19:18:17.967: INFO: Got endpoints: latency-svc-r9q6q [286.542385ms]
    Apr 22 19:18:17.972: INFO: Created: latency-svc-4lkwb
    Apr 22 19:18:17.978: INFO: Got endpoints: latency-svc-4lkwb [284.455561ms]
    Apr 22 19:18:17.985: INFO: Created: latency-svc-4bnmc
    Apr 22 19:18:17.991: INFO: Got endpoints: latency-svc-4bnmc [274.807854ms]
    Apr 22 19:18:18.003: INFO: Created: latency-svc-ss62n
    Apr 22 19:18:18.005: INFO: Got endpoints: latency-svc-ss62n [258.766703ms]
    Apr 22 19:18:18.018: INFO: Created: latency-svc-6tkh6
    Apr 22 19:18:18.024: INFO: Got endpoints: latency-svc-6tkh6 [260.825576ms]
    Apr 22 19:18:18.042: INFO: Created: latency-svc-c5lzf
    Apr 22 19:18:18.044: INFO: Got endpoints: latency-svc-c5lzf [261.808681ms]
    Apr 22 19:18:18.054: INFO: Created: latency-svc-n6t42
    Apr 22 19:18:18.062: INFO: Got endpoints: latency-svc-n6t42 [264.815837ms]
    Apr 22 19:18:18.092: INFO: Created: latency-svc-8zzgf
    Apr 22 19:18:18.106: INFO: Got endpoints: latency-svc-8zzgf [296.234685ms]
    Apr 22 19:18:18.130: INFO: Created: latency-svc-sxbzc
    Apr 22 19:18:18.134: INFO: Got endpoints: latency-svc-sxbzc [285.512735ms]
    Apr 22 19:18:18.159: INFO: Created: latency-svc-8w2fv
    Apr 22 19:18:18.167: INFO: Got endpoints: latency-svc-8w2fv [304.518635ms]
    Apr 22 19:18:18.176: INFO: Created: latency-svc-pcd27
    Apr 22 19:18:18.189: INFO: Got endpoints: latency-svc-pcd27 [309.96399ms]
    Apr 22 19:18:18.200: INFO: Created: latency-svc-xpjbl
    Apr 22 19:18:18.209: INFO: Got endpoints: latency-svc-xpjbl [304.508543ms]
    Apr 22 19:18:18.214: INFO: Created: latency-svc-zdqfh
    Apr 22 19:18:18.221: INFO: Got endpoints: latency-svc-zdqfh [302.41994ms]
    Apr 22 19:18:18.230: INFO: Created: latency-svc-pq5bb
    Apr 22 19:18:18.258: INFO: Got endpoints: latency-svc-pq5bb [326.020049ms]
    Apr 22 19:18:18.263: INFO: Created: latency-svc-pc4rl
    Apr 22 19:18:18.268: INFO: Got endpoints: latency-svc-pc4rl [319.516457ms]
    Apr 22 19:18:18.278: INFO: Created: latency-svc-zlqvr
    Apr 22 19:18:18.285: INFO: Got endpoints: latency-svc-zlqvr [318.1154ms]
    Apr 22 19:18:18.292: INFO: Created: latency-svc-465qj
    Apr 22 19:18:18.300: INFO: Got endpoints: latency-svc-465qj [322.195372ms]
    Apr 22 19:18:18.311: INFO: Created: latency-svc-x25jl
    Apr 22 19:18:18.317: INFO: Got endpoints: latency-svc-x25jl [325.790772ms]
    Apr 22 19:18:18.322: INFO: Created: latency-svc-xn4pz
    Apr 22 19:18:18.327: INFO: Got endpoints: latency-svc-xn4pz [322.100611ms]
    Apr 22 19:18:18.338: INFO: Created: latency-svc-ttpfz
    Apr 22 19:18:18.340: INFO: Got endpoints: latency-svc-ttpfz [316.271891ms]
    Apr 22 19:18:18.355: INFO: Created: latency-svc-lj8vx
    Apr 22 19:18:18.365: INFO: Got endpoints: latency-svc-lj8vx [321.350173ms]
    Apr 22 19:18:18.379: INFO: Created: latency-svc-h9smb
    Apr 22 19:18:18.387: INFO: Got endpoints: latency-svc-h9smb [325.300821ms]
    Apr 22 19:18:18.394: INFO: Created: latency-svc-dw29w
    Apr 22 19:18:18.406: INFO: Created: latency-svc-k7llg
    Apr 22 19:18:18.413: INFO: Got endpoints: latency-svc-dw29w [307.087407ms]
    Apr 22 19:18:18.417: INFO: Got endpoints: latency-svc-k7llg [282.014156ms]
    Apr 22 19:18:18.424: INFO: Created: latency-svc-jz5x8
    Apr 22 19:18:18.432: INFO: Got endpoints: latency-svc-jz5x8 [265.086339ms]
    Apr 22 19:18:18.437: INFO: Created: latency-svc-6dlqm
    Apr 22 19:18:18.446: INFO: Got endpoints: latency-svc-6dlqm [256.109816ms]
    Apr 22 19:18:18.454: INFO: Created: latency-svc-h57gj
    Apr 22 19:18:18.476: INFO: Got endpoints: latency-svc-h57gj [267.19474ms]
    Apr 22 19:18:18.477: INFO: Created: latency-svc-nnchp
    Apr 22 19:18:18.487: INFO: Created: latency-svc-src4d
    Apr 22 19:18:18.507: INFO: Created: latency-svc-8hw9x
    Apr 22 19:18:18.526: INFO: Got endpoints: latency-svc-nnchp [304.371717ms]
    Apr 22 19:18:18.532: INFO: Created: latency-svc-mhl8m
    Apr 22 19:18:18.550: INFO: Created: latency-svc-4rjnl
    Apr 22 19:18:18.560: INFO: Created: latency-svc-gvg4n
    Apr 22 19:18:18.577: INFO: Got endpoints: latency-svc-src4d [317.252348ms]
    Apr 22 19:18:18.581: INFO: Created: latency-svc-mzgkd
    Apr 22 19:18:18.606: INFO: Created: latency-svc-ls2k8
    Apr 22 19:18:18.622: INFO: Created: latency-svc-w4v8c
    Apr 22 19:18:18.626: INFO: Got endpoints: latency-svc-8hw9x [358.276173ms]
    Apr 22 19:18:18.635: INFO: Created: latency-svc-p7pwl
    Apr 22 19:18:18.646: INFO: Created: latency-svc-ktxgn
    Apr 22 19:18:18.657: INFO: Created: latency-svc-rbd49
    Apr 22 19:18:18.678: INFO: Got endpoints: latency-svc-mhl8m [393.529622ms]
    Apr 22 19:18:18.680: INFO: Created: latency-svc-nbjrv
    Apr 22 19:18:18.694: INFO: Created: latency-svc-g87nz
    Apr 22 19:18:18.716: INFO: Created: latency-svc-dp7hp
    Apr 22 19:18:18.725: INFO: Got endpoints: latency-svc-4rjnl [425.184646ms]
    Apr 22 19:18:18.731: INFO: Created: latency-svc-lsb7c
    Apr 22 19:18:18.748: INFO: Created: latency-svc-72t9d
    Apr 22 19:18:18.765: INFO: Created: latency-svc-ghrmp
    Apr 22 19:18:18.776: INFO: Got endpoints: latency-svc-gvg4n [458.527257ms]
    Apr 22 19:18:18.812: INFO: Created: latency-svc-7t8dt
    Apr 22 19:18:18.830: INFO: Got endpoints: latency-svc-mzgkd [502.525805ms]
    Apr 22 19:18:18.841: INFO: Created: latency-svc-ttbgt
    Apr 22 19:18:18.843: INFO: Created: latency-svc-zkwbn
    Apr 22 19:18:18.856: INFO: Created: latency-svc-ckvxz
    Apr 22 19:18:18.870: INFO: Got endpoints: latency-svc-ls2k8 [529.33757ms]
    Apr 22 19:18:18.891: INFO: Created: latency-svc-7qn6h
    Apr 22 19:18:18.921: INFO: Got endpoints: latency-svc-w4v8c [554.826719ms]
    Apr 22 19:18:18.948: INFO: Created: latency-svc-b8hfh
    Apr 22 19:18:18.971: INFO: Got endpoints: latency-svc-p7pwl [582.655137ms]
    Apr 22 19:18:18.992: INFO: Created: latency-svc-k9pwr
    Apr 22 19:18:19.027: INFO: Got endpoints: latency-svc-ktxgn [613.842547ms]
    Apr 22 19:18:19.046: INFO: Created: latency-svc-4f9fj
    Apr 22 19:18:19.070: INFO: Got endpoints: latency-svc-rbd49 [652.826887ms]
    Apr 22 19:18:19.090: INFO: Created: latency-svc-sf6lj
    Apr 22 19:18:19.122: INFO: Got endpoints: latency-svc-nbjrv [689.863563ms]
    Apr 22 19:18:19.152: INFO: Created: latency-svc-z52mf
    Apr 22 19:18:19.170: INFO: Got endpoints: latency-svc-g87nz [724.046073ms]
    Apr 22 19:18:19.191: INFO: Created: latency-svc-gc2r7
    Apr 22 19:18:19.220: INFO: Got endpoints: latency-svc-dp7hp [743.449386ms]
    Apr 22 19:18:19.242: INFO: Created: latency-svc-47vm9
    Apr 22 19:18:19.271: INFO: Got endpoints: latency-svc-lsb7c [745.414193ms]
    Apr 22 19:18:19.313: INFO: Created: latency-svc-sk6t9
    Apr 22 19:18:19.326: INFO: Got endpoints: latency-svc-72t9d [748.062466ms]
    Apr 22 19:18:19.361: INFO: Created: latency-svc-g96lz
    Apr 22 19:18:19.374: INFO: Got endpoints: latency-svc-ghrmp [747.869222ms]
    Apr 22 19:18:19.396: INFO: Created: latency-svc-lvzgv
    Apr 22 19:18:19.428: INFO: Got endpoints: latency-svc-7t8dt [701.759163ms]
    Apr 22 19:18:19.451: INFO: Created: latency-svc-584jm
    Apr 22 19:18:19.473: INFO: Got endpoints: latency-svc-ttbgt [696.814826ms]
    Apr 22 19:18:19.502: INFO: Created: latency-svc-vkl6g
    Apr 22 19:18:19.522: INFO: Got endpoints: latency-svc-zkwbn [843.386906ms]
    Apr 22 19:18:19.559: INFO: Created: latency-svc-pw474
    Apr 22 19:18:19.571: INFO: Got endpoints: latency-svc-ckvxz [740.169675ms]
    Apr 22 19:18:19.593: INFO: Created: latency-svc-t27nq
    Apr 22 19:18:19.621: INFO: Got endpoints: latency-svc-7qn6h [750.589476ms]
    Apr 22 19:18:19.643: INFO: Created: latency-svc-27rj2
    Apr 22 19:18:19.684: INFO: Got endpoints: latency-svc-b8hfh [763.548518ms]
    Apr 22 19:18:19.706: INFO: Created: latency-svc-xm7gh
    Apr 22 19:18:19.723: INFO: Got endpoints: latency-svc-k9pwr [752.239211ms]
    Apr 22 19:18:19.748: INFO: Created: latency-svc-6gnqk
    Apr 22 19:18:19.773: INFO: Got endpoints: latency-svc-4f9fj [744.725251ms]
    Apr 22 19:18:19.829: INFO: Created: latency-svc-zbqlm
    Apr 22 19:18:19.831: INFO: Got endpoints: latency-svc-sf6lj [760.075211ms]
    Apr 22 19:18:19.874: INFO: Got endpoints: latency-svc-z52mf [751.812927ms]
    Apr 22 19:18:19.881: INFO: Created: latency-svc-8fvqk
    Apr 22 19:18:19.894: INFO: Created: latency-svc-ltz84
    Apr 22 19:18:19.921: INFO: Got endpoints: latency-svc-gc2r7 [750.733618ms]
    Apr 22 19:18:19.939: INFO: Created: latency-svc-lkbdk
    Apr 22 19:18:19.973: INFO: Got endpoints: latency-svc-47vm9 [752.240351ms]
    Apr 22 19:18:19.989: INFO: Created: latency-svc-gvfjs
    Apr 22 19:18:20.023: INFO: Got endpoints: latency-svc-sk6t9 [751.752873ms]
    Apr 22 19:18:20.047: INFO: Created: latency-svc-njkn7
    Apr 22 19:18:20.073: INFO: Got endpoints: latency-svc-g96lz [746.577338ms]
    Apr 22 19:18:20.099: INFO: Created: latency-svc-kmwfn
    Apr 22 19:18:20.124: INFO: Got endpoints: latency-svc-lvzgv [749.196858ms]
    Apr 22 19:18:20.152: INFO: Created: latency-svc-xd4bz
    Apr 22 19:18:20.187: INFO: Got endpoints: latency-svc-584jm [758.456532ms]
    Apr 22 19:18:20.214: INFO: Created: latency-svc-m9dgs
    Apr 22 19:18:20.229: INFO: Got endpoints: latency-svc-vkl6g [755.943284ms]
    Apr 22 19:18:20.250: INFO: Created: latency-svc-q55k7
    Apr 22 19:18:20.274: INFO: Got endpoints: latency-svc-pw474 [751.506731ms]
    Apr 22 19:18:20.310: INFO: Created: latency-svc-kvzcp
    Apr 22 19:18:20.326: INFO: Got endpoints: latency-svc-t27nq [755.038634ms]
    Apr 22 19:18:20.346: INFO: Created: latency-svc-pjzkf
    Apr 22 19:18:20.372: INFO: Got endpoints: latency-svc-27rj2 [751.199065ms]
    Apr 22 19:18:20.394: INFO: Created: latency-svc-9lgwp
    Apr 22 19:18:20.422: INFO: Got endpoints: latency-svc-xm7gh [737.358429ms]
    Apr 22 19:18:20.447: INFO: Created: latency-svc-vv74c
    Apr 22 19:18:20.474: INFO: Got endpoints: latency-svc-6gnqk [749.793715ms]
    Apr 22 19:18:20.506: INFO: Created: latency-svc-cf7tv
    Apr 22 19:18:20.525: INFO: Got endpoints: latency-svc-zbqlm [751.840178ms]
    Apr 22 19:18:20.549: INFO: Created: latency-svc-5rsxs
    Apr 22 19:18:20.572: INFO: Got endpoints: latency-svc-8fvqk [740.400382ms]
    Apr 22 19:18:20.593: INFO: Created: latency-svc-9zmft
    Apr 22 19:18:20.622: INFO: Got endpoints: latency-svc-ltz84 [747.092096ms]
    Apr 22 19:18:20.640: INFO: Created: latency-svc-skdv6
    Apr 22 19:18:20.670: INFO: Got endpoints: latency-svc-lkbdk [748.447208ms]
    Apr 22 19:18:20.690: INFO: Created: latency-svc-msnq9
    Apr 22 19:18:20.724: INFO: Got endpoints: latency-svc-gvfjs [751.26434ms]
    Apr 22 19:18:20.741: INFO: Created: latency-svc-p5krt
    Apr 22 19:18:20.775: INFO: Got endpoints: latency-svc-njkn7 [752.407956ms]
    Apr 22 19:18:20.802: INFO: Created: latency-svc-9qhcm
    Apr 22 19:18:20.820: INFO: Got endpoints: latency-svc-kmwfn [747.327219ms]
    Apr 22 19:18:20.842: INFO: Created: latency-svc-vwx68
    Apr 22 19:18:20.871: INFO: Got endpoints: latency-svc-xd4bz [747.051123ms]
    Apr 22 19:18:20.892: INFO: Created: latency-svc-88s9p
    Apr 22 19:18:20.921: INFO: Got endpoints: latency-svc-m9dgs [734.152161ms]
    Apr 22 19:18:20.939: INFO: Created: latency-svc-9p25w
    Apr 22 19:18:20.972: INFO: Got endpoints: latency-svc-q55k7 [742.839498ms]
    Apr 22 19:18:20.992: INFO: Created: latency-svc-hgsvr
    Apr 22 19:18:21.021: INFO: Got endpoints: latency-svc-kvzcp [746.36155ms]
    Apr 22 19:18:21.040: INFO: Created: latency-svc-sz779
    Apr 22 19:18:21.073: INFO: Got endpoints: latency-svc-pjzkf [746.618892ms]
    Apr 22 19:18:21.099: INFO: Created: latency-svc-qnmds
    Apr 22 19:18:21.125: INFO: Got endpoints: latency-svc-9lgwp [753.297699ms]
    Apr 22 19:18:21.151: INFO: Created: latency-svc-bmc96
    Apr 22 19:18:21.171: INFO: Got endpoints: latency-svc-vv74c [749.66974ms]
    Apr 22 19:18:21.200: INFO: Created: latency-svc-bdz55
    Apr 22 19:18:21.222: INFO: Got endpoints: latency-svc-cf7tv [747.939497ms]
    Apr 22 19:18:21.241: INFO: Created: latency-svc-4cvhx
    Apr 22 19:18:21.272: INFO: Got endpoints: latency-svc-5rsxs [746.556822ms]
    Apr 22 19:18:21.316: INFO: Created: latency-svc-vslnn
    Apr 22 19:18:21.338: INFO: Got endpoints: latency-svc-9zmft [766.082637ms]
    Apr 22 19:18:21.383: INFO: Got endpoints: latency-svc-skdv6 [760.9811ms]
    Apr 22 19:18:21.400: INFO: Created: latency-svc-bz8r5
    Apr 22 19:18:21.438: INFO: Got endpoints: latency-svc-msnq9 [767.35446ms]
    Apr 22 19:18:21.454: INFO: Created: latency-svc-pnrmq
    Apr 22 19:18:21.482: INFO: Got endpoints: latency-svc-p5krt [758.09148ms]
    Apr 22 19:18:21.514: INFO: Created: latency-svc-lvn86
    Apr 22 19:18:21.542: INFO: Got endpoints: latency-svc-9qhcm [766.112908ms]
    Apr 22 19:18:21.558: INFO: Created: latency-svc-2mcsj
    Apr 22 19:18:21.586: INFO: Got endpoints: latency-svc-vwx68 [765.048399ms]
    Apr 22 19:18:21.604: INFO: Created: latency-svc-ds48w
    Apr 22 19:18:21.647: INFO: Got endpoints: latency-svc-88s9p [776.126666ms]
    Apr 22 19:18:21.658: INFO: Created: latency-svc-8dtfc
    Apr 22 19:18:21.680: INFO: Got endpoints: latency-svc-9p25w [758.995253ms]
    Apr 22 19:18:21.726: INFO: Created: latency-svc-gbqg8
    Apr 22 19:18:21.735: INFO: Got endpoints: latency-svc-hgsvr [762.256836ms]
    Apr 22 19:18:21.766: INFO: Created: latency-svc-vvs9l
    Apr 22 19:18:21.793: INFO: Got endpoints: latency-svc-sz779 [771.960946ms]
    Apr 22 19:18:21.800: INFO: Created: latency-svc-9d9q8
    Apr 22 19:18:21.826: INFO: Got endpoints: latency-svc-qnmds [752.178725ms]
    Apr 22 19:18:21.833: INFO: Created: latency-svc-np75z
    Apr 22 19:18:21.890: INFO: Created: latency-svc-cqjc5
    Apr 22 19:18:21.899: INFO: Got endpoints: latency-svc-bmc96 [772.782525ms]
    Apr 22 19:18:21.924: INFO: Got endpoints: latency-svc-bdz55 [752.61399ms]
    Apr 22 19:18:21.930: INFO: Created: latency-svc-6j4c5
    Apr 22 19:18:21.957: INFO: Created: latency-svc-6pd56
    Apr 22 19:18:21.975: INFO: Got endpoints: latency-svc-4cvhx [752.406723ms]
    Apr 22 19:18:22.004: INFO: Created: latency-svc-wkdp6
    Apr 22 19:18:22.023: INFO: Got endpoints: latency-svc-vslnn [750.780525ms]
    Apr 22 19:18:22.051: INFO: Created: latency-svc-56fkq
    Apr 22 19:18:22.077: INFO: Got endpoints: latency-svc-bz8r5 [738.670765ms]
    Apr 22 19:18:22.106: INFO: Created: latency-svc-pfjsf
    Apr 22 19:18:22.124: INFO: Got endpoints: latency-svc-pnrmq [740.510935ms]
    Apr 22 19:18:22.155: INFO: Created: latency-svc-nggl4
    Apr 22 19:18:22.176: INFO: Got endpoints: latency-svc-lvn86 [737.944058ms]
    Apr 22 19:18:22.201: INFO: Created: latency-svc-m5t7b
    Apr 22 19:18:22.223: INFO: Got endpoints: latency-svc-2mcsj [740.898135ms]
    Apr 22 19:18:22.266: INFO: Created: latency-svc-g499b
    Apr 22 19:18:22.274: INFO: Got endpoints: latency-svc-ds48w [731.01943ms]
    Apr 22 19:18:22.310: INFO: Created: latency-svc-g5v7l
    Apr 22 19:18:22.323: INFO: Got endpoints: latency-svc-8dtfc [737.698436ms]
    Apr 22 19:18:22.354: INFO: Created: latency-svc-f6cqv
    Apr 22 19:18:22.373: INFO: Got endpoints: latency-svc-gbqg8 [725.730497ms]
    Apr 22 19:18:22.405: INFO: Created: latency-svc-vtn2l
    Apr 22 19:18:22.423: INFO: Got endpoints: latency-svc-vvs9l [742.667027ms]
    Apr 22 19:18:22.505: INFO: Got endpoints: latency-svc-9d9q8 [769.962935ms]
    Apr 22 19:18:22.518: INFO: Created: latency-svc-v7bw4
    Apr 22 19:18:22.529: INFO: Got endpoints: latency-svc-np75z [735.03197ms]
    Apr 22 19:18:22.545: INFO: Created: latency-svc-f655t
    Apr 22 19:18:22.558: INFO: Created: latency-svc-q9c8j
    Apr 22 19:18:22.571: INFO: Got endpoints: latency-svc-cqjc5 [745.396947ms]
    Apr 22 19:18:22.590: INFO: Created: latency-svc-mbqdw
    Apr 22 19:18:22.623: INFO: Got endpoints: latency-svc-6j4c5 [724.06485ms]
    Apr 22 19:18:22.639: INFO: Created: latency-svc-ttgxt
    Apr 22 19:18:22.671: INFO: Got endpoints: latency-svc-6pd56 [746.26386ms]
    Apr 22 19:18:22.689: INFO: Created: latency-svc-wgvwh
    Apr 22 19:18:22.723: INFO: Got endpoints: latency-svc-wkdp6 [747.858178ms]
    Apr 22 19:18:22.744: INFO: Created: latency-svc-srptg
    Apr 22 19:18:22.771: INFO: Got endpoints: latency-svc-56fkq [747.275894ms]
    Apr 22 19:18:22.797: INFO: Created: latency-svc-qgdvl
    Apr 22 19:18:22.832: INFO: Got endpoints: latency-svc-pfjsf [753.986539ms]
    Apr 22 19:18:22.860: INFO: Created: latency-svc-q48rh
    Apr 22 19:18:22.875: INFO: Got endpoints: latency-svc-nggl4 [750.73392ms]
    Apr 22 19:18:22.906: INFO: Created: latency-svc-85c7f
    Apr 22 19:18:22.926: INFO: Got endpoints: latency-svc-m5t7b [749.164869ms]
    Apr 22 19:18:22.953: INFO: Created: latency-svc-j9jtc
    Apr 22 19:18:22.971: INFO: Got endpoints: latency-svc-g499b [746.934064ms]
    Apr 22 19:18:22.994: INFO: Created: latency-svc-nxjhf
    Apr 22 19:18:23.024: INFO: Got endpoints: latency-svc-g5v7l [749.961951ms]
    Apr 22 19:18:23.058: INFO: Created: latency-svc-jc9dr
    Apr 22 19:18:23.076: INFO: Got endpoints: latency-svc-f6cqv [752.717494ms]
    Apr 22 19:18:23.111: INFO: Created: latency-svc-cptss
    Apr 22 19:18:23.124: INFO: Got endpoints: latency-svc-vtn2l [750.94972ms]
    Apr 22 19:18:23.156: INFO: Created: latency-svc-sfb8l
    Apr 22 19:18:23.177: INFO: Got endpoints: latency-svc-v7bw4 [752.996397ms]
    Apr 22 19:18:23.207: INFO: Created: latency-svc-m85ht
    Apr 22 19:18:23.227: INFO: Got endpoints: latency-svc-f655t [721.438324ms]
    Apr 22 19:18:23.263: INFO: Created: latency-svc-hpp7s
    Apr 22 19:18:23.284: INFO: Got endpoints: latency-svc-q9c8j [755.263499ms]
    Apr 22 19:18:23.323: INFO: Got endpoints: latency-svc-mbqdw [751.561847ms]
    Apr 22 19:18:23.325: INFO: Created: latency-svc-zttcd
    Apr 22 19:18:23.352: INFO: Created: latency-svc-pjs65
    Apr 22 19:18:23.383: INFO: Got endpoints: latency-svc-ttgxt [759.604322ms]
    Apr 22 19:18:23.409: INFO: Created: latency-svc-4t5k5
    Apr 22 19:18:23.425: INFO: Got endpoints: latency-svc-wgvwh [753.54102ms]
    Apr 22 19:18:23.449: INFO: Created: latency-svc-t7ncq
    Apr 22 19:18:23.474: INFO: Got endpoints: latency-svc-srptg [750.252178ms]
    Apr 22 19:18:23.500: INFO: Created: latency-svc-qqkqc
    Apr 22 19:18:23.525: INFO: Got endpoints: latency-svc-qgdvl [753.340646ms]
    Apr 22 19:18:23.558: INFO: Created: latency-svc-qdcqk
    Apr 22 19:18:23.578: INFO: Got endpoints: latency-svc-q48rh [745.863911ms]
    Apr 22 19:18:23.596: INFO: Created: latency-svc-sz5gg
    Apr 22 19:18:23.622: INFO: Got endpoints: latency-svc-85c7f [747.333059ms]
    Apr 22 19:18:23.637: INFO: Created: latency-svc-67qgm
    Apr 22 19:18:23.672: INFO: Got endpoints: latency-svc-j9jtc [746.311258ms]
    Apr 22 19:18:23.697: INFO: Created: latency-svc-9p9sp
    Apr 22 19:18:23.721: INFO: Got endpoints: latency-svc-nxjhf [749.852763ms]
    Apr 22 19:18:23.738: INFO: Created: latency-svc-kbgpm
    Apr 22 19:18:23.777: INFO: Got endpoints: latency-svc-jc9dr [752.500871ms]
    Apr 22 19:18:23.806: INFO: Created: latency-svc-lpf8p
    Apr 22 19:18:23.827: INFO: Got endpoints: latency-svc-cptss [750.700081ms]
    Apr 22 19:18:23.854: INFO: Created: latency-svc-2xt8r
    Apr 22 19:18:23.875: INFO: Got endpoints: latency-svc-sfb8l [750.186819ms]
    Apr 22 19:18:23.901: INFO: Created: latency-svc-ckbqw
    Apr 22 19:18:23.926: INFO: Got endpoints: latency-svc-m85ht [748.226493ms]
    Apr 22 19:18:23.955: INFO: Created: latency-svc-gg6tk
    Apr 22 19:18:23.979: INFO: Got endpoints: latency-svc-hpp7s [751.391976ms]
    Apr 22 19:18:24.009: INFO: Created: latency-svc-pfwqk
    Apr 22 19:18:24.032: INFO: Got endpoints: latency-svc-zttcd [748.157943ms]
    Apr 22 19:18:24.065: INFO: Created: latency-svc-v9hhg
    Apr 22 19:18:24.073: INFO: Got endpoints: latency-svc-pjs65 [749.524328ms]
    Apr 22 19:18:24.102: INFO: Created: latency-svc-bjlk5
    Apr 22 19:18:24.128: INFO: Got endpoints: latency-svc-4t5k5 [744.570035ms]
    Apr 22 19:18:24.162: INFO: Created: latency-svc-6xrj2
    Apr 22 19:18:24.175: INFO: Got endpoints: latency-svc-t7ncq [750.105959ms]
    Apr 22 19:18:24.208: INFO: Created: latency-svc-bw622
    Apr 22 19:18:24.230: INFO: Got endpoints: latency-svc-qqkqc [755.86236ms]
    Apr 22 19:18:24.264: INFO: Created: latency-svc-s2js8
    Apr 22 19:18:24.273: INFO: Got endpoints: latency-svc-qdcqk [748.026416ms]
    Apr 22 19:18:24.302: INFO: Created: latency-svc-6dvjt
    Apr 22 19:18:24.326: INFO: Got endpoints: latency-svc-sz5gg [748.097337ms]
    Apr 22 19:18:24.366: INFO: Created: latency-svc-dvxgh
    Apr 22 19:18:24.375: INFO: Got endpoints: latency-svc-67qgm [752.211491ms]
    Apr 22 19:18:24.415: INFO: Created: latency-svc-7hrpb
    Apr 22 19:18:24.424: INFO: Got endpoints: latency-svc-9p9sp [751.609912ms]
    Apr 22 19:18:24.449: INFO: Created: latency-svc-jkqh6
    Apr 22 19:18:24.474: INFO: Got endpoints: latency-svc-kbgpm [753.094725ms]
    Apr 22 19:18:24.510: INFO: Created: latency-svc-5pq5q
    Apr 22 19:18:24.526: INFO: Got endpoints: latency-svc-lpf8p [749.33407ms]
    Apr 22 19:18:24.548: INFO: Created: latency-svc-hh2r2
    Apr 22 19:18:24.571: INFO: Got endpoints: latency-svc-2xt8r [743.9736ms]
    Apr 22 19:18:24.598: INFO: Created: latency-svc-s27pr
    Apr 22 19:18:24.623: INFO: Got endpoints: latency-svc-ckbqw [748.457942ms]
    Apr 22 19:18:24.643: INFO: Created: latency-svc-t5vv2
    Apr 22 19:18:24.680: INFO: Got endpoints: latency-svc-gg6tk [753.888888ms]
    Apr 22 19:18:24.702: INFO: Created: latency-svc-vhkv8
    Apr 22 19:18:24.722: INFO: Got endpoints: latency-svc-pfwqk [743.277247ms]
    Apr 22 19:18:24.739: INFO: Created: latency-svc-7gfbz
    Apr 22 19:18:24.771: INFO: Got endpoints: latency-svc-v9hhg [738.695774ms]
    Apr 22 19:18:24.846: INFO: Got endpoints: latency-svc-bjlk5 [772.414452ms]
    Apr 22 19:18:24.847: INFO: Created: latency-svc-jp9v6
    Apr 22 19:18:24.871: INFO: Got endpoints: latency-svc-6xrj2 [743.314ms]
    Apr 22 19:18:24.877: INFO: Created: latency-svc-z6jw2
    Apr 22 19:18:24.889: INFO: Created: latency-svc-k5mjh
    Apr 22 19:18:24.922: INFO: Got endpoints: latency-svc-bw622 [746.655149ms]
    Apr 22 19:18:24.945: INFO: Created: latency-svc-sv7kf
    Apr 22 19:18:24.977: INFO: Got endpoints: latency-svc-s2js8 [746.952178ms]
    Apr 22 19:18:25.010: INFO: Created: latency-svc-5fssl
    Apr 22 19:18:25.020: INFO: Got endpoints: latency-svc-6dvjt [746.898074ms]
    Apr 22 19:18:25.037: INFO: Created: latency-svc-nv2x6
    Apr 22 19:18:25.070: INFO: Got endpoints: latency-svc-dvxgh [742.889822ms]
    Apr 22 19:18:25.089: INFO: Created: latency-svc-8c7qw
    Apr 22 19:18:25.124: INFO: Got endpoints: latency-svc-7hrpb [748.782991ms]
    Apr 22 19:18:25.154: INFO: Created: latency-svc-wbnqt
    Apr 22 19:18:25.173: INFO: Got endpoints: latency-svc-jkqh6 [748.025395ms]
    Apr 22 19:18:25.196: INFO: Created: latency-svc-rpcnw
    Apr 22 19:18:25.224: INFO: Got endpoints: latency-svc-5pq5q [748.40077ms]
    Apr 22 19:18:25.248: INFO: Created: latency-svc-v4rm4
    Apr 22 19:18:25.273: INFO: Got endpoints: latency-svc-hh2r2 [746.052741ms]
    Apr 22 19:18:25.339: INFO: Got endpoints: latency-svc-s27pr [767.766656ms]
    Apr 22 19:18:25.345: INFO: Created: latency-svc-bpznw
    Apr 22 19:18:25.374: INFO: Got endpoints: latency-svc-t5vv2 [750.597786ms]
    Apr 22 19:18:25.424: INFO: Got endpoints: latency-svc-vhkv8 [743.60405ms]
    Apr 22 19:18:25.473: INFO: Got endpoints: latency-svc-7gfbz [750.401918ms]
    Apr 22 19:18:25.526: INFO: Got endpoints: latency-svc-jp9v6 [755.004946ms]
    Apr 22 19:18:25.579: INFO: Got endpoints: latency-svc-z6jw2 [733.364111ms]
    Apr 22 19:18:25.623: INFO: Got endpoints: latency-svc-k5mjh [751.968272ms]
    Apr 22 19:18:25.673: INFO: Got endpoints: latency-svc-sv7kf [751.072672ms]
    Apr 22 19:18:25.722: INFO: Got endpoints: latency-svc-5fssl [744.004017ms]
    Apr 22 19:18:25.771: INFO: Got endpoints: latency-svc-nv2x6 [750.704705ms]
    Apr 22 19:18:25.833: INFO: Got endpoints: latency-svc-8c7qw [762.467171ms]
    Apr 22 19:18:25.881: INFO: Got endpoints: latency-svc-wbnqt [756.156487ms]
    Apr 22 19:18:25.931: INFO: Got endpoints: latency-svc-rpcnw [757.584164ms]
    Apr 22 19:18:25.978: INFO: Got endpoints: latency-svc-v4rm4 [753.647299ms]
    Apr 22 19:18:26.023: INFO: Got endpoints: latency-svc-bpznw [750.00884ms]
    Apr 22 19:18:26.023: INFO: Latencies: [56.479755ms 74.390209ms 105.643587ms 120.553407ms 148.011899ms 167.45819ms 187.751207ms 201.692615ms 213.896212ms 235.459206ms 256.109816ms 258.766703ms 260.825576ms 261.808681ms 264.815837ms 265.086339ms 265.255778ms 267.19474ms 274.807854ms 281.735286ms 282.014156ms 283.058774ms 284.455561ms 285.512735ms 286.423046ms 286.542385ms 294.489841ms 296.234685ms 299.758897ms 299.903215ms 302.41994ms 304.371717ms 304.508543ms 304.518635ms 307.087407ms 307.737838ms 309.96399ms 312.109621ms 314.985056ms 316.271891ms 316.956446ms 317.252348ms 318.1154ms 319.516457ms 321.350173ms 322.100611ms 322.195372ms 325.300821ms 325.790772ms 326.020049ms 332.463834ms 358.276173ms 393.529622ms 425.184646ms 458.527257ms 502.525805ms 529.33757ms 554.826719ms 582.655137ms 613.842547ms 652.826887ms 689.863563ms 696.814826ms 701.759163ms 721.438324ms 724.046073ms 724.06485ms 725.730497ms 731.01943ms 733.364111ms 734.152161ms 735.03197ms 737.358429ms 737.698436ms 737.944058ms 738.670765ms 738.695774ms 740.169675ms 740.400382ms 740.510935ms 740.898135ms 742.667027ms 742.839498ms 742.889822ms 743.277247ms 743.314ms 743.449386ms 743.60405ms 743.9736ms 744.004017ms 744.570035ms 744.725251ms 745.396947ms 745.414193ms 745.863911ms 746.052741ms 746.26386ms 746.311258ms 746.36155ms 746.556822ms 746.577338ms 746.618892ms 746.655149ms 746.898074ms 746.934064ms 746.952178ms 747.051123ms 747.092096ms 747.275894ms 747.327219ms 747.333059ms 747.858178ms 747.869222ms 747.939497ms 748.025395ms 748.026416ms 748.062466ms 748.097337ms 748.157943ms 748.226493ms 748.40077ms 748.447208ms 748.457942ms 748.782991ms 749.164869ms 749.196858ms 749.33407ms 749.524328ms 749.66974ms 749.793715ms 749.852763ms 749.961951ms 750.00884ms 750.105959ms 750.186819ms 750.252178ms 750.401918ms 750.589476ms 750.597786ms 750.700081ms 750.704705ms 750.733618ms 750.73392ms 750.780525ms 750.94972ms 751.072672ms 751.199065ms 751.26434ms 751.391976ms 751.506731ms 751.561847ms 751.609912ms 751.752873ms 751.812927ms 751.840178ms 751.968272ms 752.178725ms 752.211491ms 752.239211ms 752.240351ms 752.406723ms 752.407956ms 752.500871ms 752.61399ms 752.717494ms 752.996397ms 753.094725ms 753.297699ms 753.340646ms 753.54102ms 753.647299ms 753.888888ms 753.986539ms 755.004946ms 755.038634ms 755.263499ms 755.86236ms 755.943284ms 756.156487ms 757.584164ms 758.09148ms 758.456532ms 758.995253ms 759.604322ms 760.075211ms 760.9811ms 762.256836ms 762.467171ms 763.548518ms 765.048399ms 766.082637ms 766.112908ms 767.35446ms 767.766656ms 769.962935ms 771.960946ms 772.414452ms 772.782525ms 776.126666ms 843.386906ms]
    Apr 22 19:18:26.024: INFO: 50 %ile: 746.577338ms
    Apr 22 19:18:26.024: INFO: 90 %ile: 758.09148ms
    Apr 22 19:18:26.025: INFO: 99 %ile: 776.126666ms
    Apr 22 19:18:26.025: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Apr 22 19:18:26.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-3198" for this suite. 04/22/23 19:18:26.046
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:18:26.071
Apr 22 19:18:26.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename subpath 04/22/23 19:18:26.076
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:26.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:26.106
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/22/23 19:18:26.113
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-j8q4 04/22/23 19:18:26.128
STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:18:26.128
Apr 22 19:18:26.144: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-j8q4" in namespace "subpath-2218" to be "Succeeded or Failed"
Apr 22 19:18:26.149: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81115ms
Apr 22 19:18:28.160: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015774455s
Apr 22 19:18:30.157: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 4.012864982s
Apr 22 19:18:32.155: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 6.011073247s
Apr 22 19:18:34.156: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 8.012010341s
Apr 22 19:18:36.156: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 10.012234628s
Apr 22 19:18:38.155: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 12.010994267s
Apr 22 19:18:40.158: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 14.014036639s
Apr 22 19:18:42.159: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 16.014934186s
Apr 22 19:18:44.159: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 18.015215961s
Apr 22 19:18:46.161: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 20.017020859s
Apr 22 19:18:48.158: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=false. Elapsed: 22.014110025s
Apr 22 19:18:50.160: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016274434s
STEP: Saw pod success 04/22/23 19:18:50.161
Apr 22 19:18:50.161: INFO: Pod "pod-subpath-test-configmap-j8q4" satisfied condition "Succeeded or Failed"
Apr 22 19:18:50.173: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-configmap-j8q4 container test-container-subpath-configmap-j8q4: <nil>
STEP: delete the pod 04/22/23 19:18:50.192
Apr 22 19:18:50.220: INFO: Waiting for pod pod-subpath-test-configmap-j8q4 to disappear
Apr 22 19:18:50.228: INFO: Pod pod-subpath-test-configmap-j8q4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-j8q4 04/22/23 19:18:50.228
Apr 22 19:18:50.229: INFO: Deleting pod "pod-subpath-test-configmap-j8q4" in namespace "subpath-2218"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 22 19:18:50.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2218" for this suite. 04/22/23 19:18:50.251
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":81,"skipped":1588,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.196 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:18:26.071
    Apr 22 19:18:26.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename subpath 04/22/23 19:18:26.076
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:26.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:26.106
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/22/23 19:18:26.113
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-j8q4 04/22/23 19:18:26.128
    STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:18:26.128
    Apr 22 19:18:26.144: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-j8q4" in namespace "subpath-2218" to be "Succeeded or Failed"
    Apr 22 19:18:26.149: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81115ms
    Apr 22 19:18:28.160: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015774455s
    Apr 22 19:18:30.157: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 4.012864982s
    Apr 22 19:18:32.155: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 6.011073247s
    Apr 22 19:18:34.156: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 8.012010341s
    Apr 22 19:18:36.156: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 10.012234628s
    Apr 22 19:18:38.155: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 12.010994267s
    Apr 22 19:18:40.158: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 14.014036639s
    Apr 22 19:18:42.159: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 16.014934186s
    Apr 22 19:18:44.159: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 18.015215961s
    Apr 22 19:18:46.161: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=true. Elapsed: 20.017020859s
    Apr 22 19:18:48.158: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Running", Reason="", readiness=false. Elapsed: 22.014110025s
    Apr 22 19:18:50.160: INFO: Pod "pod-subpath-test-configmap-j8q4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016274434s
    STEP: Saw pod success 04/22/23 19:18:50.161
    Apr 22 19:18:50.161: INFO: Pod "pod-subpath-test-configmap-j8q4" satisfied condition "Succeeded or Failed"
    Apr 22 19:18:50.173: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-configmap-j8q4 container test-container-subpath-configmap-j8q4: <nil>
    STEP: delete the pod 04/22/23 19:18:50.192
    Apr 22 19:18:50.220: INFO: Waiting for pod pod-subpath-test-configmap-j8q4 to disappear
    Apr 22 19:18:50.228: INFO: Pod pod-subpath-test-configmap-j8q4 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-j8q4 04/22/23 19:18:50.228
    Apr 22 19:18:50.229: INFO: Deleting pod "pod-subpath-test-configmap-j8q4" in namespace "subpath-2218"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 22 19:18:50.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2218" for this suite. 04/22/23 19:18:50.251
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:18:50.27
Apr 22 19:18:50.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:18:50.275
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:50.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:50.331
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 04/22/23 19:18:50.338
Apr 22 19:18:50.357: INFO: Waiting up to 5m0s for pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e" in namespace "emptydir-2960" to be "Succeeded or Failed"
Apr 22 19:18:50.366: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.073936ms
Apr 22 19:18:52.378: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021209956s
Apr 22 19:18:54.380: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022653024s
STEP: Saw pod success 04/22/23 19:18:54.38
Apr 22 19:18:54.380: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e" satisfied condition "Succeeded or Failed"
Apr 22 19:18:54.389: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e container test-container: <nil>
STEP: delete the pod 04/22/23 19:18:54.404
Apr 22 19:18:54.451: INFO: Waiting for pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e to disappear
Apr 22 19:18:54.460: INFO: Pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:18:54.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2960" for this suite. 04/22/23 19:18:54.474
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":82,"skipped":1589,"failed":0}
------------------------------
â€¢ [4.238 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:18:50.27
    Apr 22 19:18:50.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:18:50.275
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:50.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:50.331
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/22/23 19:18:50.338
    Apr 22 19:18:50.357: INFO: Waiting up to 5m0s for pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e" in namespace "emptydir-2960" to be "Succeeded or Failed"
    Apr 22 19:18:50.366: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.073936ms
    Apr 22 19:18:52.378: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021209956s
    Apr 22 19:18:54.380: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022653024s
    STEP: Saw pod success 04/22/23 19:18:54.38
    Apr 22 19:18:54.380: INFO: Pod "pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e" satisfied condition "Succeeded or Failed"
    Apr 22 19:18:54.389: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e container test-container: <nil>
    STEP: delete the pod 04/22/23 19:18:54.404
    Apr 22 19:18:54.451: INFO: Waiting for pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e to disappear
    Apr 22 19:18:54.460: INFO: Pod pod-4c9c5ca1-1f9c-4bcb-8c90-146f319b2c0e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:18:54.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2960" for this suite. 04/22/23 19:18:54.474
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:18:54.524
Apr 22 19:18:54.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:18:54.527
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:54.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:54.58
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 04/22/23 19:18:54.589
Apr 22 19:18:54.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: rename a version 04/22/23 19:19:02.456
STEP: check the new version name is served 04/22/23 19:19:02.525
STEP: check the old version name is removed 04/22/23 19:19:04.924
STEP: check the other version is not changed 04/22/23 19:19:06.835
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:19:15.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9515" for this suite. 04/22/23 19:19:15.115
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":83,"skipped":1590,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.605 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:18:54.524
    Apr 22 19:18:54.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:18:54.527
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:18:54.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:18:54.58
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 04/22/23 19:18:54.589
    Apr 22 19:18:54.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: rename a version 04/22/23 19:19:02.456
    STEP: check the new version name is served 04/22/23 19:19:02.525
    STEP: check the old version name is removed 04/22/23 19:19:04.924
    STEP: check the other version is not changed 04/22/23 19:19:06.835
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:19:15.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9515" for this suite. 04/22/23 19:19:15.115
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:15.144
Apr 22 19:19:15.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 19:19:15.146
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:15.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:15.197
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/22/23 19:19:15.214
STEP: delete the rc 04/22/23 19:19:20.236
STEP: wait for the rc to be deleted 04/22/23 19:19:20.245
Apr 22 19:19:21.271: INFO: 80 pods remaining
Apr 22 19:19:21.271: INFO: 80 pods has nil DeletionTimestamp
Apr 22 19:19:21.271: INFO: 
Apr 22 19:19:22.287: INFO: 71 pods remaining
Apr 22 19:19:22.287: INFO: 71 pods has nil DeletionTimestamp
Apr 22 19:19:22.287: INFO: 
Apr 22 19:19:23.279: INFO: 60 pods remaining
Apr 22 19:19:23.279: INFO: 60 pods has nil DeletionTimestamp
Apr 22 19:19:23.279: INFO: 
Apr 22 19:19:24.272: INFO: 40 pods remaining
Apr 22 19:19:24.272: INFO: 40 pods has nil DeletionTimestamp
Apr 22 19:19:24.272: INFO: 
Apr 22 19:19:25.265: INFO: 31 pods remaining
Apr 22 19:19:25.265: INFO: 31 pods has nil DeletionTimestamp
Apr 22 19:19:25.265: INFO: 
Apr 22 19:19:26.268: INFO: 20 pods remaining
Apr 22 19:19:26.268: INFO: 20 pods has nil DeletionTimestamp
Apr 22 19:19:26.268: INFO: 
STEP: Gathering metrics 04/22/23 19:19:27.266
Apr 22 19:19:27.329: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 19:19:27.337: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 8.435211ms
Apr 22 19:19:27.337: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 19:19:27.337: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 19:19:27.456: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 19:19:27.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5358" for this suite. 04/22/23 19:19:27.462
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":84,"skipped":1613,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.328 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:15.144
    Apr 22 19:19:15.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 19:19:15.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:15.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:15.197
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/22/23 19:19:15.214
    STEP: delete the rc 04/22/23 19:19:20.236
    STEP: wait for the rc to be deleted 04/22/23 19:19:20.245
    Apr 22 19:19:21.271: INFO: 80 pods remaining
    Apr 22 19:19:21.271: INFO: 80 pods has nil DeletionTimestamp
    Apr 22 19:19:21.271: INFO: 
    Apr 22 19:19:22.287: INFO: 71 pods remaining
    Apr 22 19:19:22.287: INFO: 71 pods has nil DeletionTimestamp
    Apr 22 19:19:22.287: INFO: 
    Apr 22 19:19:23.279: INFO: 60 pods remaining
    Apr 22 19:19:23.279: INFO: 60 pods has nil DeletionTimestamp
    Apr 22 19:19:23.279: INFO: 
    Apr 22 19:19:24.272: INFO: 40 pods remaining
    Apr 22 19:19:24.272: INFO: 40 pods has nil DeletionTimestamp
    Apr 22 19:19:24.272: INFO: 
    Apr 22 19:19:25.265: INFO: 31 pods remaining
    Apr 22 19:19:25.265: INFO: 31 pods has nil DeletionTimestamp
    Apr 22 19:19:25.265: INFO: 
    Apr 22 19:19:26.268: INFO: 20 pods remaining
    Apr 22 19:19:26.268: INFO: 20 pods has nil DeletionTimestamp
    Apr 22 19:19:26.268: INFO: 
    STEP: Gathering metrics 04/22/23 19:19:27.266
    Apr 22 19:19:27.329: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 19:19:27.337: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 8.435211ms
    Apr 22 19:19:27.337: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 19:19:27.337: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 19:19:27.456: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 19:19:27.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5358" for this suite. 04/22/23 19:19:27.462
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:27.475
Apr 22 19:19:27.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:19:27.476
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:27.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:27.519
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Apr 22 19:19:27.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: creating the pod 04/22/23 19:19:27.526
STEP: submitting the pod to kubernetes 04/22/23 19:19:27.526
Apr 22 19:19:27.542: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367" in namespace "pods-3973" to be "running and ready"
Apr 22 19:19:27.548: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542441ms
Apr 22 19:19:27.548: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:29.558: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015764944s
Apr 22 19:19:29.558: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:31.558: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015824446s
Apr 22 19:19:31.558: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:33.554: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011486584s
Apr 22 19:19:33.554: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:35.555: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012604628s
Apr 22 19:19:35.555: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:37.559: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017196753s
Apr 22 19:19:37.560: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:39.562: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019409997s
Apr 22 19:19:39.562: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:19:41.560: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Running", Reason="", readiness=true. Elapsed: 14.018326206s
Apr 22 19:19:41.561: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Running (Ready = true)
Apr 22 19:19:41.561: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:19:41.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3973" for this suite. 04/22/23 19:19:41.616
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":85,"skipped":1650,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.170 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:27.475
    Apr 22 19:19:27.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:19:27.476
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:27.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:27.519
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Apr 22 19:19:27.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: creating the pod 04/22/23 19:19:27.526
    STEP: submitting the pod to kubernetes 04/22/23 19:19:27.526
    Apr 22 19:19:27.542: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367" in namespace "pods-3973" to be "running and ready"
    Apr 22 19:19:27.548: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542441ms
    Apr 22 19:19:27.548: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:29.558: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015764944s
    Apr 22 19:19:29.558: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:31.558: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015824446s
    Apr 22 19:19:31.558: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:33.554: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011486584s
    Apr 22 19:19:33.554: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:35.555: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012604628s
    Apr 22 19:19:35.555: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:37.559: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017196753s
    Apr 22 19:19:37.560: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:39.562: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019409997s
    Apr 22 19:19:39.562: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:19:41.560: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367": Phase="Running", Reason="", readiness=true. Elapsed: 14.018326206s
    Apr 22 19:19:41.561: INFO: The phase of Pod pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367 is Running (Ready = true)
    Apr 22 19:19:41.561: INFO: Pod "pod-logs-websocket-4cba8788-0a00-4bf3-afcd-c53969435367" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:19:41.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3973" for this suite. 04/22/23 19:19:41.616
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:41.698
Apr 22 19:19:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:19:41.701
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:41.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:41.759
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 04/22/23 19:19:41.767
Apr 22 19:19:41.788: INFO: Waiting up to 5m0s for pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b" in namespace "emptydir-4506" to be "Succeeded or Failed"
Apr 22 19:19:41.803: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.893729ms
Apr 22 19:19:43.814: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026227087s
Apr 22 19:19:45.818: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03007061s
STEP: Saw pod success 04/22/23 19:19:45.818
Apr 22 19:19:45.819: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b" satisfied condition "Succeeded or Failed"
Apr 22 19:19:45.832: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b container test-container: <nil>
STEP: delete the pod 04/22/23 19:19:45.854
Apr 22 19:19:45.899: INFO: Waiting for pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b to disappear
Apr 22 19:19:45.908: INFO: Pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:19:45.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4506" for this suite. 04/22/23 19:19:45.92
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":86,"skipped":1705,"failed":0}
------------------------------
â€¢ [4.238 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:41.698
    Apr 22 19:19:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:19:41.701
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:41.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:41.759
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 04/22/23 19:19:41.767
    Apr 22 19:19:41.788: INFO: Waiting up to 5m0s for pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b" in namespace "emptydir-4506" to be "Succeeded or Failed"
    Apr 22 19:19:41.803: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.893729ms
    Apr 22 19:19:43.814: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026227087s
    Apr 22 19:19:45.818: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03007061s
    STEP: Saw pod success 04/22/23 19:19:45.818
    Apr 22 19:19:45.819: INFO: Pod "pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b" satisfied condition "Succeeded or Failed"
    Apr 22 19:19:45.832: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b container test-container: <nil>
    STEP: delete the pod 04/22/23 19:19:45.854
    Apr 22 19:19:45.899: INFO: Waiting for pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b to disappear
    Apr 22 19:19:45.908: INFO: Pod pod-f778d6d4-02cb-427f-8fe5-d1d89c2e543b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:19:45.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4506" for this suite. 04/22/23 19:19:45.92
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:45.971
Apr 22 19:19:45.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:19:45.974
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:46.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:46.007
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 04/22/23 19:19:46.01
Apr 22 19:19:46.023: INFO: Waiting up to 5m0s for pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682" in namespace "downward-api-5713" to be "Succeeded or Failed"
Apr 22 19:19:46.030: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Pending", Reason="", readiness=false. Elapsed: 6.145097ms
Apr 22 19:19:48.039: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159247s
Apr 22 19:19:50.038: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014945235s
STEP: Saw pod success 04/22/23 19:19:50.039
Apr 22 19:19:50.040: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682" satisfied condition "Succeeded or Failed"
Apr 22 19:19:50.050: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 container dapi-container: <nil>
STEP: delete the pod 04/22/23 19:19:50.072
Apr 22 19:19:50.112: INFO: Waiting for pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 to disappear
Apr 22 19:19:50.122: INFO: Pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 22 19:19:50.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5713" for this suite. 04/22/23 19:19:50.138
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":87,"skipped":1731,"failed":0}
------------------------------
â€¢ [4.189 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:45.971
    Apr 22 19:19:45.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:19:45.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:46.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:46.007
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 04/22/23 19:19:46.01
    Apr 22 19:19:46.023: INFO: Waiting up to 5m0s for pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682" in namespace "downward-api-5713" to be "Succeeded or Failed"
    Apr 22 19:19:46.030: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Pending", Reason="", readiness=false. Elapsed: 6.145097ms
    Apr 22 19:19:48.039: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159247s
    Apr 22 19:19:50.038: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014945235s
    STEP: Saw pod success 04/22/23 19:19:50.039
    Apr 22 19:19:50.040: INFO: Pod "downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682" satisfied condition "Succeeded or Failed"
    Apr 22 19:19:50.050: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 19:19:50.072
    Apr 22 19:19:50.112: INFO: Waiting for pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 to disappear
    Apr 22 19:19:50.122: INFO: Pod downward-api-59beccf7-36d8-43e3-9355-c97e9dd63682 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 22 19:19:50.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5713" for this suite. 04/22/23 19:19:50.138
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:50.185
Apr 22 19:19:50.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption 04/22/23 19:19:50.188
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:50.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:50.246
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 04/22/23 19:19:50.257
STEP: Waiting for the pdb to be processed 04/22/23 19:19:50.27
STEP: updating the pdb 04/22/23 19:19:52.295
STEP: Waiting for the pdb to be processed 04/22/23 19:19:52.32
STEP: patching the pdb 04/22/23 19:19:52.335
STEP: Waiting for the pdb to be processed 04/22/23 19:19:52.373
STEP: Waiting for the pdb to be deleted 04/22/23 19:19:52.406
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 22 19:19:52.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6220" for this suite. 04/22/23 19:19:52.425
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":88,"skipped":1736,"failed":0}
------------------------------
â€¢ [2.255 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:50.185
    Apr 22 19:19:50.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption 04/22/23 19:19:50.188
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:50.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:50.246
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 04/22/23 19:19:50.257
    STEP: Waiting for the pdb to be processed 04/22/23 19:19:50.27
    STEP: updating the pdb 04/22/23 19:19:52.295
    STEP: Waiting for the pdb to be processed 04/22/23 19:19:52.32
    STEP: patching the pdb 04/22/23 19:19:52.335
    STEP: Waiting for the pdb to be processed 04/22/23 19:19:52.373
    STEP: Waiting for the pdb to be deleted 04/22/23 19:19:52.406
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 22 19:19:52.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6220" for this suite. 04/22/23 19:19:52.425
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:52.448
Apr 22 19:19:52.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context-test 04/22/23 19:19:52.451
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:52.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:52.508
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Apr 22 19:19:52.530: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d" in namespace "security-context-test-5496" to be "Succeeded or Failed"
Apr 22 19:19:52.542: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.897831ms
Apr 22 19:19:54.552: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02195848s
Apr 22 19:19:56.556: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02541124s
Apr 22 19:19:56.556: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d" satisfied condition "Succeeded or Failed"
Apr 22 19:19:56.573: INFO: Got logs for pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 19:19:56.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5496" for this suite. 04/22/23 19:19:56.588
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":89,"skipped":1756,"failed":0}
------------------------------
â€¢ [4.162 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:52.448
    Apr 22 19:19:52.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context-test 04/22/23 19:19:52.451
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:52.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:52.508
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Apr 22 19:19:52.530: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d" in namespace "security-context-test-5496" to be "Succeeded or Failed"
    Apr 22 19:19:52.542: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.897831ms
    Apr 22 19:19:54.552: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02195848s
    Apr 22 19:19:56.556: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02541124s
    Apr 22 19:19:56.556: INFO: Pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d" satisfied condition "Succeeded or Failed"
    Apr 22 19:19:56.573: INFO: Got logs for pod "busybox-privileged-false-7d2fdfca-9af2-4389-abdf-237bb7189f6d": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 19:19:56.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-5496" for this suite. 04/22/23 19:19:56.588
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:19:56.621
Apr 22 19:19:56.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-webhook 04/22/23 19:19:56.625
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:56.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:56.683
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/22/23 19:19:56.692
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/22/23 19:19:57.732
STEP: Deploying the custom resource conversion webhook pod 04/22/23 19:19:57.743
STEP: Wait for the deployment to be ready 04/22/23 19:19:57.757
Apr 22 19:19:57.772: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:19:59.804
STEP: Verifying the service has paired with the endpoint 04/22/23 19:19:59.848
Apr 22 19:20:00.849: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 22 19:20:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Creating a v1 custom resource 04/22/23 19:20:03.589
STEP: Create a v2 custom resource 04/22/23 19:20:03.623
STEP: List CRs in v1 04/22/23 19:20:03.72
STEP: List CRs in v2 04/22/23 19:20:03.741
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:20:04.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4678" for this suite. 04/22/23 19:20:04.298
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":90,"skipped":1758,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.810 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:19:56.621
    Apr 22 19:19:56.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-webhook 04/22/23 19:19:56.625
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:19:56.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:19:56.683
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/22/23 19:19:56.692
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/22/23 19:19:57.732
    STEP: Deploying the custom resource conversion webhook pod 04/22/23 19:19:57.743
    STEP: Wait for the deployment to be ready 04/22/23 19:19:57.757
    Apr 22 19:19:57.772: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:19:59.804
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:19:59.848
    Apr 22 19:20:00.849: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 22 19:20:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Creating a v1 custom resource 04/22/23 19:20:03.589
    STEP: Create a v2 custom resource 04/22/23 19:20:03.623
    STEP: List CRs in v1 04/22/23 19:20:03.72
    STEP: List CRs in v2 04/22/23 19:20:03.741
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:20:04.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-4678" for this suite. 04/22/23 19:20:04.298
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:04.433
Apr 22 19:20:04.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename watch 04/22/23 19:20:04.437
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.478
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/22/23 19:20:04.483
STEP: modifying the configmap once 04/22/23 19:20:04.492
STEP: modifying the configmap a second time 04/22/23 19:20:04.502
STEP: deleting the configmap 04/22/23 19:20:04.512
STEP: creating a watch on configmaps from the resource version returned by the first update 04/22/23 19:20:04.52
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/22/23 19:20:04.522
Apr 22 19:20:04.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2329  a817aab2-a6d7-4103-8a9e-9668ad061646 14482 0 2023-04-22 19:20:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-22 19:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 19:20:04.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2329  a817aab2-a6d7-4103-8a9e-9668ad061646 14483 0 2023-04-22 19:20:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-22 19:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 22 19:20:04.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2329" for this suite. 04/22/23 19:20:04.53
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":91,"skipped":1767,"failed":0}
------------------------------
â€¢ [0.106 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:04.433
    Apr 22 19:20:04.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename watch 04/22/23 19:20:04.437
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.478
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/22/23 19:20:04.483
    STEP: modifying the configmap once 04/22/23 19:20:04.492
    STEP: modifying the configmap a second time 04/22/23 19:20:04.502
    STEP: deleting the configmap 04/22/23 19:20:04.512
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/22/23 19:20:04.52
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/22/23 19:20:04.522
    Apr 22 19:20:04.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2329  a817aab2-a6d7-4103-8a9e-9668ad061646 14482 0 2023-04-22 19:20:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-22 19:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 19:20:04.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2329  a817aab2-a6d7-4103-8a9e-9668ad061646 14483 0 2023-04-22 19:20:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-22 19:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 22 19:20:04.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2329" for this suite. 04/22/23 19:20:04.53
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:04.572
Apr 22 19:20:04.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename endpointslice 04/22/23 19:20:04.574
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.622
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Apr 22 19:20:04.643: INFO: Endpoints addresses: [10.1.1.171 10.1.1.29] , ports: [6443]
Apr 22 19:20:04.643: INFO: EndpointSlices addresses: [10.1.1.171 10.1.1.29] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 22 19:20:04.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-765" for this suite. 04/22/23 19:20:04.648
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":92,"skipped":1800,"failed":0}
------------------------------
â€¢ [0.087 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:04.572
    Apr 22 19:20:04.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename endpointslice 04/22/23 19:20:04.574
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.622
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Apr 22 19:20:04.643: INFO: Endpoints addresses: [10.1.1.171 10.1.1.29] , ports: [6443]
    Apr 22 19:20:04.643: INFO: EndpointSlices addresses: [10.1.1.171 10.1.1.29] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 22 19:20:04.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-765" for this suite. 04/22/23 19:20:04.648
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:04.672
Apr 22 19:20:04.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:20:04.674
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.695
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 04/22/23 19:20:04.698
Apr 22 19:20:04.707: INFO: Waiting up to 5m0s for pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146" in namespace "downward-api-9204" to be "running and ready"
Apr 22 19:20:04.711: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146": Phase="Pending", Reason="", readiness=false. Elapsed: 3.486262ms
Apr 22 19:20:04.711: INFO: The phase of Pod annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:20:06.723: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146": Phase="Running", Reason="", readiness=true. Elapsed: 2.015525229s
Apr 22 19:20:06.723: INFO: The phase of Pod annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146 is Running (Ready = true)
Apr 22 19:20:06.723: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146" satisfied condition "running and ready"
Apr 22 19:20:07.299: INFO: Successfully updated pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:20:11.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9204" for this suite. 04/22/23 19:20:11.377
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":93,"skipped":1830,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.723 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:04.672
    Apr 22 19:20:04.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:20:04.674
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:04.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:04.695
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 04/22/23 19:20:04.698
    Apr 22 19:20:04.707: INFO: Waiting up to 5m0s for pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146" in namespace "downward-api-9204" to be "running and ready"
    Apr 22 19:20:04.711: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146": Phase="Pending", Reason="", readiness=false. Elapsed: 3.486262ms
    Apr 22 19:20:04.711: INFO: The phase of Pod annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:20:06.723: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146": Phase="Running", Reason="", readiness=true. Elapsed: 2.015525229s
    Apr 22 19:20:06.723: INFO: The phase of Pod annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146 is Running (Ready = true)
    Apr 22 19:20:06.723: INFO: Pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146" satisfied condition "running and ready"
    Apr 22 19:20:07.299: INFO: Successfully updated pod "annotationupdate6676ce9a-7e33-4489-9103-caeebbdb4146"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:20:11.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9204" for this suite. 04/22/23 19:20:11.377
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:11.41
Apr 22 19:20:11.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:20:11.412
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:11.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:11.47
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 04/22/23 19:20:11.476
Apr 22 19:20:11.495: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502" in namespace "emptydir-8431" to be "running"
Apr 22 19:20:11.510: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502": Phase="Pending", Reason="", readiness=false. Elapsed: 14.790757ms
Apr 22 19:20:13.519: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502": Phase="Running", Reason="", readiness=false. Elapsed: 2.024338757s
Apr 22 19:20:13.520: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/22/23 19:20:13.521
Apr 22 19:20:13.522: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8431 PodName:pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:20:13.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:20:13.526: INFO: ExecWithOptions: Clientset creation
Apr 22 19:20:13.526: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-8431/pods/pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 22 19:20:13.687: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:20:13.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8431" for this suite. 04/22/23 19:20:13.705
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":94,"skipped":1845,"failed":0}
------------------------------
â€¢ [2.316 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:11.41
    Apr 22 19:20:11.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:20:11.412
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:11.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:11.47
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 04/22/23 19:20:11.476
    Apr 22 19:20:11.495: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502" in namespace "emptydir-8431" to be "running"
    Apr 22 19:20:11.510: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502": Phase="Pending", Reason="", readiness=false. Elapsed: 14.790757ms
    Apr 22 19:20:13.519: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502": Phase="Running", Reason="", readiness=false. Elapsed: 2.024338757s
    Apr 22 19:20:13.520: INFO: Pod "pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/22/23 19:20:13.521
    Apr 22 19:20:13.522: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8431 PodName:pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:20:13.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:20:13.526: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:20:13.526: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-8431/pods/pod-sharedvolume-06ed5134-9a52-4f99-ac9b-29ce9adf4502/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 22 19:20:13.687: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:20:13.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8431" for this suite. 04/22/23 19:20:13.705
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:13.752
Apr 22 19:20:13.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:20:13.753
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:13.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:13.804
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-1010-delete-me 04/22/23 19:20:13.825
STEP: Waiting for the RuntimeClass to disappear 04/22/23 19:20:13.84
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 22 19:20:13.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1010" for this suite. 04/22/23 19:20:13.876
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":95,"skipped":1894,"failed":0}
------------------------------
â€¢ [0.140 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:13.752
    Apr 22 19:20:13.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:20:13.753
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:13.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:13.804
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-1010-delete-me 04/22/23 19:20:13.825
    STEP: Waiting for the RuntimeClass to disappear 04/22/23 19:20:13.84
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 22 19:20:13.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1010" for this suite. 04/22/23 19:20:13.876
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:13.893
Apr 22 19:20:13.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:20:13.895
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:13.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:13.954
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 04/22/23 19:20:13.966
STEP: Getting a ResourceQuota 04/22/23 19:20:13.98
STEP: Updating a ResourceQuota 04/22/23 19:20:13.99
STEP: Verifying a ResourceQuota was modified 04/22/23 19:20:14
STEP: Deleting a ResourceQuota 04/22/23 19:20:14.008
STEP: Verifying the deleted ResourceQuota 04/22/23 19:20:14.021
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:20:14.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8641" for this suite. 04/22/23 19:20:14.036
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":96,"skipped":1904,"failed":0}
------------------------------
â€¢ [0.155 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:13.893
    Apr 22 19:20:13.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:20:13.895
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:13.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:13.954
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 04/22/23 19:20:13.966
    STEP: Getting a ResourceQuota 04/22/23 19:20:13.98
    STEP: Updating a ResourceQuota 04/22/23 19:20:13.99
    STEP: Verifying a ResourceQuota was modified 04/22/23 19:20:14
    STEP: Deleting a ResourceQuota 04/22/23 19:20:14.008
    STEP: Verifying the deleted ResourceQuota 04/22/23 19:20:14.021
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:20:14.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8641" for this suite. 04/22/23 19:20:14.036
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:14.07
Apr 22 19:20:14.070: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename namespaces 04/22/23 19:20:14.073
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:14.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:14.121
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 04/22/23 19:20:14.129
Apr 22 19:20:14.139: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/22/23 19:20:14.139
Apr 22 19:20:14.151: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/22/23 19:20:14.152
Apr 22 19:20:14.170: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:20:14.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2668" for this suite. 04/22/23 19:20:14.181
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":97,"skipped":1936,"failed":0}
------------------------------
â€¢ [0.122 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:14.07
    Apr 22 19:20:14.070: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename namespaces 04/22/23 19:20:14.073
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:14.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:14.121
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 04/22/23 19:20:14.129
    Apr 22 19:20:14.139: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/22/23 19:20:14.139
    Apr 22 19:20:14.151: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/22/23 19:20:14.152
    Apr 22 19:20:14.170: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:20:14.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2668" for this suite. 04/22/23 19:20:14.181
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:14.206
Apr 22 19:20:14.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:20:14.207
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:14.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:14.254
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 04/22/23 19:20:14.262
Apr 22 19:20:14.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 create -f -'
Apr 22 19:20:15.366: INFO: stderr: ""
Apr 22 19:20:15.366: INFO: stdout: "pod/pause created\n"
Apr 22 19:20:15.366: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 22 19:20:15.368: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9804" to be "running and ready"
Apr 22 19:20:15.390: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 21.656806ms
Apr 22 19:20:15.390: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'cncf25-2-node-187aa4c0d96' to be 'Running' but was 'Pending'
Apr 22 19:20:17.402: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.033327233s
Apr 22 19:20:17.402: INFO: Pod "pause" satisfied condition "running and ready"
Apr 22 19:20:17.402: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 04/22/23 19:20:17.403
Apr 22 19:20:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 label pods pause testing-label=testing-label-value'
Apr 22 19:20:17.512: INFO: stderr: ""
Apr 22 19:20:17.512: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/22/23 19:20:17.512
Apr 22 19:20:17.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pod pause -L testing-label'
Apr 22 19:20:17.631: INFO: stderr: ""
Apr 22 19:20:17.631: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/22/23 19:20:17.631
Apr 22 19:20:17.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 label pods pause testing-label-'
Apr 22 19:20:17.784: INFO: stderr: ""
Apr 22 19:20:17.784: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/22/23 19:20:17.784
Apr 22 19:20:17.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pod pause -L testing-label'
Apr 22 19:20:17.874: INFO: stderr: ""
Apr 22 19:20:17.874: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 04/22/23 19:20:17.874
Apr 22 19:20:17.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 delete --grace-period=0 --force -f -'
Apr 22 19:20:18.004: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:20:18.004: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 22 19:20:18.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get rc,svc -l name=pause --no-headers'
Apr 22 19:20:18.154: INFO: stderr: "No resources found in kubectl-9804 namespace.\n"
Apr 22 19:20:18.154: INFO: stdout: ""
Apr 22 19:20:18.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 22 19:20:18.252: INFO: stderr: ""
Apr 22 19:20:18.252: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:20:18.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9804" for this suite. 04/22/23 19:20:18.262
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":98,"skipped":1975,"failed":0}
------------------------------
â€¢ [4.071 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:14.206
    Apr 22 19:20:14.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:20:14.207
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:14.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:14.254
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 04/22/23 19:20:14.262
    Apr 22 19:20:14.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 create -f -'
    Apr 22 19:20:15.366: INFO: stderr: ""
    Apr 22 19:20:15.366: INFO: stdout: "pod/pause created\n"
    Apr 22 19:20:15.366: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 22 19:20:15.368: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9804" to be "running and ready"
    Apr 22 19:20:15.390: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 21.656806ms
    Apr 22 19:20:15.390: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'cncf25-2-node-187aa4c0d96' to be 'Running' but was 'Pending'
    Apr 22 19:20:17.402: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.033327233s
    Apr 22 19:20:17.402: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 22 19:20:17.402: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 04/22/23 19:20:17.403
    Apr 22 19:20:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 label pods pause testing-label=testing-label-value'
    Apr 22 19:20:17.512: INFO: stderr: ""
    Apr 22 19:20:17.512: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/22/23 19:20:17.512
    Apr 22 19:20:17.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pod pause -L testing-label'
    Apr 22 19:20:17.631: INFO: stderr: ""
    Apr 22 19:20:17.631: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/22/23 19:20:17.631
    Apr 22 19:20:17.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 label pods pause testing-label-'
    Apr 22 19:20:17.784: INFO: stderr: ""
    Apr 22 19:20:17.784: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/22/23 19:20:17.784
    Apr 22 19:20:17.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pod pause -L testing-label'
    Apr 22 19:20:17.874: INFO: stderr: ""
    Apr 22 19:20:17.874: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 04/22/23 19:20:17.874
    Apr 22 19:20:17.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 delete --grace-period=0 --force -f -'
    Apr 22 19:20:18.004: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:20:18.004: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 22 19:20:18.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get rc,svc -l name=pause --no-headers'
    Apr 22 19:20:18.154: INFO: stderr: "No resources found in kubectl-9804 namespace.\n"
    Apr 22 19:20:18.154: INFO: stdout: ""
    Apr 22 19:20:18.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9804 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 22 19:20:18.252: INFO: stderr: ""
    Apr 22 19:20:18.252: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:20:18.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9804" for this suite. 04/22/23 19:20:18.262
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:18.28
Apr 22 19:20:18.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:20:18.282
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:18.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:18.335
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-13c53748-ab47-4060-a5b6-a3dd53751315 04/22/23 19:20:18.342
STEP: Creating a pod to test consume configMaps 04/22/23 19:20:18.352
Apr 22 19:20:18.372: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7" in namespace "projected-6323" to be "Succeeded or Failed"
Apr 22 19:20:18.379: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.002462ms
Apr 22 19:20:20.394: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021465113s
Apr 22 19:20:22.389: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016864976s
STEP: Saw pod success 04/22/23 19:20:22.39
Apr 22 19:20:22.391: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7" satisfied condition "Succeeded or Failed"
Apr 22 19:20:22.401: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:20:22.416
Apr 22 19:20:22.441: INFO: Waiting for pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 to disappear
Apr 22 19:20:22.448: INFO: Pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:20:22.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6323" for this suite. 04/22/23 19:20:22.461
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":99,"skipped":1984,"failed":0}
------------------------------
â€¢ [4.200 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:18.28
    Apr 22 19:20:18.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:20:18.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:18.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:18.335
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-13c53748-ab47-4060-a5b6-a3dd53751315 04/22/23 19:20:18.342
    STEP: Creating a pod to test consume configMaps 04/22/23 19:20:18.352
    Apr 22 19:20:18.372: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7" in namespace "projected-6323" to be "Succeeded or Failed"
    Apr 22 19:20:18.379: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.002462ms
    Apr 22 19:20:20.394: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021465113s
    Apr 22 19:20:22.389: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016864976s
    STEP: Saw pod success 04/22/23 19:20:22.39
    Apr 22 19:20:22.391: INFO: Pod "pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7" satisfied condition "Succeeded or Failed"
    Apr 22 19:20:22.401: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:20:22.416
    Apr 22 19:20:22.441: INFO: Waiting for pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 to disappear
    Apr 22 19:20:22.448: INFO: Pod pod-projected-configmaps-c4b4aa74-899d-4a75-8595-0941f9cf6bc7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:20:22.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6323" for this suite. 04/22/23 19:20:22.461
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:22.5
Apr 22 19:20:22.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:20:22.504
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:22.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:22.56
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:20:22.591
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:20:22.947
STEP: Deploying the webhook pod 04/22/23 19:20:22.959
STEP: Wait for the deployment to be ready 04/22/23 19:20:22.987
Apr 22 19:20:23.006: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:20:25.033
STEP: Verifying the service has paired with the endpoint 04/22/23 19:20:25.081
Apr 22 19:20:26.082: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 04/22/23 19:20:26.09
STEP: Creating a custom resource definition that should be denied by the webhook 04/22/23 19:20:26.14
Apr 22 19:20:26.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:20:26.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7561" for this suite. 04/22/23 19:20:26.181
STEP: Destroying namespace "webhook-7561-markers" for this suite. 04/22/23 19:20:26.19
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":100,"skipped":2025,"failed":0}
------------------------------
â€¢ [3.778 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:22.5
    Apr 22 19:20:22.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:20:22.504
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:22.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:22.56
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:20:22.591
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:20:22.947
    STEP: Deploying the webhook pod 04/22/23 19:20:22.959
    STEP: Wait for the deployment to be ready 04/22/23 19:20:22.987
    Apr 22 19:20:23.006: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:20:25.033
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:20:25.081
    Apr 22 19:20:26.082: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/22/23 19:20:26.09
    STEP: Creating a custom resource definition that should be denied by the webhook 04/22/23 19:20:26.14
    Apr 22 19:20:26.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:20:26.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7561" for this suite. 04/22/23 19:20:26.181
    STEP: Destroying namespace "webhook-7561-markers" for this suite. 04/22/23 19:20:26.19
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:26.281
Apr 22 19:20:26.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:20:26.283
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:26.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:26.317
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-da1251fa-ce93-4270-bf8f-4274cd993731 04/22/23 19:20:26.33
STEP: Creating secret with name s-test-opt-upd-ed23c393-be1a-413d-b47e-bb00b1f296bf 04/22/23 19:20:26.338
STEP: Creating the pod 04/22/23 19:20:26.342
Apr 22 19:20:26.355: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781" in namespace "projected-6668" to be "running and ready"
Apr 22 19:20:26.364: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781": Phase="Pending", Reason="", readiness=false. Elapsed: 9.157265ms
Apr 22 19:20:26.364: INFO: The phase of Pod pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:20:28.375: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781": Phase="Running", Reason="", readiness=true. Elapsed: 2.019870014s
Apr 22 19:20:28.375: INFO: The phase of Pod pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781 is Running (Ready = true)
Apr 22 19:20:28.375: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-da1251fa-ce93-4270-bf8f-4274cd993731 04/22/23 19:20:28.433
STEP: Updating secret s-test-opt-upd-ed23c393-be1a-413d-b47e-bb00b1f296bf 04/22/23 19:20:28.45
STEP: Creating secret with name s-test-opt-create-f89120fa-96fb-4ecb-b376-162f059bb38c 04/22/23 19:20:28.464
STEP: waiting to observe update in volume 04/22/23 19:20:28.479
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:20:30.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6668" for this suite. 04/22/23 19:20:30.575
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":101,"skipped":2044,"failed":0}
------------------------------
â€¢ [4.314 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:26.281
    Apr 22 19:20:26.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:20:26.283
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:26.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:26.317
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-da1251fa-ce93-4270-bf8f-4274cd993731 04/22/23 19:20:26.33
    STEP: Creating secret with name s-test-opt-upd-ed23c393-be1a-413d-b47e-bb00b1f296bf 04/22/23 19:20:26.338
    STEP: Creating the pod 04/22/23 19:20:26.342
    Apr 22 19:20:26.355: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781" in namespace "projected-6668" to be "running and ready"
    Apr 22 19:20:26.364: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781": Phase="Pending", Reason="", readiness=false. Elapsed: 9.157265ms
    Apr 22 19:20:26.364: INFO: The phase of Pod pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:20:28.375: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781": Phase="Running", Reason="", readiness=true. Elapsed: 2.019870014s
    Apr 22 19:20:28.375: INFO: The phase of Pod pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781 is Running (Ready = true)
    Apr 22 19:20:28.375: INFO: Pod "pod-projected-secrets-1699ba5d-fd97-46f7-ae8e-807653078781" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-da1251fa-ce93-4270-bf8f-4274cd993731 04/22/23 19:20:28.433
    STEP: Updating secret s-test-opt-upd-ed23c393-be1a-413d-b47e-bb00b1f296bf 04/22/23 19:20:28.45
    STEP: Creating secret with name s-test-opt-create-f89120fa-96fb-4ecb-b376-162f059bb38c 04/22/23 19:20:28.464
    STEP: waiting to observe update in volume 04/22/23 19:20:28.479
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:20:30.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6668" for this suite. 04/22/23 19:20:30.575
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:30.6
Apr 22 19:20:30.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:20:30.602
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:30.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:30.66
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:20:30.669
Apr 22 19:20:30.696: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06" in namespace "downward-api-6174" to be "Succeeded or Failed"
Apr 22 19:20:30.722: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Pending", Reason="", readiness=false. Elapsed: 25.581665ms
Apr 22 19:20:32.733: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036531493s
Apr 22 19:20:34.732: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035232543s
STEP: Saw pod success 04/22/23 19:20:34.732
Apr 22 19:20:34.732: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06" satisfied condition "Succeeded or Failed"
Apr 22 19:20:34.741: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 container client-container: <nil>
STEP: delete the pod 04/22/23 19:20:34.757
Apr 22 19:20:34.803: INFO: Waiting for pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 to disappear
Apr 22 19:20:34.811: INFO: Pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:20:34.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6174" for this suite. 04/22/23 19:20:34.822
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":102,"skipped":2053,"failed":0}
------------------------------
â€¢ [4.239 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:30.6
    Apr 22 19:20:30.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:20:30.602
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:30.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:30.66
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:20:30.669
    Apr 22 19:20:30.696: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06" in namespace "downward-api-6174" to be "Succeeded or Failed"
    Apr 22 19:20:30.722: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Pending", Reason="", readiness=false. Elapsed: 25.581665ms
    Apr 22 19:20:32.733: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036531493s
    Apr 22 19:20:34.732: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035232543s
    STEP: Saw pod success 04/22/23 19:20:34.732
    Apr 22 19:20:34.732: INFO: Pod "downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06" satisfied condition "Succeeded or Failed"
    Apr 22 19:20:34.741: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:20:34.757
    Apr 22 19:20:34.803: INFO: Waiting for pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 to disappear
    Apr 22 19:20:34.811: INFO: Pod downwardapi-volume-6a7aa271-6625-464c-af09-c4e17a62ef06 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:20:34.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6174" for this suite. 04/22/23 19:20:34.822
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:34.854
Apr 22 19:20:34.855: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename subpath 04/22/23 19:20:34.858
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:34.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:34.91
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/22/23 19:20:34.919
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-9ds6 04/22/23 19:20:34.939
STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:20:34.939
Apr 22 19:20:34.958: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9ds6" in namespace "subpath-540" to be "Succeeded or Failed"
Apr 22 19:20:34.968: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.087871ms
Apr 22 19:20:36.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 2.019073758s
Apr 22 19:20:38.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 4.018621568s
Apr 22 19:20:40.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 6.019211291s
Apr 22 19:20:42.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 8.018445689s
Apr 22 19:20:44.986: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 10.027775946s
Apr 22 19:20:46.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 12.01892041s
Apr 22 19:20:48.981: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 14.022137724s
Apr 22 19:20:50.981: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 16.022342934s
Apr 22 19:20:52.980: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 18.021625113s
Apr 22 19:20:54.987: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 20.028319833s
Apr 22 19:20:56.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=false. Elapsed: 22.019201222s
Apr 22 19:20:58.979: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.020961258s
STEP: Saw pod success 04/22/23 19:20:58.98
Apr 22 19:20:58.982: INFO: Pod "pod-subpath-test-projected-9ds6" satisfied condition "Succeeded or Failed"
Apr 22 19:20:58.991: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-projected-9ds6 container test-container-subpath-projected-9ds6: <nil>
STEP: delete the pod 04/22/23 19:20:59.012
Apr 22 19:20:59.042: INFO: Waiting for pod pod-subpath-test-projected-9ds6 to disappear
Apr 22 19:20:59.051: INFO: Pod pod-subpath-test-projected-9ds6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-9ds6 04/22/23 19:20:59.052
Apr 22 19:20:59.053: INFO: Deleting pod "pod-subpath-test-projected-9ds6" in namespace "subpath-540"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 22 19:20:59.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-540" for this suite. 04/22/23 19:20:59.074
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":103,"skipped":2079,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.246 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:34.854
    Apr 22 19:20:34.855: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename subpath 04/22/23 19:20:34.858
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:34.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:34.91
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/22/23 19:20:34.919
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-9ds6 04/22/23 19:20:34.939
    STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:20:34.939
    Apr 22 19:20:34.958: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9ds6" in namespace "subpath-540" to be "Succeeded or Failed"
    Apr 22 19:20:34.968: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.087871ms
    Apr 22 19:20:36.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 2.019073758s
    Apr 22 19:20:38.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 4.018621568s
    Apr 22 19:20:40.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 6.019211291s
    Apr 22 19:20:42.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 8.018445689s
    Apr 22 19:20:44.986: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 10.027775946s
    Apr 22 19:20:46.977: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 12.01892041s
    Apr 22 19:20:48.981: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 14.022137724s
    Apr 22 19:20:50.981: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 16.022342934s
    Apr 22 19:20:52.980: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 18.021625113s
    Apr 22 19:20:54.987: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=true. Elapsed: 20.028319833s
    Apr 22 19:20:56.978: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Running", Reason="", readiness=false. Elapsed: 22.019201222s
    Apr 22 19:20:58.979: INFO: Pod "pod-subpath-test-projected-9ds6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.020961258s
    STEP: Saw pod success 04/22/23 19:20:58.98
    Apr 22 19:20:58.982: INFO: Pod "pod-subpath-test-projected-9ds6" satisfied condition "Succeeded or Failed"
    Apr 22 19:20:58.991: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-projected-9ds6 container test-container-subpath-projected-9ds6: <nil>
    STEP: delete the pod 04/22/23 19:20:59.012
    Apr 22 19:20:59.042: INFO: Waiting for pod pod-subpath-test-projected-9ds6 to disappear
    Apr 22 19:20:59.051: INFO: Pod pod-subpath-test-projected-9ds6 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-9ds6 04/22/23 19:20:59.052
    Apr 22 19:20:59.053: INFO: Deleting pod "pod-subpath-test-projected-9ds6" in namespace "subpath-540"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 22 19:20:59.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-540" for this suite. 04/22/23 19:20:59.074
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:59.121
Apr 22 19:20:59.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:20:59.126
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:59.181
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:59.19
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 22 19:20:59.229: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1801 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 22 19:20:59.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1801" for this suite. 04/22/23 19:20:59.281
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":104,"skipped":2084,"failed":0}
------------------------------
â€¢ [0.177 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:59.121
    Apr 22 19:20:59.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:20:59.126
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:59.181
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:59.19
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 22 19:20:59.229: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1801 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 22 19:20:59.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1801" for this suite. 04/22/23 19:20:59.281
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:20:59.299
Apr 22 19:20:59.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sysctl 04/22/23 19:20:59.303
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:59.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:59.35
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/22/23 19:20:59.366
STEP: Watching for error events or started pod 04/22/23 19:20:59.386
STEP: Waiting for pod completion 04/22/23 19:21:01.405
Apr 22 19:21:01.405: INFO: Waiting up to 3m0s for pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db" in namespace "sysctl-6936" to be "completed"
Apr 22 19:21:01.414: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108793ms
Apr 22 19:21:03.423: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018431924s
Apr 22 19:21:03.424: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/22/23 19:21:03.433
STEP: Getting logs from the pod 04/22/23 19:21:03.433
STEP: Checking that the sysctl is actually updated 04/22/23 19:21:03.453
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 19:21:03.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-6936" for this suite. 04/22/23 19:21:03.469
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":105,"skipped":2086,"failed":0}
------------------------------
â€¢ [4.190 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:20:59.299
    Apr 22 19:20:59.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sysctl 04/22/23 19:20:59.303
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:20:59.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:20:59.35
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/22/23 19:20:59.366
    STEP: Watching for error events or started pod 04/22/23 19:20:59.386
    STEP: Waiting for pod completion 04/22/23 19:21:01.405
    Apr 22 19:21:01.405: INFO: Waiting up to 3m0s for pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db" in namespace "sysctl-6936" to be "completed"
    Apr 22 19:21:01.414: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108793ms
    Apr 22 19:21:03.423: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018431924s
    Apr 22 19:21:03.424: INFO: Pod "sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/22/23 19:21:03.433
    STEP: Getting logs from the pod 04/22/23 19:21:03.433
    STEP: Checking that the sysctl is actually updated 04/22/23 19:21:03.453
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 19:21:03.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-6936" for this suite. 04/22/23 19:21:03.469
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:03.499
Apr 22 19:21:03.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-pred 04/22/23 19:21:03.503
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:03.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:03.557
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 22 19:21:03.564: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 22 19:21:03.587: INFO: Waiting for terminating namespaces to be deleted...
Apr 22 19:21:03.596: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
Apr 22 19:21:03.617: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.617: INFO: 	Container cloud-controller-manager ready: true, restart count 0
Apr 22 19:21:03.617: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.618: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:21:03.618: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:03.619: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:21:03.619: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:21:03.619: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.620: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 22 19:21:03.620: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.620: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 22 19:21:03.621: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.621: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 22 19:21:03.622: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:03.622: INFO: 	Container e2e ready: true, restart count 0
Apr 22 19:21:03.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:03.623: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:03.623: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:03.623: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 22 19:21:03.624: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
Apr 22 19:21:03.640: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.640: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:21:03.640: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:03.640: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:21:03.640: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:21:03.640: INFO: test-runtimeclass-runtimeclass-1801-preconfigured-handler-m2928 from runtimeclass-1801 started at 2023-04-22 19:20:59 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.640: INFO: 	Container test ready: false, restart count 0
Apr 22 19:21:03.640: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:03.640: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:03.640: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 22 19:21:03.640: INFO: sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db from sysctl-6936 started at 2023-04-22 19:20:59 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:03.640: INFO: 	Container test-container ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/22/23 19:21:03.64
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1758580aac7d4cff], Reason = [FailedScheduling], Message = [0/4 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.] 04/22/23 19:21:03.709
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:21:04.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8286" for this suite. 04/22/23 19:21:04.72
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":106,"skipped":2090,"failed":0}
------------------------------
â€¢ [1.233 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:03.499
    Apr 22 19:21:03.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-pred 04/22/23 19:21:03.503
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:03.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:03.557
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 22 19:21:03.564: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 22 19:21:03.587: INFO: Waiting for terminating namespaces to be deleted...
    Apr 22 19:21:03.596: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
    Apr 22 19:21:03.617: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.617: INFO: 	Container cloud-controller-manager ready: true, restart count 0
    Apr 22 19:21:03.617: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.618: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:21:03.618: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:03.619: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:21:03.619: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:21:03.619: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.620: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 22 19:21:03.620: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.620: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 22 19:21:03.621: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.621: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 22 19:21:03.622: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:03.622: INFO: 	Container e2e ready: true, restart count 0
    Apr 22 19:21:03.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:03.623: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:03.623: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:03.623: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 22 19:21:03.624: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
    Apr 22 19:21:03.640: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.640: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:21:03.640: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:03.640: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:21:03.640: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:21:03.640: INFO: test-runtimeclass-runtimeclass-1801-preconfigured-handler-m2928 from runtimeclass-1801 started at 2023-04-22 19:20:59 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.640: INFO: 	Container test ready: false, restart count 0
    Apr 22 19:21:03.640: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:03.640: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:03.640: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 22 19:21:03.640: INFO: sysctl-a8eb462c-82fe-4868-9310-9fce9825c0db from sysctl-6936 started at 2023-04-22 19:20:59 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:03.640: INFO: 	Container test-container ready: false, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/22/23 19:21:03.64
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1758580aac7d4cff], Reason = [FailedScheduling], Message = [0/4 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.] 04/22/23 19:21:03.709
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:21:04.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8286" for this suite. 04/22/23 19:21:04.72
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:04.75
Apr 22 19:21:04.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename endpointslice 04/22/23 19:21:04.753
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:04.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:04.804
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 04/22/23 19:21:09.938
STEP: referencing matching pods with named port 04/22/23 19:21:14.953
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/22/23 19:21:19.972
STEP: recreating EndpointSlices after they've been deleted 04/22/23 19:21:24.993
Apr 22 19:21:25.042: INFO: EndpointSlice for Service endpointslice-146/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 22 19:21:35.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-146" for this suite. 04/22/23 19:21:35.08
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":107,"skipped":2111,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.349 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:04.75
    Apr 22 19:21:04.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename endpointslice 04/22/23 19:21:04.753
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:04.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:04.804
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 04/22/23 19:21:09.938
    STEP: referencing matching pods with named port 04/22/23 19:21:14.953
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/22/23 19:21:19.972
    STEP: recreating EndpointSlices after they've been deleted 04/22/23 19:21:24.993
    Apr 22 19:21:25.042: INFO: EndpointSlice for Service endpointslice-146/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 22 19:21:35.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-146" for this suite. 04/22/23 19:21:35.08
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:35.103
Apr 22 19:21:35.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:21:35.107
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:35.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:35.17
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/22/23 19:21:35.179
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/22/23 19:21:35.191
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/22/23 19:21:35.192
STEP: creating a pod to probe DNS 04/22/23 19:21:35.192
STEP: submitting the pod to kubernetes 04/22/23 19:21:35.195
Apr 22 19:21:35.226: INFO: Waiting up to 15m0s for pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7" in namespace "dns-1060" to be "running"
Apr 22 19:21:35.238: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.251843ms
Apr 22 19:21:37.249: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7": Phase="Running", Reason="", readiness=true. Elapsed: 2.023070162s
Apr 22 19:21:37.249: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:21:37.25
STEP: looking for the results for each expected name from probers 04/22/23 19:21:37.261
Apr 22 19:21:37.314: INFO: DNS probes using dns-1060/dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7 succeeded

STEP: deleting the pod 04/22/23 19:21:37.314
STEP: deleting the test headless service 04/22/23 19:21:37.379
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:21:37.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1060" for this suite. 04/22/23 19:21:37.427
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":108,"skipped":2115,"failed":0}
------------------------------
â€¢ [2.337 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:35.103
    Apr 22 19:21:35.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:21:35.107
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:35.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:35.17
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/22/23 19:21:35.179
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/22/23 19:21:35.191
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1060.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/22/23 19:21:35.192
    STEP: creating a pod to probe DNS 04/22/23 19:21:35.192
    STEP: submitting the pod to kubernetes 04/22/23 19:21:35.195
    Apr 22 19:21:35.226: INFO: Waiting up to 15m0s for pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7" in namespace "dns-1060" to be "running"
    Apr 22 19:21:35.238: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.251843ms
    Apr 22 19:21:37.249: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7": Phase="Running", Reason="", readiness=true. Elapsed: 2.023070162s
    Apr 22 19:21:37.249: INFO: Pod "dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:21:37.25
    STEP: looking for the results for each expected name from probers 04/22/23 19:21:37.261
    Apr 22 19:21:37.314: INFO: DNS probes using dns-1060/dns-test-5a604510-1646-4aa3-9375-fa566c4b00c7 succeeded

    STEP: deleting the pod 04/22/23 19:21:37.314
    STEP: deleting the test headless service 04/22/23 19:21:37.379
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:21:37.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1060" for this suite. 04/22/23 19:21:37.427
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:37.45
Apr 22 19:21:37.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:21:37.453
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:37.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:37.496
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/22/23 19:21:37.503
STEP: getting /apis/node.k8s.io 04/22/23 19:21:37.51
STEP: getting /apis/node.k8s.io/v1 04/22/23 19:21:37.513
STEP: creating 04/22/23 19:21:37.516
STEP: watching 04/22/23 19:21:37.54
Apr 22 19:21:37.540: INFO: starting watch
STEP: getting 04/22/23 19:21:37.553
STEP: listing 04/22/23 19:21:37.558
STEP: patching 04/22/23 19:21:37.566
STEP: updating 04/22/23 19:21:37.576
Apr 22 19:21:37.584: INFO: waiting for watch events with expected annotations
STEP: deleting 04/22/23 19:21:37.585
STEP: deleting a collection 04/22/23 19:21:37.605
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 22 19:21:37.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4187" for this suite. 04/22/23 19:21:37.646
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":109,"skipped":2115,"failed":0}
------------------------------
â€¢ [0.207 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:37.45
    Apr 22 19:21:37.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename runtimeclass 04/22/23 19:21:37.453
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:37.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:37.496
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/22/23 19:21:37.503
    STEP: getting /apis/node.k8s.io 04/22/23 19:21:37.51
    STEP: getting /apis/node.k8s.io/v1 04/22/23 19:21:37.513
    STEP: creating 04/22/23 19:21:37.516
    STEP: watching 04/22/23 19:21:37.54
    Apr 22 19:21:37.540: INFO: starting watch
    STEP: getting 04/22/23 19:21:37.553
    STEP: listing 04/22/23 19:21:37.558
    STEP: patching 04/22/23 19:21:37.566
    STEP: updating 04/22/23 19:21:37.576
    Apr 22 19:21:37.584: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/22/23 19:21:37.585
    STEP: deleting a collection 04/22/23 19:21:37.605
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 22 19:21:37.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4187" for this suite. 04/22/23 19:21:37.646
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:37.684
Apr 22 19:21:37.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:21:37.687
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:37.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:37.72
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 04/22/23 19:21:37.729
Apr 22 19:21:37.743: INFO: Waiting up to 5m0s for pod "pod-mx2lw" in namespace "pods-2288" to be "running"
Apr 22 19:21:37.748: INFO: Pod "pod-mx2lw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926292ms
Apr 22 19:21:39.759: INFO: Pod "pod-mx2lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.0156308s
Apr 22 19:21:39.760: INFO: Pod "pod-mx2lw" satisfied condition "running"
STEP: patching /status 04/22/23 19:21:39.76
Apr 22 19:21:39.781: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:21:39.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2288" for this suite. 04/22/23 19:21:39.795
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":110,"skipped":2139,"failed":0}
------------------------------
â€¢ [2.128 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:37.684
    Apr 22 19:21:37.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:21:37.687
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:37.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:37.72
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 04/22/23 19:21:37.729
    Apr 22 19:21:37.743: INFO: Waiting up to 5m0s for pod "pod-mx2lw" in namespace "pods-2288" to be "running"
    Apr 22 19:21:37.748: INFO: Pod "pod-mx2lw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926292ms
    Apr 22 19:21:39.759: INFO: Pod "pod-mx2lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.0156308s
    Apr 22 19:21:39.760: INFO: Pod "pod-mx2lw" satisfied condition "running"
    STEP: patching /status 04/22/23 19:21:39.76
    Apr 22 19:21:39.781: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:21:39.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2288" for this suite. 04/22/23 19:21:39.795
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:39.817
Apr 22 19:21:39.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:21:39.82
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:39.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:39.881
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 04/22/23 19:21:39.89
Apr 22 19:21:39.909: INFO: Waiting up to 5m0s for pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32" in namespace "emptydir-1668" to be "Succeeded or Failed"
Apr 22 19:21:39.919: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Pending", Reason="", readiness=false. Elapsed: 10.305224ms
Apr 22 19:21:41.932: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022990492s
Apr 22 19:21:43.930: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021403925s
STEP: Saw pod success 04/22/23 19:21:43.931
Apr 22 19:21:43.931: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32" satisfied condition "Succeeded or Failed"
Apr 22 19:21:43.940: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 container test-container: <nil>
STEP: delete the pod 04/22/23 19:21:43.96
Apr 22 19:21:43.991: INFO: Waiting for pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 to disappear
Apr 22 19:21:43.995: INFO: Pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:21:43.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1668" for this suite. 04/22/23 19:21:44.009
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":111,"skipped":2148,"failed":0}
------------------------------
â€¢ [4.208 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:39.817
    Apr 22 19:21:39.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:21:39.82
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:39.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:39.881
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/22/23 19:21:39.89
    Apr 22 19:21:39.909: INFO: Waiting up to 5m0s for pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32" in namespace "emptydir-1668" to be "Succeeded or Failed"
    Apr 22 19:21:39.919: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Pending", Reason="", readiness=false. Elapsed: 10.305224ms
    Apr 22 19:21:41.932: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022990492s
    Apr 22 19:21:43.930: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021403925s
    STEP: Saw pod success 04/22/23 19:21:43.931
    Apr 22 19:21:43.931: INFO: Pod "pod-429477b7-73df-4cb2-937f-22f3a48c9f32" satisfied condition "Succeeded or Failed"
    Apr 22 19:21:43.940: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:21:43.96
    Apr 22 19:21:43.991: INFO: Waiting for pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 to disappear
    Apr 22 19:21:43.995: INFO: Pod pod-429477b7-73df-4cb2-937f-22f3a48c9f32 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:21:43.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1668" for this suite. 04/22/23 19:21:44.009
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:44.026
Apr 22 19:21:44.026: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:21:44.028
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:44.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:44.087
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-8252b0f0-6814-4d95-9197-aa46e639802c 04/22/23 19:21:44.101
STEP: Creating a pod to test consume configMaps 04/22/23 19:21:44.113
Apr 22 19:21:44.132: INFO: Waiting up to 5m0s for pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5" in namespace "configmap-6966" to be "Succeeded or Failed"
Apr 22 19:21:44.140: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.393449ms
Apr 22 19:21:46.146: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Running", Reason="", readiness=false. Elapsed: 2.013745879s
Apr 22 19:21:48.149: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016727077s
STEP: Saw pod success 04/22/23 19:21:48.149
Apr 22 19:21:48.150: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5" satisfied condition "Succeeded or Failed"
Apr 22 19:21:48.160: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:21:48.177
Apr 22 19:21:48.210: INFO: Waiting for pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 to disappear
Apr 22 19:21:48.223: INFO: Pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:21:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6966" for this suite. 04/22/23 19:21:48.236
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":112,"skipped":2165,"failed":0}
------------------------------
â€¢ [4.227 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:44.026
    Apr 22 19:21:44.026: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:21:44.028
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:44.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:44.087
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-8252b0f0-6814-4d95-9197-aa46e639802c 04/22/23 19:21:44.101
    STEP: Creating a pod to test consume configMaps 04/22/23 19:21:44.113
    Apr 22 19:21:44.132: INFO: Waiting up to 5m0s for pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5" in namespace "configmap-6966" to be "Succeeded or Failed"
    Apr 22 19:21:44.140: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.393449ms
    Apr 22 19:21:46.146: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Running", Reason="", readiness=false. Elapsed: 2.013745879s
    Apr 22 19:21:48.149: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016727077s
    STEP: Saw pod success 04/22/23 19:21:48.149
    Apr 22 19:21:48.150: INFO: Pod "pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5" satisfied condition "Succeeded or Failed"
    Apr 22 19:21:48.160: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:21:48.177
    Apr 22 19:21:48.210: INFO: Waiting for pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 to disappear
    Apr 22 19:21:48.223: INFO: Pod pod-configmaps-d425d27b-5543-4f0c-91c8-0c332b5fd9d5 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:21:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6966" for this suite. 04/22/23 19:21:48.236
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:48.278
Apr 22 19:21:48.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:21:48.28
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:48.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:48.346
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-8521 04/22/23 19:21:48.354
STEP: creating service affinity-nodeport-transition in namespace services-8521 04/22/23 19:21:48.355
STEP: creating replication controller affinity-nodeport-transition in namespace services-8521 04/22/23 19:21:48.393
I0422 19:21:48.409346      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-8521, replica count: 3
I0422 19:21:51.461219      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:21:51.494: INFO: Creating new exec pod
Apr 22 19:21:51.523: INFO: Waiting up to 5m0s for pod "execpod-affinity855th" in namespace "services-8521" to be "running"
Apr 22 19:21:51.539: INFO: Pod "execpod-affinity855th": Phase="Pending", Reason="", readiness=false. Elapsed: 15.276827ms
Apr 22 19:21:53.546: INFO: Pod "execpod-affinity855th": Phase="Running", Reason="", readiness=true. Elapsed: 2.022578798s
Apr 22 19:21:53.547: INFO: Pod "execpod-affinity855th" satisfied condition "running"
Apr 22 19:21:54.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 22 19:21:54.934: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 22 19:21:54.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:21:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.129.36 80'
Apr 22 19:21:55.266: INFO: stderr: "+ nc -v -t -w 2 10.103.129.36 80\n+ echo hostName\nConnection to 10.103.129.36 80 port [tcp/http] succeeded!\n"
Apr 22 19:21:55.266: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:21:55.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 32437'
Apr 22 19:21:55.588: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 10.1.1.165 32437\nConnection to 10.1.1.165 32437 port [tcp/*] succeeded!\n"
Apr 22 19:21:55.588: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:21:55.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32437'
Apr 22 19:21:55.930: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.128 32437\nConnection to 10.1.1.128 32437 port [tcp/*] succeeded!\n"
Apr 22 19:21:55.930: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 19:21:55.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:32437/ ; done'
Apr 22 19:21:56.420: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n"
Apr 22 19:21:56.420: INFO: stdout: "\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v"
Apr 22 19:21:56.420: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:32437/ ; done'
Apr 22 19:21:56.902: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n"
Apr 22 19:21:56.902: INFO: stdout: "\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v"
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
Apr 22 19:21:56.903: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8521, will wait for the garbage collector to delete the pods 04/22/23 19:21:56.932
Apr 22 19:21:57.023: INFO: Deleting ReplicationController affinity-nodeport-transition took: 29.507977ms
Apr 22 19:21:57.124: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.166048ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 19:21:59.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8521" for this suite. 04/22/23 19:21:59.519
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":113,"skipped":2201,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.255 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:48.278
    Apr 22 19:21:48.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:21:48.28
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:48.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:48.346
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-8521 04/22/23 19:21:48.354
    STEP: creating service affinity-nodeport-transition in namespace services-8521 04/22/23 19:21:48.355
    STEP: creating replication controller affinity-nodeport-transition in namespace services-8521 04/22/23 19:21:48.393
    I0422 19:21:48.409346      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-8521, replica count: 3
    I0422 19:21:51.461219      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:21:51.494: INFO: Creating new exec pod
    Apr 22 19:21:51.523: INFO: Waiting up to 5m0s for pod "execpod-affinity855th" in namespace "services-8521" to be "running"
    Apr 22 19:21:51.539: INFO: Pod "execpod-affinity855th": Phase="Pending", Reason="", readiness=false. Elapsed: 15.276827ms
    Apr 22 19:21:53.546: INFO: Pod "execpod-affinity855th": Phase="Running", Reason="", readiness=true. Elapsed: 2.022578798s
    Apr 22 19:21:53.547: INFO: Pod "execpod-affinity855th" satisfied condition "running"
    Apr 22 19:21:54.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Apr 22 19:21:54.934: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 22 19:21:54.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:21:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.129.36 80'
    Apr 22 19:21:55.266: INFO: stderr: "+ nc -v -t -w 2 10.103.129.36 80\n+ echo hostName\nConnection to 10.103.129.36 80 port [tcp/http] succeeded!\n"
    Apr 22 19:21:55.266: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:21:55.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 32437'
    Apr 22 19:21:55.588: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 10.1.1.165 32437\nConnection to 10.1.1.165 32437 port [tcp/*] succeeded!\n"
    Apr 22 19:21:55.588: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:21:55.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32437'
    Apr 22 19:21:55.930: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.128 32437\nConnection to 10.1.1.128 32437 port [tcp/*] succeeded!\n"
    Apr 22 19:21:55.930: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 19:21:55.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:32437/ ; done'
    Apr 22 19:21:56.420: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n"
    Apr 22 19:21:56.420: INFO: stdout: "\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-4mfkj\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-qj5fr\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v"
    Apr 22 19:21:56.420: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-4mfkj
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-qj5fr
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.421: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-8521 exec execpod-affinity855th -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:32437/ ; done'
    Apr 22 19:21:56.902: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:32437/\n"
    Apr 22 19:21:56.902: INFO: stdout: "\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v\naffinity-nodeport-transition-xd64v"
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.902: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Received response from host: affinity-nodeport-transition-xd64v
    Apr 22 19:21:56.903: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8521, will wait for the garbage collector to delete the pods 04/22/23 19:21:56.932
    Apr 22 19:21:57.023: INFO: Deleting ReplicationController affinity-nodeport-transition took: 29.507977ms
    Apr 22 19:21:57.124: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.166048ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 19:21:59.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8521" for this suite. 04/22/23 19:21:59.519
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:59.544
Apr 22 19:21:59.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename tables 04/22/23 19:21:59.549
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:59.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:59.606
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Apr 22 19:21:59.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-775" for this suite. 04/22/23 19:21:59.633
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":114,"skipped":2202,"failed":0}
------------------------------
â€¢ [0.102 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:59.544
    Apr 22 19:21:59.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename tables 04/22/23 19:21:59.549
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:59.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:59.606
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Apr 22 19:21:59.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-775" for this suite. 04/22/23 19:21:59.633
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:21:59.659
Apr 22 19:21:59.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-pred 04/22/23 19:21:59.66
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:59.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:59.701
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 22 19:21:59.709: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 22 19:21:59.725: INFO: Waiting for terminating namespaces to be deleted...
Apr 22 19:21:59.731: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
Apr 22 19:21:59.753: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.753: INFO: 	Container cloud-controller-manager ready: true, restart count 0
Apr 22 19:21:59.753: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.753: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:21:59.753: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:59.753: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:21:59.754: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:21:59.754: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.754: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 22 19:21:59.754: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.754: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 22 19:21:59.754: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.754: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 22 19:21:59.754: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:59.754: INFO: 	Container e2e ready: true, restart count 0
Apr 22 19:21:59.754: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:59.755: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:59.755: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:59.755: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 22 19:21:59.755: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
Apr 22 19:21:59.768: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
Apr 22 19:21:59.768: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:21:59.768: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:59.768: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:21:59.768: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:21:59.768: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:21:59.768: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:21:59.769: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node cncf25-2-node-187aa4bdec5 04/22/23 19:21:59.82
STEP: verifying the node has the label node cncf25-2-node-187aa4c0d96 04/22/23 19:21:59.844
Apr 22 19:21:59.868: INFO: Pod cloud-controller-manager-7c49d45757-jx65l requesting resource cpu=10m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod kube-proxy-28gqf requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod kube-proxy-rcfsq requesting resource cpu=0m on Node cncf25-2-node-187aa4c0d96
Apr 22 19:21:59.868: INFO: Pod weave-net-7dpcc requesting resource cpu=100m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod weave-net-np8wq requesting resource cpu=100m on Node cncf25-2-node-187aa4c0d96
Apr 22 19:21:59.868: INFO: Pod dashboard-metrics-scraper-64bcc67c9c-b4w74 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod kubernetes-dashboard-5c8bd6b59-tmblk requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod sonobuoy requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod sonobuoy-e2e-job-ac22730371274d86 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.868: INFO: Pod sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm requesting resource cpu=0m on Node cncf25-2-node-187aa4c0d96
STEP: Starting Pods to consume most of the cluster CPU. 04/22/23 19:21:59.868
Apr 22 19:21:59.869: INFO: Creating a pod which consumes cpu=1323m on Node cncf25-2-node-187aa4bdec5
Apr 22 19:21:59.882: INFO: Creating a pod which consumes cpu=1330m on Node cncf25-2-node-187aa4c0d96
Apr 22 19:21:59.892: INFO: Waiting up to 5m0s for pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580" in namespace "sched-pred-59" to be "running"
Apr 22 19:21:59.898: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052633ms
Apr 22 19:22:01.908: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580": Phase="Running", Reason="", readiness=true. Elapsed: 2.015741498s
Apr 22 19:22:01.908: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580" satisfied condition "running"
Apr 22 19:22:01.908: INFO: Waiting up to 5m0s for pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b" in namespace "sched-pred-59" to be "running"
Apr 22 19:22:01.918: INFO: Pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b": Phase="Running", Reason="", readiness=true. Elapsed: 9.009779ms
Apr 22 19:22:01.918: INFO: Pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/22/23 19:22:01.918
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817c230fc61], Reason = [Scheduled], Message = [Successfully assigned sched-pred-59/filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580 to cncf25-2-node-187aa4bdec5] 04/22/23 19:22:01.931
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e0da7c34], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/22/23 19:22:01.931
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e19bd733], Reason = [Created], Message = [Created container filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580] 04/22/23 19:22:01.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e6fce3bc], Reason = [Started], Message = [Started container filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580] 04/22/23 19:22:01.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817c317e1ea], Reason = [Scheduled], Message = [Successfully assigned sched-pred-59/filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b to cncf25-2-node-187aa4c0d96] 04/22/23 19:22:01.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817e46f05bf], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/22/23 19:22:01.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817e57964cb], Reason = [Created], Message = [Created container filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b] 04/22/23 19:22:01.934
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817ead14f8f], Reason = [Started], Message = [Started container filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b] 04/22/23 19:22:01.935
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.175858183c9ef37b], Reason = [FailedScheduling], Message = [0/4 nodes are available: 2 Insufficient cpu, 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/4 nodes are available: 2 No preemption victims found for incoming pod, 2 Preemption is not helpful for scheduling.] 04/22/23 19:22:01.966
STEP: removing the label node off the node cncf25-2-node-187aa4bdec5 04/22/23 19:22:02.965
STEP: verifying the node doesn't have the label node 04/22/23 19:22:03
STEP: removing the label node off the node cncf25-2-node-187aa4c0d96 04/22/23 19:22:03.018
STEP: verifying the node doesn't have the label node 04/22/23 19:22:03.054
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:22:03.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-59" for this suite. 04/22/23 19:22:03.078
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":115,"skipped":2222,"failed":0}
------------------------------
â€¢ [3.439 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:21:59.659
    Apr 22 19:21:59.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-pred 04/22/23 19:21:59.66
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:21:59.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:21:59.701
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 22 19:21:59.709: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 22 19:21:59.725: INFO: Waiting for terminating namespaces to be deleted...
    Apr 22 19:21:59.731: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
    Apr 22 19:21:59.753: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.753: INFO: 	Container cloud-controller-manager ready: true, restart count 0
    Apr 22 19:21:59.753: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.753: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:21:59.753: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:59.753: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.754: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.754: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.754: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:59.754: INFO: 	Container e2e ready: true, restart count 0
    Apr 22 19:21:59.754: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:59.755: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:59.755: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:59.755: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 22 19:21:59.755: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
    Apr 22 19:21:59.768: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
    Apr 22 19:21:59.768: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:21:59.768: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:59.768: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:21:59.768: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:21:59.768: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:21:59.768: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:21:59.769: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node cncf25-2-node-187aa4bdec5 04/22/23 19:21:59.82
    STEP: verifying the node has the label node cncf25-2-node-187aa4c0d96 04/22/23 19:21:59.844
    Apr 22 19:21:59.868: INFO: Pod cloud-controller-manager-7c49d45757-jx65l requesting resource cpu=10m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod kube-proxy-28gqf requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod kube-proxy-rcfsq requesting resource cpu=0m on Node cncf25-2-node-187aa4c0d96
    Apr 22 19:21:59.868: INFO: Pod weave-net-7dpcc requesting resource cpu=100m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod weave-net-np8wq requesting resource cpu=100m on Node cncf25-2-node-187aa4c0d96
    Apr 22 19:21:59.868: INFO: Pod dashboard-metrics-scraper-64bcc67c9c-b4w74 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod kubernetes-dashboard-5c8bd6b59-tmblk requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod sonobuoy requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod sonobuoy-e2e-job-ac22730371274d86 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 requesting resource cpu=0m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.868: INFO: Pod sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm requesting resource cpu=0m on Node cncf25-2-node-187aa4c0d96
    STEP: Starting Pods to consume most of the cluster CPU. 04/22/23 19:21:59.868
    Apr 22 19:21:59.869: INFO: Creating a pod which consumes cpu=1323m on Node cncf25-2-node-187aa4bdec5
    Apr 22 19:21:59.882: INFO: Creating a pod which consumes cpu=1330m on Node cncf25-2-node-187aa4c0d96
    Apr 22 19:21:59.892: INFO: Waiting up to 5m0s for pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580" in namespace "sched-pred-59" to be "running"
    Apr 22 19:21:59.898: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052633ms
    Apr 22 19:22:01.908: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580": Phase="Running", Reason="", readiness=true. Elapsed: 2.015741498s
    Apr 22 19:22:01.908: INFO: Pod "filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580" satisfied condition "running"
    Apr 22 19:22:01.908: INFO: Waiting up to 5m0s for pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b" in namespace "sched-pred-59" to be "running"
    Apr 22 19:22:01.918: INFO: Pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b": Phase="Running", Reason="", readiness=true. Elapsed: 9.009779ms
    Apr 22 19:22:01.918: INFO: Pod "filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/22/23 19:22:01.918
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817c230fc61], Reason = [Scheduled], Message = [Successfully assigned sched-pred-59/filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580 to cncf25-2-node-187aa4bdec5] 04/22/23 19:22:01.931
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e0da7c34], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/22/23 19:22:01.931
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e19bd733], Reason = [Created], Message = [Created container filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580] 04/22/23 19:22:01.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580.17585817e6fce3bc], Reason = [Started], Message = [Started container filler-pod-1eb5799b-2e3c-443f-9c9e-5ef537999580] 04/22/23 19:22:01.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817c317e1ea], Reason = [Scheduled], Message = [Successfully assigned sched-pred-59/filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b to cncf25-2-node-187aa4c0d96] 04/22/23 19:22:01.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817e46f05bf], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/22/23 19:22:01.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817e57964cb], Reason = [Created], Message = [Created container filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b] 04/22/23 19:22:01.934
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b.17585817ead14f8f], Reason = [Started], Message = [Started container filler-pod-5a649e9b-5f50-42cd-a8ad-491203c9618b] 04/22/23 19:22:01.935
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.175858183c9ef37b], Reason = [FailedScheduling], Message = [0/4 nodes are available: 2 Insufficient cpu, 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/4 nodes are available: 2 No preemption victims found for incoming pod, 2 Preemption is not helpful for scheduling.] 04/22/23 19:22:01.966
    STEP: removing the label node off the node cncf25-2-node-187aa4bdec5 04/22/23 19:22:02.965
    STEP: verifying the node doesn't have the label node 04/22/23 19:22:03
    STEP: removing the label node off the node cncf25-2-node-187aa4c0d96 04/22/23 19:22:03.018
    STEP: verifying the node doesn't have the label node 04/22/23 19:22:03.054
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:22:03.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-59" for this suite. 04/22/23 19:22:03.078
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:03.105
Apr 22 19:22:03.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:22:03.108
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:03.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:03.169
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-8ceea49d-f4b1-4792-9cd4-9c11b74eb92b 04/22/23 19:22:03.176
STEP: Creating a pod to test consume secrets 04/22/23 19:22:03.188
Apr 22 19:22:03.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7" in namespace "projected-9600" to be "Succeeded or Failed"
Apr 22 19:22:03.214: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.534207ms
Apr 22 19:22:05.226: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019812881s
Apr 22 19:22:07.223: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017051861s
STEP: Saw pod success 04/22/23 19:22:07.224
Apr 22 19:22:07.224: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7" satisfied condition "Succeeded or Failed"
Apr 22 19:22:07.235: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:22:07.262
Apr 22 19:22:07.297: INFO: Waiting for pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 to disappear
Apr 22 19:22:07.306: INFO: Pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:22:07.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9600" for this suite. 04/22/23 19:22:07.319
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":116,"skipped":2233,"failed":0}
------------------------------
â€¢ [4.232 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:03.105
    Apr 22 19:22:03.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:22:03.108
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:03.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:03.169
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-8ceea49d-f4b1-4792-9cd4-9c11b74eb92b 04/22/23 19:22:03.176
    STEP: Creating a pod to test consume secrets 04/22/23 19:22:03.188
    Apr 22 19:22:03.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7" in namespace "projected-9600" to be "Succeeded or Failed"
    Apr 22 19:22:03.214: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.534207ms
    Apr 22 19:22:05.226: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019812881s
    Apr 22 19:22:07.223: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017051861s
    STEP: Saw pod success 04/22/23 19:22:07.224
    Apr 22 19:22:07.224: INFO: Pod "pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7" satisfied condition "Succeeded or Failed"
    Apr 22 19:22:07.235: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:22:07.262
    Apr 22 19:22:07.297: INFO: Waiting for pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 to disappear
    Apr 22 19:22:07.306: INFO: Pod pod-projected-secrets-e3fd0223-118e-44a9-b021-5443a86ffff7 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:22:07.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9600" for this suite. 04/22/23 19:22:07.319
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:07.378
Apr 22 19:22:07.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:22:07.38
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:07.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:07.432
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 22 19:22:07.439: INFO: Creating simple deployment test-new-deployment
Apr 22 19:22:07.483: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 04/22/23 19:22:09.503
STEP: updating a scale subresource 04/22/23 19:22:09.508
STEP: verifying the deployment Spec.Replicas was modified 04/22/23 19:22:09.531
STEP: Patch a scale subresource 04/22/23 19:22:09.537
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:22:09.598: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-7052  7c6caecc-d2fd-42f2-bac2-3b7cebddbc50 15609 3 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-22 19:22:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fab38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-22 19:22:09 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:22:09 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 22 19:22:09.612: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7052  b1e7cd81-1568-49e4-83b9-a902ae1a00d3 15612 3 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 7c6caecc-d2fd-42f2-bac2-3b7cebddbc50 0xc003c1a037 0xc003c1a038}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6caecc-d2fd-42f2-bac2-3b7cebddbc50\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c1a138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:22:09.624: INFO: Pod "test-new-deployment-845c8977d9-hgmkp" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-hgmkp test-new-deployment-845c8977d9- deployment-7052  a2382615-280d-4a6c-ba78-cd51cd301e28 15614 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035faf97 0xc0035faf98}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jmlp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jmlp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:22:09.628: INFO: Pod "test-new-deployment-845c8977d9-pk8nq" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-pk8nq test-new-deployment-845c8977d9- deployment-7052  b1be5da2-1bf3-4402-8845-ec6a81bd5d97 15591 0 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb0d7 0xc0035fb0d8}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kmf6q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kmf6q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.2,StartTime:2023-04-22 19:22:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:22:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://167e7b570543c4e53404825d44e6bfedc3051378937c52531f27fde476418f7a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:22:09.628: INFO: Pod "test-new-deployment-845c8977d9-r6gnx" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-r6gnx test-new-deployment-845c8977d9- deployment-7052  8bcfb998-8aa9-4a79-8a6a-7c0c4f1a1741 15618 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb2b0 0xc0035fb2b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-phhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-phhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:22:09.629: INFO: Pod "test-new-deployment-845c8977d9-s6pb7" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-s6pb7 test-new-deployment-845c8977d9- deployment-7052  f463fae8-0ee3-4e40-93c2-1c31997b088b 15611 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb3e7 0xc0035fb3e8}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4lcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4lcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:22:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:22:09.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7052" for this suite. 04/22/23 19:22:09.645
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":117,"skipped":2276,"failed":0}
------------------------------
â€¢ [2.287 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:07.378
    Apr 22 19:22:07.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:22:07.38
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:07.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:07.432
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 22 19:22:07.439: INFO: Creating simple deployment test-new-deployment
    Apr 22 19:22:07.483: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 04/22/23 19:22:09.503
    STEP: updating a scale subresource 04/22/23 19:22:09.508
    STEP: verifying the deployment Spec.Replicas was modified 04/22/23 19:22:09.531
    STEP: Patch a scale subresource 04/22/23 19:22:09.537
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:22:09.598: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-7052  7c6caecc-d2fd-42f2-bac2-3b7cebddbc50 15609 3 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-22 19:22:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fab38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-22 19:22:09 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:22:09 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 22 19:22:09.612: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7052  b1e7cd81-1568-49e4-83b9-a902ae1a00d3 15612 3 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 7c6caecc-d2fd-42f2-bac2-3b7cebddbc50 0xc003c1a037 0xc003c1a038}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6caecc-d2fd-42f2-bac2-3b7cebddbc50\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c1a138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:22:09.624: INFO: Pod "test-new-deployment-845c8977d9-hgmkp" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-hgmkp test-new-deployment-845c8977d9- deployment-7052  a2382615-280d-4a6c-ba78-cd51cd301e28 15614 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035faf97 0xc0035faf98}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jmlp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jmlp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:22:09.628: INFO: Pod "test-new-deployment-845c8977d9-pk8nq" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-pk8nq test-new-deployment-845c8977d9- deployment-7052  b1be5da2-1bf3-4402-8845-ec6a81bd5d97 15591 0 2023-04-22 19:22:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb0d7 0xc0035fb0d8}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kmf6q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kmf6q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.2,StartTime:2023-04-22 19:22:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:22:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://167e7b570543c4e53404825d44e6bfedc3051378937c52531f27fde476418f7a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:22:09.628: INFO: Pod "test-new-deployment-845c8977d9-r6gnx" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-r6gnx test-new-deployment-845c8977d9- deployment-7052  8bcfb998-8aa9-4a79-8a6a-7c0c4f1a1741 15618 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb2b0 0xc0035fb2b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-phhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-phhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:22:09.629: INFO: Pod "test-new-deployment-845c8977d9-s6pb7" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-s6pb7 test-new-deployment-845c8977d9- deployment-7052  f463fae8-0ee3-4e40-93c2-1c31997b088b 15611 0 2023-04-22 19:22:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b1e7cd81-1568-49e4-83b9-a902ae1a00d3 0xc0035fb3e7 0xc0035fb3e8}] [] [{kube-controller-manager Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1e7cd81-1568-49e4-83b9-a902ae1a00d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:22:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4lcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4lcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:22:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:,StartTime:2023-04-22 19:22:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:22:09.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7052" for this suite. 04/22/23 19:22:09.645
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:09.679
Apr 22 19:22:09.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 19:22:09.682
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:09.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:09.713
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 04/22/23 19:22:09.723
STEP: Ensuring job reaches completions 04/22/23 19:22:09.738
STEP: Ensuring pods with index for job exist 04/22/23 19:22:19.748
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 19:22:19.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9608" for this suite. 04/22/23 19:22:19.772
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":118,"skipped":2277,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.110 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:09.679
    Apr 22 19:22:09.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 19:22:09.682
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:09.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:09.713
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 04/22/23 19:22:09.723
    STEP: Ensuring job reaches completions 04/22/23 19:22:09.738
    STEP: Ensuring pods with index for job exist 04/22/23 19:22:19.748
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 19:22:19.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9608" for this suite. 04/22/23 19:22:19.772
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:19.79
Apr 22 19:22:19.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:22:19.794
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:19.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:19.868
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:22:19.904
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:22:20.728
STEP: Deploying the webhook pod 04/22/23 19:22:20.746
STEP: Wait for the deployment to be ready 04/22/23 19:22:20.773
Apr 22 19:22:20.800: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:22:22.829
STEP: Verifying the service has paired with the endpoint 04/22/23 19:22:22.873
Apr 22 19:22:23.873: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Apr 22 19:22:23.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9781-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 19:22:24.415
STEP: Creating a custom resource that should be mutated by the webhook 04/22/23 19:22:24.467
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:22:27.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4199" for this suite. 04/22/23 19:22:27.159
STEP: Destroying namespace "webhook-4199-markers" for this suite. 04/22/23 19:22:27.177
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":119,"skipped":2279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.520 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:19.79
    Apr 22 19:22:19.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:22:19.794
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:19.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:19.868
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:22:19.904
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:22:20.728
    STEP: Deploying the webhook pod 04/22/23 19:22:20.746
    STEP: Wait for the deployment to be ready 04/22/23 19:22:20.773
    Apr 22 19:22:20.800: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:22:22.829
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:22:22.873
    Apr 22 19:22:23.873: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Apr 22 19:22:23.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9781-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 19:22:24.415
    STEP: Creating a custom resource that should be mutated by the webhook 04/22/23 19:22:24.467
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:22:27.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4199" for this suite. 04/22/23 19:22:27.159
    STEP: Destroying namespace "webhook-4199-markers" for this suite. 04/22/23 19:22:27.177
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:27.336
Apr 22 19:22:27.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:22:27.339
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:27.372
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:27.378
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/22/23 19:22:27.381
Apr 22 19:22:27.393: INFO: Waiting up to 5m0s for pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42" in namespace "emptydir-6541" to be "Succeeded or Failed"
Apr 22 19:22:27.398: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Pending", Reason="", readiness=false. Elapsed: 5.495522ms
Apr 22 19:22:29.410: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017011192s
Apr 22 19:22:31.412: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019307021s
STEP: Saw pod success 04/22/23 19:22:31.413
Apr 22 19:22:31.414: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42" satisfied condition "Succeeded or Failed"
Apr 22 19:22:31.421: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 container test-container: <nil>
STEP: delete the pod 04/22/23 19:22:31.44
Apr 22 19:22:31.461: INFO: Waiting for pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 to disappear
Apr 22 19:22:31.468: INFO: Pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:22:31.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6541" for this suite. 04/22/23 19:22:31.48
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":120,"skipped":2287,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:27.336
    Apr 22 19:22:27.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:22:27.339
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:27.372
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:27.378
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/22/23 19:22:27.381
    Apr 22 19:22:27.393: INFO: Waiting up to 5m0s for pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42" in namespace "emptydir-6541" to be "Succeeded or Failed"
    Apr 22 19:22:27.398: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Pending", Reason="", readiness=false. Elapsed: 5.495522ms
    Apr 22 19:22:29.410: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017011192s
    Apr 22 19:22:31.412: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019307021s
    STEP: Saw pod success 04/22/23 19:22:31.413
    Apr 22 19:22:31.414: INFO: Pod "pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42" satisfied condition "Succeeded or Failed"
    Apr 22 19:22:31.421: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:22:31.44
    Apr 22 19:22:31.461: INFO: Waiting for pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 to disappear
    Apr 22 19:22:31.468: INFO: Pod pod-214b56bf-b9d4-46e3-a9a2-7c7a7f273c42 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:22:31.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6541" for this suite. 04/22/23 19:22:31.48
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:31.518
Apr 22 19:22:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 19:22:31.523
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:31.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:31.574
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Apr 22 19:22:31.620: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/22/23 19:22:31.629
Apr 22 19:22:31.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:31.635: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/22/23 19:22:31.635
Apr 22 19:22:31.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:31.674: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:22:32.681: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:32.681: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:22:33.685: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:22:33.685: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/22/23 19:22:33.696
Apr 22 19:22:33.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:22:33.739: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 22 19:22:34.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:34.748: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/22/23 19:22:34.748
Apr 22 19:22:34.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:34.783: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:22:35.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:35.793: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:22:36.790: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:36.790: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:22:37.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:22:37.792: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:22:37.811
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8033, will wait for the garbage collector to delete the pods 04/22/23 19:22:37.811
Apr 22 19:22:37.886: INFO: Deleting DaemonSet.extensions daemon-set took: 14.988721ms
Apr 22 19:22:37.987: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.814714ms
Apr 22 19:22:40.498: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:22:40.498: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 19:22:40.513: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15981"},"items":null}

Apr 22 19:22:40.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15981"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:22:40.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8033" for this suite. 04/22/23 19:22:40.589
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":121,"skipped":2293,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.091 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:31.518
    Apr 22 19:22:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 19:22:31.523
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:31.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:31.574
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Apr 22 19:22:31.620: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/22/23 19:22:31.629
    Apr 22 19:22:31.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:31.635: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/22/23 19:22:31.635
    Apr 22 19:22:31.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:31.674: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:22:32.681: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:32.681: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:22:33.685: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:22:33.685: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/22/23 19:22:33.696
    Apr 22 19:22:33.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:22:33.739: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 22 19:22:34.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:34.748: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/22/23 19:22:34.748
    Apr 22 19:22:34.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:34.783: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:22:35.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:35.793: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:22:36.790: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:36.790: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:22:37.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:22:37.792: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:22:37.811
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8033, will wait for the garbage collector to delete the pods 04/22/23 19:22:37.811
    Apr 22 19:22:37.886: INFO: Deleting DaemonSet.extensions daemon-set took: 14.988721ms
    Apr 22 19:22:37.987: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.814714ms
    Apr 22 19:22:40.498: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:22:40.498: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 19:22:40.513: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15981"},"items":null}

    Apr 22 19:22:40.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15981"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:22:40.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8033" for this suite. 04/22/23 19:22:40.589
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:40.617
Apr 22 19:22:40.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename watch 04/22/23 19:22:40.621
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:40.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:40.686
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/22/23 19:22:40.695
STEP: starting a background goroutine to produce watch events 04/22/23 19:22:40.706
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/22/23 19:22:40.707
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 22 19:22:43.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-909" for this suite. 04/22/23 19:22:43.484
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":122,"skipped":2297,"failed":0}
------------------------------
â€¢ [2.924 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:40.617
    Apr 22 19:22:40.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename watch 04/22/23 19:22:40.621
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:40.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:40.686
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/22/23 19:22:40.695
    STEP: starting a background goroutine to produce watch events 04/22/23 19:22:40.706
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/22/23 19:22:40.707
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 22 19:22:43.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-909" for this suite. 04/22/23 19:22:43.484
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:43.545
Apr 22 19:22:43.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:22:43.55
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:43.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:43.617
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 04/22/23 19:22:43.639
STEP: watching for Pod to be ready 04/22/23 19:22:43.659
Apr 22 19:22:43.663: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 22 19:22:43.667: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
Apr 22 19:22:43.692: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
Apr 22 19:22:45.376: INFO: Found Pod pod-test in namespace pods-7894 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/22/23 19:22:45.391
STEP: getting the Pod and ensuring that it's patched 04/22/23 19:22:45.419
STEP: replacing the Pod's status Ready condition to False 04/22/23 19:22:45.429
STEP: check the Pod again to ensure its Ready conditions are False 04/22/23 19:22:45.459
STEP: deleting the Pod via a Collection with a LabelSelector 04/22/23 19:22:45.46
STEP: watching for the Pod to be deleted 04/22/23 19:22:45.483
Apr 22 19:22:45.487: INFO: observed event type MODIFIED
Apr 22 19:22:47.375: INFO: observed event type MODIFIED
Apr 22 19:22:48.383: INFO: observed event type MODIFIED
Apr 22 19:22:48.400: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:22:48.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7894" for this suite. 04/22/23 19:22:48.431
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":123,"skipped":2297,"failed":0}
------------------------------
â€¢ [4.900 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:43.545
    Apr 22 19:22:43.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:22:43.55
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:43.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:43.617
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 04/22/23 19:22:43.639
    STEP: watching for Pod to be ready 04/22/23 19:22:43.659
    Apr 22 19:22:43.663: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 22 19:22:43.667: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
    Apr 22 19:22:43.692: INFO: observed Pod pod-test in namespace pods-7894 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
    Apr 22 19:22:45.376: INFO: Found Pod pod-test in namespace pods-7894 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 19:22:43 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/22/23 19:22:45.391
    STEP: getting the Pod and ensuring that it's patched 04/22/23 19:22:45.419
    STEP: replacing the Pod's status Ready condition to False 04/22/23 19:22:45.429
    STEP: check the Pod again to ensure its Ready conditions are False 04/22/23 19:22:45.459
    STEP: deleting the Pod via a Collection with a LabelSelector 04/22/23 19:22:45.46
    STEP: watching for the Pod to be deleted 04/22/23 19:22:45.483
    Apr 22 19:22:45.487: INFO: observed event type MODIFIED
    Apr 22 19:22:47.375: INFO: observed event type MODIFIED
    Apr 22 19:22:48.383: INFO: observed event type MODIFIED
    Apr 22 19:22:48.400: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:22:48.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7894" for this suite. 04/22/23 19:22:48.431
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:48.45
Apr 22 19:22:48.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename csistoragecapacity 04/22/23 19:22:48.453
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.508
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/22/23 19:22:48.513
STEP: getting /apis/storage.k8s.io 04/22/23 19:22:48.519
STEP: getting /apis/storage.k8s.io/v1 04/22/23 19:22:48.521
STEP: creating 04/22/23 19:22:48.524
STEP: watching 04/22/23 19:22:48.568
Apr 22 19:22:48.568: INFO: starting watch
STEP: getting 04/22/23 19:22:48.58
STEP: listing in namespace 04/22/23 19:22:48.587
STEP: listing across namespaces 04/22/23 19:22:48.592
STEP: patching 04/22/23 19:22:48.598
STEP: updating 04/22/23 19:22:48.607
Apr 22 19:22:48.614: INFO: waiting for watch events with expected annotations in namespace
Apr 22 19:22:48.615: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/22/23 19:22:48.616
STEP: deleting a collection 04/22/23 19:22:48.641
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Apr 22 19:22:48.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-1543" for this suite. 04/22/23 19:22:48.669
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":124,"skipped":2306,"failed":0}
------------------------------
â€¢ [0.230 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:48.45
    Apr 22 19:22:48.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename csistoragecapacity 04/22/23 19:22:48.453
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.508
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/22/23 19:22:48.513
    STEP: getting /apis/storage.k8s.io 04/22/23 19:22:48.519
    STEP: getting /apis/storage.k8s.io/v1 04/22/23 19:22:48.521
    STEP: creating 04/22/23 19:22:48.524
    STEP: watching 04/22/23 19:22:48.568
    Apr 22 19:22:48.568: INFO: starting watch
    STEP: getting 04/22/23 19:22:48.58
    STEP: listing in namespace 04/22/23 19:22:48.587
    STEP: listing across namespaces 04/22/23 19:22:48.592
    STEP: patching 04/22/23 19:22:48.598
    STEP: updating 04/22/23 19:22:48.607
    Apr 22 19:22:48.614: INFO: waiting for watch events with expected annotations in namespace
    Apr 22 19:22:48.615: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/22/23 19:22:48.616
    STEP: deleting a collection 04/22/23 19:22:48.641
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Apr 22 19:22:48.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-1543" for this suite. 04/22/23 19:22:48.669
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:48.706
Apr 22 19:22:48.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sysctl 04/22/23 19:22:48.709
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.736
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/22/23 19:22:48.742
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 19:22:48.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5330" for this suite. 04/22/23 19:22:48.757
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":125,"skipped":2324,"failed":0}
------------------------------
â€¢ [0.061 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:48.706
    Apr 22 19:22:48.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sysctl 04/22/23 19:22:48.709
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.736
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/22/23 19:22:48.742
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 19:22:48.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5330" for this suite. 04/22/23 19:22:48.757
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:48.77
Apr 22 19:22:48.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:22:48.774
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.803
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.813
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:22:48.822
Apr 22 19:22:48.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d" in namespace "downward-api-7238" to be "Succeeded or Failed"
Apr 22 19:22:48.837: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.906595ms
Apr 22 19:22:50.846: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013407845s
Apr 22 19:22:52.851: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018091857s
STEP: Saw pod success 04/22/23 19:22:52.851
Apr 22 19:22:52.852: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d" satisfied condition "Succeeded or Failed"
Apr 22 19:22:52.868: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d container client-container: <nil>
STEP: delete the pod 04/22/23 19:22:52.891
Apr 22 19:22:52.930: INFO: Waiting for pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d to disappear
Apr 22 19:22:52.941: INFO: Pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:22:52.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7238" for this suite. 04/22/23 19:22:52.954
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":126,"skipped":2328,"failed":0}
------------------------------
â€¢ [4.197 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:48.77
    Apr 22 19:22:48.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:22:48.774
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:48.803
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:48.813
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:22:48.822
    Apr 22 19:22:48.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d" in namespace "downward-api-7238" to be "Succeeded or Failed"
    Apr 22 19:22:48.837: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.906595ms
    Apr 22 19:22:50.846: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013407845s
    Apr 22 19:22:52.851: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018091857s
    STEP: Saw pod success 04/22/23 19:22:52.851
    Apr 22 19:22:52.852: INFO: Pod "downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d" satisfied condition "Succeeded or Failed"
    Apr 22 19:22:52.868: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d container client-container: <nil>
    STEP: delete the pod 04/22/23 19:22:52.891
    Apr 22 19:22:52.930: INFO: Waiting for pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d to disappear
    Apr 22 19:22:52.941: INFO: Pod downwardapi-volume-eb741a53-a491-4675-a879-9dc6f0abe85d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:22:52.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7238" for this suite. 04/22/23 19:22:52.954
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:52.968
Apr 22 19:22:52.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:22:52.972
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:53.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:53.017
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7090 04/22/23 19:22:53.026
STEP: changing the ExternalName service to type=ClusterIP 04/22/23 19:22:53.035
STEP: creating replication controller externalname-service in namespace services-7090 04/22/23 19:22:53.066
I0422 19:22:53.076980      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7090, replica count: 2
I0422 19:22:56.128923      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:22:56.129: INFO: Creating new exec pod
Apr 22 19:22:56.155: INFO: Waiting up to 5m0s for pod "execpodwm6xv" in namespace "services-7090" to be "running"
Apr 22 19:22:56.162: INFO: Pod "execpodwm6xv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896436ms
Apr 22 19:22:58.169: INFO: Pod "execpodwm6xv": Phase="Running", Reason="", readiness=true. Elapsed: 2.013704004s
Apr 22 19:22:58.169: INFO: Pod "execpodwm6xv" satisfied condition "running"
Apr 22 19:22:59.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7090 exec execpodwm6xv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:22:59.534: INFO: stderr: "+ echo+  hostName\nnc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:22:59.534: INFO: stdout: "externalname-service-2zswg"
Apr 22 19:22:59.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7090 exec execpodwm6xv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.96.242 80'
Apr 22 19:22:59.855: INFO: stderr: "+ nc -v -t+ echo hostName\n -w 2 10.96.96.242 80\nConnection to 10.96.96.242 80 port [tcp/http] succeeded!\n"
Apr 22 19:22:59.855: INFO: stdout: "externalname-service-sbf9b"
Apr 22 19:22:59.855: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 19:22:59.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7090" for this suite. 04/22/23 19:22:59.932
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":127,"skipped":2331,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.978 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:52.968
    Apr 22 19:22:52.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:22:52.972
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:22:53.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:22:53.017
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-7090 04/22/23 19:22:53.026
    STEP: changing the ExternalName service to type=ClusterIP 04/22/23 19:22:53.035
    STEP: creating replication controller externalname-service in namespace services-7090 04/22/23 19:22:53.066
    I0422 19:22:53.076980      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7090, replica count: 2
    I0422 19:22:56.128923      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:22:56.129: INFO: Creating new exec pod
    Apr 22 19:22:56.155: INFO: Waiting up to 5m0s for pod "execpodwm6xv" in namespace "services-7090" to be "running"
    Apr 22 19:22:56.162: INFO: Pod "execpodwm6xv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896436ms
    Apr 22 19:22:58.169: INFO: Pod "execpodwm6xv": Phase="Running", Reason="", readiness=true. Elapsed: 2.013704004s
    Apr 22 19:22:58.169: INFO: Pod "execpodwm6xv" satisfied condition "running"
    Apr 22 19:22:59.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7090 exec execpodwm6xv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:22:59.534: INFO: stderr: "+ echo+  hostName\nnc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:22:59.534: INFO: stdout: "externalname-service-2zswg"
    Apr 22 19:22:59.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7090 exec execpodwm6xv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.96.242 80'
    Apr 22 19:22:59.855: INFO: stderr: "+ nc -v -t+ echo hostName\n -w 2 10.96.96.242 80\nConnection to 10.96.96.242 80 port [tcp/http] succeeded!\n"
    Apr 22 19:22:59.855: INFO: stdout: "externalname-service-sbf9b"
    Apr 22 19:22:59.855: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 19:22:59.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7090" for this suite. 04/22/23 19:22:59.932
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:22:59.974
Apr 22 19:22:59.975: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename taint-single-pod 04/22/23 19:22:59.977
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:23:00.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:23:00.019
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Apr 22 19:23:00.027: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 19:24:00.093: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Apr 22 19:24:00.106: INFO: Starting informer...
STEP: Starting pod... 04/22/23 19:24:00.107
Apr 22 19:24:00.348: INFO: Pod is running on cncf25-2-node-187aa4c0d96. Tainting Node
STEP: Trying to apply a taint on the Node 04/22/23 19:24:00.349
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:24:00.386
STEP: Waiting short time to make sure Pod is queued for deletion 04/22/23 19:24:00.399
Apr 22 19:24:00.400: INFO: Pod wasn't evicted. Proceeding
Apr 22 19:24:00.401: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:24:00.434
STEP: Waiting some time to make sure that toleration time passed. 04/22/23 19:24:00.442
Apr 22 19:25:15.443: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:25:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7741" for this suite. 04/22/23 19:25:15.462
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":128,"skipped":2365,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.506 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:22:59.974
    Apr 22 19:22:59.975: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename taint-single-pod 04/22/23 19:22:59.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:23:00.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:23:00.019
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Apr 22 19:23:00.027: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 19:24:00.093: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Apr 22 19:24:00.106: INFO: Starting informer...
    STEP: Starting pod... 04/22/23 19:24:00.107
    Apr 22 19:24:00.348: INFO: Pod is running on cncf25-2-node-187aa4c0d96. Tainting Node
    STEP: Trying to apply a taint on the Node 04/22/23 19:24:00.349
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:24:00.386
    STEP: Waiting short time to make sure Pod is queued for deletion 04/22/23 19:24:00.399
    Apr 22 19:24:00.400: INFO: Pod wasn't evicted. Proceeding
    Apr 22 19:24:00.401: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/22/23 19:24:00.434
    STEP: Waiting some time to make sure that toleration time passed. 04/22/23 19:24:00.442
    Apr 22 19:25:15.443: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:25:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-7741" for this suite. 04/22/23 19:25:15.462
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:15.487
Apr 22 19:25:15.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-runtime 04/22/23 19:25:15.489
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:15.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:15.558
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 04/22/23 19:25:15.567
STEP: wait for the container to reach Succeeded 04/22/23 19:25:15.585
STEP: get the container status 04/22/23 19:25:19.632
STEP: the container should be terminated 04/22/23 19:25:19.641
STEP: the termination message should be set 04/22/23 19:25:19.642
Apr 22 19:25:19.642: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/22/23 19:25:19.642
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 22 19:25:19.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4513" for this suite. 04/22/23 19:25:19.702
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":129,"skipped":2369,"failed":0}
------------------------------
â€¢ [4.233 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:15.487
    Apr 22 19:25:15.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-runtime 04/22/23 19:25:15.489
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:15.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:15.558
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 04/22/23 19:25:15.567
    STEP: wait for the container to reach Succeeded 04/22/23 19:25:15.585
    STEP: get the container status 04/22/23 19:25:19.632
    STEP: the container should be terminated 04/22/23 19:25:19.641
    STEP: the termination message should be set 04/22/23 19:25:19.642
    Apr 22 19:25:19.642: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/22/23 19:25:19.642
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 22 19:25:19.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4513" for this suite. 04/22/23 19:25:19.702
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:19.739
Apr 22 19:25:19.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:25:19.742
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:19.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:19.802
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 04/22/23 19:25:19.812
STEP: setting up watch 04/22/23 19:25:19.813
STEP: submitting the pod to kubernetes 04/22/23 19:25:19.922
STEP: verifying the pod is in kubernetes 04/22/23 19:25:19.945
STEP: verifying pod creation was observed 04/22/23 19:25:19.954
Apr 22 19:25:19.954: INFO: Waiting up to 5m0s for pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331" in namespace "pods-9606" to be "running"
Apr 22 19:25:19.974: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331": Phase="Pending", Reason="", readiness=false. Elapsed: 19.610755ms
Apr 22 19:25:21.984: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331": Phase="Running", Reason="", readiness=true. Elapsed: 2.029254588s
Apr 22 19:25:21.984: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331" satisfied condition "running"
STEP: deleting the pod gracefully 04/22/23 19:25:21.993
STEP: verifying pod deletion was observed 04/22/23 19:25:22.011
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:25:23.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9606" for this suite. 04/22/23 19:25:23.906
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":130,"skipped":2409,"failed":0}
------------------------------
â€¢ [4.191 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:19.739
    Apr 22 19:25:19.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:25:19.742
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:19.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:19.802
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 04/22/23 19:25:19.812
    STEP: setting up watch 04/22/23 19:25:19.813
    STEP: submitting the pod to kubernetes 04/22/23 19:25:19.922
    STEP: verifying the pod is in kubernetes 04/22/23 19:25:19.945
    STEP: verifying pod creation was observed 04/22/23 19:25:19.954
    Apr 22 19:25:19.954: INFO: Waiting up to 5m0s for pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331" in namespace "pods-9606" to be "running"
    Apr 22 19:25:19.974: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331": Phase="Pending", Reason="", readiness=false. Elapsed: 19.610755ms
    Apr 22 19:25:21.984: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331": Phase="Running", Reason="", readiness=true. Elapsed: 2.029254588s
    Apr 22 19:25:21.984: INFO: Pod "pod-submit-remove-055a4e93-8c37-4024-b044-add15de6e331" satisfied condition "running"
    STEP: deleting the pod gracefully 04/22/23 19:25:21.993
    STEP: verifying pod deletion was observed 04/22/23 19:25:22.011
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:25:23.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9606" for this suite. 04/22/23 19:25:23.906
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:23.952
Apr 22 19:25:23.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:25:23.954
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:23.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:23.995
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 19:25:24.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4726" for this suite. 04/22/23 19:25:24.025
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":131,"skipped":2431,"failed":0}
------------------------------
â€¢ [0.088 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:23.952
    Apr 22 19:25:23.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:25:23.954
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:23.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:23.995
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 19:25:24.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4726" for this suite. 04/22/23 19:25:24.025
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:24.053
Apr 22 19:25:24.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:25:24.057
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:24.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:24.106
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 04/22/23 19:25:24.113
STEP: Counting existing ResourceQuota 04/22/23 19:25:29.12
STEP: Creating a ResourceQuota 04/22/23 19:25:34.129
STEP: Ensuring resource quota status is calculated 04/22/23 19:25:34.141
STEP: Creating a Secret 04/22/23 19:25:36.151
STEP: Ensuring resource quota status captures secret creation 04/22/23 19:25:36.18
STEP: Deleting a secret 04/22/23 19:25:38.191
STEP: Ensuring resource quota status released usage 04/22/23 19:25:38.205
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:25:40.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5651" for this suite. 04/22/23 19:25:40.227
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":132,"skipped":2432,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.190 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:24.053
    Apr 22 19:25:24.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:25:24.057
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:24.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:24.106
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 04/22/23 19:25:24.113
    STEP: Counting existing ResourceQuota 04/22/23 19:25:29.12
    STEP: Creating a ResourceQuota 04/22/23 19:25:34.129
    STEP: Ensuring resource quota status is calculated 04/22/23 19:25:34.141
    STEP: Creating a Secret 04/22/23 19:25:36.151
    STEP: Ensuring resource quota status captures secret creation 04/22/23 19:25:36.18
    STEP: Deleting a secret 04/22/23 19:25:38.191
    STEP: Ensuring resource quota status released usage 04/22/23 19:25:38.205
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:25:40.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5651" for this suite. 04/22/23 19:25:40.227
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:40.259
Apr 22 19:25:40.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replication-controller 04/22/23 19:25:40.262
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:40.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:40.324
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 04/22/23 19:25:40.333
STEP: When the matched label of one of its pods change 04/22/23 19:25:40.346
Apr 22 19:25:40.355: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 22 19:25:45.373: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/22/23 19:25:45.404
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 22 19:25:46.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7679" for this suite. 04/22/23 19:25:46.437
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":133,"skipped":2455,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.197 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:40.259
    Apr 22 19:25:40.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replication-controller 04/22/23 19:25:40.262
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:40.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:40.324
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 04/22/23 19:25:40.333
    STEP: When the matched label of one of its pods change 04/22/23 19:25:40.346
    Apr 22 19:25:40.355: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 22 19:25:45.373: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/22/23 19:25:45.404
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 22 19:25:46.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7679" for this suite. 04/22/23 19:25:46.437
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:46.458
Apr 22 19:25:46.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:25:46.461
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:46.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:46.529
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-3542/secret-test-5613ff94-7e37-4572-a09a-779261f03242 04/22/23 19:25:46.536
STEP: Creating a pod to test consume secrets 04/22/23 19:25:46.545
Apr 22 19:25:46.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49" in namespace "secrets-3542" to be "Succeeded or Failed"
Apr 22 19:25:46.575: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Pending", Reason="", readiness=false. Elapsed: 13.218251ms
Apr 22 19:25:48.581: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019502814s
Apr 22 19:25:50.586: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023621529s
STEP: Saw pod success 04/22/23 19:25:50.586
Apr 22 19:25:50.587: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49" satisfied condition "Succeeded or Failed"
Apr 22 19:25:50.595: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 container env-test: <nil>
STEP: delete the pod 04/22/23 19:25:50.635
Apr 22 19:25:50.669: INFO: Waiting for pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 to disappear
Apr 22 19:25:50.677: INFO: Pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:25:50.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3542" for this suite. 04/22/23 19:25:50.692
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":134,"skipped":2455,"failed":0}
------------------------------
â€¢ [4.250 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:46.458
    Apr 22 19:25:46.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:25:46.461
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:46.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:46.529
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-3542/secret-test-5613ff94-7e37-4572-a09a-779261f03242 04/22/23 19:25:46.536
    STEP: Creating a pod to test consume secrets 04/22/23 19:25:46.545
    Apr 22 19:25:46.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49" in namespace "secrets-3542" to be "Succeeded or Failed"
    Apr 22 19:25:46.575: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Pending", Reason="", readiness=false. Elapsed: 13.218251ms
    Apr 22 19:25:48.581: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019502814s
    Apr 22 19:25:50.586: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023621529s
    STEP: Saw pod success 04/22/23 19:25:50.586
    Apr 22 19:25:50.587: INFO: Pod "pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49" satisfied condition "Succeeded or Failed"
    Apr 22 19:25:50.595: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 container env-test: <nil>
    STEP: delete the pod 04/22/23 19:25:50.635
    Apr 22 19:25:50.669: INFO: Waiting for pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 to disappear
    Apr 22 19:25:50.677: INFO: Pod pod-configmaps-7118061d-5757-4445-bb36-a6e42ea60e49 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:25:50.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3542" for this suite. 04/22/23 19:25:50.692
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:25:50.753
Apr 22 19:25:50.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-pred 04/22/23 19:25:50.755
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:50.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:50.816
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 22 19:25:50.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 22 19:25:50.843: INFO: Waiting for terminating namespaces to be deleted...
Apr 22 19:25:50.852: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
Apr 22 19:25:50.872: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.872: INFO: 	Container cloud-controller-manager ready: true, restart count 0
Apr 22 19:25:50.872: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.872: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:25:50.872: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:25:50.873: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:25:50.873: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 22 19:25:50.873: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 22 19:25:50.873: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 22 19:25:50.873: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container e2e ready: true, restart count 0
Apr 22 19:25:50.873: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:25:50.873: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:25:50.873: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:25:50.873: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 22 19:25:50.873: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
Apr 22 19:25:50.887: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.888: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 19:25:50.888: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
Apr 22 19:25:50.888: INFO: 	Container weave ready: true, restart count 0
Apr 22 19:25:50.888: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 19:25:50.888: INFO: pod-release-868nt from replication-controller-7679 started at 2023-04-22 19:25:45 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.888: INFO: 	Container pod-release ready: true, restart count 0
Apr 22 19:25:50.888: INFO: pod-release-kw99w from replication-controller-7679 started at 2023-04-22 19:25:40 +0000 UTC (1 container statuses recorded)
Apr 22 19:25:50.888: INFO: 	Container pod-release ready: true, restart count 0
Apr 22 19:25:50.888: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 19:25:50.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 19:25:50.888: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 19:25:50.888
Apr 22 19:25:50.904: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9760" to be "running"
Apr 22 19:25:50.914: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.382078ms
Apr 22 19:25:52.923: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.019063766s
Apr 22 19:25:52.923: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 19:25:52.931
STEP: Trying to apply a random label on the found node. 04/22/23 19:25:52.975
STEP: verifying the node has the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b 95 04/22/23 19:25:52.998
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/22/23 19:25:53.007
Apr 22 19:25:53.019: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9760" to be "not pending"
Apr 22 19:25:53.029: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.816057ms
Apr 22 19:25:55.040: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.021800518s
Apr 22 19:25:55.041: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.1.1.128 on the node which pod4 resides and expect not scheduled 04/22/23 19:25:55.041
Apr 22 19:25:55.056: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9760" to be "not pending"
Apr 22 19:25:55.068: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.356439ms
Apr 22 19:25:57.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025760861s
Apr 22 19:25:59.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023350525s
Apr 22 19:26:01.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021982676s
Apr 22 19:26:03.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022100463s
Apr 22 19:26:05.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023124544s
Apr 22 19:26:07.087: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031197447s
Apr 22 19:26:09.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023039082s
Apr 22 19:26:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.022097284s
Apr 22 19:26:13.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.022106535s
Apr 22 19:26:15.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022983139s
Apr 22 19:26:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022904052s
Apr 22 19:26:19.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.02423876s
Apr 22 19:26:21.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023926098s
Apr 22 19:26:23.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.022252749s
Apr 22 19:26:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.022147537s
Apr 22 19:26:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.021866725s
Apr 22 19:26:29.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.022208192s
Apr 22 19:26:31.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.022769575s
Apr 22 19:26:33.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.021515701s
Apr 22 19:26:35.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021916037s
Apr 22 19:26:37.087: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.031261494s
Apr 22 19:26:39.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.022309731s
Apr 22 19:26:41.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021910283s
Apr 22 19:26:43.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.022412789s
Apr 22 19:26:45.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.023237206s
Apr 22 19:26:47.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024060024s
Apr 22 19:26:49.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02074791s
Apr 22 19:26:51.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.025085812s
Apr 22 19:26:53.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.023076934s
Apr 22 19:26:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.022065347s
Apr 22 19:26:57.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.022907307s
Apr 22 19:26:59.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.024474086s
Apr 22 19:27:01.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.022491958s
Apr 22 19:27:03.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023221445s
Apr 22 19:27:05.089: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.032577092s
Apr 22 19:27:07.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023181015s
Apr 22 19:27:09.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.025204323s
Apr 22 19:27:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02188281s
Apr 22 19:27:13.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.024646175s
Apr 22 19:27:15.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.022084974s
Apr 22 19:27:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.022860558s
Apr 22 19:27:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02267398s
Apr 22 19:27:21.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023288339s
Apr 22 19:27:23.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024022736s
Apr 22 19:27:25.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021446448s
Apr 22 19:27:27.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.027370504s
Apr 22 19:27:29.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.024465133s
Apr 22 19:27:31.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023018109s
Apr 22 19:27:33.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.023234067s
Apr 22 19:27:35.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.023795597s
Apr 22 19:27:37.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022884589s
Apr 22 19:27:39.085: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.028852581s
Apr 22 19:27:41.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.024599872s
Apr 22 19:27:43.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.023292199s
Apr 22 19:27:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.024386693s
Apr 22 19:27:47.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.027151425s
Apr 22 19:27:49.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.022400225s
Apr 22 19:27:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023374647s
Apr 22 19:27:53.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.02595091s
Apr 22 19:27:55.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.022864165s
Apr 22 19:27:57.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.024234605s
Apr 22 19:27:59.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.024289068s
Apr 22 19:28:01.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.026666643s
Apr 22 19:28:03.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.024758685s
Apr 22 19:28:05.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.02301869s
Apr 22 19:28:07.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.021428932s
Apr 22 19:28:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.022208167s
Apr 22 19:28:11.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.021007751s
Apr 22 19:28:13.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.024939097s
Apr 22 19:28:15.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.02196179s
Apr 22 19:28:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.023026026s
Apr 22 19:28:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.023159055s
Apr 22 19:28:21.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.022752423s
Apr 22 19:28:23.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.023193921s
Apr 22 19:28:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.022277193s
Apr 22 19:28:27.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.025624056s
Apr 22 19:28:29.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.024523323s
Apr 22 19:28:31.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.020820092s
Apr 22 19:28:33.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.020483553s
Apr 22 19:28:35.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.023596546s
Apr 22 19:28:37.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.030094673s
Apr 22 19:28:39.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024173296s
Apr 22 19:28:41.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.022960065s
Apr 22 19:28:43.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023888981s
Apr 22 19:28:45.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.022549614s
Apr 22 19:28:47.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.023106525s
Apr 22 19:28:49.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.022129302s
Apr 22 19:28:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.023162511s
Apr 22 19:28:53.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.022547558s
Apr 22 19:28:55.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.023558535s
Apr 22 19:28:57.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.022129551s
Apr 22 19:28:59.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.022657177s
Apr 22 19:29:01.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.023467568s
Apr 22 19:29:03.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.022570411s
Apr 22 19:29:05.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.022533236s
Apr 22 19:29:07.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.025339863s
Apr 22 19:29:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.021988828s
Apr 22 19:29:11.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.021343113s
Apr 22 19:29:13.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.022465656s
Apr 22 19:29:15.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02566903s
Apr 22 19:29:17.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.020397432s
Apr 22 19:29:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.022986612s
Apr 22 19:29:21.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.021776201s
Apr 22 19:29:23.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.020887326s
Apr 22 19:29:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.022222186s
Apr 22 19:29:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.022434457s
Apr 22 19:29:29.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.022698065s
Apr 22 19:29:31.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.024125615s
Apr 22 19:29:33.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.022025198s
Apr 22 19:29:35.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.021722521s
Apr 22 19:29:37.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.021241963s
Apr 22 19:29:39.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.023413176s
Apr 22 19:29:41.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.024096567s
Apr 22 19:29:43.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.023674265s
Apr 22 19:29:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.02431207s
Apr 22 19:29:47.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.026662559s
Apr 22 19:29:49.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.025586505s
Apr 22 19:29:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.023215681s
Apr 22 19:29:53.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.030244006s
Apr 22 19:29:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.022127632s
Apr 22 19:29:57.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.022480036s
Apr 22 19:29:59.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.021875898s
Apr 22 19:30:01.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.022831188s
Apr 22 19:30:03.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.022431912s
Apr 22 19:30:05.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.022271956s
Apr 22 19:30:07.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023836376s
Apr 22 19:30:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.0221714s
Apr 22 19:30:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.021749185s
Apr 22 19:30:13.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.023437255s
Apr 22 19:30:15.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.02327567s
Apr 22 19:30:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.02277681s
Apr 22 19:30:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023105685s
Apr 22 19:30:21.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.022505324s
Apr 22 19:30:23.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.02442266s
Apr 22 19:30:25.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.02080831s
Apr 22 19:30:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.022328447s
Apr 22 19:30:29.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.021833994s
Apr 22 19:30:31.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020037711s
Apr 22 19:30:33.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.022635962s
Apr 22 19:30:35.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.030532592s
Apr 22 19:30:37.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.022526919s
Apr 22 19:30:39.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.021743287s
Apr 22 19:30:41.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.022145183s
Apr 22 19:30:43.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.02301437s
Apr 22 19:30:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.023909468s
Apr 22 19:30:47.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.022993016s
Apr 22 19:30:49.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.021143417s
Apr 22 19:30:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.022594879s
Apr 22 19:30:53.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.022294566s
Apr 22 19:30:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021566671s
Apr 22 19:30:55.085: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.028971591s
STEP: removing the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b off the node cncf25-2-node-187aa4c0d96 04/22/23 19:30:55.086
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b 04/22/23 19:30:55.125
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:30:55.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9760" for this suite. 04/22/23 19:30:55.157
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":135,"skipped":2511,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.420 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:25:50.753
    Apr 22 19:25:50.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-pred 04/22/23 19:25:50.755
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:25:50.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:25:50.816
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 22 19:25:50.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 22 19:25:50.843: INFO: Waiting for terminating namespaces to be deleted...
    Apr 22 19:25:50.852: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
    Apr 22 19:25:50.872: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.872: INFO: 	Container cloud-controller-manager ready: true, restart count 0
    Apr 22 19:25:50.872: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.872: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:25:50.872: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container e2e ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:25:50.873: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 22 19:25:50.873: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
    Apr 22 19:25:50.887: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.888: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
    Apr 22 19:25:50.888: INFO: 	Container weave ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: pod-release-868nt from replication-controller-7679 started at 2023-04-22 19:25:45 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.888: INFO: 	Container pod-release ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: pod-release-kw99w from replication-controller-7679 started at 2023-04-22 19:25:40 +0000 UTC (1 container statuses recorded)
    Apr 22 19:25:50.888: INFO: 	Container pod-release ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 19:25:50.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 19:25:50.888: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 19:25:50.888
    Apr 22 19:25:50.904: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9760" to be "running"
    Apr 22 19:25:50.914: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.382078ms
    Apr 22 19:25:52.923: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.019063766s
    Apr 22 19:25:52.923: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 19:25:52.931
    STEP: Trying to apply a random label on the found node. 04/22/23 19:25:52.975
    STEP: verifying the node has the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b 95 04/22/23 19:25:52.998
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/22/23 19:25:53.007
    Apr 22 19:25:53.019: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9760" to be "not pending"
    Apr 22 19:25:53.029: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.816057ms
    Apr 22 19:25:55.040: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.021800518s
    Apr 22 19:25:55.041: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.1.1.128 on the node which pod4 resides and expect not scheduled 04/22/23 19:25:55.041
    Apr 22 19:25:55.056: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9760" to be "not pending"
    Apr 22 19:25:55.068: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.356439ms
    Apr 22 19:25:57.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025760861s
    Apr 22 19:25:59.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023350525s
    Apr 22 19:26:01.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021982676s
    Apr 22 19:26:03.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022100463s
    Apr 22 19:26:05.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023124544s
    Apr 22 19:26:07.087: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031197447s
    Apr 22 19:26:09.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023039082s
    Apr 22 19:26:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.022097284s
    Apr 22 19:26:13.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.022106535s
    Apr 22 19:26:15.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022983139s
    Apr 22 19:26:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022904052s
    Apr 22 19:26:19.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.02423876s
    Apr 22 19:26:21.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023926098s
    Apr 22 19:26:23.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.022252749s
    Apr 22 19:26:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.022147537s
    Apr 22 19:26:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.021866725s
    Apr 22 19:26:29.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.022208192s
    Apr 22 19:26:31.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.022769575s
    Apr 22 19:26:33.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.021515701s
    Apr 22 19:26:35.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021916037s
    Apr 22 19:26:37.087: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.031261494s
    Apr 22 19:26:39.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.022309731s
    Apr 22 19:26:41.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021910283s
    Apr 22 19:26:43.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.022412789s
    Apr 22 19:26:45.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.023237206s
    Apr 22 19:26:47.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024060024s
    Apr 22 19:26:49.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02074791s
    Apr 22 19:26:51.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.025085812s
    Apr 22 19:26:53.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.023076934s
    Apr 22 19:26:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.022065347s
    Apr 22 19:26:57.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.022907307s
    Apr 22 19:26:59.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.024474086s
    Apr 22 19:27:01.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.022491958s
    Apr 22 19:27:03.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023221445s
    Apr 22 19:27:05.089: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.032577092s
    Apr 22 19:27:07.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023181015s
    Apr 22 19:27:09.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.025204323s
    Apr 22 19:27:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02188281s
    Apr 22 19:27:13.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.024646175s
    Apr 22 19:27:15.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.022084974s
    Apr 22 19:27:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.022860558s
    Apr 22 19:27:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02267398s
    Apr 22 19:27:21.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023288339s
    Apr 22 19:27:23.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024022736s
    Apr 22 19:27:25.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021446448s
    Apr 22 19:27:27.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.027370504s
    Apr 22 19:27:29.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.024465133s
    Apr 22 19:27:31.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023018109s
    Apr 22 19:27:33.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.023234067s
    Apr 22 19:27:35.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.023795597s
    Apr 22 19:27:37.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022884589s
    Apr 22 19:27:39.085: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.028852581s
    Apr 22 19:27:41.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.024599872s
    Apr 22 19:27:43.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.023292199s
    Apr 22 19:27:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.024386693s
    Apr 22 19:27:47.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.027151425s
    Apr 22 19:27:49.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.022400225s
    Apr 22 19:27:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023374647s
    Apr 22 19:27:53.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.02595091s
    Apr 22 19:27:55.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.022864165s
    Apr 22 19:27:57.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.024234605s
    Apr 22 19:27:59.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.024289068s
    Apr 22 19:28:01.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.026666643s
    Apr 22 19:28:03.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.024758685s
    Apr 22 19:28:05.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.02301869s
    Apr 22 19:28:07.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.021428932s
    Apr 22 19:28:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.022208167s
    Apr 22 19:28:11.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.021007751s
    Apr 22 19:28:13.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.024939097s
    Apr 22 19:28:15.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.02196179s
    Apr 22 19:28:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.023026026s
    Apr 22 19:28:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.023159055s
    Apr 22 19:28:21.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.022752423s
    Apr 22 19:28:23.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.023193921s
    Apr 22 19:28:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.022277193s
    Apr 22 19:28:27.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.025624056s
    Apr 22 19:28:29.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.024523323s
    Apr 22 19:28:31.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.020820092s
    Apr 22 19:28:33.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.020483553s
    Apr 22 19:28:35.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.023596546s
    Apr 22 19:28:37.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.030094673s
    Apr 22 19:28:39.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024173296s
    Apr 22 19:28:41.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.022960065s
    Apr 22 19:28:43.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023888981s
    Apr 22 19:28:45.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.022549614s
    Apr 22 19:28:47.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.023106525s
    Apr 22 19:28:49.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.022129302s
    Apr 22 19:28:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.023162511s
    Apr 22 19:28:53.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.022547558s
    Apr 22 19:28:55.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.023558535s
    Apr 22 19:28:57.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.022129551s
    Apr 22 19:28:59.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.022657177s
    Apr 22 19:29:01.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.023467568s
    Apr 22 19:29:03.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.022570411s
    Apr 22 19:29:05.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.022533236s
    Apr 22 19:29:07.081: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.025339863s
    Apr 22 19:29:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.021988828s
    Apr 22 19:29:11.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.021343113s
    Apr 22 19:29:13.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.022465656s
    Apr 22 19:29:15.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02566903s
    Apr 22 19:29:17.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.020397432s
    Apr 22 19:29:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.022986612s
    Apr 22 19:29:21.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.021776201s
    Apr 22 19:29:23.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.020887326s
    Apr 22 19:29:25.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.022222186s
    Apr 22 19:29:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.022434457s
    Apr 22 19:29:29.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.022698065s
    Apr 22 19:29:31.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.024125615s
    Apr 22 19:29:33.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.022025198s
    Apr 22 19:29:35.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.021722521s
    Apr 22 19:29:37.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.021241963s
    Apr 22 19:29:39.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.023413176s
    Apr 22 19:29:41.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.024096567s
    Apr 22 19:29:43.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.023674265s
    Apr 22 19:29:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.02431207s
    Apr 22 19:29:47.083: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.026662559s
    Apr 22 19:29:49.082: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.025586505s
    Apr 22 19:29:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.023215681s
    Apr 22 19:29:53.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.030244006s
    Apr 22 19:29:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.022127632s
    Apr 22 19:29:57.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.022480036s
    Apr 22 19:29:59.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.021875898s
    Apr 22 19:30:01.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.022831188s
    Apr 22 19:30:03.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.022431912s
    Apr 22 19:30:05.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.022271956s
    Apr 22 19:30:07.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023836376s
    Apr 22 19:30:09.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.0221714s
    Apr 22 19:30:11.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.021749185s
    Apr 22 19:30:13.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.023437255s
    Apr 22 19:30:15.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.02327567s
    Apr 22 19:30:17.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.02277681s
    Apr 22 19:30:19.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023105685s
    Apr 22 19:30:21.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.022505324s
    Apr 22 19:30:23.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.02442266s
    Apr 22 19:30:25.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.02080831s
    Apr 22 19:30:27.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.022328447s
    Apr 22 19:30:29.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.021833994s
    Apr 22 19:30:31.076: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020037711s
    Apr 22 19:30:33.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.022635962s
    Apr 22 19:30:35.086: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.030532592s
    Apr 22 19:30:37.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.022526919s
    Apr 22 19:30:39.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.021743287s
    Apr 22 19:30:41.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.022145183s
    Apr 22 19:30:43.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.02301437s
    Apr 22 19:30:45.080: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.023909468s
    Apr 22 19:30:47.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.022993016s
    Apr 22 19:30:49.077: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.021143417s
    Apr 22 19:30:51.079: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.022594879s
    Apr 22 19:30:53.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.022294566s
    Apr 22 19:30:55.078: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021566671s
    Apr 22 19:30:55.085: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.028971591s
    STEP: removing the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b off the node cncf25-2-node-187aa4c0d96 04/22/23 19:30:55.086
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-d050ce18-c82b-4306-9c88-16318b590c7b 04/22/23 19:30:55.125
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:30:55.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9760" for this suite. 04/22/23 19:30:55.157
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:30:55.19
Apr 22 19:30:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context-test 04/22/23 19:30:55.193
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:30:55.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:30:55.254
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Apr 22 19:30:55.288: INFO: Waiting up to 5m0s for pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e" in namespace "security-context-test-1496" to be "Succeeded or Failed"
Apr 22 19:30:55.302: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.000261ms
Apr 22 19:30:57.315: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027124745s
Apr 22 19:30:59.313: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025156498s
Apr 22 19:30:59.314: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 19:30:59.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1496" for this suite. 04/22/23 19:30:59.328
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":136,"skipped":2515,"failed":0}
------------------------------
â€¢ [4.155 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:30:55.19
    Apr 22 19:30:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context-test 04/22/23 19:30:55.193
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:30:55.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:30:55.254
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Apr 22 19:30:55.288: INFO: Waiting up to 5m0s for pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e" in namespace "security-context-test-1496" to be "Succeeded or Failed"
    Apr 22 19:30:55.302: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.000261ms
    Apr 22 19:30:57.315: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027124745s
    Apr 22 19:30:59.313: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025156498s
    Apr 22 19:30:59.314: INFO: Pod "busybox-user-65534-938fb6c8-160f-41c9-b16c-07e03712121e" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 19:30:59.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1496" for this suite. 04/22/23 19:30:59.328
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:30:59.36
Apr 22 19:30:59.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 19:30:59.363
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:30:59.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:30:59.426
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 04/22/23 19:30:59.435
STEP: Ensuring active pods == parallelism 04/22/23 19:30:59.449
STEP: Orphaning one of the Job's Pods 04/22/23 19:31:01.462
Apr 22 19:31:02.004: INFO: Successfully updated pod "adopt-release-fgc5h"
STEP: Checking that the Job readopts the Pod 04/22/23 19:31:02.004
Apr 22 19:31:02.004: INFO: Waiting up to 15m0s for pod "adopt-release-fgc5h" in namespace "job-626" to be "adopted"
Apr 22 19:31:02.015: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 10.614327ms
Apr 22 19:31:04.024: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.0194817s
Apr 22 19:31:04.024: INFO: Pod "adopt-release-fgc5h" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/22/23 19:31:04.024
Apr 22 19:31:04.541: INFO: Successfully updated pod "adopt-release-fgc5h"
STEP: Checking that the Job releases the Pod 04/22/23 19:31:04.541
Apr 22 19:31:04.541: INFO: Waiting up to 15m0s for pod "adopt-release-fgc5h" in namespace "job-626" to be "released"
Apr 22 19:31:04.546: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 5.002159ms
Apr 22 19:31:06.555: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.014390971s
Apr 22 19:31:06.556: INFO: Pod "adopt-release-fgc5h" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 19:31:06.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-626" for this suite. 04/22/23 19:31:06.568
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":137,"skipped":2523,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.235 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:30:59.36
    Apr 22 19:30:59.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 19:30:59.363
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:30:59.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:30:59.426
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 04/22/23 19:30:59.435
    STEP: Ensuring active pods == parallelism 04/22/23 19:30:59.449
    STEP: Orphaning one of the Job's Pods 04/22/23 19:31:01.462
    Apr 22 19:31:02.004: INFO: Successfully updated pod "adopt-release-fgc5h"
    STEP: Checking that the Job readopts the Pod 04/22/23 19:31:02.004
    Apr 22 19:31:02.004: INFO: Waiting up to 15m0s for pod "adopt-release-fgc5h" in namespace "job-626" to be "adopted"
    Apr 22 19:31:02.015: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 10.614327ms
    Apr 22 19:31:04.024: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.0194817s
    Apr 22 19:31:04.024: INFO: Pod "adopt-release-fgc5h" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/22/23 19:31:04.024
    Apr 22 19:31:04.541: INFO: Successfully updated pod "adopt-release-fgc5h"
    STEP: Checking that the Job releases the Pod 04/22/23 19:31:04.541
    Apr 22 19:31:04.541: INFO: Waiting up to 15m0s for pod "adopt-release-fgc5h" in namespace "job-626" to be "released"
    Apr 22 19:31:04.546: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 5.002159ms
    Apr 22 19:31:06.555: INFO: Pod "adopt-release-fgc5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.014390971s
    Apr 22 19:31:06.556: INFO: Pod "adopt-release-fgc5h" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 19:31:06.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-626" for this suite. 04/22/23 19:31:06.568
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:31:06.618
Apr 22 19:31:06.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 19:31:06.621
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:31:06.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:31:06.674
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 in namespace container-probe-6602 04/22/23 19:31:06.681
Apr 22 19:31:06.696: INFO: Waiting up to 5m0s for pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2" in namespace "container-probe-6602" to be "not pending"
Apr 22 19:31:06.702: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983028ms
Apr 22 19:31:08.713: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2": Phase="Running", Reason="", readiness=true. Elapsed: 2.016963718s
Apr 22 19:31:08.713: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2" satisfied condition "not pending"
Apr 22 19:31:08.713: INFO: Started pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 in namespace container-probe-6602
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:31:08.713
Apr 22 19:31:08.722: INFO: Initial restart count of pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 is 0
STEP: deleting the pod 04/22/23 19:35:09.952
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 19:35:09.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6602" for this suite. 04/22/23 19:35:10.017
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":138,"skipped":2550,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.421 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:31:06.618
    Apr 22 19:31:06.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 19:31:06.621
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:31:06.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:31:06.674
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 in namespace container-probe-6602 04/22/23 19:31:06.681
    Apr 22 19:31:06.696: INFO: Waiting up to 5m0s for pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2" in namespace "container-probe-6602" to be "not pending"
    Apr 22 19:31:06.702: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983028ms
    Apr 22 19:31:08.713: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2": Phase="Running", Reason="", readiness=true. Elapsed: 2.016963718s
    Apr 22 19:31:08.713: INFO: Pod "liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2" satisfied condition "not pending"
    Apr 22 19:31:08.713: INFO: Started pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 in namespace container-probe-6602
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:31:08.713
    Apr 22 19:31:08.722: INFO: Initial restart count of pod liveness-dd9c32c5-9497-493b-a4d6-48fad3573ce2 is 0
    STEP: deleting the pod 04/22/23 19:35:09.952
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 19:35:09.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6602" for this suite. 04/22/23 19:35:10.017
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:35:10.042
Apr 22 19:35:10.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:35:10.046
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:10.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:10.098
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:35:10.112
Apr 22 19:35:10.128: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1779" to be "running and ready"
Apr 22 19:35:10.139: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.849849ms
Apr 22 19:35:10.140: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:35:12.149: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020746069s
Apr 22 19:35:12.150: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 22 19:35:12.151: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 04/22/23 19:35:12.162
Apr 22 19:35:12.180: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1779" to be "running and ready"
Apr 22 19:35:12.190: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 10.093019ms
Apr 22 19:35:12.191: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:35:14.201: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020839249s
Apr 22 19:35:14.201: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 22 19:35:14.201: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/22/23 19:35:14.21
STEP: delete the pod with lifecycle hook 04/22/23 19:35:14.259
Apr 22 19:35:14.280: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 22 19:35:14.292: INFO: Pod pod-with-poststart-http-hook still exists
Apr 22 19:35:16.294: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 22 19:35:16.301: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 22 19:35:16.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1779" for this suite. 04/22/23 19:35:16.311
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":139,"skipped":2566,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.288 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:35:10.042
    Apr 22 19:35:10.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:35:10.046
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:10.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:10.098
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:35:10.112
    Apr 22 19:35:10.128: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1779" to be "running and ready"
    Apr 22 19:35:10.139: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.849849ms
    Apr 22 19:35:10.140: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:35:12.149: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020746069s
    Apr 22 19:35:12.150: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 22 19:35:12.151: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 04/22/23 19:35:12.162
    Apr 22 19:35:12.180: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1779" to be "running and ready"
    Apr 22 19:35:12.190: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 10.093019ms
    Apr 22 19:35:12.191: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:35:14.201: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020839249s
    Apr 22 19:35:14.201: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 22 19:35:14.201: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/22/23 19:35:14.21
    STEP: delete the pod with lifecycle hook 04/22/23 19:35:14.259
    Apr 22 19:35:14.280: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 22 19:35:14.292: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 22 19:35:16.294: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 22 19:35:16.301: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 22 19:35:16.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1779" for this suite. 04/22/23 19:35:16.311
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:35:16.37
Apr 22 19:35:16.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename endpointslice 04/22/23 19:35:16.373
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:16.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:16.433
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 04/22/23 19:35:16.441
STEP: getting /apis/discovery.k8s.io 04/22/23 19:35:16.448
STEP: getting /apis/discovery.k8s.iov1 04/22/23 19:35:16.451
STEP: creating 04/22/23 19:35:16.455
STEP: getting 04/22/23 19:35:16.499
STEP: listing 04/22/23 19:35:16.508
STEP: watching 04/22/23 19:35:16.518
Apr 22 19:35:16.518: INFO: starting watch
STEP: cluster-wide listing 04/22/23 19:35:16.522
STEP: cluster-wide watching 04/22/23 19:35:16.533
Apr 22 19:35:16.533: INFO: starting watch
STEP: patching 04/22/23 19:35:16.537
STEP: updating 04/22/23 19:35:16.551
Apr 22 19:35:16.572: INFO: waiting for watch events with expected annotations
Apr 22 19:35:16.572: INFO: saw patched and updated annotations
STEP: deleting 04/22/23 19:35:16.573
STEP: deleting a collection 04/22/23 19:35:16.604
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 22 19:35:16.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7497" for this suite. 04/22/23 19:35:16.653
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":140,"skipped":2593,"failed":0}
------------------------------
â€¢ [0.299 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:35:16.37
    Apr 22 19:35:16.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename endpointslice 04/22/23 19:35:16.373
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:16.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:16.433
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 04/22/23 19:35:16.441
    STEP: getting /apis/discovery.k8s.io 04/22/23 19:35:16.448
    STEP: getting /apis/discovery.k8s.iov1 04/22/23 19:35:16.451
    STEP: creating 04/22/23 19:35:16.455
    STEP: getting 04/22/23 19:35:16.499
    STEP: listing 04/22/23 19:35:16.508
    STEP: watching 04/22/23 19:35:16.518
    Apr 22 19:35:16.518: INFO: starting watch
    STEP: cluster-wide listing 04/22/23 19:35:16.522
    STEP: cluster-wide watching 04/22/23 19:35:16.533
    Apr 22 19:35:16.533: INFO: starting watch
    STEP: patching 04/22/23 19:35:16.537
    STEP: updating 04/22/23 19:35:16.551
    Apr 22 19:35:16.572: INFO: waiting for watch events with expected annotations
    Apr 22 19:35:16.572: INFO: saw patched and updated annotations
    STEP: deleting 04/22/23 19:35:16.573
    STEP: deleting a collection 04/22/23 19:35:16.604
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 22 19:35:16.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7497" for this suite. 04/22/23 19:35:16.653
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:35:16.698
Apr 22 19:35:16.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 19:35:16.701
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:16.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:16.756
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6677 04/22/23 19:35:16.767
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 04/22/23 19:35:16.781
Apr 22 19:35:16.810: INFO: Found 0 stateful pods, waiting for 3
Apr 22 19:35:26.822: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:35:26.823: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:35:26.823: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:35:26.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:35:27.275: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:35:27.275: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:35:27.275: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/22/23 19:35:37.326
Apr 22 19:35:37.376: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/22/23 19:35:37.376
STEP: Updating Pods in reverse ordinal order 04/22/23 19:35:47.422
Apr 22 19:35:47.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:35:47.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:35:47.794: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:35:47.794: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 04/22/23 19:36:07.849
Apr 22 19:36:07.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:36:08.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:36:08.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:36:08.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 19:36:18.274: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/22/23 19:36:28.316
Apr 22 19:36:28.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:36:28.730: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:36:28.730: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:36:28.730: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 19:36:38.784: INFO: Deleting all statefulset in ns statefulset-6677
Apr 22 19:36:38.794: INFO: Scaling statefulset ss2 to 0
Apr 22 19:36:48.842: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 19:36:48.850: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 19:36:48.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6677" for this suite. 04/22/23 19:36:48.916
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":141,"skipped":2626,"failed":0}
------------------------------
â€¢ [SLOW TEST] [92.231 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:35:16.698
    Apr 22 19:35:16.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 19:35:16.701
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:35:16.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:35:16.756
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6677 04/22/23 19:35:16.767
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 04/22/23 19:35:16.781
    Apr 22 19:35:16.810: INFO: Found 0 stateful pods, waiting for 3
    Apr 22 19:35:26.822: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:35:26.823: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:35:26.823: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:35:26.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:35:27.275: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:35:27.275: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:35:27.275: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/22/23 19:35:37.326
    Apr 22 19:35:37.376: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/22/23 19:35:37.376
    STEP: Updating Pods in reverse ordinal order 04/22/23 19:35:47.422
    Apr 22 19:35:47.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:35:47.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:35:47.794: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:35:47.794: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 04/22/23 19:36:07.849
    Apr 22 19:36:07.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:36:08.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:36:08.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:36:08.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 19:36:18.274: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/22/23 19:36:28.316
    Apr 22 19:36:28.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-6677 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:36:28.730: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:36:28.730: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:36:28.730: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 19:36:38.784: INFO: Deleting all statefulset in ns statefulset-6677
    Apr 22 19:36:38.794: INFO: Scaling statefulset ss2 to 0
    Apr 22 19:36:48.842: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 19:36:48.850: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 19:36:48.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6677" for this suite. 04/22/23 19:36:48.916
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:36:48.945
Apr 22 19:36:48.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename events 04/22/23 19:36:48.949
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:48.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:49
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/22/23 19:36:49.008
Apr 22 19:36:49.025: INFO: created test-event-1
Apr 22 19:36:49.034: INFO: created test-event-2
Apr 22 19:36:49.043: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/22/23 19:36:49.044
STEP: delete collection of events 04/22/23 19:36:49.051
Apr 22 19:36:49.051: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/22/23 19:36:49.088
Apr 22 19:36:49.089: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 22 19:36:49.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4350" for this suite. 04/22/23 19:36:49.101
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":142,"skipped":2638,"failed":0}
------------------------------
â€¢ [0.167 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:36:48.945
    Apr 22 19:36:48.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename events 04/22/23 19:36:48.949
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:48.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:49
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/22/23 19:36:49.008
    Apr 22 19:36:49.025: INFO: created test-event-1
    Apr 22 19:36:49.034: INFO: created test-event-2
    Apr 22 19:36:49.043: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/22/23 19:36:49.044
    STEP: delete collection of events 04/22/23 19:36:49.051
    Apr 22 19:36:49.051: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/22/23 19:36:49.088
    Apr 22 19:36:49.089: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 22 19:36:49.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4350" for this suite. 04/22/23 19:36:49.101
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:36:49.145
Apr 22 19:36:49.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:36:49.148
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:49.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:49.18
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-e49a5efe-d511-4010-9b90-9ac8abcfd64b 04/22/23 19:36:49.187
STEP: Creating a pod to test consume configMaps 04/22/23 19:36:49.195
Apr 22 19:36:49.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624" in namespace "projected-1213" to be "Succeeded or Failed"
Apr 22 19:36:49.214: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Pending", Reason="", readiness=false. Elapsed: 6.794777ms
Apr 22 19:36:51.226: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018526294s
Apr 22 19:36:53.224: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017078783s
STEP: Saw pod success 04/22/23 19:36:53.224
Apr 22 19:36:53.225: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624" satisfied condition "Succeeded or Failed"
Apr 22 19:36:53.235: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:36:53.282
Apr 22 19:36:53.318: INFO: Waiting for pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 to disappear
Apr 22 19:36:53.353: INFO: Pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:36:53.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1213" for this suite. 04/22/23 19:36:53.38
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":143,"skipped":2674,"failed":0}
------------------------------
â€¢ [4.249 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:36:49.145
    Apr 22 19:36:49.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:36:49.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:49.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:49.18
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-e49a5efe-d511-4010-9b90-9ac8abcfd64b 04/22/23 19:36:49.187
    STEP: Creating a pod to test consume configMaps 04/22/23 19:36:49.195
    Apr 22 19:36:49.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624" in namespace "projected-1213" to be "Succeeded or Failed"
    Apr 22 19:36:49.214: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Pending", Reason="", readiness=false. Elapsed: 6.794777ms
    Apr 22 19:36:51.226: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018526294s
    Apr 22 19:36:53.224: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017078783s
    STEP: Saw pod success 04/22/23 19:36:53.224
    Apr 22 19:36:53.225: INFO: Pod "pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624" satisfied condition "Succeeded or Failed"
    Apr 22 19:36:53.235: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:36:53.282
    Apr 22 19:36:53.318: INFO: Waiting for pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 to disappear
    Apr 22 19:36:53.353: INFO: Pod pod-projected-configmaps-038af02e-fbd2-4dfe-8110-8123955be624 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:36:53.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1213" for this suite. 04/22/23 19:36:53.38
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:36:53.413
Apr 22 19:36:53.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename subpath 04/22/23 19:36:53.419
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:53.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:53.479
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/22/23 19:36:53.486
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-pwms 04/22/23 19:36:53.514
STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:36:53.514
Apr 22 19:36:53.532: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pwms" in namespace "subpath-4834" to be "Succeeded or Failed"
Apr 22 19:36:53.543: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Pending", Reason="", readiness=false. Elapsed: 9.947368ms
Apr 22 19:36:55.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 2.01890913s
Apr 22 19:36:57.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 4.019169889s
Apr 22 19:36:59.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 6.019781218s
Apr 22 19:37:01.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 8.019389727s
Apr 22 19:37:03.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 10.0196069s
Apr 22 19:37:05.551: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 12.018429985s
Apr 22 19:37:07.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 14.01957567s
Apr 22 19:37:09.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 16.019954986s
Apr 22 19:37:11.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 18.020117669s
Apr 22 19:37:13.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 20.020058108s
Apr 22 19:37:15.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=false. Elapsed: 22.019923647s
Apr 22 19:37:17.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01927715s
STEP: Saw pod success 04/22/23 19:37:17.552
Apr 22 19:37:17.553: INFO: Pod "pod-subpath-test-downwardapi-pwms" satisfied condition "Succeeded or Failed"
Apr 22 19:37:17.561: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-downwardapi-pwms container test-container-subpath-downwardapi-pwms: <nil>
STEP: delete the pod 04/22/23 19:37:17.579
Apr 22 19:37:17.610: INFO: Waiting for pod pod-subpath-test-downwardapi-pwms to disappear
Apr 22 19:37:17.618: INFO: Pod pod-subpath-test-downwardapi-pwms no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-pwms 04/22/23 19:37:17.618
Apr 22 19:37:17.618: INFO: Deleting pod "pod-subpath-test-downwardapi-pwms" in namespace "subpath-4834"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 22 19:37:17.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4834" for this suite. 04/22/23 19:37:17.64
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":144,"skipped":2698,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.256 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:36:53.413
    Apr 22 19:36:53.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename subpath 04/22/23 19:36:53.419
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:36:53.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:36:53.479
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/22/23 19:36:53.486
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-pwms 04/22/23 19:36:53.514
    STEP: Creating a pod to test atomic-volume-subpath 04/22/23 19:36:53.514
    Apr 22 19:36:53.532: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pwms" in namespace "subpath-4834" to be "Succeeded or Failed"
    Apr 22 19:36:53.543: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Pending", Reason="", readiness=false. Elapsed: 9.947368ms
    Apr 22 19:36:55.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 2.01890913s
    Apr 22 19:36:57.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 4.019169889s
    Apr 22 19:36:59.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 6.019781218s
    Apr 22 19:37:01.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 8.019389727s
    Apr 22 19:37:03.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 10.0196069s
    Apr 22 19:37:05.551: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 12.018429985s
    Apr 22 19:37:07.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 14.01957567s
    Apr 22 19:37:09.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 16.019954986s
    Apr 22 19:37:11.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 18.020117669s
    Apr 22 19:37:13.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 20.020058108s
    Apr 22 19:37:15.553: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Running", Reason="", readiness=false. Elapsed: 22.019923647s
    Apr 22 19:37:17.552: INFO: Pod "pod-subpath-test-downwardapi-pwms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01927715s
    STEP: Saw pod success 04/22/23 19:37:17.552
    Apr 22 19:37:17.553: INFO: Pod "pod-subpath-test-downwardapi-pwms" satisfied condition "Succeeded or Failed"
    Apr 22 19:37:17.561: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-subpath-test-downwardapi-pwms container test-container-subpath-downwardapi-pwms: <nil>
    STEP: delete the pod 04/22/23 19:37:17.579
    Apr 22 19:37:17.610: INFO: Waiting for pod pod-subpath-test-downwardapi-pwms to disappear
    Apr 22 19:37:17.618: INFO: Pod pod-subpath-test-downwardapi-pwms no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-pwms 04/22/23 19:37:17.618
    Apr 22 19:37:17.618: INFO: Deleting pod "pod-subpath-test-downwardapi-pwms" in namespace "subpath-4834"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 22 19:37:17.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4834" for this suite. 04/22/23 19:37:17.64
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:37:17.691
Apr 22 19:37:17.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:37:17.694
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:17.742
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:17.751
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 04/22/23 19:37:17.772
Apr 22 19:37:17.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 create -f -'
Apr 22 19:37:19.336: INFO: stderr: ""
Apr 22 19:37:19.336: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 19:37:19.336
Apr 22 19:37:19.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 19:37:19.478: INFO: stderr: ""
Apr 22 19:37:19.478: INFO: stdout: "update-demo-nautilus-8l9h2 update-demo-nautilus-m8svv "
Apr 22 19:37:19.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 19:37:19.572: INFO: stderr: ""
Apr 22 19:37:19.572: INFO: stdout: ""
Apr 22 19:37:19.572: INFO: update-demo-nautilus-8l9h2 is created but not running
Apr 22 19:37:24.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 19:37:24.767: INFO: stderr: ""
Apr 22 19:37:24.767: INFO: stdout: "update-demo-nautilus-8l9h2 update-demo-nautilus-m8svv "
Apr 22 19:37:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 19:37:24.911: INFO: stderr: ""
Apr 22 19:37:24.911: INFO: stdout: "true"
Apr 22 19:37:24.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 19:37:25.008: INFO: stderr: ""
Apr 22 19:37:25.008: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 19:37:25.008: INFO: validating pod update-demo-nautilus-8l9h2
Apr 22 19:37:25.026: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 19:37:25.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 19:37:25.027: INFO: update-demo-nautilus-8l9h2 is verified up and running
Apr 22 19:37:25.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-m8svv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 19:37:25.119: INFO: stderr: ""
Apr 22 19:37:25.119: INFO: stdout: "true"
Apr 22 19:37:25.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-m8svv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 19:37:25.222: INFO: stderr: ""
Apr 22 19:37:25.222: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 19:37:25.222: INFO: validating pod update-demo-nautilus-m8svv
Apr 22 19:37:25.239: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 19:37:25.239: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 19:37:25.239: INFO: update-demo-nautilus-m8svv is verified up and running
STEP: using delete to clean up resources 04/22/23 19:37:25.239
Apr 22 19:37:25.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 delete --grace-period=0 --force -f -'
Apr 22 19:37:25.380: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 19:37:25.380: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 22 19:37:25.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get rc,svc -l name=update-demo --no-headers'
Apr 22 19:37:25.539: INFO: stderr: "No resources found in kubectl-8565 namespace.\n"
Apr 22 19:37:25.539: INFO: stdout: ""
Apr 22 19:37:25.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 22 19:37:25.693: INFO: stderr: ""
Apr 22 19:37:25.693: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:37:25.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8565" for this suite. 04/22/23 19:37:25.703
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":145,"skipped":2702,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.032 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:37:17.691
    Apr 22 19:37:17.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:37:17.694
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:17.742
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:17.751
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 04/22/23 19:37:17.772
    Apr 22 19:37:17.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 create -f -'
    Apr 22 19:37:19.336: INFO: stderr: ""
    Apr 22 19:37:19.336: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 19:37:19.336
    Apr 22 19:37:19.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 19:37:19.478: INFO: stderr: ""
    Apr 22 19:37:19.478: INFO: stdout: "update-demo-nautilus-8l9h2 update-demo-nautilus-m8svv "
    Apr 22 19:37:19.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 19:37:19.572: INFO: stderr: ""
    Apr 22 19:37:19.572: INFO: stdout: ""
    Apr 22 19:37:19.572: INFO: update-demo-nautilus-8l9h2 is created but not running
    Apr 22 19:37:24.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 19:37:24.767: INFO: stderr: ""
    Apr 22 19:37:24.767: INFO: stdout: "update-demo-nautilus-8l9h2 update-demo-nautilus-m8svv "
    Apr 22 19:37:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 19:37:24.911: INFO: stderr: ""
    Apr 22 19:37:24.911: INFO: stdout: "true"
    Apr 22 19:37:24.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-8l9h2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 19:37:25.008: INFO: stderr: ""
    Apr 22 19:37:25.008: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 19:37:25.008: INFO: validating pod update-demo-nautilus-8l9h2
    Apr 22 19:37:25.026: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 19:37:25.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 19:37:25.027: INFO: update-demo-nautilus-8l9h2 is verified up and running
    Apr 22 19:37:25.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-m8svv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 19:37:25.119: INFO: stderr: ""
    Apr 22 19:37:25.119: INFO: stdout: "true"
    Apr 22 19:37:25.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods update-demo-nautilus-m8svv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 19:37:25.222: INFO: stderr: ""
    Apr 22 19:37:25.222: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 19:37:25.222: INFO: validating pod update-demo-nautilus-m8svv
    Apr 22 19:37:25.239: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 19:37:25.239: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 19:37:25.239: INFO: update-demo-nautilus-m8svv is verified up and running
    STEP: using delete to clean up resources 04/22/23 19:37:25.239
    Apr 22 19:37:25.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 delete --grace-period=0 --force -f -'
    Apr 22 19:37:25.380: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 19:37:25.380: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 22 19:37:25.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get rc,svc -l name=update-demo --no-headers'
    Apr 22 19:37:25.539: INFO: stderr: "No resources found in kubectl-8565 namespace.\n"
    Apr 22 19:37:25.539: INFO: stdout: ""
    Apr 22 19:37:25.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8565 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 22 19:37:25.693: INFO: stderr: ""
    Apr 22 19:37:25.693: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:37:25.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8565" for this suite. 04/22/23 19:37:25.703
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:37:25.725
Apr 22 19:37:25.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename proxy 04/22/23 19:37:25.727
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:25.779
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:25.789
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 22 19:37:25.795: INFO: Creating pod...
Apr 22 19:37:25.814: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2905" to be "running"
Apr 22 19:37:25.820: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 5.973882ms
Apr 22 19:37:27.832: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017805704s
Apr 22 19:37:27.832: INFO: Pod "agnhost" satisfied condition "running"
Apr 22 19:37:27.832: INFO: Creating service...
Apr 22 19:37:27.876: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/DELETE
Apr 22 19:37:27.907: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 22 19:37:27.908: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/GET
Apr 22 19:37:27.918: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 22 19:37:27.918: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/HEAD
Apr 22 19:37:27.925: INFO: http.Client request:HEAD | StatusCode:200
Apr 22 19:37:27.925: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 22 19:37:27.935: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 22 19:37:27.935: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/PATCH
Apr 22 19:37:27.943: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 22 19:37:27.943: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/POST
Apr 22 19:37:27.952: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 22 19:37:27.952: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/PUT
Apr 22 19:37:27.961: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 22 19:37:27.961: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/DELETE
Apr 22 19:37:27.972: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 22 19:37:27.972: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/GET
Apr 22 19:37:27.980: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 22 19:37:27.980: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/HEAD
Apr 22 19:37:27.988: INFO: http.Client request:HEAD | StatusCode:200
Apr 22 19:37:27.988: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/OPTIONS
Apr 22 19:37:27.998: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 22 19:37:27.998: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/PATCH
Apr 22 19:37:28.011: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 22 19:37:28.011: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/POST
Apr 22 19:37:28.022: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 22 19:37:28.022: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/PUT
Apr 22 19:37:28.031: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 22 19:37:28.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2905" for this suite. 04/22/23 19:37:28.037
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":146,"skipped":2735,"failed":0}
------------------------------
â€¢ [2.322 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:37:25.725
    Apr 22 19:37:25.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename proxy 04/22/23 19:37:25.727
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:25.779
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:25.789
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 22 19:37:25.795: INFO: Creating pod...
    Apr 22 19:37:25.814: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2905" to be "running"
    Apr 22 19:37:25.820: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 5.973882ms
    Apr 22 19:37:27.832: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017805704s
    Apr 22 19:37:27.832: INFO: Pod "agnhost" satisfied condition "running"
    Apr 22 19:37:27.832: INFO: Creating service...
    Apr 22 19:37:27.876: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/DELETE
    Apr 22 19:37:27.907: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 22 19:37:27.908: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/GET
    Apr 22 19:37:27.918: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 22 19:37:27.918: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/HEAD
    Apr 22 19:37:27.925: INFO: http.Client request:HEAD | StatusCode:200
    Apr 22 19:37:27.925: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 22 19:37:27.935: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 22 19:37:27.935: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/PATCH
    Apr 22 19:37:27.943: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 22 19:37:27.943: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/POST
    Apr 22 19:37:27.952: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 22 19:37:27.952: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/pods/agnhost/proxy/some/path/with/PUT
    Apr 22 19:37:27.961: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 22 19:37:27.961: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/DELETE
    Apr 22 19:37:27.972: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 22 19:37:27.972: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/GET
    Apr 22 19:37:27.980: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 22 19:37:27.980: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/HEAD
    Apr 22 19:37:27.988: INFO: http.Client request:HEAD | StatusCode:200
    Apr 22 19:37:27.988: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/OPTIONS
    Apr 22 19:37:27.998: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 22 19:37:27.998: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/PATCH
    Apr 22 19:37:28.011: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 22 19:37:28.011: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/POST
    Apr 22 19:37:28.022: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 22 19:37:28.022: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2905/services/test-service/proxy/some/path/with/PUT
    Apr 22 19:37:28.031: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 22 19:37:28.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2905" for this suite. 04/22/23 19:37:28.037
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:37:28.049
Apr 22 19:37:28.050: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:37:28.051
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:28.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:28.08
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/22/23 19:37:28.091
Apr 22 19:37:28.102: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1167  0f73a5ac-aebf-479b-8273-96323d719a00 19480 0 2023-04-22 19:37:28 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-22 19:37:28 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-826bb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-826bb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 22 19:37:28.104: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1167" to be "running and ready"
Apr 22 19:37:28.110: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.157595ms
Apr 22 19:37:28.111: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:37:30.122: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.017711851s
Apr 22 19:37:30.122: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 22 19:37:30.122: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/22/23 19:37:30.122
Apr 22 19:37:30.123: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1167 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:37:30.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:37:30.124: INFO: ExecWithOptions: Clientset creation
Apr 22 19:37:30.124: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1167/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/22/23 19:37:30.348
Apr 22 19:37:30.348: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1167 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:37:30.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:37:30.350: INFO: ExecWithOptions: Clientset creation
Apr 22 19:37:30.350: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1167/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 22 19:37:30.542: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:37:30.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1167" for this suite. 04/22/23 19:37:30.595
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":147,"skipped":2735,"failed":0}
------------------------------
â€¢ [2.563 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:37:28.049
    Apr 22 19:37:28.050: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:37:28.051
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:28.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:28.08
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/22/23 19:37:28.091
    Apr 22 19:37:28.102: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1167  0f73a5ac-aebf-479b-8273-96323d719a00 19480 0 2023-04-22 19:37:28 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-22 19:37:28 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-826bb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-826bb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 22 19:37:28.104: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1167" to be "running and ready"
    Apr 22 19:37:28.110: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.157595ms
    Apr 22 19:37:28.111: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:37:30.122: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.017711851s
    Apr 22 19:37:30.122: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 22 19:37:30.122: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/22/23 19:37:30.122
    Apr 22 19:37:30.123: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1167 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:37:30.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:37:30.124: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:37:30.124: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1167/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/22/23 19:37:30.348
    Apr 22 19:37:30.348: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1167 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:37:30.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:37:30.350: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:37:30.350: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1167/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 22 19:37:30.542: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:37:30.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1167" for this suite. 04/22/23 19:37:30.595
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:37:30.627
Apr 22 19:37:30.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 19:37:30.631
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:30.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:30.691
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Apr 22 19:37:30.715: INFO: Waiting up to 2m0s for pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" in namespace "var-expansion-353" to be "container 0 failed with reason CreateContainerConfigError"
Apr 22 19:37:30.725: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299283ms
Apr 22 19:37:32.734: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01720145s
Apr 22 19:37:32.734: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 22 19:37:32.734: INFO: Deleting pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" in namespace "var-expansion-353"
Apr 22 19:37:32.751: INFO: Wait up to 5m0s for pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 19:37:34.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-353" for this suite. 04/22/23 19:37:34.784
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":148,"skipped":2750,"failed":0}
------------------------------
â€¢ [4.175 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:37:30.627
    Apr 22 19:37:30.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 19:37:30.631
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:30.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:30.691
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Apr 22 19:37:30.715: INFO: Waiting up to 2m0s for pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" in namespace "var-expansion-353" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 22 19:37:30.725: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299283ms
    Apr 22 19:37:32.734: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01720145s
    Apr 22 19:37:32.734: INFO: Pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 22 19:37:32.734: INFO: Deleting pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" in namespace "var-expansion-353"
    Apr 22 19:37:32.751: INFO: Wait up to 5m0s for pod "var-expansion-358789bd-f208-49df-99f4-13de584813ed" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 19:37:34.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-353" for this suite. 04/22/23 19:37:34.784
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:37:34.833
Apr 22 19:37:34.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename cronjob 04/22/23 19:37:34.837
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:34.894
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:34.899
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/22/23 19:37:34.907
STEP: Ensuring a job is scheduled 04/22/23 19:37:34.924
STEP: Ensuring exactly one is scheduled 04/22/23 19:38:00.934
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/22/23 19:38:00.945
STEP: Ensuring no more jobs are scheduled 04/22/23 19:38:00.954
STEP: Removing cronjob 04/22/23 19:43:00.972
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 22 19:43:00.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9771" for this suite. 04/22/23 19:43:01.006
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":149,"skipped":2771,"failed":0}
------------------------------
â€¢ [SLOW TEST] [326.198 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:37:34.833
    Apr 22 19:37:34.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename cronjob 04/22/23 19:37:34.837
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:37:34.894
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:37:34.899
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/22/23 19:37:34.907
    STEP: Ensuring a job is scheduled 04/22/23 19:37:34.924
    STEP: Ensuring exactly one is scheduled 04/22/23 19:38:00.934
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/22/23 19:38:00.945
    STEP: Ensuring no more jobs are scheduled 04/22/23 19:38:00.954
    STEP: Removing cronjob 04/22/23 19:43:00.972
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 22 19:43:00.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9771" for this suite. 04/22/23 19:43:01.006
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:01.035
Apr 22 19:43:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:43:01.04
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:01.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:01.144
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:43:01.151
Apr 22 19:43:01.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8" in namespace "projected-7959" to be "Succeeded or Failed"
Apr 22 19:43:01.182: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209871ms
Apr 22 19:43:03.192: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020610854s
Apr 22 19:43:05.191: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0199731s
STEP: Saw pod success 04/22/23 19:43:05.191
Apr 22 19:43:05.192: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8" satisfied condition "Succeeded or Failed"
Apr 22 19:43:05.200: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 container client-container: <nil>
STEP: delete the pod 04/22/23 19:43:05.243
Apr 22 19:43:05.274: INFO: Waiting for pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 to disappear
Apr 22 19:43:05.283: INFO: Pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 19:43:05.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7959" for this suite. 04/22/23 19:43:05.296
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":150,"skipped":2771,"failed":0}
------------------------------
â€¢ [4.279 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:01.035
    Apr 22 19:43:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:43:01.04
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:01.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:01.144
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:43:01.151
    Apr 22 19:43:01.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8" in namespace "projected-7959" to be "Succeeded or Failed"
    Apr 22 19:43:01.182: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209871ms
    Apr 22 19:43:03.192: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020610854s
    Apr 22 19:43:05.191: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0199731s
    STEP: Saw pod success 04/22/23 19:43:05.191
    Apr 22 19:43:05.192: INFO: Pod "downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:05.200: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:43:05.243
    Apr 22 19:43:05.274: INFO: Waiting for pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 to disappear
    Apr 22 19:43:05.283: INFO: Pod downwardapi-volume-199c8f1a-1ac4-4f99-8f69-2e4f421252f8 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 19:43:05.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7959" for this suite. 04/22/23 19:43:05.296
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:05.318
Apr 22 19:43:05.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:43:05.321
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:05.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:05.392
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-40a9f24c-c8b8-4dbf-b8ed-a5a45f6da60e 04/22/23 19:43:05.434
STEP: Creating a pod to test consume secrets 04/22/23 19:43:05.442
Apr 22 19:43:05.456: INFO: Waiting up to 5m0s for pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522" in namespace "secrets-2874" to be "Succeeded or Failed"
Apr 22 19:43:05.463: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Pending", Reason="", readiness=false. Elapsed: 7.192957ms
Apr 22 19:43:07.472: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016168729s
Apr 22 19:43:09.472: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016677317s
STEP: Saw pod success 04/22/23 19:43:09.473
Apr 22 19:43:09.474: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522" satisfied condition "Succeeded or Failed"
Apr 22 19:43:09.482: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:43:09.499
Apr 22 19:43:09.546: INFO: Waiting for pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 to disappear
Apr 22 19:43:09.552: INFO: Pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:43:09.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2874" for this suite. 04/22/23 19:43:09.563
STEP: Destroying namespace "secret-namespace-1842" for this suite. 04/22/23 19:43:09.581
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":151,"skipped":2778,"failed":0}
------------------------------
â€¢ [4.281 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:05.318
    Apr 22 19:43:05.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:43:05.321
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:05.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:05.392
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-40a9f24c-c8b8-4dbf-b8ed-a5a45f6da60e 04/22/23 19:43:05.434
    STEP: Creating a pod to test consume secrets 04/22/23 19:43:05.442
    Apr 22 19:43:05.456: INFO: Waiting up to 5m0s for pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522" in namespace "secrets-2874" to be "Succeeded or Failed"
    Apr 22 19:43:05.463: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Pending", Reason="", readiness=false. Elapsed: 7.192957ms
    Apr 22 19:43:07.472: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016168729s
    Apr 22 19:43:09.472: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016677317s
    STEP: Saw pod success 04/22/23 19:43:09.473
    Apr 22 19:43:09.474: INFO: Pod "pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:09.482: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:43:09.499
    Apr 22 19:43:09.546: INFO: Waiting for pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 to disappear
    Apr 22 19:43:09.552: INFO: Pod pod-secrets-6324f98f-f69e-4d7b-81d1-b1a8d9812522 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:43:09.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2874" for this suite. 04/22/23 19:43:09.563
    STEP: Destroying namespace "secret-namespace-1842" for this suite. 04/22/23 19:43:09.581
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:09.62
Apr 22 19:43:09.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:43:09.623
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:09.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:09.685
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 04/22/23 19:43:09.693
Apr 22 19:43:09.710: INFO: Waiting up to 5m0s for pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4" in namespace "downward-api-112" to be "Succeeded or Failed"
Apr 22 19:43:09.726: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.805471ms
Apr 22 19:43:11.736: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Running", Reason="", readiness=false. Elapsed: 2.025323583s
Apr 22 19:43:13.739: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027679099s
STEP: Saw pod success 04/22/23 19:43:13.739
Apr 22 19:43:13.740: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4" satisfied condition "Succeeded or Failed"
Apr 22 19:43:13.751: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 container dapi-container: <nil>
STEP: delete the pod 04/22/23 19:43:13.774
Apr 22 19:43:13.813: INFO: Waiting for pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 to disappear
Apr 22 19:43:13.839: INFO: Pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 22 19:43:13.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-112" for this suite. 04/22/23 19:43:13.855
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":152,"skipped":2783,"failed":0}
------------------------------
â€¢ [4.257 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:09.62
    Apr 22 19:43:09.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:43:09.623
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:09.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:09.685
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 04/22/23 19:43:09.693
    Apr 22 19:43:09.710: INFO: Waiting up to 5m0s for pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4" in namespace "downward-api-112" to be "Succeeded or Failed"
    Apr 22 19:43:09.726: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.805471ms
    Apr 22 19:43:11.736: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Running", Reason="", readiness=false. Elapsed: 2.025323583s
    Apr 22 19:43:13.739: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027679099s
    STEP: Saw pod success 04/22/23 19:43:13.739
    Apr 22 19:43:13.740: INFO: Pod "downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:13.751: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 19:43:13.774
    Apr 22 19:43:13.813: INFO: Waiting for pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 to disappear
    Apr 22 19:43:13.839: INFO: Pod downward-api-f327aac7-bd8a-477f-bf6f-acc04d1c59b4 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 22 19:43:13.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-112" for this suite. 04/22/23 19:43:13.855
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:13.879
Apr 22 19:43:13.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:43:13.883
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:13.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:13.949
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/22/23 19:43:13.974
STEP: waiting for Deployment to be created 04/22/23 19:43:13.987
STEP: waiting for all Replicas to be Ready 04/22/23 19:43:13.992
Apr 22 19:43:13.995: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:13.996: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.033: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.033: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.063: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.064: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.137: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:14.137: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 22 19:43:15.557: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 22 19:43:15.557: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 22 19:43:15.840: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/22/23 19:43:15.84
W0422 19:43:15.873465      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 22 19:43:15.877: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/22/23 19:43:15.878
Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
Apr 22 19:43:15.886: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:15.886: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:15.887: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.887: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.888: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.888: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.898: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.898: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.924: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.924: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:15.955: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:15.955: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:15.968: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:15.968: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:17.631: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:17.631: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:17.671: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
STEP: listing Deployments 04/22/23 19:43:17.671
Apr 22 19:43:17.680: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/22/23 19:43:17.68
Apr 22 19:43:17.715: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/22/23 19:43:17.716
Apr 22 19:43:17.739: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:17.742: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:17.780: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:17.812: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:17.832: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:17.843: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:18.933: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:19.604: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:19.659: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:19.681: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 22 19:43:20.912: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/22/23 19:43:20.963
STEP: fetching the DeploymentStatus 04/22/23 19:43:20.982
Apr 22 19:43:20.994: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:20.998: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3
Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3
STEP: deleting the Deployment 04/22/23 19:43:21.002
Apr 22 19:43:21.023: INFO: observed event type MODIFIED
Apr 22 19:43:21.025: INFO: observed event type MODIFIED
Apr 22 19:43:21.025: INFO: observed event type MODIFIED
Apr 22 19:43:21.025: INFO: observed event type MODIFIED
Apr 22 19:43:21.026: INFO: observed event type MODIFIED
Apr 22 19:43:21.026: INFO: observed event type MODIFIED
Apr 22 19:43:21.027: INFO: observed event type MODIFIED
Apr 22 19:43:21.027: INFO: observed event type MODIFIED
Apr 22 19:43:21.027: INFO: observed event type MODIFIED
Apr 22 19:43:21.028: INFO: observed event type MODIFIED
Apr 22 19:43:21.028: INFO: observed event type MODIFIED
Apr 22 19:43:21.028: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:43:21.041: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 22 19:43:21.051: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-1708  ea04f5a2-c47f-4f8b-b314-0a4033717262 20735 4 2023-04-22 19:43:15 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328b67 0xc003328b68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328c00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 22 19:43:21.061: INFO: pod: "test-deployment-54cc775c4b-cbx25":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-cbx25 test-deployment-54cc775c4b- deployment-1708  a2c40b6d-a66d-4c2e-abfa-60db886ca113 20730 0 2023-04-22 19:43:17 +0000 UTC 2023-04-22 19:43:21 +0000 UTC 0xc003c6e000 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ea04f5a2-c47f-4f8b-b314-0a4033717262 0xc003c6e047 0xc003c6e048}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea04f5a2-c47f-4f8b-b314-0a4033717262\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-79s2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-79s2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.6,StartTime:2023-04-22 19:43:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:sha256:4873874c08efc72e9729683a83ffbb7502ee729e9a5ac097723806ea7fa13517,ContainerID:containerd://ff1c0f4395135dcb440fd4d43a456716f02391f1a8bc2ebc2a9c6b8d2b3644c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 22 19:43:21.061: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-1708  04bd1d3a-899b-4056-9992-b21498240ade 20726 2 2023-04-22 19:43:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328c67 0xc003328c68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328cf0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 22 19:43:21.073: INFO: pod: "test-deployment-7c7d8d58c8-2zhjh":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-2zhjh test-deployment-7c7d8d58c8- deployment-1708  aa534506-2b5d-489e-9b87-b2f5e9f4cbe8 20725 0 2023-04-22 19:43:19 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 04bd1d3a-899b-4056-9992-b21498240ade 0xc003c6ec77 0xc003c6ec78}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04bd1d3a-899b-4056-9992-b21498240ade\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqcdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqcdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.7,StartTime:2023-04-22 19:43:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9228f0a159276a823e4a0cf5dcf7a9b5e982ba2acb08597f8ed5a130a641c032,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 22 19:43:21.074: INFO: pod: "test-deployment-7c7d8d58c8-kdj9m":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-kdj9m test-deployment-7c7d8d58c8- deployment-1708  2f426753-800f-46c1-a8dd-4e9e596dd709 20694 0 2023-04-22 19:43:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 04bd1d3a-899b-4056-9992-b21498240ade 0xc003c6ee57 0xc003c6ee58}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04bd1d3a-899b-4056-9992-b21498240ade\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wz8pn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wz8pn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 19:43:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://10055a97161d41110c2d5053b6ea18b7fd9543b3c67d8394fae396f374d5a38e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 22 19:43:21.074: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-1708  509de7f8-d8cf-402d-a048-c960bfc3cc84 20637 3 2023-04-22 19:43:13 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328d67 0xc003328d68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328e00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:43:21.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1708" for this suite. 04/22/23 19:43:21.096
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":153,"skipped":2784,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.234 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:13.879
    Apr 22 19:43:13.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:43:13.883
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:13.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:13.949
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/22/23 19:43:13.974
    STEP: waiting for Deployment to be created 04/22/23 19:43:13.987
    STEP: waiting for all Replicas to be Ready 04/22/23 19:43:13.992
    Apr 22 19:43:13.995: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:13.996: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.033: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.033: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.063: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.064: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.137: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:14.137: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 22 19:43:15.557: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 22 19:43:15.557: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 22 19:43:15.840: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/22/23 19:43:15.84
    W0422 19:43:15.873465      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 22 19:43:15.877: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/22/23 19:43:15.878
    Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.883: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.885: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 0
    Apr 22 19:43:15.886: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:15.886: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:15.887: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.887: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.888: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.888: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.898: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.898: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.924: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.924: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:15.955: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:15.955: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:15.968: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:15.968: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:17.631: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:17.631: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:17.671: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    STEP: listing Deployments 04/22/23 19:43:17.671
    Apr 22 19:43:17.680: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/22/23 19:43:17.68
    Apr 22 19:43:17.715: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/22/23 19:43:17.716
    Apr 22 19:43:17.739: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:17.742: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:17.780: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:17.812: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:17.832: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:17.843: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:18.933: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:19.604: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:19.659: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:19.681: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 22 19:43:20.912: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/22/23 19:43:20.963
    STEP: fetching the DeploymentStatus 04/22/23 19:43:20.982
    Apr 22 19:43:20.994: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:20.998: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:20.999: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 1
    Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:21.000: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3
    Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 2
    Apr 22 19:43:21.001: INFO: observed Deployment test-deployment in namespace deployment-1708 with ReadyReplicas 3
    STEP: deleting the Deployment 04/22/23 19:43:21.002
    Apr 22 19:43:21.023: INFO: observed event type MODIFIED
    Apr 22 19:43:21.025: INFO: observed event type MODIFIED
    Apr 22 19:43:21.025: INFO: observed event type MODIFIED
    Apr 22 19:43:21.025: INFO: observed event type MODIFIED
    Apr 22 19:43:21.026: INFO: observed event type MODIFIED
    Apr 22 19:43:21.026: INFO: observed event type MODIFIED
    Apr 22 19:43:21.027: INFO: observed event type MODIFIED
    Apr 22 19:43:21.027: INFO: observed event type MODIFIED
    Apr 22 19:43:21.027: INFO: observed event type MODIFIED
    Apr 22 19:43:21.028: INFO: observed event type MODIFIED
    Apr 22 19:43:21.028: INFO: observed event type MODIFIED
    Apr 22 19:43:21.028: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:43:21.041: INFO: Log out all the ReplicaSets if there is no deployment created
    Apr 22 19:43:21.051: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-1708  ea04f5a2-c47f-4f8b-b314-0a4033717262 20735 4 2023-04-22 19:43:15 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328b67 0xc003328b68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328c00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 22 19:43:21.061: INFO: pod: "test-deployment-54cc775c4b-cbx25":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-cbx25 test-deployment-54cc775c4b- deployment-1708  a2c40b6d-a66d-4c2e-abfa-60db886ca113 20730 0 2023-04-22 19:43:17 +0000 UTC 2023-04-22 19:43:21 +0000 UTC 0xc003c6e000 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ea04f5a2-c47f-4f8b-b314-0a4033717262 0xc003c6e047 0xc003c6e048}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea04f5a2-c47f-4f8b-b314-0a4033717262\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-79s2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-79s2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.6,StartTime:2023-04-22 19:43:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:sha256:4873874c08efc72e9729683a83ffbb7502ee729e9a5ac097723806ea7fa13517,ContainerID:containerd://ff1c0f4395135dcb440fd4d43a456716f02391f1a8bc2ebc2a9c6b8d2b3644c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 22 19:43:21.061: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-1708  04bd1d3a-899b-4056-9992-b21498240ade 20726 2 2023-04-22 19:43:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328c67 0xc003328c68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328cf0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Apr 22 19:43:21.073: INFO: pod: "test-deployment-7c7d8d58c8-2zhjh":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-2zhjh test-deployment-7c7d8d58c8- deployment-1708  aa534506-2b5d-489e-9b87-b2f5e9f4cbe8 20725 0 2023-04-22 19:43:19 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 04bd1d3a-899b-4056-9992-b21498240ade 0xc003c6ec77 0xc003c6ec78}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04bd1d3a-899b-4056-9992-b21498240ade\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.44.0.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqcdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqcdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4bdec5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.165,PodIP:10.44.0.7,StartTime:2023-04-22 19:43:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9228f0a159276a823e4a0cf5dcf7a9b5e982ba2acb08597f8ed5a130a641c032,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.44.0.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 22 19:43:21.074: INFO: pod: "test-deployment-7c7d8d58c8-kdj9m":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-kdj9m test-deployment-7c7d8d58c8- deployment-1708  2f426753-800f-46c1-a8dd-4e9e596dd709 20694 0 2023-04-22 19:43:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 04bd1d3a-899b-4056-9992-b21498240ade 0xc003c6ee57 0xc003c6ee58}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04bd1d3a-899b-4056-9992-b21498240ade\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wz8pn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wz8pn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 19:43:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 19:43:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://10055a97161d41110c2d5053b6ea18b7fd9543b3c67d8394fae396f374d5a38e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 22 19:43:21.074: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-1708  509de7f8-d8cf-402d-a048-c960bfc3cc84 20637 3 2023-04-22 19:43:13 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 2901fb52-989d-48ac-81c5-a2449a5f5c3f 0xc003328d67 0xc003328d68}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2901fb52-989d-48ac-81c5-a2449a5f5c3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003328e00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:43:21.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1708" for this suite. 04/22/23 19:43:21.096
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:21.116
Apr 22 19:43:21.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 19:43:21.122
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:21.168
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:21.172
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 04/22/23 19:43:21.215
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:43:21.224
Apr 22 19:43:21.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:21.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:21.233: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:43:21.234: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:43:22.248: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:22.249: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:22.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:43:22.267: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:43:23.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:23.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:23.262: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:43:23.262: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/22/23 19:43:23.272
Apr 22 19:43:23.318: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:23.318: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:23.341: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:43:23.341: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:43:24.356: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:24.356: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:24.376: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:43:24.376: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:43:25.354: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:25.354: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:43:25.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:43:25.374: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/22/23 19:43:25.374
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:43:25.393
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-694, will wait for the garbage collector to delete the pods 04/22/23 19:43:25.394
Apr 22 19:43:25.490: INFO: Deleting DaemonSet.extensions daemon-set took: 35.934795ms
Apr 22 19:43:25.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.224243ms
Apr 22 19:43:27.697: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:43:27.697: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 19:43:27.702: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20878"},"items":null}

Apr 22 19:43:27.707: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20878"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:43:27.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-694" for this suite. 04/22/23 19:43:27.731
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":154,"skipped":2789,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.626 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:21.116
    Apr 22 19:43:21.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 19:43:21.122
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:21.168
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:21.172
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 04/22/23 19:43:21.215
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:43:21.224
    Apr 22 19:43:21.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:21.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:21.233: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:43:21.234: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:43:22.248: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:22.249: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:22.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:43:22.267: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:43:23.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:23.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:23.262: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:43:23.262: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/22/23 19:43:23.272
    Apr 22 19:43:23.318: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:23.318: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:23.341: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:43:23.341: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:43:24.356: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:24.356: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:24.376: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:43:24.376: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:43:25.354: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:25.354: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:43:25.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:43:25.374: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/22/23 19:43:25.374
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:43:25.393
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-694, will wait for the garbage collector to delete the pods 04/22/23 19:43:25.394
    Apr 22 19:43:25.490: INFO: Deleting DaemonSet.extensions daemon-set took: 35.934795ms
    Apr 22 19:43:25.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.224243ms
    Apr 22 19:43:27.697: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:43:27.697: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 19:43:27.702: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20878"},"items":null}

    Apr 22 19:43:27.707: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20878"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:43:27.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-694" for this suite. 04/22/23 19:43:27.731
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:27.758
Apr 22 19:43:27.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:43:27.76
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:27.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:27.855
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-98f175ca-562d-43f8-b9ab-42888c1528f3 04/22/23 19:43:27.865
STEP: Creating secret with name secret-projected-all-test-volume-d5078810-49fa-4b9b-9a7a-19637079b119 04/22/23 19:43:27.88
STEP: Creating a pod to test Check all projections for projected volume plugin 04/22/23 19:43:27.892
Apr 22 19:43:27.918: INFO: Waiting up to 5m0s for pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979" in namespace "projected-927" to be "Succeeded or Failed"
Apr 22 19:43:27.926: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Pending", Reason="", readiness=false. Elapsed: 7.653039ms
Apr 22 19:43:29.938: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019172229s
Apr 22 19:43:31.938: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019029107s
STEP: Saw pod success 04/22/23 19:43:31.938
Apr 22 19:43:31.939: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979" satisfied condition "Succeeded or Failed"
Apr 22 19:43:31.947: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 container projected-all-volume-test: <nil>
STEP: delete the pod 04/22/23 19:43:31.963
Apr 22 19:43:31.996: INFO: Waiting for pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 to disappear
Apr 22 19:43:32.006: INFO: Pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Apr 22 19:43:32.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-927" for this suite. 04/22/23 19:43:32.02
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":155,"skipped":2801,"failed":0}
------------------------------
â€¢ [4.278 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:27.758
    Apr 22 19:43:27.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:43:27.76
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:27.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:27.855
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-98f175ca-562d-43f8-b9ab-42888c1528f3 04/22/23 19:43:27.865
    STEP: Creating secret with name secret-projected-all-test-volume-d5078810-49fa-4b9b-9a7a-19637079b119 04/22/23 19:43:27.88
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/22/23 19:43:27.892
    Apr 22 19:43:27.918: INFO: Waiting up to 5m0s for pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979" in namespace "projected-927" to be "Succeeded or Failed"
    Apr 22 19:43:27.926: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Pending", Reason="", readiness=false. Elapsed: 7.653039ms
    Apr 22 19:43:29.938: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019172229s
    Apr 22 19:43:31.938: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019029107s
    STEP: Saw pod success 04/22/23 19:43:31.938
    Apr 22 19:43:31.939: INFO: Pod "projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:31.947: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 container projected-all-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:43:31.963
    Apr 22 19:43:31.996: INFO: Waiting for pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 to disappear
    Apr 22 19:43:32.006: INFO: Pod projected-volume-25e47315-7328-453e-bcf9-9aef0dbb6979 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Apr 22 19:43:32.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-927" for this suite. 04/22/23 19:43:32.02
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:32.048
Apr 22 19:43:32.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 19:43:32.052
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:32.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:32.122
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 22 19:43:32.134: INFO: Creating deployment "test-recreate-deployment"
Apr 22 19:43:32.147: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 22 19:43:32.171: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 22 19:43:34.192: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 22 19:43:34.203: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 22 19:43:34.235: INFO: Updating deployment test-recreate-deployment
Apr 22 19:43:34.235: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 19:43:34.384: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2183  2681750c-3cfe-4718-82d5-1ebd47e5faf5 20982 2 2023-04-22 19:43:32 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a44ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:43:34 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-22 19:43:34 +0000 UTC,LastTransitionTime:2023-04-22 19:43:32 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 22 19:43:34.392: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2183  d1299abd-22bd-469b-a0aa-5b39d2a4cbd9 20979 1 2023-04-22 19:43:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 2681750c-3cfe-4718-82d5-1ebd47e5faf5 0xc0035fa170 0xc0035fa171}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2681750c-3cfe-4718-82d5-1ebd47e5faf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:43:34.392: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 22 19:43:34.393: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2183  0564cced-e76e-47af-bb1e-6c6e3ce27f08 20971 2 2023-04-22 19:43:32 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 2681750c-3cfe-4718-82d5-1ebd47e5faf5 0xc0035fa037 0xc0035fa038}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2681750c-3cfe-4718-82d5-1ebd47e5faf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 19:43:34.401: INFO: Pod "test-recreate-deployment-9d58999df-pd6fg" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-pd6fg test-recreate-deployment-9d58999df- deployment-2183  3211e3b1-df17-4011-82a9-4ccdab6209a4 20983 0 2023-04-22 19:43:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df d1299abd-22bd-469b-a0aa-5b39d2a4cbd9 0xc0035fa6b0 0xc0035fa6b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1299abd-22bd-469b-a0aa-5b39d2a4cbd9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mrfdh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mrfdh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:43:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 19:43:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2183" for this suite. 04/22/23 19:43:34.413
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":156,"skipped":2842,"failed":0}
------------------------------
â€¢ [2.375 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:32.048
    Apr 22 19:43:32.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 19:43:32.052
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:32.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:32.122
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 22 19:43:32.134: INFO: Creating deployment "test-recreate-deployment"
    Apr 22 19:43:32.147: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 22 19:43:32.171: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 22 19:43:34.192: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 22 19:43:34.203: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 22 19:43:34.235: INFO: Updating deployment test-recreate-deployment
    Apr 22 19:43:34.235: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 19:43:34.384: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-2183  2681750c-3cfe-4718-82d5-1ebd47e5faf5 20982 2 2023-04-22 19:43:32 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a44ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-22 19:43:34 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-22 19:43:34 +0000 UTC,LastTransitionTime:2023-04-22 19:43:32 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 22 19:43:34.392: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2183  d1299abd-22bd-469b-a0aa-5b39d2a4cbd9 20979 1 2023-04-22 19:43:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 2681750c-3cfe-4718-82d5-1ebd47e5faf5 0xc0035fa170 0xc0035fa171}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2681750c-3cfe-4718-82d5-1ebd47e5faf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:43:34.392: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 22 19:43:34.393: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2183  0564cced-e76e-47af-bb1e-6c6e3ce27f08 20971 2 2023-04-22 19:43:32 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 2681750c-3cfe-4718-82d5-1ebd47e5faf5 0xc0035fa037 0xc0035fa038}] [] [{kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2681750c-3cfe-4718-82d5-1ebd47e5faf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 19:43:34.401: INFO: Pod "test-recreate-deployment-9d58999df-pd6fg" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-pd6fg test-recreate-deployment-9d58999df- deployment-2183  3211e3b1-df17-4011-82a9-4ccdab6209a4 20983 0 2023-04-22 19:43:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df d1299abd-22bd-469b-a0aa-5b39d2a4cbd9 0xc0035fa6b0 0xc0035fa6b1}] [] [{kube-controller-manager Update v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1299abd-22bd-469b-a0aa-5b39d2a4cbd9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 19:43:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mrfdh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mrfdh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 19:43:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:,StartTime:2023-04-22 19:43:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 19:43:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2183" for this suite. 04/22/23 19:43:34.413
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:34.468
Apr 22 19:43:34.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 19:43:34.47
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:34.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:34.549
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Apr 22 19:43:34.578: INFO: Waiting up to 2m0s for pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" in namespace "var-expansion-6086" to be "container 0 failed with reason CreateContainerConfigError"
Apr 22 19:43:34.587: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040": Phase="Pending", Reason="", readiness=false. Elapsed: 8.223912ms
Apr 22 19:43:36.596: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01746403s
Apr 22 19:43:36.597: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 22 19:43:36.597: INFO: Deleting pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" in namespace "var-expansion-6086"
Apr 22 19:43:36.614: INFO: Wait up to 5m0s for pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 19:43:38.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6086" for this suite. 04/22/23 19:43:38.646
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":157,"skipped":2875,"failed":0}
------------------------------
â€¢ [4.198 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:34.468
    Apr 22 19:43:34.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 19:43:34.47
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:34.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:34.549
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Apr 22 19:43:34.578: INFO: Waiting up to 2m0s for pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" in namespace "var-expansion-6086" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 22 19:43:34.587: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040": Phase="Pending", Reason="", readiness=false. Elapsed: 8.223912ms
    Apr 22 19:43:36.596: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01746403s
    Apr 22 19:43:36.597: INFO: Pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 22 19:43:36.597: INFO: Deleting pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" in namespace "var-expansion-6086"
    Apr 22 19:43:36.614: INFO: Wait up to 5m0s for pod "var-expansion-e984c3cf-c9cf-46cd-8d0c-758f3529f040" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 19:43:38.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6086" for this suite. 04/22/23 19:43:38.646
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:38.678
Apr 22 19:43:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 19:43:38.683
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:38.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:38.74
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 22 19:43:38.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:43:45.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4483" for this suite. 04/22/23 19:43:45.258
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":158,"skipped":2888,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.597 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:38.678
    Apr 22 19:43:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 19:43:38.683
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:38.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:38.74
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 22 19:43:38.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:43:45.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4483" for this suite. 04/22/23 19:43:45.258
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:45.292
Apr 22 19:43:45.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:43:45.295
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:45.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:45.348
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-26a64e97-0605-4d1f-88b4-95475f770164 04/22/23 19:43:45.354
STEP: Creating a pod to test consume secrets 04/22/23 19:43:45.365
Apr 22 19:43:45.376: INFO: Waiting up to 5m0s for pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f" in namespace "secrets-9819" to be "Succeeded or Failed"
Apr 22 19:43:45.387: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.218251ms
Apr 22 19:43:47.396: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019850314s
Apr 22 19:43:49.397: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020862243s
STEP: Saw pod success 04/22/23 19:43:49.397
Apr 22 19:43:49.398: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f" satisfied condition "Succeeded or Failed"
Apr 22 19:43:49.405: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:43:49.425
Apr 22 19:43:49.455: INFO: Waiting for pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f to disappear
Apr 22 19:43:49.466: INFO: Pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:43:49.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9819" for this suite. 04/22/23 19:43:49.481
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":159,"skipped":2922,"failed":0}
------------------------------
â€¢ [4.206 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:45.292
    Apr 22 19:43:45.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:43:45.295
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:45.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:45.348
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-26a64e97-0605-4d1f-88b4-95475f770164 04/22/23 19:43:45.354
    STEP: Creating a pod to test consume secrets 04/22/23 19:43:45.365
    Apr 22 19:43:45.376: INFO: Waiting up to 5m0s for pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f" in namespace "secrets-9819" to be "Succeeded or Failed"
    Apr 22 19:43:45.387: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.218251ms
    Apr 22 19:43:47.396: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019850314s
    Apr 22 19:43:49.397: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020862243s
    STEP: Saw pod success 04/22/23 19:43:49.397
    Apr 22 19:43:49.398: INFO: Pod "pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:49.405: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:43:49.425
    Apr 22 19:43:49.455: INFO: Waiting for pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f to disappear
    Apr 22 19:43:49.466: INFO: Pod pod-secrets-4a2e16db-5208-4a87-9205-784d8079b73f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:43:49.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9819" for this suite. 04/22/23 19:43:49.481
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:49.513
Apr 22 19:43:49.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:43:49.515
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:49.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:49.583
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/22/23 19:43:49.589
STEP: submitting the pod to kubernetes 04/22/23 19:43:49.591
STEP: verifying QOS class is set on the pod 04/22/23 19:43:49.607
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Apr 22 19:43:49.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7003" for this suite. 04/22/23 19:43:49.629
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":160,"skipped":2939,"failed":0}
------------------------------
â€¢ [0.129 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:49.513
    Apr 22 19:43:49.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:43:49.515
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:49.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:49.583
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/22/23 19:43:49.589
    STEP: submitting the pod to kubernetes 04/22/23 19:43:49.591
    STEP: verifying QOS class is set on the pod 04/22/23 19:43:49.607
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Apr 22 19:43:49.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7003" for this suite. 04/22/23 19:43:49.629
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:49.652
Apr 22 19:43:49.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replication-controller 04/22/23 19:43:49.657
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:49.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:49.701
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 04/22/23 19:43:49.716
STEP: waiting for RC to be added 04/22/23 19:43:49.729
STEP: waiting for available Replicas 04/22/23 19:43:49.73
STEP: patching ReplicationController 04/22/23 19:43:50.759
STEP: waiting for RC to be modified 04/22/23 19:43:50.778
STEP: patching ReplicationController status 04/22/23 19:43:50.78
STEP: waiting for RC to be modified 04/22/23 19:43:50.794
STEP: waiting for available Replicas 04/22/23 19:43:50.795
STEP: fetching ReplicationController status 04/22/23 19:43:50.813
STEP: patching ReplicationController scale 04/22/23 19:43:50.823
STEP: waiting for RC to be modified 04/22/23 19:43:50.84
STEP: waiting for ReplicationController's scale to be the max amount 04/22/23 19:43:50.841
STEP: fetching ReplicationController; ensuring that it's patched 04/22/23 19:43:52.004
STEP: updating ReplicationController status 04/22/23 19:43:52.014
STEP: waiting for RC to be modified 04/22/23 19:43:52.028
STEP: listing all ReplicationControllers 04/22/23 19:43:52.03
STEP: checking that ReplicationController has expected values 04/22/23 19:43:52.043
STEP: deleting ReplicationControllers by collection 04/22/23 19:43:52.044
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/22/23 19:43:52.075
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 22 19:43:52.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7155" for this suite. 04/22/23 19:43:52.157
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":161,"skipped":2939,"failed":0}
------------------------------
â€¢ [2.518 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:49.652
    Apr 22 19:43:49.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replication-controller 04/22/23 19:43:49.657
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:49.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:49.701
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 04/22/23 19:43:49.716
    STEP: waiting for RC to be added 04/22/23 19:43:49.729
    STEP: waiting for available Replicas 04/22/23 19:43:49.73
    STEP: patching ReplicationController 04/22/23 19:43:50.759
    STEP: waiting for RC to be modified 04/22/23 19:43:50.778
    STEP: patching ReplicationController status 04/22/23 19:43:50.78
    STEP: waiting for RC to be modified 04/22/23 19:43:50.794
    STEP: waiting for available Replicas 04/22/23 19:43:50.795
    STEP: fetching ReplicationController status 04/22/23 19:43:50.813
    STEP: patching ReplicationController scale 04/22/23 19:43:50.823
    STEP: waiting for RC to be modified 04/22/23 19:43:50.84
    STEP: waiting for ReplicationController's scale to be the max amount 04/22/23 19:43:50.841
    STEP: fetching ReplicationController; ensuring that it's patched 04/22/23 19:43:52.004
    STEP: updating ReplicationController status 04/22/23 19:43:52.014
    STEP: waiting for RC to be modified 04/22/23 19:43:52.028
    STEP: listing all ReplicationControllers 04/22/23 19:43:52.03
    STEP: checking that ReplicationController has expected values 04/22/23 19:43:52.043
    STEP: deleting ReplicationControllers by collection 04/22/23 19:43:52.044
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/22/23 19:43:52.075
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 22 19:43:52.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7155" for this suite. 04/22/23 19:43:52.157
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:52.202
Apr 22 19:43:52.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:43:52.205
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:52.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:52.247
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:43:52.257
Apr 22 19:43:52.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046" in namespace "projected-6942" to be "Succeeded or Failed"
Apr 22 19:43:52.286: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Pending", Reason="", readiness=false. Elapsed: 14.99286ms
Apr 22 19:43:54.297: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025422315s
Apr 22 19:43:56.298: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026819631s
STEP: Saw pod success 04/22/23 19:43:56.298
Apr 22 19:43:56.299: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046" satisfied condition "Succeeded or Failed"
Apr 22 19:43:56.310: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 container client-container: <nil>
STEP: delete the pod 04/22/23 19:43:56.33
Apr 22 19:43:56.362: INFO: Waiting for pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 to disappear
Apr 22 19:43:56.378: INFO: Pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 19:43:56.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6942" for this suite. 04/22/23 19:43:56.394
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":162,"skipped":2958,"failed":0}
------------------------------
â€¢ [4.209 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:52.202
    Apr 22 19:43:52.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:43:52.205
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:52.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:52.247
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:43:52.257
    Apr 22 19:43:52.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046" in namespace "projected-6942" to be "Succeeded or Failed"
    Apr 22 19:43:52.286: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Pending", Reason="", readiness=false. Elapsed: 14.99286ms
    Apr 22 19:43:54.297: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025422315s
    Apr 22 19:43:56.298: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026819631s
    STEP: Saw pod success 04/22/23 19:43:56.298
    Apr 22 19:43:56.299: INFO: Pod "downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046" satisfied condition "Succeeded or Failed"
    Apr 22 19:43:56.310: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:43:56.33
    Apr 22 19:43:56.362: INFO: Waiting for pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 to disappear
    Apr 22 19:43:56.378: INFO: Pod downwardapi-volume-7443b770-e691-4410-b701-fbc5efad2046 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 19:43:56.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6942" for this suite. 04/22/23 19:43:56.394
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:43:56.43
Apr 22 19:43:56.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:43:56.434
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:56.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:56.496
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 04/22/23 19:43:56.508
Apr 22 19:43:56.525: INFO: Waiting up to 5m0s for pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed" in namespace "downward-api-9235" to be "Succeeded or Failed"
Apr 22 19:43:56.534: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.551083ms
Apr 22 19:43:58.544: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01839921s
Apr 22 19:44:00.544: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019268106s
STEP: Saw pod success 04/22/23 19:44:00.545
Apr 22 19:44:00.545: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed" satisfied condition "Succeeded or Failed"
Apr 22 19:44:00.554: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed container dapi-container: <nil>
STEP: delete the pod 04/22/23 19:44:00.575
Apr 22 19:44:00.607: INFO: Waiting for pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed to disappear
Apr 22 19:44:00.615: INFO: Pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 22 19:44:00.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9235" for this suite. 04/22/23 19:44:00.625
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":163,"skipped":2962,"failed":0}
------------------------------
â€¢ [4.210 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:43:56.43
    Apr 22 19:43:56.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:43:56.434
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:43:56.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:43:56.496
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 04/22/23 19:43:56.508
    Apr 22 19:43:56.525: INFO: Waiting up to 5m0s for pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed" in namespace "downward-api-9235" to be "Succeeded or Failed"
    Apr 22 19:43:56.534: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.551083ms
    Apr 22 19:43:58.544: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01839921s
    Apr 22 19:44:00.544: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019268106s
    STEP: Saw pod success 04/22/23 19:44:00.545
    Apr 22 19:44:00.545: INFO: Pod "downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed" satisfied condition "Succeeded or Failed"
    Apr 22 19:44:00.554: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed container dapi-container: <nil>
    STEP: delete the pod 04/22/23 19:44:00.575
    Apr 22 19:44:00.607: INFO: Waiting for pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed to disappear
    Apr 22 19:44:00.615: INFO: Pod downward-api-7b7eda3c-e881-43d1-acbe-dbb5d486f7ed no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 22 19:44:00.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9235" for this suite. 04/22/23 19:44:00.625
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:44:00.641
Apr 22 19:44:00.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:44:00.645
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:00.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:00.699
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 04/22/23 19:44:00.709
Apr 22 19:44:00.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 22 19:44:00.876: INFO: stderr: ""
Apr 22 19:44:00.876: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 04/22/23 19:44:00.876
Apr 22 19:44:00.876: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 22 19:44:00.876: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3542" to be "running and ready, or succeeded"
Apr 22 19:44:00.892: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 16.06845ms
Apr 22 19:44:00.892: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'cncf25-2-node-187aa4c0d96' to be 'Running' but was 'Pending'
Apr 22 19:44:02.903: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.027053645s
Apr 22 19:44:02.903: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 22 19:44:02.904: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/22/23 19:44:02.904
Apr 22 19:44:02.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator'
Apr 22 19:44:03.066: INFO: stderr: ""
Apr 22 19:44:03.066: INFO: stdout: "I0422 19:44:01.586975       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/n45z 394\nI0422 19:44:01.787209       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/ppm 570\nI0422 19:44:01.987737       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hmc 330\nI0422 19:44:02.187175       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/x4h 575\nI0422 19:44:02.387957       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/79d5 590\nI0422 19:44:02.587523       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/97c 293\nI0422 19:44:02.787041       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/8xhx 598\nI0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
STEP: limiting log lines 04/22/23 19:44:03.066
Apr 22 19:44:03.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --tail=1'
Apr 22 19:44:03.195: INFO: stderr: ""
Apr 22 19:44:03.195: INFO: stdout: "I0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
Apr 22 19:44:03.195: INFO: got output "I0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
STEP: limiting log bytes 04/22/23 19:44:03.195
Apr 22 19:44:03.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --limit-bytes=1'
Apr 22 19:44:03.327: INFO: stderr: ""
Apr 22 19:44:03.327: INFO: stdout: "I"
Apr 22 19:44:03.327: INFO: got output "I"
STEP: exposing timestamps 04/22/23 19:44:03.327
Apr 22 19:44:03.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 22 19:44:03.479: INFO: stderr: ""
Apr 22 19:44:03.479: INFO: stdout: "2023-04-22T19:44:03.387483296Z I0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\n"
Apr 22 19:44:03.479: INFO: got output "2023-04-22T19:44:03.387483296Z I0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\n"
STEP: restricting to a time range 04/22/23 19:44:03.479
Apr 22 19:44:05.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --since=1s'
Apr 22 19:44:06.117: INFO: stderr: ""
Apr 22 19:44:06.117: INFO: stdout: "I0422 19:44:05.187086       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lvp 568\nI0422 19:44:05.387643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/vlbf 542\nI0422 19:44:05.587064       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/m6r 573\nI0422 19:44:05.787602       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/wbhr 586\nI0422 19:44:05.987059       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/twbk 570\n"
Apr 22 19:44:06.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --since=24h'
Apr 22 19:44:06.256: INFO: stderr: ""
Apr 22 19:44:06.256: INFO: stdout: "I0422 19:44:01.586975       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/n45z 394\nI0422 19:44:01.787209       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/ppm 570\nI0422 19:44:01.987737       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hmc 330\nI0422 19:44:02.187175       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/x4h 575\nI0422 19:44:02.387957       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/79d5 590\nI0422 19:44:02.587523       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/97c 293\nI0422 19:44:02.787041       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/8xhx 598\nI0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\nI0422 19:44:03.187796       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/w4s 441\nI0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\nI0422 19:44:03.587868       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/vxzm 420\nI0422 19:44:03.787396       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/wk5 346\nI0422 19:44:03.987955       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/hgq 532\nI0422 19:44:04.187636       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/v49g 302\nI0422 19:44:04.387663       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/vvs 497\nI0422 19:44:04.587653       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/n899 406\nI0422 19:44:04.787107       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/nh82 217\nI0422 19:44:04.987667       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/6ks 244\nI0422 19:44:05.187086       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lvp 568\nI0422 19:44:05.387643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/vlbf 542\nI0422 19:44:05.587064       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/m6r 573\nI0422 19:44:05.787602       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/wbhr 586\nI0422 19:44:05.987059       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/twbk 570\nI0422 19:44:06.187512       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/x7w 432\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Apr 22 19:44:06.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 delete pod logs-generator'
Apr 22 19:44:07.143: INFO: stderr: ""
Apr 22 19:44:07.144: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:44:07.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3542" for this suite. 04/22/23 19:44:07.155
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":164,"skipped":2965,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.528 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:44:00.641
    Apr 22 19:44:00.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:44:00.645
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:00.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:00.699
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 04/22/23 19:44:00.709
    Apr 22 19:44:00.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 22 19:44:00.876: INFO: stderr: ""
    Apr 22 19:44:00.876: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 04/22/23 19:44:00.876
    Apr 22 19:44:00.876: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 22 19:44:00.876: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3542" to be "running and ready, or succeeded"
    Apr 22 19:44:00.892: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 16.06845ms
    Apr 22 19:44:00.892: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'cncf25-2-node-187aa4c0d96' to be 'Running' but was 'Pending'
    Apr 22 19:44:02.903: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.027053645s
    Apr 22 19:44:02.903: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 22 19:44:02.904: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/22/23 19:44:02.904
    Apr 22 19:44:02.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator'
    Apr 22 19:44:03.066: INFO: stderr: ""
    Apr 22 19:44:03.066: INFO: stdout: "I0422 19:44:01.586975       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/n45z 394\nI0422 19:44:01.787209       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/ppm 570\nI0422 19:44:01.987737       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hmc 330\nI0422 19:44:02.187175       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/x4h 575\nI0422 19:44:02.387957       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/79d5 590\nI0422 19:44:02.587523       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/97c 293\nI0422 19:44:02.787041       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/8xhx 598\nI0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
    STEP: limiting log lines 04/22/23 19:44:03.066
    Apr 22 19:44:03.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --tail=1'
    Apr 22 19:44:03.195: INFO: stderr: ""
    Apr 22 19:44:03.195: INFO: stdout: "I0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
    Apr 22 19:44:03.195: INFO: got output "I0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\n"
    STEP: limiting log bytes 04/22/23 19:44:03.195
    Apr 22 19:44:03.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --limit-bytes=1'
    Apr 22 19:44:03.327: INFO: stderr: ""
    Apr 22 19:44:03.327: INFO: stdout: "I"
    Apr 22 19:44:03.327: INFO: got output "I"
    STEP: exposing timestamps 04/22/23 19:44:03.327
    Apr 22 19:44:03.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 22 19:44:03.479: INFO: stderr: ""
    Apr 22 19:44:03.479: INFO: stdout: "2023-04-22T19:44:03.387483296Z I0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\n"
    Apr 22 19:44:03.479: INFO: got output "2023-04-22T19:44:03.387483296Z I0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\n"
    STEP: restricting to a time range 04/22/23 19:44:03.479
    Apr 22 19:44:05.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --since=1s'
    Apr 22 19:44:06.117: INFO: stderr: ""
    Apr 22 19:44:06.117: INFO: stdout: "I0422 19:44:05.187086       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lvp 568\nI0422 19:44:05.387643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/vlbf 542\nI0422 19:44:05.587064       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/m6r 573\nI0422 19:44:05.787602       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/wbhr 586\nI0422 19:44:05.987059       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/twbk 570\n"
    Apr 22 19:44:06.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 logs logs-generator logs-generator --since=24h'
    Apr 22 19:44:06.256: INFO: stderr: ""
    Apr 22 19:44:06.256: INFO: stdout: "I0422 19:44:01.586975       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/n45z 394\nI0422 19:44:01.787209       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/ppm 570\nI0422 19:44:01.987737       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hmc 330\nI0422 19:44:02.187175       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/x4h 575\nI0422 19:44:02.387957       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/79d5 590\nI0422 19:44:02.587523       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/97c 293\nI0422 19:44:02.787041       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/8xhx 598\nI0422 19:44:02.987756       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/jqw 423\nI0422 19:44:03.187796       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/w4s 441\nI0422 19:44:03.387195       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/frc7 556\nI0422 19:44:03.587868       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/vxzm 420\nI0422 19:44:03.787396       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/wk5 346\nI0422 19:44:03.987955       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/hgq 532\nI0422 19:44:04.187636       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/v49g 302\nI0422 19:44:04.387663       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/vvs 497\nI0422 19:44:04.587653       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/n899 406\nI0422 19:44:04.787107       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/nh82 217\nI0422 19:44:04.987667       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/6ks 244\nI0422 19:44:05.187086       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lvp 568\nI0422 19:44:05.387643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/vlbf 542\nI0422 19:44:05.587064       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/m6r 573\nI0422 19:44:05.787602       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/wbhr 586\nI0422 19:44:05.987059       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/twbk 570\nI0422 19:44:06.187512       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/x7w 432\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Apr 22 19:44:06.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-3542 delete pod logs-generator'
    Apr 22 19:44:07.143: INFO: stderr: ""
    Apr 22 19:44:07.144: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:44:07.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3542" for this suite. 04/22/23 19:44:07.155
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:44:07.182
Apr 22 19:44:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:44:07.184
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:07.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:07.239
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 04/22/23 19:44:07.248
STEP: Creating a ResourceQuota 04/22/23 19:44:12.259
STEP: Ensuring resource quota status is calculated 04/22/23 19:44:12.275
STEP: Creating a Pod that fits quota 04/22/23 19:44:14.284
STEP: Ensuring ResourceQuota status captures the pod usage 04/22/23 19:44:14.327
STEP: Not allowing a pod to be created that exceeds remaining quota 04/22/23 19:44:16.337
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/22/23 19:44:16.343
STEP: Ensuring a pod cannot update its resource requirements 04/22/23 19:44:16.349
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/22/23 19:44:16.368
STEP: Deleting the pod 04/22/23 19:44:18.378
STEP: Ensuring resource quota status released the pod usage 04/22/23 19:44:18.418
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:44:20.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5995" for this suite. 04/22/23 19:44:20.439
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":165,"skipped":2978,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.279 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:44:07.182
    Apr 22 19:44:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:44:07.184
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:07.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:07.239
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 04/22/23 19:44:07.248
    STEP: Creating a ResourceQuota 04/22/23 19:44:12.259
    STEP: Ensuring resource quota status is calculated 04/22/23 19:44:12.275
    STEP: Creating a Pod that fits quota 04/22/23 19:44:14.284
    STEP: Ensuring ResourceQuota status captures the pod usage 04/22/23 19:44:14.327
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/22/23 19:44:16.337
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/22/23 19:44:16.343
    STEP: Ensuring a pod cannot update its resource requirements 04/22/23 19:44:16.349
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/22/23 19:44:16.368
    STEP: Deleting the pod 04/22/23 19:44:18.378
    STEP: Ensuring resource quota status released the pod usage 04/22/23 19:44:18.418
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:44:20.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5995" for this suite. 04/22/23 19:44:20.439
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:44:20.484
Apr 22 19:44:20.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:44:20.488
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:20.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:20.55
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 04/22/23 19:44:20.559
Apr 22 19:44:20.581: INFO: Waiting up to 5m0s for pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1" in namespace "downward-api-170" to be "running and ready"
Apr 22 19:44:20.592: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.403412ms
Apr 22 19:44:20.592: INFO: The phase of Pod labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:44:22.602: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.020126901s
Apr 22 19:44:22.602: INFO: The phase of Pod labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1 is Running (Ready = true)
Apr 22 19:44:22.603: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1" satisfied condition "running and ready"
Apr 22 19:44:23.159: INFO: Successfully updated pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:44:27.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-170" for this suite. 04/22/23 19:44:27.228
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":166,"skipped":2993,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.768 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:44:20.484
    Apr 22 19:44:20.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:44:20.488
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:20.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:20.55
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 04/22/23 19:44:20.559
    Apr 22 19:44:20.581: INFO: Waiting up to 5m0s for pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1" in namespace "downward-api-170" to be "running and ready"
    Apr 22 19:44:20.592: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.403412ms
    Apr 22 19:44:20.592: INFO: The phase of Pod labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:44:22.602: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.020126901s
    Apr 22 19:44:22.602: INFO: The phase of Pod labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1 is Running (Ready = true)
    Apr 22 19:44:22.603: INFO: Pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1" satisfied condition "running and ready"
    Apr 22 19:44:23.159: INFO: Successfully updated pod "labelsupdateb3582827-dd86-4d6b-ac81-1381b4b644b1"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:44:27.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-170" for this suite. 04/22/23 19:44:27.228
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:44:27.255
Apr 22 19:44:27.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:44:27.261
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:27.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:27.316
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Apr 22 19:44:27.358: INFO: created pod
Apr 22 19:44:27.358: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-565" to be "Succeeded or Failed"
Apr 22 19:44:27.373: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.735121ms
Apr 22 19:44:29.383: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024904122s
Apr 22 19:44:31.383: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024406295s
STEP: Saw pod success 04/22/23 19:44:31.383
Apr 22 19:44:31.383: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 22 19:45:01.384: INFO: polling logs
Apr 22 19:45:01.416: INFO: Pod logs: 
I0422 19:44:28.111270       1 log.go:195] OK: Got token
I0422 19:44:28.111494       1 log.go:195] validating with in-cluster discovery
I0422 19:44:28.112179       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0422 19:44:28.112332       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-565:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682193267, NotBefore:1682192667, IssuedAt:1682192667, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-565", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6ad413e7-bcad-436f-96fc-3b575e4c7754"}}}
I0422 19:44:28.149432       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0422 19:44:28.165797       1 log.go:195] OK: Validated signature on JWT
I0422 19:44:28.165999       1 log.go:195] OK: Got valid claims from token!
I0422 19:44:28.166172       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-565:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682193267, NotBefore:1682192667, IssuedAt:1682192667, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-565", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6ad413e7-bcad-436f-96fc-3b575e4c7754"}}}

Apr 22 19:45:01.416: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 19:45:01.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-565" for this suite. 04/22/23 19:45:01.439
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":167,"skipped":2999,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.199 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:44:27.255
    Apr 22 19:44:27.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:44:27.261
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:44:27.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:44:27.316
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Apr 22 19:44:27.358: INFO: created pod
    Apr 22 19:44:27.358: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-565" to be "Succeeded or Failed"
    Apr 22 19:44:27.373: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.735121ms
    Apr 22 19:44:29.383: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024904122s
    Apr 22 19:44:31.383: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024406295s
    STEP: Saw pod success 04/22/23 19:44:31.383
    Apr 22 19:44:31.383: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 22 19:45:01.384: INFO: polling logs
    Apr 22 19:45:01.416: INFO: Pod logs: 
    I0422 19:44:28.111270       1 log.go:195] OK: Got token
    I0422 19:44:28.111494       1 log.go:195] validating with in-cluster discovery
    I0422 19:44:28.112179       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0422 19:44:28.112332       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-565:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682193267, NotBefore:1682192667, IssuedAt:1682192667, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-565", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6ad413e7-bcad-436f-96fc-3b575e4c7754"}}}
    I0422 19:44:28.149432       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0422 19:44:28.165797       1 log.go:195] OK: Validated signature on JWT
    I0422 19:44:28.165999       1 log.go:195] OK: Got valid claims from token!
    I0422 19:44:28.166172       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-565:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682193267, NotBefore:1682192667, IssuedAt:1682192667, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-565", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6ad413e7-bcad-436f-96fc-3b575e4c7754"}}}

    Apr 22 19:45:01.416: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 19:45:01.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-565" for this suite. 04/22/23 19:45:01.439
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:45:01.46
Apr 22 19:45:01.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir-wrapper 04/22/23 19:45:01.464
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:01.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:01.542
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 22 19:45:01.578: INFO: Waiting up to 5m0s for pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552" in namespace "emptydir-wrapper-7609" to be "running and ready"
Apr 22 19:45:01.587: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552": Phase="Pending", Reason="", readiness=false. Elapsed: 8.408392ms
Apr 22 19:45:01.587: INFO: The phase of Pod pod-secrets-df05361c-6765-4871-9162-a45b800a1552 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:45:03.596: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552": Phase="Running", Reason="", readiness=true. Elapsed: 2.018230542s
Apr 22 19:45:03.597: INFO: The phase of Pod pod-secrets-df05361c-6765-4871-9162-a45b800a1552 is Running (Ready = true)
Apr 22 19:45:03.597: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/22/23 19:45:03.607
STEP: Cleaning up the configmap 04/22/23 19:45:03.624
STEP: Cleaning up the pod 04/22/23 19:45:03.636
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 22 19:45:03.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7609" for this suite. 04/22/23 19:45:03.674
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":168,"skipped":3005,"failed":0}
------------------------------
â€¢ [2.232 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:45:01.46
    Apr 22 19:45:01.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir-wrapper 04/22/23 19:45:01.464
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:01.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:01.542
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 22 19:45:01.578: INFO: Waiting up to 5m0s for pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552" in namespace "emptydir-wrapper-7609" to be "running and ready"
    Apr 22 19:45:01.587: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552": Phase="Pending", Reason="", readiness=false. Elapsed: 8.408392ms
    Apr 22 19:45:01.587: INFO: The phase of Pod pod-secrets-df05361c-6765-4871-9162-a45b800a1552 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:45:03.596: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552": Phase="Running", Reason="", readiness=true. Elapsed: 2.018230542s
    Apr 22 19:45:03.597: INFO: The phase of Pod pod-secrets-df05361c-6765-4871-9162-a45b800a1552 is Running (Ready = true)
    Apr 22 19:45:03.597: INFO: Pod "pod-secrets-df05361c-6765-4871-9162-a45b800a1552" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/22/23 19:45:03.607
    STEP: Cleaning up the configmap 04/22/23 19:45:03.624
    STEP: Cleaning up the pod 04/22/23 19:45:03.636
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:45:03.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7609" for this suite. 04/22/23 19:45:03.674
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:45:03.714
Apr 22 19:45:03.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename namespaces 04/22/23 19:45:03.717
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:03.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:03.763
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 04/22/23 19:45:03.771
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:03.82
STEP: Creating a service in the namespace 04/22/23 19:45:03.83
STEP: Deleting the namespace 04/22/23 19:45:03.873
STEP: Waiting for the namespace to be removed. 04/22/23 19:45:03.89
STEP: Recreating the namespace 04/22/23 19:45:09.904
STEP: Verifying there is no service in the namespace 04/22/23 19:45:09.963
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:45:09.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9660" for this suite. 04/22/23 19:45:09.982
STEP: Destroying namespace "nsdeletetest-6066" for this suite. 04/22/23 19:45:09.996
Apr 22 19:45:10.003: INFO: Namespace nsdeletetest-6066 was already deleted
STEP: Destroying namespace "nsdeletetest-4489" for this suite. 04/22/23 19:45:10.004
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":169,"skipped":3015,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.303 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:45:03.714
    Apr 22 19:45:03.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename namespaces 04/22/23 19:45:03.717
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:03.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:03.763
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 04/22/23 19:45:03.771
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:03.82
    STEP: Creating a service in the namespace 04/22/23 19:45:03.83
    STEP: Deleting the namespace 04/22/23 19:45:03.873
    STEP: Waiting for the namespace to be removed. 04/22/23 19:45:03.89
    STEP: Recreating the namespace 04/22/23 19:45:09.904
    STEP: Verifying there is no service in the namespace 04/22/23 19:45:09.963
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:45:09.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9660" for this suite. 04/22/23 19:45:09.982
    STEP: Destroying namespace "nsdeletetest-6066" for this suite. 04/22/23 19:45:09.996
    Apr 22 19:45:10.003: INFO: Namespace nsdeletetest-6066 was already deleted
    STEP: Destroying namespace "nsdeletetest-4489" for this suite. 04/22/23 19:45:10.004
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:45:10.024
Apr 22 19:45:10.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:45:10.028
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:10.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:10.086
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-cecfa95a-c433-42de-9aa6-08b6c19a5a42 04/22/23 19:45:10.094
STEP: Creating a pod to test consume configMaps 04/22/23 19:45:10.103
Apr 22 19:45:10.120: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d" in namespace "projected-4156" to be "Succeeded or Failed"
Apr 22 19:45:10.130: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.02182ms
Apr 22 19:45:12.142: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021354095s
Apr 22 19:45:14.144: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022990318s
STEP: Saw pod success 04/22/23 19:45:14.144
Apr 22 19:45:14.144: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d" satisfied condition "Succeeded or Failed"
Apr 22 19:45:14.159: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:45:14.18
Apr 22 19:45:14.216: INFO: Waiting for pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d to disappear
Apr 22 19:45:14.229: INFO: Pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 19:45:14.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4156" for this suite. 04/22/23 19:45:14.242
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":170,"skipped":3027,"failed":0}
------------------------------
â€¢ [4.236 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:45:10.024
    Apr 22 19:45:10.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:45:10.028
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:10.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:10.086
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-cecfa95a-c433-42de-9aa6-08b6c19a5a42 04/22/23 19:45:10.094
    STEP: Creating a pod to test consume configMaps 04/22/23 19:45:10.103
    Apr 22 19:45:10.120: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d" in namespace "projected-4156" to be "Succeeded or Failed"
    Apr 22 19:45:10.130: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.02182ms
    Apr 22 19:45:12.142: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021354095s
    Apr 22 19:45:14.144: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022990318s
    STEP: Saw pod success 04/22/23 19:45:14.144
    Apr 22 19:45:14.144: INFO: Pod "pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d" satisfied condition "Succeeded or Failed"
    Apr 22 19:45:14.159: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:45:14.18
    Apr 22 19:45:14.216: INFO: Waiting for pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d to disappear
    Apr 22 19:45:14.229: INFO: Pod pod-projected-configmaps-726cb7a4-9309-4704-b188-10126b06907d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 19:45:14.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4156" for this suite. 04/22/23 19:45:14.242
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:45:14.275
Apr 22 19:45:14.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:45:14.278
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:14.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:14.346
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/22/23 19:45:14.355
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/22/23 19:45:14.356
STEP: creating a pod to probe DNS 04/22/23 19:45:14.357
STEP: submitting the pod to kubernetes 04/22/23 19:45:14.357
Apr 22 19:45:14.386: INFO: Waiting up to 15m0s for pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c" in namespace "dns-7469" to be "running"
Apr 22 19:45:14.394: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.108065ms
Apr 22 19:45:16.403: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c": Phase="Running", Reason="", readiness=true. Elapsed: 2.016931276s
Apr 22 19:45:16.403: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:45:16.404
STEP: looking for the results for each expected name from probers 04/22/23 19:45:16.413
Apr 22 19:45:16.461: INFO: DNS probes using dns-7469/dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c succeeded

STEP: deleting the pod 04/22/23 19:45:16.461
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:45:16.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7469" for this suite. 04/22/23 19:45:16.531
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":171,"skipped":3031,"failed":0}
------------------------------
â€¢ [2.273 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:45:14.275
    Apr 22 19:45:14.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:45:14.278
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:14.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:14.346
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/22/23 19:45:14.355
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/22/23 19:45:14.356
    STEP: creating a pod to probe DNS 04/22/23 19:45:14.357
    STEP: submitting the pod to kubernetes 04/22/23 19:45:14.357
    Apr 22 19:45:14.386: INFO: Waiting up to 15m0s for pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c" in namespace "dns-7469" to be "running"
    Apr 22 19:45:14.394: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.108065ms
    Apr 22 19:45:16.403: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c": Phase="Running", Reason="", readiness=true. Elapsed: 2.016931276s
    Apr 22 19:45:16.403: INFO: Pod "dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:45:16.404
    STEP: looking for the results for each expected name from probers 04/22/23 19:45:16.413
    Apr 22 19:45:16.461: INFO: DNS probes using dns-7469/dns-test-b4b3ae7a-b725-4240-8e4b-4440425e5d5c succeeded

    STEP: deleting the pod 04/22/23 19:45:16.461
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:45:16.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7469" for this suite. 04/22/23 19:45:16.531
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:45:16.572
Apr 22 19:45:16.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 19:45:16.575
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:16.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:16.627
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1348 04/22/23 19:45:16.635
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 04/22/23 19:45:16.647
STEP: Creating stateful set ss in namespace statefulset-1348 04/22/23 19:45:16.666
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1348 04/22/23 19:45:16.68
Apr 22 19:45:16.688: INFO: Found 0 stateful pods, waiting for 1
Apr 22 19:45:26.701: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/22/23 19:45:26.702
Apr 22 19:45:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:45:27.088: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:45:27.088: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:45:27.088: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 19:45:27.103: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 22 19:45:37.116: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 19:45:37.116: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 19:45:37.203: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998963s
Apr 22 19:45:38.212: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984468905s
Apr 22 19:45:39.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975155389s
Apr 22 19:45:40.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.963348834s
Apr 22 19:45:41.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.949642765s
Apr 22 19:45:42.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.939641524s
Apr 22 19:45:43.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.928883005s
Apr 22 19:45:44.287: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.911795316s
Apr 22 19:45:45.297: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.900339015s
Apr 22 19:45:46.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 889.792008ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1348 04/22/23 19:45:47.308
Apr 22 19:45:47.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:45:47.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:45:47.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:45:47.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 19:45:47.696: INFO: Found 1 stateful pods, waiting for 3
Apr 22 19:45:57.710: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:45:57.710: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:45:57.710: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/22/23 19:45:57.71
STEP: Scale down will halt with unhealthy stateful pod 04/22/23 19:45:57.71
Apr 22 19:45:57.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:45:58.067: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:45:58.067: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:45:58.067: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 19:45:58.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:45:58.419: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:45:58.420: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:45:58.420: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 19:45:58.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 19:45:58.649: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 19:45:58.649: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 19:45:58.649: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 19:45:58.649: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 19:45:58.654: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 22 19:46:08.675: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 19:46:08.675: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 19:46:08.675: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 19:46:08.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999233s
Apr 22 19:46:09.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987560283s
Apr 22 19:46:10.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977029461s
Apr 22 19:46:11.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964380551s
Apr 22 19:46:12.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950207638s
Apr 22 19:46:13.779: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939793639s
Apr 22 19:46:14.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.924940769s
Apr 22 19:46:15.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.914165419s
Apr 22 19:46:16.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.901486926s
Apr 22 19:46:17.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 881.159032ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1348 04/22/23 19:46:18.836
Apr 22 19:46:18.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:46:19.118: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:46:19.118: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:46:19.118: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 19:46:19.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:46:19.444: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:46:19.445: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:46:19.445: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 19:46:19.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 19:46:19.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 19:46:19.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 19:46:19.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 19:46:19.713: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/22/23 19:46:29.753
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 19:46:29.755: INFO: Deleting all statefulset in ns statefulset-1348
Apr 22 19:46:29.762: INFO: Scaling statefulset ss to 0
Apr 22 19:46:29.790: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 19:46:29.798: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 19:46:29.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1348" for this suite. 04/22/23 19:46:29.853
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":172,"skipped":3058,"failed":0}
------------------------------
â€¢ [SLOW TEST] [73.299 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:45:16.572
    Apr 22 19:45:16.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 19:45:16.575
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:45:16.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:45:16.627
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1348 04/22/23 19:45:16.635
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/22/23 19:45:16.647
    STEP: Creating stateful set ss in namespace statefulset-1348 04/22/23 19:45:16.666
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1348 04/22/23 19:45:16.68
    Apr 22 19:45:16.688: INFO: Found 0 stateful pods, waiting for 1
    Apr 22 19:45:26.701: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/22/23 19:45:26.702
    Apr 22 19:45:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:45:27.088: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:45:27.088: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:45:27.088: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 19:45:27.103: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 22 19:45:37.116: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 19:45:37.116: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 19:45:37.203: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998963s
    Apr 22 19:45:38.212: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984468905s
    Apr 22 19:45:39.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975155389s
    Apr 22 19:45:40.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.963348834s
    Apr 22 19:45:41.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.949642765s
    Apr 22 19:45:42.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.939641524s
    Apr 22 19:45:43.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.928883005s
    Apr 22 19:45:44.287: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.911795316s
    Apr 22 19:45:45.297: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.900339015s
    Apr 22 19:45:46.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 889.792008ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1348 04/22/23 19:45:47.308
    Apr 22 19:45:47.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:45:47.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:45:47.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:45:47.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 19:45:47.696: INFO: Found 1 stateful pods, waiting for 3
    Apr 22 19:45:57.710: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:45:57.710: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:45:57.710: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/22/23 19:45:57.71
    STEP: Scale down will halt with unhealthy stateful pod 04/22/23 19:45:57.71
    Apr 22 19:45:57.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:45:58.067: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:45:58.067: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:45:58.067: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 19:45:58.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:45:58.419: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:45:58.420: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:45:58.420: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 19:45:58.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 19:45:58.649: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 19:45:58.649: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 19:45:58.649: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 19:45:58.649: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 19:45:58.654: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Apr 22 19:46:08.675: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 19:46:08.675: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 19:46:08.675: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 19:46:08.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999233s
    Apr 22 19:46:09.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987560283s
    Apr 22 19:46:10.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977029461s
    Apr 22 19:46:11.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964380551s
    Apr 22 19:46:12.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950207638s
    Apr 22 19:46:13.779: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939793639s
    Apr 22 19:46:14.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.924940769s
    Apr 22 19:46:15.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.914165419s
    Apr 22 19:46:16.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.901486926s
    Apr 22 19:46:17.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 881.159032ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1348 04/22/23 19:46:18.836
    Apr 22 19:46:18.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:46:19.118: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:46:19.118: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:46:19.118: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 19:46:19.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:46:19.444: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:46:19.445: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:46:19.445: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 19:46:19.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-1348 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 19:46:19.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 19:46:19.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 19:46:19.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 19:46:19.713: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/22/23 19:46:29.753
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 19:46:29.755: INFO: Deleting all statefulset in ns statefulset-1348
    Apr 22 19:46:29.762: INFO: Scaling statefulset ss to 0
    Apr 22 19:46:29.790: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 19:46:29.798: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 19:46:29.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1348" for this suite. 04/22/23 19:46:29.853
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:46:29.898
Apr 22 19:46:29.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:46:29.902
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:46:29.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:46:29.952
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/22/23 19:46:29.964
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:46:29.978
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:46:29.979
STEP: creating a pod to probe DNS 04/22/23 19:46:29.981
STEP: submitting the pod to kubernetes 04/22/23 19:46:29.981
Apr 22 19:46:30.001: INFO: Waiting up to 15m0s for pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f" in namespace "dns-2088" to be "running"
Apr 22 19:46:30.012: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.350214ms
Apr 22 19:46:32.024: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.02203821s
Apr 22 19:46:32.024: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:46:32.024
STEP: looking for the results for each expected name from probers 04/22/23 19:46:32.034
Apr 22 19:46:32.059: INFO: DNS probes using dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f succeeded

STEP: deleting the pod 04/22/23 19:46:32.059
STEP: changing the externalName to bar.example.com 04/22/23 19:46:32.096
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:46:32.122
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:46:32.123
STEP: creating a second pod to probe DNS 04/22/23 19:46:32.124
STEP: submitting the pod to kubernetes 04/22/23 19:46:32.125
Apr 22 19:46:32.142: INFO: Waiting up to 15m0s for pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f" in namespace "dns-2088" to be "running"
Apr 22 19:46:32.152: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.958042ms
Apr 22 19:46:34.163: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f": Phase="Running", Reason="", readiness=true. Elapsed: 2.02028739s
Apr 22 19:46:34.163: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:46:34.163
STEP: looking for the results for each expected name from probers 04/22/23 19:46:34.172
Apr 22 19:46:34.187: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:34.198: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:34.198: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:46:39.213: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:39.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:39.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:46:44.214: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:44.225: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:44.225: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:46:49.210: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:49.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:49.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:46:54.211: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:54.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:54.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:46:59.211: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:59.221: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 22 19:46:59.221: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

Apr 22 19:47:04.220: INFO: DNS probes using dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f succeeded

STEP: deleting the pod 04/22/23 19:47:04.22
STEP: changing the service to type=ClusterIP 04/22/23 19:47:04.252
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:47:04.316
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
 04/22/23 19:47:04.316
STEP: creating a third pod to probe DNS 04/22/23 19:47:04.317
STEP: submitting the pod to kubernetes 04/22/23 19:47:04.326
Apr 22 19:47:04.366: INFO: Waiting up to 15m0s for pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4" in namespace "dns-2088" to be "running"
Apr 22 19:47:04.380: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.673572ms
Apr 22 19:47:06.390: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.024013645s
Apr 22 19:47:06.390: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:47:06.39
STEP: looking for the results for each expected name from probers 04/22/23 19:47:06.399
Apr 22 19:47:06.432: INFO: DNS probes using dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4 succeeded

STEP: deleting the pod 04/22/23 19:47:06.432
STEP: deleting the test externalName service 04/22/23 19:47:06.476
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:47:06.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2088" for this suite. 04/22/23 19:47:06.541
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":173,"skipped":3075,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.656 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:46:29.898
    Apr 22 19:46:29.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:46:29.902
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:46:29.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:46:29.952
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/22/23 19:46:29.964
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:46:29.978
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:46:29.979
    STEP: creating a pod to probe DNS 04/22/23 19:46:29.981
    STEP: submitting the pod to kubernetes 04/22/23 19:46:29.981
    Apr 22 19:46:30.001: INFO: Waiting up to 15m0s for pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f" in namespace "dns-2088" to be "running"
    Apr 22 19:46:30.012: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.350214ms
    Apr 22 19:46:32.024: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.02203821s
    Apr 22 19:46:32.024: INFO: Pod "dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:46:32.024
    STEP: looking for the results for each expected name from probers 04/22/23 19:46:32.034
    Apr 22 19:46:32.059: INFO: DNS probes using dns-test-139a0979-202d-49b3-92a7-a5ae43f23a5f succeeded

    STEP: deleting the pod 04/22/23 19:46:32.059
    STEP: changing the externalName to bar.example.com 04/22/23 19:46:32.096
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:46:32.122
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:46:32.123
    STEP: creating a second pod to probe DNS 04/22/23 19:46:32.124
    STEP: submitting the pod to kubernetes 04/22/23 19:46:32.125
    Apr 22 19:46:32.142: INFO: Waiting up to 15m0s for pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f" in namespace "dns-2088" to be "running"
    Apr 22 19:46:32.152: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.958042ms
    Apr 22 19:46:34.163: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f": Phase="Running", Reason="", readiness=true. Elapsed: 2.02028739s
    Apr 22 19:46:34.163: INFO: Pod "dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:46:34.163
    STEP: looking for the results for each expected name from probers 04/22/23 19:46:34.172
    Apr 22 19:46:34.187: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:34.198: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:34.198: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:46:39.213: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:39.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:39.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:46:44.214: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:44.225: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:44.225: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:46:49.210: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:49.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:49.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:46:54.211: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:54.222: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:54.222: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:46:59.211: INFO: File wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:59.221: INFO: File jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local from pod  dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 22 19:46:59.221: INFO: Lookups using dns-2088/dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f failed for: [wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local]

    Apr 22 19:47:04.220: INFO: DNS probes using dns-test-f8d5de24-ffb9-4e61-9874-794a0329f08f succeeded

    STEP: deleting the pod 04/22/23 19:47:04.22
    STEP: changing the service to type=ClusterIP 04/22/23 19:47:04.252
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:47:04.316
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2088.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2088.svc.cluster.local; sleep 1; done
     04/22/23 19:47:04.316
    STEP: creating a third pod to probe DNS 04/22/23 19:47:04.317
    STEP: submitting the pod to kubernetes 04/22/23 19:47:04.326
    Apr 22 19:47:04.366: INFO: Waiting up to 15m0s for pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4" in namespace "dns-2088" to be "running"
    Apr 22 19:47:04.380: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.673572ms
    Apr 22 19:47:06.390: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.024013645s
    Apr 22 19:47:06.390: INFO: Pod "dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:47:06.39
    STEP: looking for the results for each expected name from probers 04/22/23 19:47:06.399
    Apr 22 19:47:06.432: INFO: DNS probes using dns-test-ee96be6c-91c7-4ced-bc49-1d5fe4e907b4 succeeded

    STEP: deleting the pod 04/22/23 19:47:06.432
    STEP: deleting the test externalName service 04/22/23 19:47:06.476
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:47:06.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2088" for this suite. 04/22/23 19:47:06.541
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:06.588
Apr 22 19:47:06.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:47:06.591
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:06.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:06.623
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:47:06.629
Apr 22 19:47:06.640: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098" in namespace "downward-api-2340" to be "Succeeded or Failed"
Apr 22 19:47:06.649: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Pending", Reason="", readiness=false. Elapsed: 8.542267ms
Apr 22 19:47:08.662: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021401357s
Apr 22 19:47:10.660: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019842798s
STEP: Saw pod success 04/22/23 19:47:10.66
Apr 22 19:47:10.661: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098" satisfied condition "Succeeded or Failed"
Apr 22 19:47:10.670: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 container client-container: <nil>
STEP: delete the pod 04/22/23 19:47:10.71
Apr 22 19:47:10.755: INFO: Waiting for pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 to disappear
Apr 22 19:47:10.766: INFO: Pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:47:10.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2340" for this suite. 04/22/23 19:47:10.776
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":174,"skipped":3092,"failed":0}
------------------------------
â€¢ [4.205 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:06.588
    Apr 22 19:47:06.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:47:06.591
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:06.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:06.623
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:47:06.629
    Apr 22 19:47:06.640: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098" in namespace "downward-api-2340" to be "Succeeded or Failed"
    Apr 22 19:47:06.649: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Pending", Reason="", readiness=false. Elapsed: 8.542267ms
    Apr 22 19:47:08.662: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021401357s
    Apr 22 19:47:10.660: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019842798s
    STEP: Saw pod success 04/22/23 19:47:10.66
    Apr 22 19:47:10.661: INFO: Pod "downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098" satisfied condition "Succeeded or Failed"
    Apr 22 19:47:10.670: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:47:10.71
    Apr 22 19:47:10.755: INFO: Waiting for pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 to disappear
    Apr 22 19:47:10.766: INFO: Pod downwardapi-volume-9d8d4c7e-497a-4798-8774-e55fdeee5098 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:47:10.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2340" for this suite. 04/22/23 19:47:10.776
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:10.801
Apr 22 19:47:10.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename hostport 04/22/23 19:47:10.805
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:10.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:10.88
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/22/23 19:47:10.901
Apr 22 19:47:10.932: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8989" to be "running and ready"
Apr 22 19:47:10.942: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.848782ms
Apr 22 19:47:10.942: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:47:12.956: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024488895s
Apr 22 19:47:12.956: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 22 19:47:12.956: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.1.1.165 on the node which pod1 resides and expect scheduled 04/22/23 19:47:12.956
Apr 22 19:47:12.981: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8989" to be "running and ready"
Apr 22 19:47:12.999: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.405749ms
Apr 22 19:47:12.999: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:47:15.009: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.027035987s
Apr 22 19:47:15.009: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 22 19:47:15.010: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.1.1.165 but use UDP protocol on the node which pod2 resides 04/22/23 19:47:15.01
Apr 22 19:47:15.032: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8989" to be "running and ready"
Apr 22 19:47:15.043: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128425ms
Apr 22 19:47:15.043: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:47:17.052: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019388453s
Apr 22 19:47:17.052: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 22 19:47:17.052: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 22 19:47:17.069: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8989" to be "running and ready"
Apr 22 19:47:17.114: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 45.67659ms
Apr 22 19:47:17.114: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:47:19.124: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.055395832s
Apr 22 19:47:19.125: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 22 19:47:19.125: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/22/23 19:47:19.135
Apr 22 19:47:19.136: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.1.1.165 http://127.0.0.1:54323/hostname] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:47:19.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:47:19.138: INFO: ExecWithOptions: Clientset creation
Apr 22 19:47:19.138: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.1.1.165+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.1.165, port: 54323 04/22/23 19:47:19.348
Apr 22 19:47:19.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.1.1.165:54323/hostname] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:47:19.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:47:19.349: INFO: ExecWithOptions: Clientset creation
Apr 22 19:47:19.349: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.1.1.165%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.1.165, port: 54323 UDP 04/22/23 19:47:19.501
Apr 22 19:47:19.501: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.1.1.165 54323] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:47:19.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:47:19.502: INFO: ExecWithOptions: Clientset creation
Apr 22 19:47:19.503: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.1.1.165+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Apr 22 19:47:24.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8989" for this suite. 04/22/23 19:47:24.673
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":175,"skipped":3114,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.894 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:10.801
    Apr 22 19:47:10.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename hostport 04/22/23 19:47:10.805
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:10.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:10.88
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/22/23 19:47:10.901
    Apr 22 19:47:10.932: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8989" to be "running and ready"
    Apr 22 19:47:10.942: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.848782ms
    Apr 22 19:47:10.942: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:47:12.956: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024488895s
    Apr 22 19:47:12.956: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 22 19:47:12.956: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.1.1.165 on the node which pod1 resides and expect scheduled 04/22/23 19:47:12.956
    Apr 22 19:47:12.981: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8989" to be "running and ready"
    Apr 22 19:47:12.999: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.405749ms
    Apr 22 19:47:12.999: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:47:15.009: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.027035987s
    Apr 22 19:47:15.009: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 22 19:47:15.010: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.1.1.165 but use UDP protocol on the node which pod2 resides 04/22/23 19:47:15.01
    Apr 22 19:47:15.032: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8989" to be "running and ready"
    Apr 22 19:47:15.043: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128425ms
    Apr 22 19:47:15.043: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:47:17.052: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019388453s
    Apr 22 19:47:17.052: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 22 19:47:17.052: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 22 19:47:17.069: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8989" to be "running and ready"
    Apr 22 19:47:17.114: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 45.67659ms
    Apr 22 19:47:17.114: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:47:19.124: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.055395832s
    Apr 22 19:47:19.125: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 22 19:47:19.125: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/22/23 19:47:19.135
    Apr 22 19:47:19.136: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.1.1.165 http://127.0.0.1:54323/hostname] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:47:19.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:47:19.138: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:47:19.138: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.1.1.165+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.1.165, port: 54323 04/22/23 19:47:19.348
    Apr 22 19:47:19.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.1.1.165:54323/hostname] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:47:19.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:47:19.349: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:47:19.349: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.1.1.165%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.1.1.165, port: 54323 UDP 04/22/23 19:47:19.501
    Apr 22 19:47:19.501: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.1.1.165 54323] Namespace:hostport-8989 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:47:19.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:47:19.502: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:47:19.503: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8989/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.1.1.165+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Apr 22 19:47:24.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-8989" for this suite. 04/22/23 19:47:24.673
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:24.707
Apr 22 19:47:24.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 19:47:24.712
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:24.766
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:24.774
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:47:24.782
Apr 22 19:47:24.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24" in namespace "downward-api-1995" to be "Succeeded or Failed"
Apr 22 19:47:24.819: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Pending", Reason="", readiness=false. Elapsed: 11.975752ms
Apr 22 19:47:26.829: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021584092s
Apr 22 19:47:28.828: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02070502s
STEP: Saw pod success 04/22/23 19:47:28.828
Apr 22 19:47:28.829: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24" satisfied condition "Succeeded or Failed"
Apr 22 19:47:28.837: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 container client-container: <nil>
STEP: delete the pod 04/22/23 19:47:28.853
Apr 22 19:47:28.882: INFO: Waiting for pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 to disappear
Apr 22 19:47:28.890: INFO: Pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 19:47:28.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1995" for this suite. 04/22/23 19:47:28.9
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":176,"skipped":3116,"failed":0}
------------------------------
â€¢ [4.208 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:24.707
    Apr 22 19:47:24.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 19:47:24.712
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:24.766
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:24.774
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:47:24.782
    Apr 22 19:47:24.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24" in namespace "downward-api-1995" to be "Succeeded or Failed"
    Apr 22 19:47:24.819: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Pending", Reason="", readiness=false. Elapsed: 11.975752ms
    Apr 22 19:47:26.829: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021584092s
    Apr 22 19:47:28.828: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02070502s
    STEP: Saw pod success 04/22/23 19:47:28.828
    Apr 22 19:47:28.829: INFO: Pod "downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24" satisfied condition "Succeeded or Failed"
    Apr 22 19:47:28.837: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:47:28.853
    Apr 22 19:47:28.882: INFO: Waiting for pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 to disappear
    Apr 22 19:47:28.890: INFO: Pod downwardapi-volume-42b8f4ee-9fee-497d-9500-99f3f2ad8a24 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 19:47:28.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1995" for this suite. 04/22/23 19:47:28.9
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:28.944
Apr 22 19:47:28.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 19:47:28.947
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:29.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:29.015
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/22/23 19:47:29.022
STEP: Wait for the Deployment to create new ReplicaSet 04/22/23 19:47:29.034
STEP: delete the deployment 04/22/23 19:47:29.548
STEP: wait for all rs to be garbage collected 04/22/23 19:47:29.564
STEP: expected 0 pods, got 2 pods 04/22/23 19:47:29.574
STEP: expected 0 rs, got 1 rs 04/22/23 19:47:29.596
STEP: Gathering metrics 04/22/23 19:47:30.115
Apr 22 19:47:30.165: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 19:47:30.171: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 5.246407ms
Apr 22 19:47:30.171: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 19:47:30.171: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 19:47:30.260: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 19:47:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7801" for this suite. 04/22/23 19:47:30.266
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":177,"skipped":3162,"failed":0}
------------------------------
â€¢ [1.331 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:28.944
    Apr 22 19:47:28.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 19:47:28.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:29.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:29.015
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/22/23 19:47:29.022
    STEP: Wait for the Deployment to create new ReplicaSet 04/22/23 19:47:29.034
    STEP: delete the deployment 04/22/23 19:47:29.548
    STEP: wait for all rs to be garbage collected 04/22/23 19:47:29.564
    STEP: expected 0 pods, got 2 pods 04/22/23 19:47:29.574
    STEP: expected 0 rs, got 1 rs 04/22/23 19:47:29.596
    STEP: Gathering metrics 04/22/23 19:47:30.115
    Apr 22 19:47:30.165: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 19:47:30.171: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 5.246407ms
    Apr 22 19:47:30.171: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 19:47:30.171: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 19:47:30.260: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 19:47:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7801" for this suite. 04/22/23 19:47:30.266
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:30.281
Apr 22 19:47:30.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename ingress 04/22/23 19:47:30.282
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:30.306
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:30.315
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/22/23 19:47:30.325
STEP: getting /apis/networking.k8s.io 04/22/23 19:47:30.33
STEP: getting /apis/networking.k8s.iov1 04/22/23 19:47:30.332
STEP: creating 04/22/23 19:47:30.334
STEP: getting 04/22/23 19:47:30.354
STEP: listing 04/22/23 19:47:30.362
STEP: watching 04/22/23 19:47:30.367
Apr 22 19:47:30.367: INFO: starting watch
STEP: cluster-wide listing 04/22/23 19:47:30.369
STEP: cluster-wide watching 04/22/23 19:47:30.373
Apr 22 19:47:30.373: INFO: starting watch
STEP: patching 04/22/23 19:47:30.375
STEP: updating 04/22/23 19:47:30.382
Apr 22 19:47:30.393: INFO: waiting for watch events with expected annotations
Apr 22 19:47:30.393: INFO: saw patched and updated annotations
STEP: patching /status 04/22/23 19:47:30.393
STEP: updating /status 04/22/23 19:47:30.4
STEP: get /status 04/22/23 19:47:30.414
STEP: deleting 04/22/23 19:47:30.418
STEP: deleting a collection 04/22/23 19:47:30.433
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Apr 22 19:47:30.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-6655" for this suite. 04/22/23 19:47:30.457
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":178,"skipped":3174,"failed":0}
------------------------------
â€¢ [0.186 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:30.281
    Apr 22 19:47:30.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename ingress 04/22/23 19:47:30.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:30.306
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:30.315
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/22/23 19:47:30.325
    STEP: getting /apis/networking.k8s.io 04/22/23 19:47:30.33
    STEP: getting /apis/networking.k8s.iov1 04/22/23 19:47:30.332
    STEP: creating 04/22/23 19:47:30.334
    STEP: getting 04/22/23 19:47:30.354
    STEP: listing 04/22/23 19:47:30.362
    STEP: watching 04/22/23 19:47:30.367
    Apr 22 19:47:30.367: INFO: starting watch
    STEP: cluster-wide listing 04/22/23 19:47:30.369
    STEP: cluster-wide watching 04/22/23 19:47:30.373
    Apr 22 19:47:30.373: INFO: starting watch
    STEP: patching 04/22/23 19:47:30.375
    STEP: updating 04/22/23 19:47:30.382
    Apr 22 19:47:30.393: INFO: waiting for watch events with expected annotations
    Apr 22 19:47:30.393: INFO: saw patched and updated annotations
    STEP: patching /status 04/22/23 19:47:30.393
    STEP: updating /status 04/22/23 19:47:30.4
    STEP: get /status 04/22/23 19:47:30.414
    STEP: deleting 04/22/23 19:47:30.418
    STEP: deleting a collection 04/22/23 19:47:30.433
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Apr 22 19:47:30.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-6655" for this suite. 04/22/23 19:47:30.457
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:30.482
Apr 22 19:47:30.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-runtime 04/22/23 19:47:30.485
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:30.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:30.519
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 04/22/23 19:47:30.524
STEP: wait for the container to reach Succeeded 04/22/23 19:47:30.535
STEP: get the container status 04/22/23 19:47:34.585
STEP: the container should be terminated 04/22/23 19:47:34.594
STEP: the termination message should be set 04/22/23 19:47:34.595
Apr 22 19:47:34.595: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/22/23 19:47:34.595
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 22 19:47:34.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5123" for this suite. 04/22/23 19:47:34.666
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":179,"skipped":3197,"failed":0}
------------------------------
â€¢ [4.208 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:30.482
    Apr 22 19:47:30.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-runtime 04/22/23 19:47:30.485
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:30.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:30.519
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 04/22/23 19:47:30.524
    STEP: wait for the container to reach Succeeded 04/22/23 19:47:30.535
    STEP: get the container status 04/22/23 19:47:34.585
    STEP: the container should be terminated 04/22/23 19:47:34.594
    STEP: the termination message should be set 04/22/23 19:47:34.595
    Apr 22 19:47:34.595: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/22/23 19:47:34.595
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 22 19:47:34.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5123" for this suite. 04/22/23 19:47:34.666
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:47:34.7
Apr 22 19:47:34.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename cronjob 04/22/23 19:47:34.705
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:34.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:34.766
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/22/23 19:47:34.776
STEP: Ensuring no jobs are scheduled 04/22/23 19:47:34.795
STEP: Ensuring no job exists by listing jobs explicitly 04/22/23 19:52:34.814
STEP: Removing cronjob 04/22/23 19:52:34.826
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 22 19:52:34.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7551" for this suite. 04/22/23 19:52:34.857
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":180,"skipped":3212,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.178 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:47:34.7
    Apr 22 19:47:34.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename cronjob 04/22/23 19:47:34.705
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:47:34.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:47:34.766
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/22/23 19:47:34.776
    STEP: Ensuring no jobs are scheduled 04/22/23 19:47:34.795
    STEP: Ensuring no job exists by listing jobs explicitly 04/22/23 19:52:34.814
    STEP: Removing cronjob 04/22/23 19:52:34.826
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 22 19:52:34.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7551" for this suite. 04/22/23 19:52:34.857
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:52:34.882
Apr 22 19:52:34.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 19:52:34.886
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:34.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:34.952
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Apr 22 19:52:35.017: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:52:35.03
Apr 22 19:52:35.042: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:35.042: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:35.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:52:35.051: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:52:36.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:36.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:36.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:52:36.076: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:52:37.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:37.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:37.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:52:37.076: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image. 04/22/23 19:52:37.122
STEP: Check that daemon pods images are updated. 04/22/23 19:52:37.157
Apr 22 19:52:37.168: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 22 19:52:37.168: INFO: Wrong image for pod: daemon-set-llqxf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 22 19:52:37.184: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:37.184: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:38.198: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 22 19:52:38.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:38.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:39.197: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 22 19:52:39.210: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:39.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:40.191: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 22 19:52:40.191: INFO: Pod daemon-set-j5fbl is not available
Apr 22 19:52:40.202: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:40.202: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:41.206: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:41.207: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:42.198: INFO: Pod daemon-set-6xcsc is not available
Apr 22 19:52:42.215: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:42.215: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 04/22/23 19:52:42.216
Apr 22 19:52:42.231: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:42.232: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:42.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:52:42.243: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:52:43.257: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:43.257: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:52:43.268: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:52:43.269: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:52:43.326
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1770, will wait for the garbage collector to delete the pods 04/22/23 19:52:43.327
Apr 22 19:52:43.406: INFO: Deleting DaemonSet.extensions daemon-set took: 19.89268ms
Apr 22 19:52:43.507: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.116077ms
Apr 22 19:52:46.117: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:52:46.118: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 19:52:46.127: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23506"},"items":null}

Apr 22 19:52:46.137: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23506"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:52:46.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1770" for this suite. 04/22/23 19:52:46.185
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":181,"skipped":3217,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.319 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:52:34.882
    Apr 22 19:52:34.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 19:52:34.886
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:34.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:34.952
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Apr 22 19:52:35.017: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:52:35.03
    Apr 22 19:52:35.042: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:35.042: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:35.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:52:35.051: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:52:36.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:36.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:36.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:52:36.076: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:52:37.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:37.066: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:37.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:52:37.076: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Update daemon pods image. 04/22/23 19:52:37.122
    STEP: Check that daemon pods images are updated. 04/22/23 19:52:37.157
    Apr 22 19:52:37.168: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 22 19:52:37.168: INFO: Wrong image for pod: daemon-set-llqxf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 22 19:52:37.184: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:37.184: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:38.198: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 22 19:52:38.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:38.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:39.197: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 22 19:52:39.210: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:39.211: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:40.191: INFO: Wrong image for pod: daemon-set-446ct. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 22 19:52:40.191: INFO: Pod daemon-set-j5fbl is not available
    Apr 22 19:52:40.202: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:40.202: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:41.206: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:41.207: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:42.198: INFO: Pod daemon-set-6xcsc is not available
    Apr 22 19:52:42.215: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:42.215: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 04/22/23 19:52:42.216
    Apr 22 19:52:42.231: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:42.232: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:42.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:52:42.243: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:52:43.257: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:43.257: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:52:43.268: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:52:43.269: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:52:43.326
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1770, will wait for the garbage collector to delete the pods 04/22/23 19:52:43.327
    Apr 22 19:52:43.406: INFO: Deleting DaemonSet.extensions daemon-set took: 19.89268ms
    Apr 22 19:52:43.507: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.116077ms
    Apr 22 19:52:46.117: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:52:46.118: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 19:52:46.127: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23506"},"items":null}

    Apr 22 19:52:46.137: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23506"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:52:46.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1770" for this suite. 04/22/23 19:52:46.185
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:52:46.213
Apr 22 19:52:46.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename namespaces 04/22/23 19:52:46.216
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:46.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:46.273
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 04/22/23 19:52:46.28
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:46.318
STEP: Creating a pod in the namespace 04/22/23 19:52:46.326
STEP: Waiting for the pod to have running status 04/22/23 19:52:46.342
Apr 22 19:52:46.343: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7496" to be "running"
Apr 22 19:52:46.351: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06891ms
Apr 22 19:52:48.366: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023586785s
Apr 22 19:52:48.367: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/22/23 19:52:48.367
STEP: Waiting for the namespace to be removed. 04/22/23 19:52:48.389
STEP: Recreating the namespace 04/22/23 19:52:59.398
STEP: Verifying there are no pods in the namespace 04/22/23 19:52:59.447
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:52:59.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1451" for this suite. 04/22/23 19:52:59.474
STEP: Destroying namespace "nsdeletetest-7496" for this suite. 04/22/23 19:52:59.505
Apr 22 19:52:59.523: INFO: Namespace nsdeletetest-7496 was already deleted
STEP: Destroying namespace "nsdeletetest-940" for this suite. 04/22/23 19:52:59.523
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":182,"skipped":3234,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.321 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:52:46.213
    Apr 22 19:52:46.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename namespaces 04/22/23 19:52:46.216
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:46.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:46.273
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 04/22/23 19:52:46.28
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:46.318
    STEP: Creating a pod in the namespace 04/22/23 19:52:46.326
    STEP: Waiting for the pod to have running status 04/22/23 19:52:46.342
    Apr 22 19:52:46.343: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7496" to be "running"
    Apr 22 19:52:46.351: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06891ms
    Apr 22 19:52:48.366: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023586785s
    Apr 22 19:52:48.367: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/22/23 19:52:48.367
    STEP: Waiting for the namespace to be removed. 04/22/23 19:52:48.389
    STEP: Recreating the namespace 04/22/23 19:52:59.398
    STEP: Verifying there are no pods in the namespace 04/22/23 19:52:59.447
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:52:59.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1451" for this suite. 04/22/23 19:52:59.474
    STEP: Destroying namespace "nsdeletetest-7496" for this suite. 04/22/23 19:52:59.505
    Apr 22 19:52:59.523: INFO: Namespace nsdeletetest-7496 was already deleted
    STEP: Destroying namespace "nsdeletetest-940" for this suite. 04/22/23 19:52:59.523
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:52:59.544
Apr 22 19:52:59.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:52:59.548
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:59.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:59.605
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Apr 22 19:52:59.632: INFO: Waiting up to 5m0s for pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732" in namespace "pods-3080" to be "running and ready"
Apr 22 19:52:59.642: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732": Phase="Pending", Reason="", readiness=false. Elapsed: 9.693975ms
Apr 22 19:52:59.643: INFO: The phase of Pod server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:53:01.659: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732": Phase="Running", Reason="", readiness=true. Elapsed: 2.026746318s
Apr 22 19:53:01.659: INFO: The phase of Pod server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732 is Running (Ready = true)
Apr 22 19:53:01.660: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732" satisfied condition "running and ready"
Apr 22 19:53:01.741: INFO: Waiting up to 5m0s for pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb" in namespace "pods-3080" to be "Succeeded or Failed"
Apr 22 19:53:01.754: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.397647ms
Apr 22 19:53:03.772: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030825992s
Apr 22 19:53:05.770: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02901255s
STEP: Saw pod success 04/22/23 19:53:05.77
Apr 22 19:53:05.770: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb" satisfied condition "Succeeded or Failed"
Apr 22 19:53:05.780: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb container env3cont: <nil>
STEP: delete the pod 04/22/23 19:53:05.835
Apr 22 19:53:05.868: INFO: Waiting for pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb to disappear
Apr 22 19:53:05.879: INFO: Pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:53:05.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3080" for this suite. 04/22/23 19:53:05.894
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":183,"skipped":3249,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.369 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:52:59.544
    Apr 22 19:52:59.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:52:59.548
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:52:59.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:52:59.605
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Apr 22 19:52:59.632: INFO: Waiting up to 5m0s for pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732" in namespace "pods-3080" to be "running and ready"
    Apr 22 19:52:59.642: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732": Phase="Pending", Reason="", readiness=false. Elapsed: 9.693975ms
    Apr 22 19:52:59.643: INFO: The phase of Pod server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:53:01.659: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732": Phase="Running", Reason="", readiness=true. Elapsed: 2.026746318s
    Apr 22 19:53:01.659: INFO: The phase of Pod server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732 is Running (Ready = true)
    Apr 22 19:53:01.660: INFO: Pod "server-envvars-881ebca9-f3e7-4bb6-a9f8-ef3bc11c4732" satisfied condition "running and ready"
    Apr 22 19:53:01.741: INFO: Waiting up to 5m0s for pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb" in namespace "pods-3080" to be "Succeeded or Failed"
    Apr 22 19:53:01.754: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.397647ms
    Apr 22 19:53:03.772: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030825992s
    Apr 22 19:53:05.770: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02901255s
    STEP: Saw pod success 04/22/23 19:53:05.77
    Apr 22 19:53:05.770: INFO: Pod "client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb" satisfied condition "Succeeded or Failed"
    Apr 22 19:53:05.780: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb container env3cont: <nil>
    STEP: delete the pod 04/22/23 19:53:05.835
    Apr 22 19:53:05.868: INFO: Waiting for pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb to disappear
    Apr 22 19:53:05.879: INFO: Pod client-envvars-c855e672-a599-4ac1-82c4-13aa9de5ccbb no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:53:05.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3080" for this suite. 04/22/23 19:53:05.894
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:05.928
Apr 22 19:53:05.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:53:05.931
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:05.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:05.993
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Apr 22 19:53:06.029: INFO: Waiting up to 5m0s for pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1" in namespace "svcaccounts-9347" to be "running"
Apr 22 19:53:06.038: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964601ms
Apr 22 19:53:08.047: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1": Phase="Running", Reason="", readiness=true. Elapsed: 2.018546078s
Apr 22 19:53:08.048: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1" satisfied condition "running"
STEP: reading a file in the container 04/22/23 19:53:08.048
Apr 22 19:53:08.048: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/22/23 19:53:08.364
Apr 22 19:53:08.364: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/22/23 19:53:08.691
Apr 22 19:53:08.691: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 22 19:53:09.013: INFO: Got root ca configmap in namespace "svcaccounts-9347"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 19:53:09.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9347" for this suite. 04/22/23 19:53:09.031
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":184,"skipped":3258,"failed":0}
------------------------------
â€¢ [3.132 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:05.928
    Apr 22 19:53:05.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:53:05.931
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:05.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:05.993
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Apr 22 19:53:06.029: INFO: Waiting up to 5m0s for pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1" in namespace "svcaccounts-9347" to be "running"
    Apr 22 19:53:06.038: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964601ms
    Apr 22 19:53:08.047: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1": Phase="Running", Reason="", readiness=true. Elapsed: 2.018546078s
    Apr 22 19:53:08.048: INFO: Pod "pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1" satisfied condition "running"
    STEP: reading a file in the container 04/22/23 19:53:08.048
    Apr 22 19:53:08.048: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/22/23 19:53:08.364
    Apr 22 19:53:08.364: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/22/23 19:53:08.691
    Apr 22 19:53:08.691: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9347 pod-service-account-ea452bda-7140-40b7-956a-6c6202246db1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 22 19:53:09.013: INFO: Got root ca configmap in namespace "svcaccounts-9347"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 19:53:09.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9347" for this suite. 04/22/23 19:53:09.031
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:09.078
Apr 22 19:53:09.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 19:53:09.081
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:09.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:09.157
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/22/23 19:53:09.164
Apr 22 19:53:09.183: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 22 19:53:14.192: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 19:53:14.192
STEP: getting scale subresource 04/22/23 19:53:14.193
STEP: updating a scale subresource 04/22/23 19:53:14.198
STEP: verifying the replicaset Spec.Replicas was modified 04/22/23 19:53:14.208
STEP: Patch a scale subresource 04/22/23 19:53:14.214
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 19:53:14.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6212" for this suite. 04/22/23 19:53:14.246
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":185,"skipped":3281,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.188 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:09.078
    Apr 22 19:53:09.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 19:53:09.081
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:09.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:09.157
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/22/23 19:53:09.164
    Apr 22 19:53:09.183: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 22 19:53:14.192: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 19:53:14.192
    STEP: getting scale subresource 04/22/23 19:53:14.193
    STEP: updating a scale subresource 04/22/23 19:53:14.198
    STEP: verifying the replicaset Spec.Replicas was modified 04/22/23 19:53:14.208
    STEP: Patch a scale subresource 04/22/23 19:53:14.214
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 19:53:14.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6212" for this suite. 04/22/23 19:53:14.246
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:14.287
Apr 22 19:53:14.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 19:53:14.291
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:14.364
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:14.369
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 in namespace container-probe-7085 04/22/23 19:53:14.376
Apr 22 19:53:14.391: INFO: Waiting up to 5m0s for pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025" in namespace "container-probe-7085" to be "not pending"
Apr 22 19:53:14.406: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025": Phase="Pending", Reason="", readiness=false. Elapsed: 15.229426ms
Apr 22 19:53:16.419: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025": Phase="Running", Reason="", readiness=true. Elapsed: 2.028183731s
Apr 22 19:53:16.420: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025" satisfied condition "not pending"
Apr 22 19:53:16.420: INFO: Started pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 in namespace container-probe-7085
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:53:16.42
Apr 22 19:53:16.427: INFO: Initial restart count of pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 is 0
Apr 22 19:53:36.547: INFO: Restart count of pod container-probe-7085/liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 is now 1 (20.120144215s elapsed)
STEP: deleting the pod 04/22/23 19:53:36.548
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 19:53:36.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7085" for this suite. 04/22/23 19:53:36.619
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":186,"skipped":3290,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.348 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:14.287
    Apr 22 19:53:14.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 19:53:14.291
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:14.364
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:14.369
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 in namespace container-probe-7085 04/22/23 19:53:14.376
    Apr 22 19:53:14.391: INFO: Waiting up to 5m0s for pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025" in namespace "container-probe-7085" to be "not pending"
    Apr 22 19:53:14.406: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025": Phase="Pending", Reason="", readiness=false. Elapsed: 15.229426ms
    Apr 22 19:53:16.419: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025": Phase="Running", Reason="", readiness=true. Elapsed: 2.028183731s
    Apr 22 19:53:16.420: INFO: Pod "liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025" satisfied condition "not pending"
    Apr 22 19:53:16.420: INFO: Started pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 in namespace container-probe-7085
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 19:53:16.42
    Apr 22 19:53:16.427: INFO: Initial restart count of pod liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 is 0
    Apr 22 19:53:36.547: INFO: Restart count of pod container-probe-7085/liveness-a93a1060-75ef-44cc-81ed-10d6a5eb9025 is now 1 (20.120144215s elapsed)
    STEP: deleting the pod 04/22/23 19:53:36.548
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 19:53:36.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7085" for this suite. 04/22/23 19:53:36.619
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:36.664
Apr 22 19:53:36.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:53:36.667
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:36.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:36.768
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-b1ca5b76-3193-434f-9af5-e6eb5eb0fd70 04/22/23 19:53:36.777
STEP: Creating a pod to test consume configMaps 04/22/23 19:53:36.792
Apr 22 19:53:36.822: INFO: Waiting up to 5m0s for pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8" in namespace "configmap-9498" to be "Succeeded or Failed"
Apr 22 19:53:36.830: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.719514ms
Apr 22 19:53:38.841: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019808297s
Apr 22 19:53:40.842: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019950839s
STEP: Saw pod success 04/22/23 19:53:40.842
Apr 22 19:53:40.842: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8" satisfied condition "Succeeded or Failed"
Apr 22 19:53:40.851: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 container configmap-volume-test: <nil>
STEP: delete the pod 04/22/23 19:53:40.868
Apr 22 19:53:40.909: INFO: Waiting for pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 to disappear
Apr 22 19:53:40.921: INFO: Pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:53:40.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9498" for this suite. 04/22/23 19:53:40.937
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":187,"skipped":3316,"failed":0}
------------------------------
â€¢ [4.289 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:36.664
    Apr 22 19:53:36.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:53:36.667
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:36.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:36.768
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-b1ca5b76-3193-434f-9af5-e6eb5eb0fd70 04/22/23 19:53:36.777
    STEP: Creating a pod to test consume configMaps 04/22/23 19:53:36.792
    Apr 22 19:53:36.822: INFO: Waiting up to 5m0s for pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8" in namespace "configmap-9498" to be "Succeeded or Failed"
    Apr 22 19:53:36.830: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.719514ms
    Apr 22 19:53:38.841: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019808297s
    Apr 22 19:53:40.842: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019950839s
    STEP: Saw pod success 04/22/23 19:53:40.842
    Apr 22 19:53:40.842: INFO: Pod "pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8" satisfied condition "Succeeded or Failed"
    Apr 22 19:53:40.851: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 container configmap-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:53:40.868
    Apr 22 19:53:40.909: INFO: Waiting for pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 to disappear
    Apr 22 19:53:40.921: INFO: Pod pod-configmaps-197ef79b-f9a7-4735-aa99-6ea8fec65fa8 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:53:40.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9498" for this suite. 04/22/23 19:53:40.937
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:40.976
Apr 22 19:53:40.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:53:40.977
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:41.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:41.035
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:53:41.071
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:53:41.626
STEP: Deploying the webhook pod 04/22/23 19:53:41.658
STEP: Wait for the deployment to be ready 04/22/23 19:53:41.691
Apr 22 19:53:41.712: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:53:43.742
STEP: Verifying the service has paired with the endpoint 04/22/23 19:53:43.798
Apr 22 19:53:44.799: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/22/23 19:53:44.809
STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:44.81
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/22/23 19:53:44.849
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/22/23 19:53:45.879
STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:45.88
STEP: Having no error when timeout is longer than webhook latency 04/22/23 19:53:46.957
STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:46.962
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/22/23 19:53:52.042
STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:52.043
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:53:57.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2581" for this suite. 04/22/23 19:53:57.129
STEP: Destroying namespace "webhook-2581-markers" for this suite. 04/22/23 19:53:57.147
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":188,"skipped":3366,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.302 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:40.976
    Apr 22 19:53:40.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:53:40.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:41.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:41.035
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:53:41.071
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:53:41.626
    STEP: Deploying the webhook pod 04/22/23 19:53:41.658
    STEP: Wait for the deployment to be ready 04/22/23 19:53:41.691
    Apr 22 19:53:41.712: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:53:43.742
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:53:43.798
    Apr 22 19:53:44.799: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/22/23 19:53:44.809
    STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:44.81
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/22/23 19:53:44.849
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/22/23 19:53:45.879
    STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:45.88
    STEP: Having no error when timeout is longer than webhook latency 04/22/23 19:53:46.957
    STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:46.962
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/22/23 19:53:52.042
    STEP: Registering slow webhook via the AdmissionRegistration API 04/22/23 19:53:52.043
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:53:57.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2581" for this suite. 04/22/23 19:53:57.129
    STEP: Destroying namespace "webhook-2581-markers" for this suite. 04/22/23 19:53:57.147
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:53:57.28
Apr 22 19:53:57.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:53:57.286
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:57.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:57.327
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3175 04/22/23 19:53:57.334
STEP: changing the ExternalName service to type=NodePort 04/22/23 19:53:57.34
STEP: creating replication controller externalname-service in namespace services-3175 04/22/23 19:53:57.378
I0422 19:53:57.386492      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3175, replica count: 2
I0422 19:54:00.439372      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:54:00.440: INFO: Creating new exec pod
Apr 22 19:54:00.458: INFO: Waiting up to 5m0s for pod "execpodlkmxv" in namespace "services-3175" to be "running"
Apr 22 19:54:00.471: INFO: Pod "execpodlkmxv": Phase="Pending", Reason="", readiness=false. Elapsed: 12.421206ms
Apr 22 19:54:02.478: INFO: Pod "execpodlkmxv": Phase="Running", Reason="", readiness=true. Elapsed: 2.019788434s
Apr 22 19:54:02.478: INFO: Pod "execpodlkmxv" satisfied condition "running"
Apr 22 19:54:03.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:03.789: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:03.790: INFO: stdout: ""
Apr 22 19:54:04.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:05.071: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:05.071: INFO: stdout: ""
Apr 22 19:54:05.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:06.035: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:06.035: INFO: stdout: ""
Apr 22 19:54:06.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:07.027: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:07.028: INFO: stdout: ""
Apr 22 19:54:07.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:08.077: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:08.077: INFO: stdout: ""
Apr 22 19:54:08.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:09.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:09.034: INFO: stdout: ""
Apr 22 19:54:09.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:10.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:10.044: INFO: stdout: ""
Apr 22 19:54:10.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:11.028: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:11.028: INFO: stdout: ""
Apr 22 19:54:11.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 22 19:54:12.075: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:12.075: INFO: stdout: "externalname-service-z9rcm"
Apr 22 19:54:12.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.129.155 80'
Apr 22 19:54:12.353: INFO: stderr: "+ nc -v -t -w 2 10.103.129.155 80\n+ echo hostName\nConnection to 10.103.129.155 80 port [tcp/http] succeeded!\n"
Apr 22 19:54:12.353: INFO: stdout: "externalname-service-z9rcm"
Apr 22 19:54:12.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 32765'
Apr 22 19:54:12.634: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 32765\n+ echo hostName\nConnection to 10.1.1.165 32765 port [tcp/*] succeeded!\n"
Apr 22 19:54:12.634: INFO: stdout: "externalname-service-488rz"
Apr 22 19:54:12.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32765'
Apr 22 19:54:12.893: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 32765\n+ echo hostName\nConnection to 10.1.1.128 32765 port [tcp/*] succeeded!\n"
Apr 22 19:54:12.893: INFO: stdout: ""
Apr 22 19:54:13.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32765'
Apr 22 19:54:14.215: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 32765\n+ echo hostName\nConnection to 10.1.1.128 32765 port [tcp/*] succeeded!\n"
Apr 22 19:54:14.215: INFO: stdout: "externalname-service-z9rcm"
Apr 22 19:54:14.215: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 19:54:14.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3175" for this suite. 04/22/23 19:54:14.305
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":189,"skipped":3378,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.039 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:53:57.28
    Apr 22 19:53:57.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:53:57.286
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:53:57.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:53:57.327
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-3175 04/22/23 19:53:57.334
    STEP: changing the ExternalName service to type=NodePort 04/22/23 19:53:57.34
    STEP: creating replication controller externalname-service in namespace services-3175 04/22/23 19:53:57.378
    I0422 19:53:57.386492      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3175, replica count: 2
    I0422 19:54:00.439372      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:54:00.440: INFO: Creating new exec pod
    Apr 22 19:54:00.458: INFO: Waiting up to 5m0s for pod "execpodlkmxv" in namespace "services-3175" to be "running"
    Apr 22 19:54:00.471: INFO: Pod "execpodlkmxv": Phase="Pending", Reason="", readiness=false. Elapsed: 12.421206ms
    Apr 22 19:54:02.478: INFO: Pod "execpodlkmxv": Phase="Running", Reason="", readiness=true. Elapsed: 2.019788434s
    Apr 22 19:54:02.478: INFO: Pod "execpodlkmxv" satisfied condition "running"
    Apr 22 19:54:03.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:03.789: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:03.790: INFO: stdout: ""
    Apr 22 19:54:04.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:05.071: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:05.071: INFO: stdout: ""
    Apr 22 19:54:05.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:06.035: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:06.035: INFO: stdout: ""
    Apr 22 19:54:06.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:07.027: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:07.028: INFO: stdout: ""
    Apr 22 19:54:07.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:08.077: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:08.077: INFO: stdout: ""
    Apr 22 19:54:08.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:09.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:09.034: INFO: stdout: ""
    Apr 22 19:54:09.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:10.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:10.044: INFO: stdout: ""
    Apr 22 19:54:10.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:11.028: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:11.028: INFO: stdout: ""
    Apr 22 19:54:11.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 22 19:54:12.075: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:12.075: INFO: stdout: "externalname-service-z9rcm"
    Apr 22 19:54:12.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.129.155 80'
    Apr 22 19:54:12.353: INFO: stderr: "+ nc -v -t -w 2 10.103.129.155 80\n+ echo hostName\nConnection to 10.103.129.155 80 port [tcp/http] succeeded!\n"
    Apr 22 19:54:12.353: INFO: stdout: "externalname-service-z9rcm"
    Apr 22 19:54:12.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 32765'
    Apr 22 19:54:12.634: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 32765\n+ echo hostName\nConnection to 10.1.1.165 32765 port [tcp/*] succeeded!\n"
    Apr 22 19:54:12.634: INFO: stdout: "externalname-service-488rz"
    Apr 22 19:54:12.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32765'
    Apr 22 19:54:12.893: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 32765\n+ echo hostName\nConnection to 10.1.1.128 32765 port [tcp/*] succeeded!\n"
    Apr 22 19:54:12.893: INFO: stdout: ""
    Apr 22 19:54:13.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3175 exec execpodlkmxv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 32765'
    Apr 22 19:54:14.215: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 32765\n+ echo hostName\nConnection to 10.1.1.128 32765 port [tcp/*] succeeded!\n"
    Apr 22 19:54:14.215: INFO: stdout: "externalname-service-z9rcm"
    Apr 22 19:54:14.215: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 19:54:14.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3175" for this suite. 04/22/23 19:54:14.305
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:14.321
Apr 22 19:54:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:54:14.327
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:14.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:14.373
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Apr 22 19:54:14.382: INFO: Got root ca configmap in namespace "svcaccounts-5101"
Apr 22 19:54:14.389: INFO: Deleted root ca configmap in namespace "svcaccounts-5101"
STEP: waiting for a new root ca configmap created 04/22/23 19:54:14.89
Apr 22 19:54:14.900: INFO: Recreated root ca configmap in namespace "svcaccounts-5101"
Apr 22 19:54:14.916: INFO: Updated root ca configmap in namespace "svcaccounts-5101"
STEP: waiting for the root ca configmap reconciled 04/22/23 19:54:15.417
Apr 22 19:54:15.427: INFO: Reconciled root ca configmap in namespace "svcaccounts-5101"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 19:54:15.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5101" for this suite. 04/22/23 19:54:15.439
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":190,"skipped":3385,"failed":0}
------------------------------
â€¢ [1.137 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:14.321
    Apr 22 19:54:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:54:14.327
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:14.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:14.373
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Apr 22 19:54:14.382: INFO: Got root ca configmap in namespace "svcaccounts-5101"
    Apr 22 19:54:14.389: INFO: Deleted root ca configmap in namespace "svcaccounts-5101"
    STEP: waiting for a new root ca configmap created 04/22/23 19:54:14.89
    Apr 22 19:54:14.900: INFO: Recreated root ca configmap in namespace "svcaccounts-5101"
    Apr 22 19:54:14.916: INFO: Updated root ca configmap in namespace "svcaccounts-5101"
    STEP: waiting for the root ca configmap reconciled 04/22/23 19:54:15.417
    Apr 22 19:54:15.427: INFO: Reconciled root ca configmap in namespace "svcaccounts-5101"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 19:54:15.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5101" for this suite. 04/22/23 19:54:15.439
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:15.494
Apr 22 19:54:15.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:54:15.497
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:15.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:15.558
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 04/22/23 19:54:15.567
Apr 22 19:54:15.586: INFO: Waiting up to 5m0s for pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745" in namespace "pods-6266" to be "running and ready"
Apr 22 19:54:15.595: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720847ms
Apr 22 19:54:15.595: INFO: The phase of Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:54:17.605: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745": Phase="Running", Reason="", readiness=true. Elapsed: 2.019210267s
Apr 22 19:54:17.606: INFO: The phase of Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 is Running (Ready = true)
Apr 22 19:54:17.606: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745" satisfied condition "running and ready"
Apr 22 19:54:17.628: INFO: Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 has hostIP: 10.1.1.128
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:54:17.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6266" for this suite. 04/22/23 19:54:17.643
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":191,"skipped":3422,"failed":0}
------------------------------
â€¢ [2.176 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:15.494
    Apr 22 19:54:15.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:54:15.497
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:15.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:15.558
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 04/22/23 19:54:15.567
    Apr 22 19:54:15.586: INFO: Waiting up to 5m0s for pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745" in namespace "pods-6266" to be "running and ready"
    Apr 22 19:54:15.595: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720847ms
    Apr 22 19:54:15.595: INFO: The phase of Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:54:17.605: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745": Phase="Running", Reason="", readiness=true. Elapsed: 2.019210267s
    Apr 22 19:54:17.606: INFO: The phase of Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 is Running (Ready = true)
    Apr 22 19:54:17.606: INFO: Pod "pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745" satisfied condition "running and ready"
    Apr 22 19:54:17.628: INFO: Pod pod-hostip-0113918e-ee57-4070-b9b2-9ca7d5d7b745 has hostIP: 10.1.1.128
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:54:17.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6266" for this suite. 04/22/23 19:54:17.643
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:17.68
Apr 22 19:54:17.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:54:17.683
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:17.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:17.744
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:54:17.764
Apr 22 19:54:17.790: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9205" to be "running and ready"
Apr 22 19:54:17.802: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.438893ms
Apr 22 19:54:17.803: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:54:19.810: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020215697s
Apr 22 19:54:19.811: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 22 19:54:19.811: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 04/22/23 19:54:19.817
Apr 22 19:54:19.826: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9205" to be "running and ready"
Apr 22 19:54:19.831: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.426951ms
Apr 22 19:54:19.831: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:54:21.837: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011013233s
Apr 22 19:54:21.838: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 22 19:54:21.838: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/22/23 19:54:21.844
Apr 22 19:54:21.858: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 22 19:54:21.864: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 22 19:54:23.866: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 22 19:54:23.878: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 22 19:54:25.866: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 22 19:54:25.876: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/22/23 19:54:25.877
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 22 19:54:25.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9205" for this suite. 04/22/23 19:54:25.913
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":192,"skipped":3424,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.253 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:17.68
    Apr 22 19:54:17.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 19:54:17.683
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:17.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:17.744
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/22/23 19:54:17.764
    Apr 22 19:54:17.790: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9205" to be "running and ready"
    Apr 22 19:54:17.802: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.438893ms
    Apr 22 19:54:17.803: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:54:19.810: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020215697s
    Apr 22 19:54:19.811: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 22 19:54:19.811: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 04/22/23 19:54:19.817
    Apr 22 19:54:19.826: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9205" to be "running and ready"
    Apr 22 19:54:19.831: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.426951ms
    Apr 22 19:54:19.831: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:54:21.837: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011013233s
    Apr 22 19:54:21.838: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 22 19:54:21.838: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/22/23 19:54:21.844
    Apr 22 19:54:21.858: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 22 19:54:21.864: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 22 19:54:23.866: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 22 19:54:23.878: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 22 19:54:25.866: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 22 19:54:25.876: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/22/23 19:54:25.877
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 22 19:54:25.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9205" for this suite. 04/22/23 19:54:25.913
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:25.959
Apr 22 19:54:25.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename namespaces 04/22/23 19:54:25.962
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.026
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 04/22/23 19:54:26.034
STEP: patching the Namespace 04/22/23 19:54:26.074
STEP: get the Namespace and ensuring it has the label 04/22/23 19:54:26.086
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:54:26.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-196" for this suite. 04/22/23 19:54:26.103
STEP: Destroying namespace "nspatchtest-78426b4e-3896-4d3c-a76c-fee04239c4c9-2101" for this suite. 04/22/23 19:54:26.117
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":193,"skipped":3455,"failed":0}
------------------------------
â€¢ [0.170 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:25.959
    Apr 22 19:54:25.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename namespaces 04/22/23 19:54:25.962
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.026
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 04/22/23 19:54:26.034
    STEP: patching the Namespace 04/22/23 19:54:26.074
    STEP: get the Namespace and ensuring it has the label 04/22/23 19:54:26.086
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:54:26.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-196" for this suite. 04/22/23 19:54:26.103
    STEP: Destroying namespace "nspatchtest-78426b4e-3896-4d3c-a76c-fee04239c4c9-2101" for this suite. 04/22/23 19:54:26.117
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:26.151
Apr 22 19:54:26.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 19:54:26.155
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.203
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Apr 22 19:54:26.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2716 version'
Apr 22 19:54:26.325: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 22 19:54:26.325: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 19:54:26.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2716" for this suite. 04/22/23 19:54:26.344
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":194,"skipped":3479,"failed":0}
------------------------------
â€¢ [0.217 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:26.151
    Apr 22 19:54:26.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 19:54:26.155
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.203
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Apr 22 19:54:26.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2716 version'
    Apr 22 19:54:26.325: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 22 19:54:26.325: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 19:54:26.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2716" for this suite. 04/22/23 19:54:26.344
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:26.369
Apr 22 19:54:26.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename lease-test 04/22/23 19:54:26.37
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.426
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Apr 22 19:54:26.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5803" for this suite. 04/22/23 19:54:26.594
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":195,"skipped":3488,"failed":0}
------------------------------
â€¢ [0.239 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:26.369
    Apr 22 19:54:26.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename lease-test 04/22/23 19:54:26.37
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.426
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Apr 22 19:54:26.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-5803" for this suite. 04/22/23 19:54:26.594
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:26.646
Apr 22 19:54:26.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:54:26.649
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.702
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Apr 22 19:54:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 19:54:29.688
Apr 22 19:54:29.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 create -f -'
Apr 22 19:54:30.882: INFO: stderr: ""
Apr 22 19:54:30.882: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 22 19:54:30.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 delete e2e-test-crd-publish-openapi-5354-crds test-cr'
Apr 22 19:54:31.029: INFO: stderr: ""
Apr 22 19:54:31.029: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 22 19:54:31.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 apply -f -'
Apr 22 19:54:32.215: INFO: stderr: ""
Apr 22 19:54:32.215: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 22 19:54:32.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 delete e2e-test-crd-publish-openapi-5354-crds test-cr'
Apr 22 19:54:32.295: INFO: stderr: ""
Apr 22 19:54:32.295: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/22/23 19:54:32.295
Apr 22 19:54:32.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 explain e2e-test-crd-publish-openapi-5354-crds'
Apr 22 19:54:32.522: INFO: stderr: ""
Apr 22 19:54:32.522: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5354-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:54:35.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2826" for this suite. 04/22/23 19:54:35.926
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":196,"skipped":3545,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.297 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:26.646
    Apr 22 19:54:26.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 19:54:26.649
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:26.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:26.702
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Apr 22 19:54:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 19:54:29.688
    Apr 22 19:54:29.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 create -f -'
    Apr 22 19:54:30.882: INFO: stderr: ""
    Apr 22 19:54:30.882: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 22 19:54:30.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 delete e2e-test-crd-publish-openapi-5354-crds test-cr'
    Apr 22 19:54:31.029: INFO: stderr: ""
    Apr 22 19:54:31.029: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 22 19:54:31.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 apply -f -'
    Apr 22 19:54:32.215: INFO: stderr: ""
    Apr 22 19:54:32.215: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 22 19:54:32.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 --namespace=crd-publish-openapi-2826 delete e2e-test-crd-publish-openapi-5354-crds test-cr'
    Apr 22 19:54:32.295: INFO: stderr: ""
    Apr 22 19:54:32.295: INFO: stdout: "e2e-test-crd-publish-openapi-5354-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/22/23 19:54:32.295
    Apr 22 19:54:32.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-2826 explain e2e-test-crd-publish-openapi-5354-crds'
    Apr 22 19:54:32.522: INFO: stderr: ""
    Apr 22 19:54:32.522: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5354-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:54:35.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2826" for this suite. 04/22/23 19:54:35.926
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:35.944
Apr 22 19:54:35.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:54:35.947
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:35.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:35.993
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-471f541c-d2c1-4be8-9704-2920c28006c0 04/22/23 19:54:36.01
STEP: Creating a pod to test consume secrets 04/22/23 19:54:36.018
Apr 22 19:54:36.035: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2" in namespace "projected-9576" to be "Succeeded or Failed"
Apr 22 19:54:36.044: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.06996ms
Apr 22 19:54:38.057: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021849788s
Apr 22 19:54:40.054: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01931903s
STEP: Saw pod success 04/22/23 19:54:40.054
Apr 22 19:54:40.055: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2" satisfied condition "Succeeded or Failed"
Apr 22 19:54:40.063: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:54:40.1
Apr 22 19:54:40.123: INFO: Waiting for pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 to disappear
Apr 22 19:54:40.129: INFO: Pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:54:40.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9576" for this suite. 04/22/23 19:54:40.14
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":197,"skipped":3547,"failed":0}
------------------------------
â€¢ [4.207 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:35.944
    Apr 22 19:54:35.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:54:35.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:35.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:35.993
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-471f541c-d2c1-4be8-9704-2920c28006c0 04/22/23 19:54:36.01
    STEP: Creating a pod to test consume secrets 04/22/23 19:54:36.018
    Apr 22 19:54:36.035: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2" in namespace "projected-9576" to be "Succeeded or Failed"
    Apr 22 19:54:36.044: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.06996ms
    Apr 22 19:54:38.057: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021849788s
    Apr 22 19:54:40.054: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01931903s
    STEP: Saw pod success 04/22/23 19:54:40.054
    Apr 22 19:54:40.055: INFO: Pod "pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2" satisfied condition "Succeeded or Failed"
    Apr 22 19:54:40.063: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:54:40.1
    Apr 22 19:54:40.123: INFO: Waiting for pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 to disappear
    Apr 22 19:54:40.129: INFO: Pod pod-projected-secrets-3a5ceedc-4c3a-426f-8769-98aba4d731e2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:54:40.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9576" for this suite. 04/22/23 19:54:40.14
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:40.168
Apr 22 19:54:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:54:40.172
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:40.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:40.217
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-c69a05d1-2f60-4feb-ae87-97890c94a6bc 04/22/23 19:54:40.226
STEP: Creating a pod to test consume secrets 04/22/23 19:54:40.236
Apr 22 19:54:40.253: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751" in namespace "projected-9993" to be "Succeeded or Failed"
Apr 22 19:54:40.264: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Pending", Reason="", readiness=false. Elapsed: 10.689386ms
Apr 22 19:54:42.273: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019312468s
Apr 22 19:54:44.273: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019944804s
STEP: Saw pod success 04/22/23 19:54:44.274
Apr 22 19:54:44.275: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751" satisfied condition "Succeeded or Failed"
Apr 22 19:54:44.282: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:54:44.298
Apr 22 19:54:44.330: INFO: Waiting for pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 to disappear
Apr 22 19:54:44.338: INFO: Pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 19:54:44.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9993" for this suite. 04/22/23 19:54:44.349
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":198,"skipped":3555,"failed":0}
------------------------------
â€¢ [4.203 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:40.168
    Apr 22 19:54:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:54:40.172
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:40.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:40.217
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-c69a05d1-2f60-4feb-ae87-97890c94a6bc 04/22/23 19:54:40.226
    STEP: Creating a pod to test consume secrets 04/22/23 19:54:40.236
    Apr 22 19:54:40.253: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751" in namespace "projected-9993" to be "Succeeded or Failed"
    Apr 22 19:54:40.264: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Pending", Reason="", readiness=false. Elapsed: 10.689386ms
    Apr 22 19:54:42.273: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019312468s
    Apr 22 19:54:44.273: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019944804s
    STEP: Saw pod success 04/22/23 19:54:44.274
    Apr 22 19:54:44.275: INFO: Pod "pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751" satisfied condition "Succeeded or Failed"
    Apr 22 19:54:44.282: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:54:44.298
    Apr 22 19:54:44.330: INFO: Waiting for pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 to disappear
    Apr 22 19:54:44.338: INFO: Pod pod-projected-secrets-c6fe2fe7-10ef-477e-92ca-6a7d52158751 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 19:54:44.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9993" for this suite. 04/22/23 19:54:44.349
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:54:44.38
Apr 22 19:54:44.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 19:54:44.383
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:44.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:44.429
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 04/22/23 19:54:44.438
STEP: waiting for pod running 04/22/23 19:54:44.459
Apr 22 19:54:44.459: INFO: Waiting up to 2m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000" to be "running"
Apr 22 19:54:44.472: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.87607ms
Apr 22 19:54:46.482: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.023410537s
Apr 22 19:54:46.483: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" satisfied condition "running"
STEP: creating a file in subpath 04/22/23 19:54:46.483
Apr 22 19:54:46.518: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7000 PodName:var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:54:46.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:54:46.521: INFO: ExecWithOptions: Clientset creation
Apr 22 19:54:46.522: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7000/pods/var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/22/23 19:54:46.679
Apr 22 19:54:46.684: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7000 PodName:var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 19:54:46.684: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 19:54:46.686: INFO: ExecWithOptions: Clientset creation
Apr 22 19:54:46.686: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7000/pods/var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/22/23 19:54:46.803
Apr 22 19:54:47.338: INFO: Successfully updated pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4"
STEP: waiting for annotated pod running 04/22/23 19:54:47.339
Apr 22 19:54:47.340: INFO: Waiting up to 2m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000" to be "running"
Apr 22 19:54:47.353: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Running", Reason="", readiness=true. Elapsed: 12.969801ms
Apr 22 19:54:47.354: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" satisfied condition "running"
STEP: deleting the pod gracefully 04/22/23 19:54:47.354
Apr 22 19:54:47.355: INFO: Deleting pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000"
Apr 22 19:54:47.376: INFO: Wait up to 5m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 19:55:21.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7000" for this suite. 04/22/23 19:55:21.428
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":199,"skipped":3572,"failed":0}
------------------------------
â€¢ [SLOW TEST] [37.064 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:54:44.38
    Apr 22 19:54:44.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 19:54:44.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:54:44.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:54:44.429
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 04/22/23 19:54:44.438
    STEP: waiting for pod running 04/22/23 19:54:44.459
    Apr 22 19:54:44.459: INFO: Waiting up to 2m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000" to be "running"
    Apr 22 19:54:44.472: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.87607ms
    Apr 22 19:54:46.482: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.023410537s
    Apr 22 19:54:46.483: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" satisfied condition "running"
    STEP: creating a file in subpath 04/22/23 19:54:46.483
    Apr 22 19:54:46.518: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7000 PodName:var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:54:46.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:54:46.521: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:54:46.522: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7000/pods/var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/22/23 19:54:46.679
    Apr 22 19:54:46.684: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7000 PodName:var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 19:54:46.684: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 19:54:46.686: INFO: ExecWithOptions: Clientset creation
    Apr 22 19:54:46.686: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7000/pods/var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/22/23 19:54:46.803
    Apr 22 19:54:47.338: INFO: Successfully updated pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4"
    STEP: waiting for annotated pod running 04/22/23 19:54:47.339
    Apr 22 19:54:47.340: INFO: Waiting up to 2m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000" to be "running"
    Apr 22 19:54:47.353: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4": Phase="Running", Reason="", readiness=true. Elapsed: 12.969801ms
    Apr 22 19:54:47.354: INFO: Pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" satisfied condition "running"
    STEP: deleting the pod gracefully 04/22/23 19:54:47.354
    Apr 22 19:54:47.355: INFO: Deleting pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" in namespace "var-expansion-7000"
    Apr 22 19:54:47.376: INFO: Wait up to 5m0s for pod "var-expansion-50ae2507-63ba-46ea-aea9-9525816ff4c4" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 19:55:21.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7000" for this suite. 04/22/23 19:55:21.428
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:55:21.446
Apr 22 19:55:21.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:55:21.449
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:55:21.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:55:21.508
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 04/22/23 19:55:21.515
STEP: Creating a ResourceQuota 04/22/23 19:55:26.524
STEP: Ensuring resource quota status is calculated 04/22/23 19:55:26.536
STEP: Creating a ReplicationController 04/22/23 19:55:28.546
STEP: Ensuring resource quota status captures replication controller creation 04/22/23 19:55:28.578
STEP: Deleting a ReplicationController 04/22/23 19:55:30.587
STEP: Ensuring resource quota status released usage 04/22/23 19:55:30.602
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:55:32.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8582" for this suite. 04/22/23 19:55:32.624
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":200,"skipped":3575,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.192 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:55:21.446
    Apr 22 19:55:21.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:55:21.449
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:55:21.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:55:21.508
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 04/22/23 19:55:21.515
    STEP: Creating a ResourceQuota 04/22/23 19:55:26.524
    STEP: Ensuring resource quota status is calculated 04/22/23 19:55:26.536
    STEP: Creating a ReplicationController 04/22/23 19:55:28.546
    STEP: Ensuring resource quota status captures replication controller creation 04/22/23 19:55:28.578
    STEP: Deleting a ReplicationController 04/22/23 19:55:30.587
    STEP: Ensuring resource quota status released usage 04/22/23 19:55:30.602
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:55:32.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8582" for this suite. 04/22/23 19:55:32.624
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:55:32.662
Apr 22 19:55:32.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption 04/22/23 19:55:32.665
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:55:32.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:55:32.759
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 22 19:55:32.806: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 19:56:32.898: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:56:32.906
Apr 22 19:56:32.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption-path 04/22/23 19:56:32.91
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:56:32.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:56:32.962
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 04/22/23 19:56:32.973
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 19:56:32.974
Apr 22 19:56:32.994: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4701" to be "running"
Apr 22 19:56:33.008: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 14.054768ms
Apr 22 19:56:35.017: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.022616416s
Apr 22 19:56:35.017: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 19:56:35.025
Apr 22 19:56:35.051: INFO: found a healthy node: cncf25-2-node-187aa4c0d96
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Apr 22 19:56:45.215: INFO: pods created so far: [1 1 1]
Apr 22 19:56:45.215: INFO: length of pods created so far: 3
Apr 22 19:56:47.245: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Apr 22 19:56:54.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4701" for this suite. 04/22/23 19:56:54.271
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:56:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3993" for this suite. 04/22/23 19:56:54.364
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":201,"skipped":3595,"failed":0}
------------------------------
â€¢ [SLOW TEST] [81.769 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:55:32.662
    Apr 22 19:55:32.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption 04/22/23 19:55:32.665
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:55:32.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:55:32.759
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 22 19:55:32.806: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 19:56:32.898: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:56:32.906
    Apr 22 19:56:32.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption-path 04/22/23 19:56:32.91
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:56:32.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:56:32.962
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 04/22/23 19:56:32.973
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 19:56:32.974
    Apr 22 19:56:32.994: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4701" to be "running"
    Apr 22 19:56:33.008: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 14.054768ms
    Apr 22 19:56:35.017: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.022616416s
    Apr 22 19:56:35.017: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 19:56:35.025
    Apr 22 19:56:35.051: INFO: found a healthy node: cncf25-2-node-187aa4c0d96
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Apr 22 19:56:45.215: INFO: pods created so far: [1 1 1]
    Apr 22 19:56:45.215: INFO: length of pods created so far: 3
    Apr 22 19:56:47.245: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Apr 22 19:56:54.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-4701" for this suite. 04/22/23 19:56:54.271
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:56:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3993" for this suite. 04/22/23 19:56:54.364
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:56:54.437
Apr 22 19:56:54.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 19:56:54.439
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:56:54.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:56:54.476
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6842 04/22/23 19:56:54.484
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Apr 22 19:56:54.524: INFO: Found 0 stateful pods, waiting for 1
Apr 22 19:57:04.535: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/22/23 19:57:04.552
W0422 19:57:04.582453      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 22 19:57:04.601: INFO: Found 1 stateful pods, waiting for 2
Apr 22 19:57:14.612: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 19:57:14.612: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/22/23 19:57:14.628
STEP: Delete all of the StatefulSets 04/22/23 19:57:14.636
STEP: Verify that StatefulSets have been deleted 04/22/23 19:57:14.652
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 19:57:14.660: INFO: Deleting all statefulset in ns statefulset-6842
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 19:57:14.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6842" for this suite. 04/22/23 19:57:14.706
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":202,"skipped":3605,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.296 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:56:54.437
    Apr 22 19:56:54.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 19:56:54.439
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:56:54.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:56:54.476
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6842 04/22/23 19:56:54.484
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Apr 22 19:56:54.524: INFO: Found 0 stateful pods, waiting for 1
    Apr 22 19:57:04.535: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/22/23 19:57:04.552
    W0422 19:57:04.582453      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 22 19:57:04.601: INFO: Found 1 stateful pods, waiting for 2
    Apr 22 19:57:14.612: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 19:57:14.612: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/22/23 19:57:14.628
    STEP: Delete all of the StatefulSets 04/22/23 19:57:14.636
    STEP: Verify that StatefulSets have been deleted 04/22/23 19:57:14.652
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 19:57:14.660: INFO: Deleting all statefulset in ns statefulset-6842
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 19:57:14.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6842" for this suite. 04/22/23 19:57:14.706
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:57:14.747
Apr 22 19:57:14.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 19:57:14.751
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:14.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:14.791
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-8b6fd710-73f7-439d-abd2-d0507828f14d 04/22/23 19:57:14.803
STEP: Creating a pod to test consume configMaps 04/22/23 19:57:14.822
Apr 22 19:57:14.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1" in namespace "configmap-2348" to be "Succeeded or Failed"
Apr 22 19:57:14.840: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.518003ms
Apr 22 19:57:16.852: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019230517s
Apr 22 19:57:18.848: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015286252s
STEP: Saw pod success 04/22/23 19:57:18.848
Apr 22 19:57:18.849: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1" satisfied condition "Succeeded or Failed"
Apr 22 19:57:18.856: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:57:18.893
Apr 22 19:57:18.918: INFO: Waiting for pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 to disappear
Apr 22 19:57:18.927: INFO: Pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 19:57:18.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2348" for this suite. 04/22/23 19:57:18.944
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":203,"skipped":3624,"failed":0}
------------------------------
â€¢ [4.214 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:57:14.747
    Apr 22 19:57:14.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 19:57:14.751
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:14.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:14.791
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-8b6fd710-73f7-439d-abd2-d0507828f14d 04/22/23 19:57:14.803
    STEP: Creating a pod to test consume configMaps 04/22/23 19:57:14.822
    Apr 22 19:57:14.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1" in namespace "configmap-2348" to be "Succeeded or Failed"
    Apr 22 19:57:14.840: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.518003ms
    Apr 22 19:57:16.852: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019230517s
    Apr 22 19:57:18.848: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015286252s
    STEP: Saw pod success 04/22/23 19:57:18.848
    Apr 22 19:57:18.849: INFO: Pod "pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1" satisfied condition "Succeeded or Failed"
    Apr 22 19:57:18.856: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:57:18.893
    Apr 22 19:57:18.918: INFO: Waiting for pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 to disappear
    Apr 22 19:57:18.927: INFO: Pod pod-configmaps-e5717237-8ed4-4440-8864-870f3ec069d1 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 19:57:18.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2348" for this suite. 04/22/23 19:57:18.944
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:57:18.981
Apr 22 19:57:18.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:57:18.984
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:19.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:19.035
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:57:19.069
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:57:20.379
STEP: Deploying the webhook pod 04/22/23 19:57:20.398
STEP: Wait for the deployment to be ready 04/22/23 19:57:20.413
Apr 22 19:57:20.423: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/22/23 19:57:22.447
STEP: Verifying the service has paired with the endpoint 04/22/23 19:57:22.51
Apr 22 19:57:23.511: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 04/22/23 19:57:23.52
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/22/23 19:57:23.578
STEP: Creating a configMap that should not be mutated 04/22/23 19:57:23.594
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/22/23 19:57:23.619
STEP: Creating a configMap that should be mutated 04/22/23 19:57:23.641
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:57:23.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3753" for this suite. 04/22/23 19:57:23.714
STEP: Destroying namespace "webhook-3753-markers" for this suite. 04/22/23 19:57:23.728
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":204,"skipped":3628,"failed":0}
------------------------------
â€¢ [4.843 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:57:18.981
    Apr 22 19:57:18.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:57:18.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:19.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:19.035
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:57:19.069
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:57:20.379
    STEP: Deploying the webhook pod 04/22/23 19:57:20.398
    STEP: Wait for the deployment to be ready 04/22/23 19:57:20.413
    Apr 22 19:57:20.423: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/22/23 19:57:22.447
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:57:22.51
    Apr 22 19:57:23.511: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 04/22/23 19:57:23.52
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/22/23 19:57:23.578
    STEP: Creating a configMap that should not be mutated 04/22/23 19:57:23.594
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/22/23 19:57:23.619
    STEP: Creating a configMap that should be mutated 04/22/23 19:57:23.641
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:57:23.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3753" for this suite. 04/22/23 19:57:23.714
    STEP: Destroying namespace "webhook-3753-markers" for this suite. 04/22/23 19:57:23.728
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:57:23.827
Apr 22 19:57:23.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 19:57:23.832
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:23.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:23.864
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 04/22/23 19:57:40.894
STEP: Creating a ResourceQuota 04/22/23 19:57:45.904
STEP: Ensuring resource quota status is calculated 04/22/23 19:57:45.919
STEP: Creating a ConfigMap 04/22/23 19:57:47.928
STEP: Ensuring resource quota status captures configMap creation 04/22/23 19:57:47.956
STEP: Deleting a ConfigMap 04/22/23 19:57:49.968
STEP: Ensuring resource quota status released usage 04/22/23 19:57:49.984
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 19:57:51.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3670" for this suite. 04/22/23 19:57:52.005
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":205,"skipped":3640,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.194 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:57:23.827
    Apr 22 19:57:23.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 19:57:23.832
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:23.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:23.864
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 04/22/23 19:57:40.894
    STEP: Creating a ResourceQuota 04/22/23 19:57:45.904
    STEP: Ensuring resource quota status is calculated 04/22/23 19:57:45.919
    STEP: Creating a ConfigMap 04/22/23 19:57:47.928
    STEP: Ensuring resource quota status captures configMap creation 04/22/23 19:57:47.956
    STEP: Deleting a ConfigMap 04/22/23 19:57:49.968
    STEP: Ensuring resource quota status released usage 04/22/23 19:57:49.984
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 19:57:51.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3670" for this suite. 04/22/23 19:57:52.005
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:57:52.041
Apr 22 19:57:52.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 19:57:52.045
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:52.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:52.087
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 04/22/23 19:57:52.136
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:57:52.15
Apr 22 19:57:52.160: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:52.160: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:52.169: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:57:52.169: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 19:57:53.180: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:53.181: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:53.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:57:53.189: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:57:54.179: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:54.179: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:54.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:57:54.188: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/22/23 19:57:54.195
Apr 22 19:57:54.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:54.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:54.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:57:54.239: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:57:55.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:55.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:55.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:57:55.259: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:57:56.265: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:56.265: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:56.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:57:56.280: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:57:57.247: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:57.248: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:57.254: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 22 19:57:57.254: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
Apr 22 19:57:58.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:58.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 19:57:58.260: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 19:57:58.261: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:57:58.269
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1767, will wait for the garbage collector to delete the pods 04/22/23 19:57:58.27
Apr 22 19:57:58.354: INFO: Deleting DaemonSet.extensions daemon-set took: 23.982905ms
Apr 22 19:57:58.455: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.396001ms
Apr 22 19:58:00.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 19:58:00.963: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 19:58:00.971: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25395"},"items":null}

Apr 22 19:58:00.981: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25395"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 19:58:01.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1767" for this suite. 04/22/23 19:58:01.025
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":206,"skipped":3661,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.999 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:57:52.041
    Apr 22 19:57:52.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 19:57:52.045
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:57:52.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:57:52.087
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 04/22/23 19:57:52.136
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 19:57:52.15
    Apr 22 19:57:52.160: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:52.160: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:52.169: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:57:52.169: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 19:57:53.180: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:53.181: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:53.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:57:53.189: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:57:54.179: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:54.179: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:54.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:57:54.188: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/22/23 19:57:54.195
    Apr 22 19:57:54.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:54.230: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:54.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:57:54.239: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:57:55.250: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:55.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:55.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:57:55.259: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:57:56.265: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:56.265: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:56.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:57:56.280: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:57:57.247: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:57.248: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:57.254: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 22 19:57:57.254: INFO: Node cncf25-2-node-187aa4c0d96 is running 0 daemon pod, expected 1
    Apr 22 19:57:58.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:58.251: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 19:57:58.260: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 19:57:58.261: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 19:57:58.269
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1767, will wait for the garbage collector to delete the pods 04/22/23 19:57:58.27
    Apr 22 19:57:58.354: INFO: Deleting DaemonSet.extensions daemon-set took: 23.982905ms
    Apr 22 19:57:58.455: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.396001ms
    Apr 22 19:58:00.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 19:58:00.963: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 19:58:00.971: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25395"},"items":null}

    Apr 22 19:58:00.981: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25395"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 19:58:01.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1767" for this suite. 04/22/23 19:58:01.025
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:01.046
Apr 22 19:58:01.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 19:58:01.051
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:01.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:01.111
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 19:58:01.162
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:58:01.884
STEP: Deploying the webhook pod 04/22/23 19:58:01.904
STEP: Wait for the deployment to be ready 04/22/23 19:58:01.929
Apr 22 19:58:01.954: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 19:58:03.979
STEP: Verifying the service has paired with the endpoint 04/22/23 19:58:04.024
Apr 22 19:58:05.024: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 04/22/23 19:58:05.034
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/22/23 19:58:05.039
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/22/23 19:58:05.039
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/22/23 19:58:05.04
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/22/23 19:58:05.043
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/22/23 19:58:05.044
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/22/23 19:58:05.048
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 19:58:05.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2355" for this suite. 04/22/23 19:58:05.061
STEP: Destroying namespace "webhook-2355-markers" for this suite. 04/22/23 19:58:05.079
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":207,"skipped":3666,"failed":0}
------------------------------
â€¢ [4.147 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:01.046
    Apr 22 19:58:01.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 19:58:01.051
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:01.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:01.111
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 19:58:01.162
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 19:58:01.884
    STEP: Deploying the webhook pod 04/22/23 19:58:01.904
    STEP: Wait for the deployment to be ready 04/22/23 19:58:01.929
    Apr 22 19:58:01.954: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 19:58:03.979
    STEP: Verifying the service has paired with the endpoint 04/22/23 19:58:04.024
    Apr 22 19:58:05.024: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 04/22/23 19:58:05.034
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/22/23 19:58:05.039
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/22/23 19:58:05.039
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/22/23 19:58:05.04
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/22/23 19:58:05.043
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/22/23 19:58:05.044
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/22/23 19:58:05.048
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 19:58:05.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2355" for this suite. 04/22/23 19:58:05.061
    STEP: Destroying namespace "webhook-2355-markers" for this suite. 04/22/23 19:58:05.079
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:05.224
Apr 22 19:58:05.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:58:05.226
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:05.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:05.25
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 04/22/23 19:58:05.254
Apr 22 19:58:05.261: INFO: Waiting up to 5m0s for pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5" in namespace "emptydir-3206" to be "Succeeded or Failed"
Apr 22 19:58:05.268: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.349723ms
Apr 22 19:58:07.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015208287s
Apr 22 19:58:09.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014617705s
STEP: Saw pod success 04/22/23 19:58:09.276
Apr 22 19:58:09.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5" satisfied condition "Succeeded or Failed"
Apr 22 19:58:09.284: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 container test-container: <nil>
STEP: delete the pod 04/22/23 19:58:09.308
Apr 22 19:58:09.370: INFO: Waiting for pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 to disappear
Apr 22 19:58:09.377: INFO: Pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:58:09.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3206" for this suite. 04/22/23 19:58:09.386
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":208,"skipped":3685,"failed":0}
------------------------------
â€¢ [4.172 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:05.224
    Apr 22 19:58:05.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:58:05.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:05.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:05.25
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/22/23 19:58:05.254
    Apr 22 19:58:05.261: INFO: Waiting up to 5m0s for pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5" in namespace "emptydir-3206" to be "Succeeded or Failed"
    Apr 22 19:58:05.268: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.349723ms
    Apr 22 19:58:07.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015208287s
    Apr 22 19:58:09.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014617705s
    STEP: Saw pod success 04/22/23 19:58:09.276
    Apr 22 19:58:09.276: INFO: Pod "pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5" satisfied condition "Succeeded or Failed"
    Apr 22 19:58:09.284: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:58:09.308
    Apr 22 19:58:09.370: INFO: Waiting for pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 to disappear
    Apr 22 19:58:09.377: INFO: Pod pod-f4fab426-9f16-41da-bcf2-f3b539aa4be5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:58:09.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3206" for this suite. 04/22/23 19:58:09.386
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:09.439
Apr 22 19:58:09.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 19:58:09.442
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:09.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:09.472
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 04/22/23 19:58:09.479
Apr 22 19:58:09.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435" in namespace "projected-4948" to be "Succeeded or Failed"
Apr 22 19:58:09.505: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Pending", Reason="", readiness=false. Elapsed: 9.27201ms
Apr 22 19:58:11.517: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021853607s
Apr 22 19:58:13.513: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01786315s
STEP: Saw pod success 04/22/23 19:58:13.513
Apr 22 19:58:13.514: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435" satisfied condition "Succeeded or Failed"
Apr 22 19:58:13.521: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 container client-container: <nil>
STEP: delete the pod 04/22/23 19:58:13.535
Apr 22 19:58:13.569: INFO: Waiting for pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 to disappear
Apr 22 19:58:13.580: INFO: Pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 19:58:13.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4948" for this suite. 04/22/23 19:58:13.593
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":209,"skipped":3734,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:09.439
    Apr 22 19:58:09.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 19:58:09.442
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:09.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:09.472
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 04/22/23 19:58:09.479
    Apr 22 19:58:09.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435" in namespace "projected-4948" to be "Succeeded or Failed"
    Apr 22 19:58:09.505: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Pending", Reason="", readiness=false. Elapsed: 9.27201ms
    Apr 22 19:58:11.517: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021853607s
    Apr 22 19:58:13.513: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01786315s
    STEP: Saw pod success 04/22/23 19:58:13.513
    Apr 22 19:58:13.514: INFO: Pod "downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435" satisfied condition "Succeeded or Failed"
    Apr 22 19:58:13.521: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 container client-container: <nil>
    STEP: delete the pod 04/22/23 19:58:13.535
    Apr 22 19:58:13.569: INFO: Waiting for pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 to disappear
    Apr 22 19:58:13.580: INFO: Pod downwardapi-volume-b7932298-c380-40ca-b10d-597ab763c435 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 19:58:13.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4948" for this suite. 04/22/23 19:58:13.593
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:13.628
Apr 22 19:58:13.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 19:58:13.631
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:13.677
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:13.687
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/22/23 19:58:13.695
Apr 22 19:58:13.713: INFO: Waiting up to 5m0s for pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a" in namespace "emptydir-1804" to be "Succeeded or Failed"
Apr 22 19:58:13.720: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604614ms
Apr 22 19:58:15.727: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014017769s
Apr 22 19:58:17.728: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015181442s
STEP: Saw pod success 04/22/23 19:58:17.728
Apr 22 19:58:17.729: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a" satisfied condition "Succeeded or Failed"
Apr 22 19:58:17.736: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a container test-container: <nil>
STEP: delete the pod 04/22/23 19:58:17.751
Apr 22 19:58:17.787: INFO: Waiting for pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a to disappear
Apr 22 19:58:17.794: INFO: Pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 19:58:17.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1804" for this suite. 04/22/23 19:58:17.804
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":210,"skipped":3758,"failed":0}
------------------------------
â€¢ [4.190 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:13.628
    Apr 22 19:58:13.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 19:58:13.631
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:13.677
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:13.687
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/22/23 19:58:13.695
    Apr 22 19:58:13.713: INFO: Waiting up to 5m0s for pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a" in namespace "emptydir-1804" to be "Succeeded or Failed"
    Apr 22 19:58:13.720: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604614ms
    Apr 22 19:58:15.727: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014017769s
    Apr 22 19:58:17.728: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015181442s
    STEP: Saw pod success 04/22/23 19:58:17.728
    Apr 22 19:58:17.729: INFO: Pod "pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a" satisfied condition "Succeeded or Failed"
    Apr 22 19:58:17.736: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a container test-container: <nil>
    STEP: delete the pod 04/22/23 19:58:17.751
    Apr 22 19:58:17.787: INFO: Waiting for pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a to disappear
    Apr 22 19:58:17.794: INFO: Pod pod-4c130bc4-0c90-4fc5-99c3-33eda63c2a3a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 19:58:17.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1804" for this suite. 04/22/23 19:58:17.804
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:17.839
Apr 22 19:58:17.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:58:17.842
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:17.883
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:17.891
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-59146a1f-7206-4bad-b851-0656b8e1a29d 04/22/23 19:58:17.9
STEP: Creating a pod to test consume secrets 04/22/23 19:58:17.909
Apr 22 19:58:17.925: INFO: Waiting up to 5m0s for pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36" in namespace "secrets-8073" to be "Succeeded or Failed"
Apr 22 19:58:17.936: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.690072ms
Apr 22 19:58:19.946: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020977553s
Apr 22 19:58:21.944: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019442441s
STEP: Saw pod success 04/22/23 19:58:21.944
Apr 22 19:58:21.945: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36" satisfied condition "Succeeded or Failed"
Apr 22 19:58:21.955: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 19:58:21.973
Apr 22 19:58:22.017: INFO: Waiting for pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 to disappear
Apr 22 19:58:22.023: INFO: Pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:58:22.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8073" for this suite. 04/22/23 19:58:22.036
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":211,"skipped":3769,"failed":0}
------------------------------
â€¢ [4.210 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:17.839
    Apr 22 19:58:17.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:58:17.842
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:17.883
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:17.891
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-59146a1f-7206-4bad-b851-0656b8e1a29d 04/22/23 19:58:17.9
    STEP: Creating a pod to test consume secrets 04/22/23 19:58:17.909
    Apr 22 19:58:17.925: INFO: Waiting up to 5m0s for pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36" in namespace "secrets-8073" to be "Succeeded or Failed"
    Apr 22 19:58:17.936: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.690072ms
    Apr 22 19:58:19.946: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020977553s
    Apr 22 19:58:21.944: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019442441s
    STEP: Saw pod success 04/22/23 19:58:21.944
    Apr 22 19:58:21.945: INFO: Pod "pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36" satisfied condition "Succeeded or Failed"
    Apr 22 19:58:21.955: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 19:58:21.973
    Apr 22 19:58:22.017: INFO: Waiting for pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 to disappear
    Apr 22 19:58:22.023: INFO: Pod pod-secrets-99aa185e-0363-4f46-bc73-8413ed78ca36 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:58:22.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8073" for this suite. 04/22/23 19:58:22.036
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:22.071
Apr 22 19:58:22.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 19:58:22.074
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:22.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:22.113
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Apr 22 19:58:22.140: INFO: Waiting up to 5m0s for pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686" in namespace "container-probe-2102" to be "running and ready"
Apr 22 19:58:22.154: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Pending", Reason="", readiness=false. Elapsed: 14.502692ms
Apr 22 19:58:22.154: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:58:24.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 2.025388336s
Apr 22 19:58:24.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:26.166: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 4.025975844s
Apr 22 19:58:26.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:28.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 6.025306308s
Apr 22 19:58:28.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:30.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 8.02580888s
Apr 22 19:58:30.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:32.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 10.024249223s
Apr 22 19:58:32.164: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:34.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 12.02406082s
Apr 22 19:58:34.164: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:36.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 14.025091734s
Apr 22 19:58:36.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:38.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 16.025745138s
Apr 22 19:58:38.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:40.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 18.025154102s
Apr 22 19:58:40.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:42.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 20.024843586s
Apr 22 19:58:42.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
Apr 22 19:58:44.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=true. Elapsed: 22.025231639s
Apr 22 19:58:44.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = true)
Apr 22 19:58:44.166: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686" satisfied condition "running and ready"
Apr 22 19:58:44.175: INFO: Container started at 2023-04-22 19:58:22 +0000 UTC, pod became ready at 2023-04-22 19:58:42 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 19:58:44.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2102" for this suite. 04/22/23 19:58:44.191
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":212,"skipped":3793,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.137 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:22.071
    Apr 22 19:58:22.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 19:58:22.074
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:22.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:22.113
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Apr 22 19:58:22.140: INFO: Waiting up to 5m0s for pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686" in namespace "container-probe-2102" to be "running and ready"
    Apr 22 19:58:22.154: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Pending", Reason="", readiness=false. Elapsed: 14.502692ms
    Apr 22 19:58:22.154: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:58:24.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 2.025388336s
    Apr 22 19:58:24.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:26.166: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 4.025975844s
    Apr 22 19:58:26.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:28.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 6.025306308s
    Apr 22 19:58:28.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:30.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 8.02580888s
    Apr 22 19:58:30.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:32.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 10.024249223s
    Apr 22 19:58:32.164: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:34.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 12.02406082s
    Apr 22 19:58:34.164: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:36.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 14.025091734s
    Apr 22 19:58:36.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:38.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 16.025745138s
    Apr 22 19:58:38.166: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:40.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 18.025154102s
    Apr 22 19:58:40.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:42.164: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=false. Elapsed: 20.024843586s
    Apr 22 19:58:42.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = false)
    Apr 22 19:58:44.165: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686": Phase="Running", Reason="", readiness=true. Elapsed: 22.025231639s
    Apr 22 19:58:44.165: INFO: The phase of Pod test-webserver-5164b80b-36db-4e29-8c27-52de9795e686 is Running (Ready = true)
    Apr 22 19:58:44.166: INFO: Pod "test-webserver-5164b80b-36db-4e29-8c27-52de9795e686" satisfied condition "running and ready"
    Apr 22 19:58:44.175: INFO: Container started at 2023-04-22 19:58:22 +0000 UTC, pod became ready at 2023-04-22 19:58:42 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 19:58:44.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2102" for this suite. 04/22/23 19:58:44.191
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:44.219
Apr 22 19:58:44.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename init-container 04/22/23 19:58:44.222
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:44.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:44.278
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 04/22/23 19:58:44.287
Apr 22 19:58:44.287: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 19:58:50.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4228" for this suite. 04/22/23 19:58:50.188
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":213,"skipped":3809,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.979 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:44.219
    Apr 22 19:58:44.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename init-container 04/22/23 19:58:44.222
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:44.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:44.278
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 04/22/23 19:58:44.287
    Apr 22 19:58:44.287: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 19:58:50.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-4228" for this suite. 04/22/23 19:58:50.188
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:50.223
Apr 22 19:58:50.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:58:50.226
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:50.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:50.269
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Apr 22 19:58:50.311: INFO: created pod pod-service-account-defaultsa
Apr 22 19:58:50.311: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 22 19:58:50.321: INFO: created pod pod-service-account-mountsa
Apr 22 19:58:50.321: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 22 19:58:50.340: INFO: created pod pod-service-account-nomountsa
Apr 22 19:58:50.341: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 22 19:58:50.352: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 22 19:58:50.352: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 22 19:58:50.362: INFO: created pod pod-service-account-mountsa-mountspec
Apr 22 19:58:50.364: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 22 19:58:50.379: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 22 19:58:50.379: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 22 19:58:50.388: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 22 19:58:50.388: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 22 19:58:50.399: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 22 19:58:50.399: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 22 19:58:50.409: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 22 19:58:50.409: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 19:58:50.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-551" for this suite. 04/22/23 19:58:50.431
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":214,"skipped":3849,"failed":0}
------------------------------
â€¢ [0.235 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:50.223
    Apr 22 19:58:50.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 19:58:50.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:50.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:50.269
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Apr 22 19:58:50.311: INFO: created pod pod-service-account-defaultsa
    Apr 22 19:58:50.311: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 22 19:58:50.321: INFO: created pod pod-service-account-mountsa
    Apr 22 19:58:50.321: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 22 19:58:50.340: INFO: created pod pod-service-account-nomountsa
    Apr 22 19:58:50.341: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 22 19:58:50.352: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 22 19:58:50.352: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 22 19:58:50.362: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 22 19:58:50.364: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 22 19:58:50.379: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 22 19:58:50.379: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 22 19:58:50.388: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 22 19:58:50.388: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 22 19:58:50.399: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 22 19:58:50.399: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 22 19:58:50.409: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 22 19:58:50.409: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 19:58:50.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-551" for this suite. 04/22/23 19:58:50.431
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:50.481
Apr 22 19:58:50.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:58:50.482
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:50.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:50.517
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8646.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8646.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/22/23 19:58:50.522
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8646.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8646.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/22/23 19:58:50.522
STEP: creating a pod to probe /etc/hosts 04/22/23 19:58:50.522
STEP: submitting the pod to kubernetes 04/22/23 19:58:50.522
Apr 22 19:58:50.531: INFO: Waiting up to 15m0s for pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464" in namespace "dns-8646" to be "running"
Apr 22 19:58:50.534: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.972325ms
Apr 22 19:58:52.545: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013723205s
Apr 22 19:58:54.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012849696s
Apr 22 19:58:56.541: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009856485s
Apr 22 19:58:58.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Running", Reason="", readiness=true. Elapsed: 8.012396028s
Apr 22 19:58:58.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:58:58.545
STEP: looking for the results for each expected name from probers 04/22/23 19:58:58.554
Apr 22 19:58:58.598: INFO: DNS probes using dns-8646/dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464 succeeded

STEP: deleting the pod 04/22/23 19:58:58.599
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:58:58.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8646" for this suite. 04/22/23 19:58:58.655
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":215,"skipped":3885,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.184 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:50.481
    Apr 22 19:58:50.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:58:50.482
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:50.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:50.517
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8646.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8646.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/22/23 19:58:50.522
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8646.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8646.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/22/23 19:58:50.522
    STEP: creating a pod to probe /etc/hosts 04/22/23 19:58:50.522
    STEP: submitting the pod to kubernetes 04/22/23 19:58:50.522
    Apr 22 19:58:50.531: INFO: Waiting up to 15m0s for pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464" in namespace "dns-8646" to be "running"
    Apr 22 19:58:50.534: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.972325ms
    Apr 22 19:58:52.545: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013723205s
    Apr 22 19:58:54.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012849696s
    Apr 22 19:58:56.541: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009856485s
    Apr 22 19:58:58.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464": Phase="Running", Reason="", readiness=true. Elapsed: 8.012396028s
    Apr 22 19:58:58.544: INFO: Pod "dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:58:58.545
    STEP: looking for the results for each expected name from probers 04/22/23 19:58:58.554
    Apr 22 19:58:58.598: INFO: DNS probes using dns-8646/dns-test-cf307db0-5bac-4ac4-b906-dc310f26c464 succeeded

    STEP: deleting the pod 04/22/23 19:58:58.599
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:58:58.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8646" for this suite. 04/22/23 19:58:58.655
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:58:58.711
Apr 22 19:58:58.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename containers 04/22/23 19:58:58.714
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:58.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:58.745
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 04/22/23 19:58:58.752
Apr 22 19:58:58.768: INFO: Waiting up to 5m0s for pod "client-containers-e2312e50-4815-417a-8908-8470c1606101" in namespace "containers-6760" to be "Succeeded or Failed"
Apr 22 19:58:58.781: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Pending", Reason="", readiness=false. Elapsed: 13.189071ms
Apr 22 19:59:00.791: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022738845s
Apr 22 19:59:02.790: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022271605s
STEP: Saw pod success 04/22/23 19:59:02.79
Apr 22 19:59:02.791: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101" satisfied condition "Succeeded or Failed"
Apr 22 19:59:02.799: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod client-containers-e2312e50-4815-417a-8908-8470c1606101 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 19:59:02.844
Apr 22 19:59:02.877: INFO: Waiting for pod client-containers-e2312e50-4815-417a-8908-8470c1606101 to disappear
Apr 22 19:59:02.883: INFO: Pod client-containers-e2312e50-4815-417a-8908-8470c1606101 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 22 19:59:02.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6760" for this suite. 04/22/23 19:59:02.897
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":216,"skipped":3924,"failed":0}
------------------------------
â€¢ [4.217 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:58:58.711
    Apr 22 19:58:58.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename containers 04/22/23 19:58:58.714
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:58:58.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:58:58.745
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 04/22/23 19:58:58.752
    Apr 22 19:58:58.768: INFO: Waiting up to 5m0s for pod "client-containers-e2312e50-4815-417a-8908-8470c1606101" in namespace "containers-6760" to be "Succeeded or Failed"
    Apr 22 19:58:58.781: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Pending", Reason="", readiness=false. Elapsed: 13.189071ms
    Apr 22 19:59:00.791: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022738845s
    Apr 22 19:59:02.790: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022271605s
    STEP: Saw pod success 04/22/23 19:59:02.79
    Apr 22 19:59:02.791: INFO: Pod "client-containers-e2312e50-4815-417a-8908-8470c1606101" satisfied condition "Succeeded or Failed"
    Apr 22 19:59:02.799: INFO: Trying to get logs from node cncf25-2-node-187aa4bdec5 pod client-containers-e2312e50-4815-417a-8908-8470c1606101 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 19:59:02.844
    Apr 22 19:59:02.877: INFO: Waiting for pod client-containers-e2312e50-4815-417a-8908-8470c1606101 to disappear
    Apr 22 19:59:02.883: INFO: Pod client-containers-e2312e50-4815-417a-8908-8470c1606101 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 22 19:59:02.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6760" for this suite. 04/22/23 19:59:02.897
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:02.934
Apr 22 19:59:02.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubelet-test 04/22/23 19:59:02.941
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:02.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:02.978
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 22 19:59:03.004: INFO: Waiting up to 5m0s for pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59" in namespace "kubelet-test-5600" to be "running and ready"
Apr 22 19:59:03.011: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59": Phase="Pending", Reason="", readiness=false. Elapsed: 7.151969ms
Apr 22 19:59:03.012: INFO: The phase of Pod busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:59:05.020: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59": Phase="Running", Reason="", readiness=true. Elapsed: 2.015592213s
Apr 22 19:59:05.020: INFO: The phase of Pod busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59 is Running (Ready = true)
Apr 22 19:59:05.020: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 22 19:59:05.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5600" for this suite. 04/22/23 19:59:05.056
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":217,"skipped":3929,"failed":0}
------------------------------
â€¢ [2.139 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:02.934
    Apr 22 19:59:02.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubelet-test 04/22/23 19:59:02.941
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:02.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:02.978
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 22 19:59:03.004: INFO: Waiting up to 5m0s for pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59" in namespace "kubelet-test-5600" to be "running and ready"
    Apr 22 19:59:03.011: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59": Phase="Pending", Reason="", readiness=false. Elapsed: 7.151969ms
    Apr 22 19:59:03.012: INFO: The phase of Pod busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:59:05.020: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59": Phase="Running", Reason="", readiness=true. Elapsed: 2.015592213s
    Apr 22 19:59:05.020: INFO: The phase of Pod busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59 is Running (Ready = true)
    Apr 22 19:59:05.020: INFO: Pod "busybox-scheduling-850f61d1-4331-47d3-acf0-f7690786cc59" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 22 19:59:05.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5600" for this suite. 04/22/23 19:59:05.056
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:05.078
Apr 22 19:59:05.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 19:59:05.081
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:05.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:05.167
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-cb23291a-136b-45a1-81ec-86b8b41f8d0f 04/22/23 19:59:05.176
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 22 19:59:05.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-715" for this suite. 04/22/23 19:59:05.195
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":218,"skipped":3946,"failed":0}
------------------------------
â€¢ [0.129 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:05.078
    Apr 22 19:59:05.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 19:59:05.081
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:05.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:05.167
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-cb23291a-136b-45a1-81ec-86b8b41f8d0f 04/22/23 19:59:05.176
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 19:59:05.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-715" for this suite. 04/22/23 19:59:05.195
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:05.235
Apr 22 19:59:05.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename dns 04/22/23 19:59:05.239
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:05.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:05.284
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/22/23 19:59:05.299
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3224;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3224;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +notcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_tcp@PTR;sleep 1; done
 04/22/23 19:59:05.369
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3224;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3224;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +notcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_tcp@PTR;sleep 1; done
 04/22/23 19:59:05.369
STEP: creating a pod to probe DNS 04/22/23 19:59:05.37
STEP: submitting the pod to kubernetes 04/22/23 19:59:05.371
Apr 22 19:59:05.385: INFO: Waiting up to 15m0s for pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9" in namespace "dns-3224" to be "running"
Apr 22 19:59:05.394: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.680294ms
Apr 22 19:59:07.416: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030514297s
Apr 22 19:59:09.412: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026857883s
Apr 22 19:59:11.413: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027125428s
Apr 22 19:59:13.423: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.03743401s
Apr 22 19:59:15.414: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028309693s
Apr 22 19:59:17.415: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Running", Reason="", readiness=true. Elapsed: 12.02948312s
Apr 22 19:59:17.415: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9" satisfied condition "running"
STEP: retrieving the pod 04/22/23 19:59:17.415
STEP: looking for the results for each expected name from probers 04/22/23 19:59:17.425
Apr 22 19:59:17.451: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.473: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.483: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.496: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.511: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.522: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.529: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.538: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.590: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.602: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.610: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.620: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.629: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.644: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.658: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.666: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:17.698: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

Apr 22 19:59:22.706: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.712: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.718: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.723: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.734: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.748: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.755: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.770: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.807: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.818: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.827: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.833: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.839: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.844: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.851: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.859: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:22.897: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

Apr 22 19:59:27.708: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.718: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.727: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.738: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.747: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.756: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.766: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.776: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.825: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.833: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.843: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.858: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.868: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.881: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.892: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.902: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:27.946: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

Apr 22 19:59:32.709: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.718: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.727: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.736: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.746: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.757: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.765: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.774: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.820: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.829: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.839: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.848: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.859: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.869: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.879: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.885: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
Apr 22 19:59:32.912: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

Apr 22 19:59:37.918: INFO: DNS probes using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 succeeded

STEP: deleting the pod 04/22/23 19:59:37.918
STEP: deleting the test service 04/22/23 19:59:37.969
STEP: deleting the test headless service 04/22/23 19:59:38.023
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 22 19:59:38.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3224" for this suite. 04/22/23 19:59:38.047
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":219,"skipped":3989,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.819 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:05.235
    Apr 22 19:59:05.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename dns 04/22/23 19:59:05.239
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:05.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:05.284
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/22/23 19:59:05.299
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3224;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3224;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +notcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_tcp@PTR;sleep 1; done
     04/22/23 19:59:05.369
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3224;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3224;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3224.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3224.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3224.svc;check="$$(dig +notcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.52.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.52.121_tcp@PTR;sleep 1; done
     04/22/23 19:59:05.369
    STEP: creating a pod to probe DNS 04/22/23 19:59:05.37
    STEP: submitting the pod to kubernetes 04/22/23 19:59:05.371
    Apr 22 19:59:05.385: INFO: Waiting up to 15m0s for pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9" in namespace "dns-3224" to be "running"
    Apr 22 19:59:05.394: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.680294ms
    Apr 22 19:59:07.416: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030514297s
    Apr 22 19:59:09.412: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026857883s
    Apr 22 19:59:11.413: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027125428s
    Apr 22 19:59:13.423: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.03743401s
    Apr 22 19:59:15.414: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028309693s
    Apr 22 19:59:17.415: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9": Phase="Running", Reason="", readiness=true. Elapsed: 12.02948312s
    Apr 22 19:59:17.415: INFO: Pod "dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9" satisfied condition "running"
    STEP: retrieving the pod 04/22/23 19:59:17.415
    STEP: looking for the results for each expected name from probers 04/22/23 19:59:17.425
    Apr 22 19:59:17.451: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.473: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.483: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.496: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.511: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.522: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.529: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.538: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.590: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.602: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.610: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.620: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.629: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.644: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.658: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.666: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:17.698: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

    Apr 22 19:59:22.706: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.712: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.718: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.723: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.734: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.748: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.755: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.770: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.807: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.818: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.827: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.833: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.839: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.844: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.851: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.859: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:22.897: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

    Apr 22 19:59:27.708: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.718: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.727: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.738: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.747: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.756: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.766: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.776: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.825: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.833: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.843: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.858: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.868: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.881: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.892: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.902: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:27.946: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

    Apr 22 19:59:32.709: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.718: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.727: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.736: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.746: INFO: Unable to read wheezy_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.757: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.765: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.774: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.820: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.829: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.839: INFO: Unable to read jessie_udp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.848: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224 from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.859: INFO: Unable to read jessie_udp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.869: INFO: Unable to read jessie_tcp@dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.879: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.885: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc from pod dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9: the server could not find the requested resource (get pods dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9)
    Apr 22 19:59:32.912: INFO: Lookups using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3224 wheezy_tcp@dns-test-service.dns-3224 wheezy_udp@dns-test-service.dns-3224.svc wheezy_tcp@dns-test-service.dns-3224.svc wheezy_udp@_http._tcp.dns-test-service.dns-3224.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3224.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3224 jessie_tcp@dns-test-service.dns-3224 jessie_udp@dns-test-service.dns-3224.svc jessie_tcp@dns-test-service.dns-3224.svc jessie_udp@_http._tcp.dns-test-service.dns-3224.svc jessie_tcp@_http._tcp.dns-test-service.dns-3224.svc]

    Apr 22 19:59:37.918: INFO: DNS probes using dns-3224/dns-test-756b635e-de5e-445b-a0b0-2bacc6d842c9 succeeded

    STEP: deleting the pod 04/22/23 19:59:37.918
    STEP: deleting the test service 04/22/23 19:59:37.969
    STEP: deleting the test headless service 04/22/23 19:59:38.023
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 22 19:59:38.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3224" for this suite. 04/22/23 19:59:38.047
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:38.075
Apr 22 19:59:38.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 19:59:38.08
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:38.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:38.109
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 04/22/23 19:59:38.115
STEP: submitting the pod to kubernetes 04/22/23 19:59:38.115
Apr 22 19:59:38.124: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" in namespace "pods-6935" to be "running and ready"
Apr 22 19:59:38.128: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.89415ms
Apr 22 19:59:38.128: INFO: The phase of Pod pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a is Pending, waiting for it to be Running (with Ready = true)
Apr 22 19:59:40.138: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013563054s
Apr 22 19:59:40.138: INFO: The phase of Pod pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a is Running (Ready = true)
Apr 22 19:59:40.138: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/22/23 19:59:40.146
STEP: updating the pod 04/22/23 19:59:40.154
Apr 22 19:59:40.695: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a"
Apr 22 19:59:40.696: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" in namespace "pods-6935" to be "terminated with reason DeadlineExceeded"
Apr 22 19:59:40.706: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 9.655544ms
Apr 22 19:59:42.715: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 2.019091697s
Apr 22 19:59:44.714: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=false. Elapsed: 4.018074743s
Apr 22 19:59:46.716: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.020252269s
Apr 22 19:59:46.716: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 19:59:46.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6935" for this suite. 04/22/23 19:59:46.734
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":220,"skipped":4027,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.678 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:38.075
    Apr 22 19:59:38.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 19:59:38.08
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:38.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:38.109
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 04/22/23 19:59:38.115
    STEP: submitting the pod to kubernetes 04/22/23 19:59:38.115
    Apr 22 19:59:38.124: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" in namespace "pods-6935" to be "running and ready"
    Apr 22 19:59:38.128: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.89415ms
    Apr 22 19:59:38.128: INFO: The phase of Pod pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 19:59:40.138: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013563054s
    Apr 22 19:59:40.138: INFO: The phase of Pod pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a is Running (Ready = true)
    Apr 22 19:59:40.138: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/22/23 19:59:40.146
    STEP: updating the pod 04/22/23 19:59:40.154
    Apr 22 19:59:40.695: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a"
    Apr 22 19:59:40.696: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" in namespace "pods-6935" to be "terminated with reason DeadlineExceeded"
    Apr 22 19:59:40.706: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 9.655544ms
    Apr 22 19:59:42.715: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=true. Elapsed: 2.019091697s
    Apr 22 19:59:44.714: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Running", Reason="", readiness=false. Elapsed: 4.018074743s
    Apr 22 19:59:46.716: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.020252269s
    Apr 22 19:59:46.716: INFO: Pod "pod-update-activedeadlineseconds-f7421e0f-6ef5-405d-9d9b-a2b45251b70a" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 19:59:46.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6935" for this suite. 04/22/23 19:59:46.734
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:46.81
Apr 22 19:59:46.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context 04/22/23 19:59:46.813
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:46.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:46.874
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/22/23 19:59:46.884
Apr 22 19:59:46.901: INFO: Waiting up to 5m0s for pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43" in namespace "security-context-2704" to be "Succeeded or Failed"
Apr 22 19:59:46.912: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Pending", Reason="", readiness=false. Elapsed: 11.261359ms
Apr 22 19:59:48.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022575566s
Apr 22 19:59:50.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022066565s
STEP: Saw pod success 04/22/23 19:59:50.923
Apr 22 19:59:50.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43" satisfied condition "Succeeded or Failed"
Apr 22 19:59:50.931: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 container test-container: <nil>
STEP: delete the pod 04/22/23 19:59:50.946
Apr 22 19:59:50.983: INFO: Waiting for pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 to disappear
Apr 22 19:59:50.992: INFO: Pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 19:59:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-2704" for this suite. 04/22/23 19:59:51.006
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":221,"skipped":4089,"failed":0}
------------------------------
â€¢ [4.219 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:46.81
    Apr 22 19:59:46.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context 04/22/23 19:59:46.813
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:46.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:46.874
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/22/23 19:59:46.884
    Apr 22 19:59:46.901: INFO: Waiting up to 5m0s for pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43" in namespace "security-context-2704" to be "Succeeded or Failed"
    Apr 22 19:59:46.912: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Pending", Reason="", readiness=false. Elapsed: 11.261359ms
    Apr 22 19:59:48.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022575566s
    Apr 22 19:59:50.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022066565s
    STEP: Saw pod success 04/22/23 19:59:50.923
    Apr 22 19:59:50.923: INFO: Pod "security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43" satisfied condition "Succeeded or Failed"
    Apr 22 19:59:50.931: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 container test-container: <nil>
    STEP: delete the pod 04/22/23 19:59:50.946
    Apr 22 19:59:50.983: INFO: Waiting for pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 to disappear
    Apr 22 19:59:50.992: INFO: Pod security-context-3f8f34aa-25d1-4810-94bf-e8bc1d7a6b43 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 19:59:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-2704" for this suite. 04/22/23 19:59:51.006
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:51.055
Apr 22 19:59:51.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 19:59:51.057
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:51.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:51.132
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/22/23 19:59:51.136
STEP: Verify that the required pods have come up 04/22/23 19:59:51.153
Apr 22 19:59:51.160: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 22 19:59:56.174: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/22/23 19:59:56.175
Apr 22 19:59:56.182: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/22/23 19:59:56.183
STEP: DeleteCollection of the ReplicaSets 04/22/23 19:59:56.196
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/22/23 19:59:56.208
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 19:59:56.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5267" for this suite. 04/22/23 19:59:56.236
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":222,"skipped":4095,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.209 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:51.055
    Apr 22 19:59:51.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 19:59:51.057
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:51.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:51.132
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/22/23 19:59:51.136
    STEP: Verify that the required pods have come up 04/22/23 19:59:51.153
    Apr 22 19:59:51.160: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 22 19:59:56.174: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/22/23 19:59:56.175
    Apr 22 19:59:56.182: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/22/23 19:59:56.183
    STEP: DeleteCollection of the ReplicaSets 04/22/23 19:59:56.196
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/22/23 19:59:56.208
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 19:59:56.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5267" for this suite. 04/22/23 19:59:56.236
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 19:59:56.276
Apr 22 19:59:56.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 19:59:56.285
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:56.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:56.322
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-2249 04/22/23 19:59:56.326
STEP: creating replication controller nodeport-test in namespace services-2249 04/22/23 19:59:56.348
I0422 19:59:56.357194      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2249, replica count: 2
I0422 19:59:59.408032      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 19:59:59.408: INFO: Creating new exec pod
Apr 22 19:59:59.422: INFO: Waiting up to 5m0s for pod "execpodjtjz8" in namespace "services-2249" to be "running"
Apr 22 19:59:59.431: INFO: Pod "execpodjtjz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.652657ms
Apr 22 20:00:01.439: INFO: Pod "execpodjtjz8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016558732s
Apr 22 20:00:01.439: INFO: Pod "execpodjtjz8" satisfied condition "running"
Apr 22 20:00:02.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 22 20:00:02.821: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 22 20:00:02.821: INFO: stdout: "nodeport-test-2cp59"
Apr 22 20:00:02.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.151.251 80'
Apr 22 20:00:03.107: INFO: stderr: "+ nc -v -t -w 2 10.98.151.251 80\n+ echo hostName\nConnection to 10.98.151.251 80 port [tcp/http] succeeded!\n"
Apr 22 20:00:03.107: INFO: stdout: ""
Apr 22 20:00:04.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.151.251 80'
Apr 22 20:00:04.443: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.151.251 80\nConnection to 10.98.151.251 80 port [tcp/http] succeeded!\n"
Apr 22 20:00:04.443: INFO: stdout: "nodeport-test-2cp59"
Apr 22 20:00:04.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 31266'
Apr 22 20:00:04.728: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.165 31266\nConnection to 10.1.1.165 31266 port [tcp/*] succeeded!\n"
Apr 22 20:00:04.728: INFO: stdout: ""
Apr 22 20:00:05.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 31266'
Apr 22 20:00:06.069: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 31266\nConnection to 10.1.1.165 31266 port [tcp/*] succeeded!\n+ echo hostName\n"
Apr 22 20:00:06.069: INFO: stdout: "nodeport-test-hm6sp"
Apr 22 20:00:06.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 31266'
Apr 22 20:00:06.361: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 31266\n+ echo hostName\nConnection to 10.1.1.128 31266 port [tcp/*] succeeded!\n"
Apr 22 20:00:06.361: INFO: stdout: ""
Apr 22 20:00:07.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 31266'
Apr 22 20:00:07.694: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.128 31266\nConnection to 10.1.1.128 31266 port [tcp/*] succeeded!\n"
Apr 22 20:00:07.695: INFO: stdout: "nodeport-test-hm6sp"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:00:07.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2249" for this suite. 04/22/23 20:00:07.703
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":223,"skipped":4096,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.442 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 19:59:56.276
    Apr 22 19:59:56.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 19:59:56.285
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 19:59:56.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 19:59:56.322
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-2249 04/22/23 19:59:56.326
    STEP: creating replication controller nodeport-test in namespace services-2249 04/22/23 19:59:56.348
    I0422 19:59:56.357194      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2249, replica count: 2
    I0422 19:59:59.408032      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 19:59:59.408: INFO: Creating new exec pod
    Apr 22 19:59:59.422: INFO: Waiting up to 5m0s for pod "execpodjtjz8" in namespace "services-2249" to be "running"
    Apr 22 19:59:59.431: INFO: Pod "execpodjtjz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.652657ms
    Apr 22 20:00:01.439: INFO: Pod "execpodjtjz8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016558732s
    Apr 22 20:00:01.439: INFO: Pod "execpodjtjz8" satisfied condition "running"
    Apr 22 20:00:02.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 22 20:00:02.821: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 22 20:00:02.821: INFO: stdout: "nodeport-test-2cp59"
    Apr 22 20:00:02.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.151.251 80'
    Apr 22 20:00:03.107: INFO: stderr: "+ nc -v -t -w 2 10.98.151.251 80\n+ echo hostName\nConnection to 10.98.151.251 80 port [tcp/http] succeeded!\n"
    Apr 22 20:00:03.107: INFO: stdout: ""
    Apr 22 20:00:04.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.151.251 80'
    Apr 22 20:00:04.443: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.151.251 80\nConnection to 10.98.151.251 80 port [tcp/http] succeeded!\n"
    Apr 22 20:00:04.443: INFO: stdout: "nodeport-test-2cp59"
    Apr 22 20:00:04.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 31266'
    Apr 22 20:00:04.728: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.165 31266\nConnection to 10.1.1.165 31266 port [tcp/*] succeeded!\n"
    Apr 22 20:00:04.728: INFO: stdout: ""
    Apr 22 20:00:05.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 31266'
    Apr 22 20:00:06.069: INFO: stderr: "+ nc -v -t -w 2 10.1.1.165 31266\nConnection to 10.1.1.165 31266 port [tcp/*] succeeded!\n+ echo hostName\n"
    Apr 22 20:00:06.069: INFO: stdout: "nodeport-test-hm6sp"
    Apr 22 20:00:06.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 31266'
    Apr 22 20:00:06.361: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 31266\n+ echo hostName\nConnection to 10.1.1.128 31266 port [tcp/*] succeeded!\n"
    Apr 22 20:00:06.361: INFO: stdout: ""
    Apr 22 20:00:07.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-2249 exec execpodjtjz8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 31266'
    Apr 22 20:00:07.694: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.128 31266\nConnection to 10.1.1.128 31266 port [tcp/*] succeeded!\n"
    Apr 22 20:00:07.695: INFO: stdout: "nodeport-test-hm6sp"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:00:07.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2249" for this suite. 04/22/23 20:00:07.703
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:07.719
Apr 22 20:00:07.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:00:07.721
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:07.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:07.769
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:00:07.782
Apr 22 20:00:07.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a" in namespace "projected-885" to be "Succeeded or Failed"
Apr 22 20:00:07.821: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018425ms
Apr 22 20:00:09.828: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025761745s
Apr 22 20:00:11.829: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026575374s
STEP: Saw pod success 04/22/23 20:00:11.83
Apr 22 20:00:11.831: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a" satisfied condition "Succeeded or Failed"
Apr 22 20:00:11.838: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a container client-container: <nil>
STEP: delete the pod 04/22/23 20:00:11.853
Apr 22 20:00:11.882: INFO: Waiting for pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a to disappear
Apr 22 20:00:11.890: INFO: Pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:00:11.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-885" for this suite. 04/22/23 20:00:11.902
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":224,"skipped":4096,"failed":0}
------------------------------
â€¢ [4.206 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:07.719
    Apr 22 20:00:07.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:00:07.721
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:07.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:07.769
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:00:07.782
    Apr 22 20:00:07.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a" in namespace "projected-885" to be "Succeeded or Failed"
    Apr 22 20:00:07.821: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018425ms
    Apr 22 20:00:09.828: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025761745s
    Apr 22 20:00:11.829: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026575374s
    STEP: Saw pod success 04/22/23 20:00:11.83
    Apr 22 20:00:11.831: INFO: Pod "downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a" satisfied condition "Succeeded or Failed"
    Apr 22 20:00:11.838: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a container client-container: <nil>
    STEP: delete the pod 04/22/23 20:00:11.853
    Apr 22 20:00:11.882: INFO: Waiting for pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a to disappear
    Apr 22 20:00:11.890: INFO: Pod downwardapi-volume-b78a8107-a81f-4e37-8075-bf0dc59d932a no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:00:11.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-885" for this suite. 04/22/23 20:00:11.902
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:11.937
Apr 22 20:00:11.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename server-version 04/22/23 20:00:11.94
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:11.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:11.994
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/22/23 20:00:12.004
STEP: Confirm major version 04/22/23 20:00:12.009
Apr 22 20:00:12.009: INFO: Major version: 1
STEP: Confirm minor version 04/22/23 20:00:12.009
Apr 22 20:00:12.010: INFO: cleanMinorVersion: 25
Apr 22 20:00:12.010: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Apr 22 20:00:12.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-4093" for this suite. 04/22/23 20:00:12.017
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":225,"skipped":4102,"failed":0}
------------------------------
â€¢ [0.092 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:11.937
    Apr 22 20:00:11.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename server-version 04/22/23 20:00:11.94
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:11.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:11.994
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/22/23 20:00:12.004
    STEP: Confirm major version 04/22/23 20:00:12.009
    Apr 22 20:00:12.009: INFO: Major version: 1
    STEP: Confirm minor version 04/22/23 20:00:12.009
    Apr 22 20:00:12.010: INFO: cleanMinorVersion: 25
    Apr 22 20:00:12.010: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Apr 22 20:00:12.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-4093" for this suite. 04/22/23 20:00:12.017
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:12.064
Apr 22 20:00:12.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:00:12.066
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.104
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 22 20:00:12.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-896" for this suite. 04/22/23 20:00:12.157
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":226,"skipped":4128,"failed":0}
------------------------------
â€¢ [0.106 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:12.064
    Apr 22 20:00:12.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:00:12.066
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.104
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 22 20:00:12.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-896" for this suite. 04/22/23 20:00:12.157
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:12.171
Apr 22 20:00:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:00:12.174
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.202
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 04/22/23 20:00:12.214
STEP: waiting for available Endpoint 04/22/23 20:00:12.222
STEP: listing all Endpoints 04/22/23 20:00:12.226
STEP: updating the Endpoint 04/22/23 20:00:12.231
STEP: fetching the Endpoint 04/22/23 20:00:12.239
STEP: patching the Endpoint 04/22/23 20:00:12.245
STEP: fetching the Endpoint 04/22/23 20:00:12.257
STEP: deleting the Endpoint by Collection 04/22/23 20:00:12.262
STEP: waiting for Endpoint deletion 04/22/23 20:00:12.287
STEP: fetching the Endpoint 04/22/23 20:00:12.292
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:00:12.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3167" for this suite. 04/22/23 20:00:12.308
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":227,"skipped":4130,"failed":0}
------------------------------
â€¢ [0.148 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:12.171
    Apr 22 20:00:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:00:12.174
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.202
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 04/22/23 20:00:12.214
    STEP: waiting for available Endpoint 04/22/23 20:00:12.222
    STEP: listing all Endpoints 04/22/23 20:00:12.226
    STEP: updating the Endpoint 04/22/23 20:00:12.231
    STEP: fetching the Endpoint 04/22/23 20:00:12.239
    STEP: patching the Endpoint 04/22/23 20:00:12.245
    STEP: fetching the Endpoint 04/22/23 20:00:12.257
    STEP: deleting the Endpoint by Collection 04/22/23 20:00:12.262
    STEP: waiting for Endpoint deletion 04/22/23 20:00:12.287
    STEP: fetching the Endpoint 04/22/23 20:00:12.292
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:00:12.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3167" for this suite. 04/22/23 20:00:12.308
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:12.338
Apr 22 20:00:12.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replication-controller 04/22/23 20:00:12.34
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.376
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 04/22/23 20:00:12.384
Apr 22 20:00:12.395: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2676" to be "running and ready"
Apr 22 20:00:12.402: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.866278ms
Apr 22 20:00:12.403: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:00:14.408: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.012762579s
Apr 22 20:00:14.408: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 22 20:00:14.408: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/22/23 20:00:14.413
STEP: Then the orphan pod is adopted 04/22/23 20:00:14.422
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 22 20:00:15.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2676" for this suite. 04/22/23 20:00:15.44
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":228,"skipped":4150,"failed":0}
------------------------------
â€¢ [3.116 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:12.338
    Apr 22 20:00:12.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replication-controller 04/22/23 20:00:12.34
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:12.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:12.376
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/22/23 20:00:12.384
    Apr 22 20:00:12.395: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2676" to be "running and ready"
    Apr 22 20:00:12.402: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.866278ms
    Apr 22 20:00:12.403: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:00:14.408: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.012762579s
    Apr 22 20:00:14.408: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 22 20:00:14.408: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/22/23 20:00:14.413
    STEP: Then the orphan pod is adopted 04/22/23 20:00:14.422
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 22 20:00:15.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2676" for this suite. 04/22/23 20:00:15.44
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:15.477
Apr 22 20:00:15.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename podtemplate 04/22/23 20:00:15.481
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.509
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 22 20:00:15.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9801" for this suite. 04/22/23 20:00:15.565
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":229,"skipped":4182,"failed":0}
------------------------------
â€¢ [0.097 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:15.477
    Apr 22 20:00:15.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename podtemplate 04/22/23 20:00:15.481
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.509
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 22 20:00:15.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9801" for this suite. 04/22/23 20:00:15.565
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:15.587
Apr 22 20:00:15.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:00:15.591
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.616
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 04/22/23 20:00:15.635
STEP: watching for the Service to be added 04/22/23 20:00:15.65
Apr 22 20:00:15.652: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 22 20:00:15.653: INFO: Service test-service-h692p created
STEP: Getting /status 04/22/23 20:00:15.653
Apr 22 20:00:15.663: INFO: Service test-service-h692p has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/22/23 20:00:15.663
STEP: watching for the Service to be patched 04/22/23 20:00:15.671
Apr 22 20:00:15.674: INFO: observed Service test-service-h692p in namespace services-5921 with annotations: map[] & LoadBalancer: {[]}
Apr 22 20:00:15.674: INFO: Found Service test-service-h692p in namespace services-5921 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 22 20:00:15.676: INFO: Service test-service-h692p has service status patched
STEP: updating the ServiceStatus 04/22/23 20:00:15.676
Apr 22 20:00:15.689: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/22/23 20:00:15.689
Apr 22 20:00:15.692: INFO: Observed Service test-service-h692p in namespace services-5921 with annotations: map[] & Conditions: {[]}
Apr 22 20:00:15.692: INFO: Observed event: &Service{ObjectMeta:{test-service-h692p  services-5921  964a3350-6ed6-4455-8529-ff4c23302999 26501 0 2023-04-22 20:00:15 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-22 20:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-22 20:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.101.181.4,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.101.181.4],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 22 20:00:15.694: INFO: Found Service test-service-h692p in namespace services-5921 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 22 20:00:15.694: INFO: Service test-service-h692p has service status updated
STEP: patching the service 04/22/23 20:00:15.695
STEP: watching for the Service to be patched 04/22/23 20:00:15.711
Apr 22 20:00:15.713: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
Apr 22 20:00:15.714: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
Apr 22 20:00:15.715: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
Apr 22 20:00:15.715: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service:patched test-service-static:true]
Apr 22 20:00:15.715: INFO: Service test-service-h692p patched
STEP: deleting the service 04/22/23 20:00:15.716
STEP: watching for the Service to be deleted 04/22/23 20:00:15.737
Apr 22 20:00:15.739: INFO: Observed event: ADDED
Apr 22 20:00:15.739: INFO: Observed event: MODIFIED
Apr 22 20:00:15.739: INFO: Observed event: MODIFIED
Apr 22 20:00:15.740: INFO: Observed event: MODIFIED
Apr 22 20:00:15.740: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 22 20:00:15.740: INFO: Service test-service-h692p deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:00:15.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5921" for this suite. 04/22/23 20:00:15.748
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":230,"skipped":4191,"failed":0}
------------------------------
â€¢ [0.168 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:15.587
    Apr 22 20:00:15.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:00:15.591
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.616
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 04/22/23 20:00:15.635
    STEP: watching for the Service to be added 04/22/23 20:00:15.65
    Apr 22 20:00:15.652: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 22 20:00:15.653: INFO: Service test-service-h692p created
    STEP: Getting /status 04/22/23 20:00:15.653
    Apr 22 20:00:15.663: INFO: Service test-service-h692p has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/22/23 20:00:15.663
    STEP: watching for the Service to be patched 04/22/23 20:00:15.671
    Apr 22 20:00:15.674: INFO: observed Service test-service-h692p in namespace services-5921 with annotations: map[] & LoadBalancer: {[]}
    Apr 22 20:00:15.674: INFO: Found Service test-service-h692p in namespace services-5921 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 22 20:00:15.676: INFO: Service test-service-h692p has service status patched
    STEP: updating the ServiceStatus 04/22/23 20:00:15.676
    Apr 22 20:00:15.689: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/22/23 20:00:15.689
    Apr 22 20:00:15.692: INFO: Observed Service test-service-h692p in namespace services-5921 with annotations: map[] & Conditions: {[]}
    Apr 22 20:00:15.692: INFO: Observed event: &Service{ObjectMeta:{test-service-h692p  services-5921  964a3350-6ed6-4455-8529-ff4c23302999 26501 0 2023-04-22 20:00:15 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-22 20:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-22 20:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.101.181.4,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.101.181.4],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 22 20:00:15.694: INFO: Found Service test-service-h692p in namespace services-5921 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 22 20:00:15.694: INFO: Service test-service-h692p has service status updated
    STEP: patching the service 04/22/23 20:00:15.695
    STEP: watching for the Service to be patched 04/22/23 20:00:15.711
    Apr 22 20:00:15.713: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
    Apr 22 20:00:15.714: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
    Apr 22 20:00:15.715: INFO: observed Service test-service-h692p in namespace services-5921 with labels: map[test-service-static:true]
    Apr 22 20:00:15.715: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service:patched test-service-static:true]
    Apr 22 20:00:15.715: INFO: Service test-service-h692p patched
    STEP: deleting the service 04/22/23 20:00:15.716
    STEP: watching for the Service to be deleted 04/22/23 20:00:15.737
    Apr 22 20:00:15.739: INFO: Observed event: ADDED
    Apr 22 20:00:15.739: INFO: Observed event: MODIFIED
    Apr 22 20:00:15.739: INFO: Observed event: MODIFIED
    Apr 22 20:00:15.740: INFO: Observed event: MODIFIED
    Apr 22 20:00:15.740: INFO: Found Service test-service-h692p in namespace services-5921 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 22 20:00:15.740: INFO: Service test-service-h692p deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:00:15.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5921" for this suite. 04/22/23 20:00:15.748
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:15.762
Apr 22 20:00:15.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 20:00:15.764
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.801
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9622 04/22/23 20:00:15.81
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 04/22/23 20:00:15.851
STEP: Creating pod with conflicting port in namespace statefulset-9622 04/22/23 20:00:15.895
STEP: Waiting until pod test-pod will start running in namespace statefulset-9622 04/22/23 20:00:15.928
Apr 22 20:00:15.928: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9622" to be "running"
Apr 22 20:00:15.946: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.670504ms
Apr 22 20:00:17.951: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023282539s
Apr 22 20:00:17.952: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-9622 04/22/23 20:00:17.952
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9622 04/22/23 20:00:17.961
Apr 22 20:00:17.973: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Pending. Waiting for statefulset controller to delete.
Apr 22 20:00:17.992: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Failed. Waiting for statefulset controller to delete.
Apr 22 20:00:18.008: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Failed. Waiting for statefulset controller to delete.
Apr 22 20:00:18.012: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9622
STEP: Removing pod with conflicting port in namespace statefulset-9622 04/22/23 20:00:18.012
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9622 and will be in running state 04/22/23 20:00:18.038
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 20:00:20.056: INFO: Deleting all statefulset in ns statefulset-9622
Apr 22 20:00:20.067: INFO: Scaling statefulset ss to 0
Apr 22 20:00:30.119: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:00:30.128: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 20:00:30.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9622" for this suite. 04/22/23 20:00:30.229
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":231,"skipped":4204,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.528 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:15.762
    Apr 22 20:00:15.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 20:00:15.764
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:15.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:15.801
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9622 04/22/23 20:00:15.81
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 04/22/23 20:00:15.851
    STEP: Creating pod with conflicting port in namespace statefulset-9622 04/22/23 20:00:15.895
    STEP: Waiting until pod test-pod will start running in namespace statefulset-9622 04/22/23 20:00:15.928
    Apr 22 20:00:15.928: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9622" to be "running"
    Apr 22 20:00:15.946: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.670504ms
    Apr 22 20:00:17.951: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023282539s
    Apr 22 20:00:17.952: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-9622 04/22/23 20:00:17.952
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9622 04/22/23 20:00:17.961
    Apr 22 20:00:17.973: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 22 20:00:17.992: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 22 20:00:18.008: INFO: Observed stateful pod in namespace: statefulset-9622, name: ss-0, uid: 9debe9d5-e3ee-46f2-8394-9fd14dcae743, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 22 20:00:18.012: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9622
    STEP: Removing pod with conflicting port in namespace statefulset-9622 04/22/23 20:00:18.012
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9622 and will be in running state 04/22/23 20:00:18.038
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 20:00:20.056: INFO: Deleting all statefulset in ns statefulset-9622
    Apr 22 20:00:20.067: INFO: Scaling statefulset ss to 0
    Apr 22 20:00:30.119: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:00:30.128: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 20:00:30.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9622" for this suite. 04/22/23 20:00:30.229
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:30.317
Apr 22 20:00:30.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 20:00:30.321
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:30.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:30.422
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 04/22/23 20:00:30.429
STEP: Creating a ResourceQuota 04/22/23 20:00:35.436
STEP: Ensuring resource quota status is calculated 04/22/23 20:00:35.444
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 20:00:37.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3522" for this suite. 04/22/23 20:00:37.466
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":232,"skipped":4216,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.167 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:30.317
    Apr 22 20:00:30.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 20:00:30.321
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:30.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:30.422
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 04/22/23 20:00:30.429
    STEP: Creating a ResourceQuota 04/22/23 20:00:35.436
    STEP: Ensuring resource quota status is calculated 04/22/23 20:00:35.444
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 20:00:37.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3522" for this suite. 04/22/23 20:00:37.466
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:37.488
Apr 22 20:00:37.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 20:00:37.493
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:37.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:37.546
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-32a2ae11-717a-4b16-ad55-e915594d18ec 04/22/23 20:00:37.553
STEP: Creating a pod to test consume secrets 04/22/23 20:00:37.566
Apr 22 20:00:37.580: INFO: Waiting up to 5m0s for pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a" in namespace "secrets-4439" to be "Succeeded or Failed"
Apr 22 20:00:37.596: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.595421ms
Apr 22 20:00:39.604: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023411768s
Apr 22 20:00:41.605: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02417987s
STEP: Saw pod success 04/22/23 20:00:41.605
Apr 22 20:00:41.606: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a" satisfied condition "Succeeded or Failed"
Apr 22 20:00:41.615: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 20:00:41.633
Apr 22 20:00:41.668: INFO: Waiting for pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a to disappear
Apr 22 20:00:41.676: INFO: Pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 20:00:41.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4439" for this suite. 04/22/23 20:00:41.693
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":233,"skipped":4219,"failed":0}
------------------------------
â€¢ [4.221 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:37.488
    Apr 22 20:00:37.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 20:00:37.493
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:37.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:37.546
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-32a2ae11-717a-4b16-ad55-e915594d18ec 04/22/23 20:00:37.553
    STEP: Creating a pod to test consume secrets 04/22/23 20:00:37.566
    Apr 22 20:00:37.580: INFO: Waiting up to 5m0s for pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a" in namespace "secrets-4439" to be "Succeeded or Failed"
    Apr 22 20:00:37.596: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.595421ms
    Apr 22 20:00:39.604: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023411768s
    Apr 22 20:00:41.605: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02417987s
    STEP: Saw pod success 04/22/23 20:00:41.605
    Apr 22 20:00:41.606: INFO: Pod "pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a" satisfied condition "Succeeded or Failed"
    Apr 22 20:00:41.615: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 20:00:41.633
    Apr 22 20:00:41.668: INFO: Waiting for pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a to disappear
    Apr 22 20:00:41.676: INFO: Pod pod-secrets-9516f7a6-db3c-45c1-b6b6-5c54b8734a1a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 20:00:41.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4439" for this suite. 04/22/23 20:00:41.693
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:41.729
Apr 22 20:00:41.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename controllerrevisions 04/22/23 20:00:41.732
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:41.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:41.789
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-rvwtf-daemon-set" 04/22/23 20:00:41.832
STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 20:00:41.852
Apr 22 20:00:41.861: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:41.861: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:41.866: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
Apr 22 20:00:41.867: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 20:00:42.881: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:42.882: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:42.893: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
Apr 22 20:00:42.893: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 20:00:43.879: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:43.879: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:00:43.892: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 2
Apr 22 20:00:43.892: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-rvwtf-daemon-set
STEP: Confirm DaemonSet "e2e-rvwtf-daemon-set" successfully created with "daemonset-name=e2e-rvwtf-daemon-set" label 04/22/23 20:00:43.902
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-rvwtf-daemon-set" 04/22/23 20:00:43.921
Apr 22 20:00:43.929: INFO: Located ControllerRevision: "e2e-rvwtf-daemon-set-f7b7c5964"
STEP: Patching ControllerRevision "e2e-rvwtf-daemon-set-f7b7c5964" 04/22/23 20:00:43.938
Apr 22 20:00:43.957: INFO: e2e-rvwtf-daemon-set-f7b7c5964 has been patched
STEP: Create a new ControllerRevision 04/22/23 20:00:43.957
Apr 22 20:00:43.978: INFO: Created ControllerRevision: e2e-rvwtf-daemon-set-64b4456bdb
STEP: Confirm that there are two ControllerRevisions 04/22/23 20:00:43.979
Apr 22 20:00:43.979: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 22 20:00:43.988: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-rvwtf-daemon-set-f7b7c5964" 04/22/23 20:00:43.988
STEP: Confirm that there is only one ControllerRevision 04/22/23 20:00:44.001
Apr 22 20:00:44.001: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 22 20:00:44.008: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-rvwtf-daemon-set-64b4456bdb" 04/22/23 20:00:44.014
Apr 22 20:00:44.034: INFO: e2e-rvwtf-daemon-set-64b4456bdb has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/22/23 20:00:44.034
W0422 20:00:44.056988      20 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/22/23 20:00:44.057
Apr 22 20:00:44.058: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 22 20:00:45.064: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 22 20:00:45.074: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-rvwtf-daemon-set-64b4456bdb=updated" 04/22/23 20:00:45.074
STEP: Confirm that there is only one ControllerRevision 04/22/23 20:00:45.094
Apr 22 20:00:45.095: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 22 20:00:45.102: INFO: Found 1 ControllerRevisions
Apr 22 20:00:45.108: INFO: ControllerRevision "e2e-rvwtf-daemon-set-64df8d448c" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-rvwtf-daemon-set" 04/22/23 20:00:45.117
STEP: deleting DaemonSet.extensions e2e-rvwtf-daemon-set in namespace controllerrevisions-1084, will wait for the garbage collector to delete the pods 04/22/23 20:00:45.117
Apr 22 20:00:45.190: INFO: Deleting DaemonSet.extensions e2e-rvwtf-daemon-set took: 14.464356ms
Apr 22 20:00:45.301: INFO: Terminating DaemonSet.extensions e2e-rvwtf-daemon-set pods took: 111.082797ms
Apr 22 20:00:46.712: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
Apr 22 20:00:46.712: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-rvwtf-daemon-set
Apr 22 20:00:46.724: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26791"},"items":null}

Apr 22 20:00:46.746: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26791"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Apr 22 20:00:46.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-1084" for this suite. 04/22/23 20:00:46.789
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":234,"skipped":4245,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.072 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:41.729
    Apr 22 20:00:41.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename controllerrevisions 04/22/23 20:00:41.732
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:41.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:41.789
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-rvwtf-daemon-set" 04/22/23 20:00:41.832
    STEP: Check that daemon pods launch on every node of the cluster. 04/22/23 20:00:41.852
    Apr 22 20:00:41.861: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:41.861: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:41.866: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
    Apr 22 20:00:41.867: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 20:00:42.881: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:42.882: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:42.893: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
    Apr 22 20:00:42.893: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 20:00:43.879: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:43.879: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:00:43.892: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 2
    Apr 22 20:00:43.892: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-rvwtf-daemon-set
    STEP: Confirm DaemonSet "e2e-rvwtf-daemon-set" successfully created with "daemonset-name=e2e-rvwtf-daemon-set" label 04/22/23 20:00:43.902
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-rvwtf-daemon-set" 04/22/23 20:00:43.921
    Apr 22 20:00:43.929: INFO: Located ControllerRevision: "e2e-rvwtf-daemon-set-f7b7c5964"
    STEP: Patching ControllerRevision "e2e-rvwtf-daemon-set-f7b7c5964" 04/22/23 20:00:43.938
    Apr 22 20:00:43.957: INFO: e2e-rvwtf-daemon-set-f7b7c5964 has been patched
    STEP: Create a new ControllerRevision 04/22/23 20:00:43.957
    Apr 22 20:00:43.978: INFO: Created ControllerRevision: e2e-rvwtf-daemon-set-64b4456bdb
    STEP: Confirm that there are two ControllerRevisions 04/22/23 20:00:43.979
    Apr 22 20:00:43.979: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 22 20:00:43.988: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-rvwtf-daemon-set-f7b7c5964" 04/22/23 20:00:43.988
    STEP: Confirm that there is only one ControllerRevision 04/22/23 20:00:44.001
    Apr 22 20:00:44.001: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 22 20:00:44.008: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-rvwtf-daemon-set-64b4456bdb" 04/22/23 20:00:44.014
    Apr 22 20:00:44.034: INFO: e2e-rvwtf-daemon-set-64b4456bdb has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/22/23 20:00:44.034
    W0422 20:00:44.056988      20 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/22/23 20:00:44.057
    Apr 22 20:00:44.058: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 22 20:00:45.064: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 22 20:00:45.074: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-rvwtf-daemon-set-64b4456bdb=updated" 04/22/23 20:00:45.074
    STEP: Confirm that there is only one ControllerRevision 04/22/23 20:00:45.094
    Apr 22 20:00:45.095: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 22 20:00:45.102: INFO: Found 1 ControllerRevisions
    Apr 22 20:00:45.108: INFO: ControllerRevision "e2e-rvwtf-daemon-set-64df8d448c" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-rvwtf-daemon-set" 04/22/23 20:00:45.117
    STEP: deleting DaemonSet.extensions e2e-rvwtf-daemon-set in namespace controllerrevisions-1084, will wait for the garbage collector to delete the pods 04/22/23 20:00:45.117
    Apr 22 20:00:45.190: INFO: Deleting DaemonSet.extensions e2e-rvwtf-daemon-set took: 14.464356ms
    Apr 22 20:00:45.301: INFO: Terminating DaemonSet.extensions e2e-rvwtf-daemon-set pods took: 111.082797ms
    Apr 22 20:00:46.712: INFO: Number of nodes with available pods controlled by daemonset e2e-rvwtf-daemon-set: 0
    Apr 22 20:00:46.712: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-rvwtf-daemon-set
    Apr 22 20:00:46.724: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26791"},"items":null}

    Apr 22 20:00:46.746: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26791"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 20:00:46.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-1084" for this suite. 04/22/23 20:00:46.789
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:46.813
Apr 22 20:00:46.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename certificates 04/22/23 20:00:46.816
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:46.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:46.846
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/22/23 20:00:48.311
STEP: getting /apis/certificates.k8s.io 04/22/23 20:00:48.321
STEP: getting /apis/certificates.k8s.io/v1 04/22/23 20:00:48.324
STEP: creating 04/22/23 20:00:48.327
STEP: getting 04/22/23 20:00:48.364
STEP: listing 04/22/23 20:00:48.371
STEP: watching 04/22/23 20:00:48.38
Apr 22 20:00:48.380: INFO: starting watch
STEP: patching 04/22/23 20:00:48.382
STEP: updating 04/22/23 20:00:48.405
Apr 22 20:00:48.418: INFO: waiting for watch events with expected annotations
Apr 22 20:00:48.419: INFO: saw patched and updated annotations
STEP: getting /approval 04/22/23 20:00:48.419
STEP: patching /approval 04/22/23 20:00:48.425
STEP: updating /approval 04/22/23 20:00:48.439
STEP: getting /status 04/22/23 20:00:48.456
STEP: patching /status 04/22/23 20:00:48.462
STEP: updating /status 04/22/23 20:00:48.476
STEP: deleting 04/22/23 20:00:48.489
STEP: deleting a collection 04/22/23 20:00:48.515
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:00:48.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-9316" for this suite. 04/22/23 20:00:48.549
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":235,"skipped":4259,"failed":0}
------------------------------
â€¢ [1.746 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:46.813
    Apr 22 20:00:46.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename certificates 04/22/23 20:00:46.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:46.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:46.846
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/22/23 20:00:48.311
    STEP: getting /apis/certificates.k8s.io 04/22/23 20:00:48.321
    STEP: getting /apis/certificates.k8s.io/v1 04/22/23 20:00:48.324
    STEP: creating 04/22/23 20:00:48.327
    STEP: getting 04/22/23 20:00:48.364
    STEP: listing 04/22/23 20:00:48.371
    STEP: watching 04/22/23 20:00:48.38
    Apr 22 20:00:48.380: INFO: starting watch
    STEP: patching 04/22/23 20:00:48.382
    STEP: updating 04/22/23 20:00:48.405
    Apr 22 20:00:48.418: INFO: waiting for watch events with expected annotations
    Apr 22 20:00:48.419: INFO: saw patched and updated annotations
    STEP: getting /approval 04/22/23 20:00:48.419
    STEP: patching /approval 04/22/23 20:00:48.425
    STEP: updating /approval 04/22/23 20:00:48.439
    STEP: getting /status 04/22/23 20:00:48.456
    STEP: patching /status 04/22/23 20:00:48.462
    STEP: updating /status 04/22/23 20:00:48.476
    STEP: deleting 04/22/23 20:00:48.489
    STEP: deleting a collection 04/22/23 20:00:48.515
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:00:48.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-9316" for this suite. 04/22/23 20:00:48.549
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:48.582
Apr 22 20:00:48.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context-test 04/22/23 20:00:48.586
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:48.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:48.62
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Apr 22 20:00:48.640: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a" in namespace "security-context-test-5938" to be "Succeeded or Failed"
Apr 22 20:00:48.655: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.933712ms
Apr 22 20:00:50.663: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023391299s
Apr 22 20:00:52.662: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022606567s
Apr 22 20:00:54.664: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024193841s
Apr 22 20:00:54.664: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 20:00:54.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5938" for this suite. 04/22/23 20:00:54.739
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":236,"skipped":4298,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.174 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:48.582
    Apr 22 20:00:48.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context-test 04/22/23 20:00:48.586
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:48.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:48.62
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Apr 22 20:00:48.640: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a" in namespace "security-context-test-5938" to be "Succeeded or Failed"
    Apr 22 20:00:48.655: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.933712ms
    Apr 22 20:00:50.663: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023391299s
    Apr 22 20:00:52.662: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022606567s
    Apr 22 20:00:54.664: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024193841s
    Apr 22 20:00:54.664: INFO: Pod "alpine-nnp-false-8f2c1eca-e50a-46df-94ee-a31a7fcce98a" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 20:00:54.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-5938" for this suite. 04/22/23 20:00:54.739
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:54.757
Apr 22 20:00:54.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:00:54.765
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:54.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:54.854
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 04/22/23 20:00:54.864
Apr 22 20:00:54.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4382 api-versions'
Apr 22 20:00:55.007: INFO: stderr: ""
Apr 22 20:00:55.007: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:00:55.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4382" for this suite. 04/22/23 20:00:55.019
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":237,"skipped":4306,"failed":0}
------------------------------
â€¢ [0.278 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:54.757
    Apr 22 20:00:54.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:00:54.765
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:54.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:54.854
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 04/22/23 20:00:54.864
    Apr 22 20:00:54.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4382 api-versions'
    Apr 22 20:00:55.007: INFO: stderr: ""
    Apr 22 20:00:55.007: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:00:55.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4382" for this suite. 04/22/23 20:00:55.019
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:55.037
Apr 22 20:00:55.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 20:00:55.041
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:55.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:55.09
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/22/23 20:00:55.099
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/22/23 20:00:55.104
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/22/23 20:00:55.106
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/22/23 20:00:55.107
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/22/23 20:00:55.112
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/22/23 20:00:55.113
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/22/23 20:00:55.118
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:00:55.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7786" for this suite. 04/22/23 20:00:55.131
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":238,"skipped":4311,"failed":0}
------------------------------
â€¢ [0.122 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:55.037
    Apr 22 20:00:55.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 20:00:55.041
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:55.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:55.09
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/22/23 20:00:55.099
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/22/23 20:00:55.104
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/22/23 20:00:55.106
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/22/23 20:00:55.107
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/22/23 20:00:55.112
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/22/23 20:00:55.113
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/22/23 20:00:55.118
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:00:55.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7786" for this suite. 04/22/23 20:00:55.131
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:00:55.203
Apr 22 20:00:55.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:00:55.21
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:55.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:55.266
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-7318 04/22/23 20:00:55.277
Apr 22 20:00:55.299: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7318" to be "running and ready"
Apr 22 20:00:55.311: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.573627ms
Apr 22 20:00:55.312: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:00:57.321: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.021310418s
Apr 22 20:00:57.321: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 22 20:00:57.321: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 22 20:00:57.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 22 20:00:57.718: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 22 20:00:57.718: INFO: stdout: "iptables"
Apr 22 20:00:57.718: INFO: proxyMode: iptables
Apr 22 20:00:57.741: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 22 20:00:57.760: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-7318 04/22/23 20:00:57.76
STEP: creating replication controller affinity-nodeport-timeout in namespace services-7318 04/22/23 20:00:57.818
I0422 20:00:57.835263      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7318, replica count: 3
I0422 20:01:00.889001      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 20:01:00.915: INFO: Creating new exec pod
Apr 22 20:01:00.934: INFO: Waiting up to 5m0s for pod "execpod-affinity8td52" in namespace "services-7318" to be "running"
Apr 22 20:01:00.942: INFO: Pod "execpod-affinity8td52": Phase="Pending", Reason="", readiness=false. Elapsed: 7.419743ms
Apr 22 20:01:02.952: INFO: Pod "execpod-affinity8td52": Phase="Running", Reason="", readiness=true. Elapsed: 2.017379592s
Apr 22 20:01:02.952: INFO: Pod "execpod-affinity8td52" satisfied condition "running"
Apr 22 20:01:03.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Apr 22 20:01:04.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Apr 22 20:01:04.317: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:01:04.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.21.63 80'
Apr 22 20:01:04.669: INFO: stderr: "+ nc -v -t -w 2 10.111.21.63 80\n+ echo hostName\nConnection to 10.111.21.63 80 port [tcp/http] succeeded!\n"
Apr 22 20:01:04.669: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:01:04.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 30508'
Apr 22 20:01:05.022: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.165 30508\nConnection to 10.1.1.165 30508 port [tcp/*] succeeded!\n"
Apr 22 20:01:05.022: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:01:05.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 30508'
Apr 22 20:01:05.346: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 30508\n+ echo hostNameConnection to 10.1.1.128 30508 port [tcp/*] succeeded!\n\n"
Apr 22 20:01:05.346: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:01:05.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:30508/ ; done'
Apr 22 20:01:05.837: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
Apr 22 20:01:05.837: INFO: stdout: "\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w"
Apr 22 20:01:05.837: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.837: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
Apr 22 20:01:05.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
Apr 22 20:01:06.169: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
Apr 22 20:01:06.169: INFO: stdout: "affinity-nodeport-timeout-bgn7w"
Apr 22 20:01:26.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
Apr 22 20:01:26.529: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
Apr 22 20:01:26.530: INFO: stdout: "affinity-nodeport-timeout-bgn7w"
Apr 22 20:01:46.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
Apr 22 20:01:46.858: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
Apr 22 20:01:46.858: INFO: stdout: "affinity-nodeport-timeout-csv6w"
Apr 22 20:01:46.858: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7318, will wait for the garbage collector to delete the pods 04/22/23 20:01:46.889
Apr 22 20:01:46.964: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 8.841733ms
Apr 22 20:01:47.065: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.765836ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:01:49.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7318" for this suite. 04/22/23 20:01:49.333
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":239,"skipped":4360,"failed":0}
------------------------------
â€¢ [SLOW TEST] [54.142 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:00:55.203
    Apr 22 20:00:55.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:00:55.21
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:00:55.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:00:55.266
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-7318 04/22/23 20:00:55.277
    Apr 22 20:00:55.299: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7318" to be "running and ready"
    Apr 22 20:00:55.311: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.573627ms
    Apr 22 20:00:55.312: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:00:57.321: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.021310418s
    Apr 22 20:00:57.321: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 22 20:00:57.321: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 22 20:00:57.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 22 20:00:57.718: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 22 20:00:57.718: INFO: stdout: "iptables"
    Apr 22 20:00:57.718: INFO: proxyMode: iptables
    Apr 22 20:00:57.741: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 22 20:00:57.760: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-7318 04/22/23 20:00:57.76
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-7318 04/22/23 20:00:57.818
    I0422 20:00:57.835263      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7318, replica count: 3
    I0422 20:01:00.889001      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 20:01:00.915: INFO: Creating new exec pod
    Apr 22 20:01:00.934: INFO: Waiting up to 5m0s for pod "execpod-affinity8td52" in namespace "services-7318" to be "running"
    Apr 22 20:01:00.942: INFO: Pod "execpod-affinity8td52": Phase="Pending", Reason="", readiness=false. Elapsed: 7.419743ms
    Apr 22 20:01:02.952: INFO: Pod "execpod-affinity8td52": Phase="Running", Reason="", readiness=true. Elapsed: 2.017379592s
    Apr 22 20:01:02.952: INFO: Pod "execpod-affinity8td52" satisfied condition "running"
    Apr 22 20:01:03.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Apr 22 20:01:04.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Apr 22 20:01:04.317: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:01:04.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.21.63 80'
    Apr 22 20:01:04.669: INFO: stderr: "+ nc -v -t -w 2 10.111.21.63 80\n+ echo hostName\nConnection to 10.111.21.63 80 port [tcp/http] succeeded!\n"
    Apr 22 20:01:04.669: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:01:04.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.165 30508'
    Apr 22 20:01:05.022: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.1.1.165 30508\nConnection to 10.1.1.165 30508 port [tcp/*] succeeded!\n"
    Apr 22 20:01:05.022: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:01:05.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.1.1.128 30508'
    Apr 22 20:01:05.346: INFO: stderr: "+ nc -v -t -w 2 10.1.1.128 30508\n+ echo hostNameConnection to 10.1.1.128 30508 port [tcp/*] succeeded!\n\n"
    Apr 22 20:01:05.346: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:01:05.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.1.1.165:30508/ ; done'
    Apr 22 20:01:05.837: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
    Apr 22 20:01:05.837: INFO: stdout: "\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w\naffinity-nodeport-timeout-bgn7w"
    Apr 22 20:01:05.837: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.837: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.838: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.839: INFO: Received response from host: affinity-nodeport-timeout-bgn7w
    Apr 22 20:01:05.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
    Apr 22 20:01:06.169: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
    Apr 22 20:01:06.169: INFO: stdout: "affinity-nodeport-timeout-bgn7w"
    Apr 22 20:01:26.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
    Apr 22 20:01:26.529: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
    Apr 22 20:01:26.530: INFO: stdout: "affinity-nodeport-timeout-bgn7w"
    Apr 22 20:01:46.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7318 exec execpod-affinity8td52 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.1.1.165:30508/'
    Apr 22 20:01:46.858: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.1.1.165:30508/\n"
    Apr 22 20:01:46.858: INFO: stdout: "affinity-nodeport-timeout-csv6w"
    Apr 22 20:01:46.858: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7318, will wait for the garbage collector to delete the pods 04/22/23 20:01:46.889
    Apr 22 20:01:46.964: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 8.841733ms
    Apr 22 20:01:47.065: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.765836ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:01:49.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7318" for this suite. 04/22/23 20:01:49.333
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:01:49.381
Apr 22 20:01:49.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:01:49.383
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:49.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:49.436
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-7c1f8c39-9104-4198-b2b9-a28d01d5f51f 04/22/23 20:01:49.446
STEP: Creating a pod to test consume configMaps 04/22/23 20:01:49.458
Apr 22 20:01:49.472: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2" in namespace "projected-7559" to be "Succeeded or Failed"
Apr 22 20:01:49.486: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.387944ms
Apr 22 20:01:51.494: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021581177s
Apr 22 20:01:53.494: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02166898s
STEP: Saw pod success 04/22/23 20:01:53.495
Apr 22 20:01:53.495: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2" satisfied condition "Succeeded or Failed"
Apr 22 20:01:53.504: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/22/23 20:01:53.526
Apr 22 20:01:53.555: INFO: Waiting for pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 to disappear
Apr 22 20:01:53.566: INFO: Pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 20:01:53.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7559" for this suite. 04/22/23 20:01:53.578
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":240,"skipped":4400,"failed":0}
------------------------------
â€¢ [4.213 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:01:49.381
    Apr 22 20:01:49.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:01:49.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:49.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:49.436
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-7c1f8c39-9104-4198-b2b9-a28d01d5f51f 04/22/23 20:01:49.446
    STEP: Creating a pod to test consume configMaps 04/22/23 20:01:49.458
    Apr 22 20:01:49.472: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2" in namespace "projected-7559" to be "Succeeded or Failed"
    Apr 22 20:01:49.486: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.387944ms
    Apr 22 20:01:51.494: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021581177s
    Apr 22 20:01:53.494: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02166898s
    STEP: Saw pod success 04/22/23 20:01:53.495
    Apr 22 20:01:53.495: INFO: Pod "pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2" satisfied condition "Succeeded or Failed"
    Apr 22 20:01:53.504: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/22/23 20:01:53.526
    Apr 22 20:01:53.555: INFO: Waiting for pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 to disappear
    Apr 22 20:01:53.566: INFO: Pod pod-projected-configmaps-cd3db7eb-18fa-4119-96bd-7f49d17e06f2 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 20:01:53.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7559" for this suite. 04/22/23 20:01:53.578
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:01:53.604
Apr 22 20:01:53.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:01:53.609
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:53.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:53.693
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:01:53.703
Apr 22 20:01:53.726: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae" in namespace "projected-9964" to be "Succeeded or Failed"
Apr 22 20:01:53.744: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Pending", Reason="", readiness=false. Elapsed: 17.805988ms
Apr 22 20:01:55.756: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029944502s
Apr 22 20:01:57.758: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031761528s
STEP: Saw pod success 04/22/23 20:01:57.758
Apr 22 20:01:57.758: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae" satisfied condition "Succeeded or Failed"
Apr 22 20:01:57.766: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae container client-container: <nil>
STEP: delete the pod 04/22/23 20:01:57.782
Apr 22 20:01:57.821: INFO: Waiting for pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae to disappear
Apr 22 20:01:57.827: INFO: Pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:01:57.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9964" for this suite. 04/22/23 20:01:57.84
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":241,"skipped":4401,"failed":0}
------------------------------
â€¢ [4.251 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:01:53.604
    Apr 22 20:01:53.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:01:53.609
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:53.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:53.693
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:01:53.703
    Apr 22 20:01:53.726: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae" in namespace "projected-9964" to be "Succeeded or Failed"
    Apr 22 20:01:53.744: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Pending", Reason="", readiness=false. Elapsed: 17.805988ms
    Apr 22 20:01:55.756: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029944502s
    Apr 22 20:01:57.758: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031761528s
    STEP: Saw pod success 04/22/23 20:01:57.758
    Apr 22 20:01:57.758: INFO: Pod "downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae" satisfied condition "Succeeded or Failed"
    Apr 22 20:01:57.766: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae container client-container: <nil>
    STEP: delete the pod 04/22/23 20:01:57.782
    Apr 22 20:01:57.821: INFO: Waiting for pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae to disappear
    Apr 22 20:01:57.827: INFO: Pod downwardapi-volume-9374a4ab-eaea-4fd6-8e9f-d749e2dffaae no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:01:57.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9964" for this suite. 04/22/23 20:01:57.84
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:01:57.874
Apr 22 20:01:57.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 20:01:57.877
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:57.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:57.915
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 04/22/23 20:01:57.923
Apr 22 20:01:57.942: INFO: Waiting up to 5m0s for pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426" in namespace "var-expansion-4000" to be "Succeeded or Failed"
Apr 22 20:01:57.953: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Pending", Reason="", readiness=false. Elapsed: 9.892395ms
Apr 22 20:01:59.963: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019787352s
Apr 22 20:02:01.964: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020726343s
STEP: Saw pod success 04/22/23 20:02:01.964
Apr 22 20:02:01.965: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426" satisfied condition "Succeeded or Failed"
Apr 22 20:02:01.972: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 container dapi-container: <nil>
STEP: delete the pod 04/22/23 20:02:01.987
Apr 22 20:02:02.018: INFO: Waiting for pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 to disappear
Apr 22 20:02:02.028: INFO: Pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 20:02:02.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4000" for this suite. 04/22/23 20:02:02.044
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":242,"skipped":4421,"failed":0}
------------------------------
â€¢ [4.195 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:01:57.874
    Apr 22 20:01:57.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 20:01:57.877
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:01:57.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:01:57.915
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 04/22/23 20:01:57.923
    Apr 22 20:01:57.942: INFO: Waiting up to 5m0s for pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426" in namespace "var-expansion-4000" to be "Succeeded or Failed"
    Apr 22 20:01:57.953: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Pending", Reason="", readiness=false. Elapsed: 9.892395ms
    Apr 22 20:01:59.963: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019787352s
    Apr 22 20:02:01.964: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020726343s
    STEP: Saw pod success 04/22/23 20:02:01.964
    Apr 22 20:02:01.965: INFO: Pod "var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426" satisfied condition "Succeeded or Failed"
    Apr 22 20:02:01.972: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 20:02:01.987
    Apr 22 20:02:02.018: INFO: Waiting for pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 to disappear
    Apr 22 20:02:02.028: INFO: Pod var-expansion-317b3e1c-539a-412d-bd08-e4c743c4f426 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 20:02:02.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4000" for this suite. 04/22/23 20:02:02.044
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:02.088
Apr 22 20:02:02.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:02:02.095
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:02.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:02.178
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/22/23 20:02:02.185
Apr 22 20:02:02.197: INFO: Waiting up to 5m0s for pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71" in namespace "emptydir-1533" to be "Succeeded or Failed"
Apr 22 20:02:02.203: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Pending", Reason="", readiness=false. Elapsed: 5.59417ms
Apr 22 20:02:04.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017380377s
Apr 22 20:02:06.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017485512s
STEP: Saw pod success 04/22/23 20:02:06.215
Apr 22 20:02:06.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71" satisfied condition "Succeeded or Failed"
Apr 22 20:02:06.224: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 container test-container: <nil>
STEP: delete the pod 04/22/23 20:02:06.239
Apr 22 20:02:06.275: INFO: Waiting for pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 to disappear
Apr 22 20:02:06.286: INFO: Pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:02:06.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1533" for this suite. 04/22/23 20:02:06.301
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":243,"skipped":4425,"failed":0}
------------------------------
â€¢ [4.234 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:02.088
    Apr 22 20:02:02.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:02:02.095
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:02.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:02.178
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/22/23 20:02:02.185
    Apr 22 20:02:02.197: INFO: Waiting up to 5m0s for pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71" in namespace "emptydir-1533" to be "Succeeded or Failed"
    Apr 22 20:02:02.203: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Pending", Reason="", readiness=false. Elapsed: 5.59417ms
    Apr 22 20:02:04.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017380377s
    Apr 22 20:02:06.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017485512s
    STEP: Saw pod success 04/22/23 20:02:06.215
    Apr 22 20:02:06.215: INFO: Pod "pod-7fc4a656-1780-46da-81f3-61f878d31c71" satisfied condition "Succeeded or Failed"
    Apr 22 20:02:06.224: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 container test-container: <nil>
    STEP: delete the pod 04/22/23 20:02:06.239
    Apr 22 20:02:06.275: INFO: Waiting for pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 to disappear
    Apr 22 20:02:06.286: INFO: Pod pod-7fc4a656-1780-46da-81f3-61f878d31c71 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:02:06.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1533" for this suite. 04/22/23 20:02:06.301
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:06.332
Apr 22 20:02:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:02:06.335
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:06.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:06.379
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 04/22/23 20:02:06.391
Apr 22 20:02:06.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 create -f -'
Apr 22 20:02:07.681: INFO: stderr: ""
Apr 22 20:02:07.681: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:07.681
Apr 22 20:02:07.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 20:02:07.758: INFO: stderr: ""
Apr 22 20:02:07.758: INFO: stdout: "update-demo-nautilus-pfl7q update-demo-nautilus-phcs6 "
Apr 22 20:02:07.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:07.840: INFO: stderr: ""
Apr 22 20:02:07.840: INFO: stdout: ""
Apr 22 20:02:07.840: INFO: update-demo-nautilus-pfl7q is created but not running
Apr 22 20:02:12.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 20:02:13.026: INFO: stderr: ""
Apr 22 20:02:13.026: INFO: stdout: "update-demo-nautilus-pfl7q update-demo-nautilus-phcs6 "
Apr 22 20:02:13.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:13.170: INFO: stderr: ""
Apr 22 20:02:13.170: INFO: stdout: "true"
Apr 22 20:02:13.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 20:02:13.292: INFO: stderr: ""
Apr 22 20:02:13.292: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 20:02:13.292: INFO: validating pod update-demo-nautilus-pfl7q
Apr 22 20:02:13.307: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 20:02:13.307: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 20:02:13.308: INFO: update-demo-nautilus-pfl7q is verified up and running
Apr 22 20:02:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:13.418: INFO: stderr: ""
Apr 22 20:02:13.418: INFO: stdout: "true"
Apr 22 20:02:13.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 20:02:13.529: INFO: stderr: ""
Apr 22 20:02:13.530: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 20:02:13.530: INFO: validating pod update-demo-nautilus-phcs6
Apr 22 20:02:13.545: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 20:02:13.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 20:02:13.545: INFO: update-demo-nautilus-phcs6 is verified up and running
STEP: scaling down the replication controller 04/22/23 20:02:13.545
Apr 22 20:02:13.551: INFO: scanned /root for discovery docs: <nil>
Apr 22 20:02:13.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 22 20:02:14.707: INFO: stderr: ""
Apr 22 20:02:14.707: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:14.707
Apr 22 20:02:14.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 20:02:14.883: INFO: stderr: ""
Apr 22 20:02:14.884: INFO: stdout: "update-demo-nautilus-phcs6 "
Apr 22 20:02:14.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:15.022: INFO: stderr: ""
Apr 22 20:02:15.022: INFO: stdout: "true"
Apr 22 20:02:15.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 20:02:15.165: INFO: stderr: ""
Apr 22 20:02:15.165: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 20:02:15.165: INFO: validating pod update-demo-nautilus-phcs6
Apr 22 20:02:15.175: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 20:02:15.175: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 20:02:15.175: INFO: update-demo-nautilus-phcs6 is verified up and running
STEP: scaling up the replication controller 04/22/23 20:02:15.175
Apr 22 20:02:15.178: INFO: scanned /root for discovery docs: <nil>
Apr 22 20:02:15.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 22 20:02:16.351: INFO: stderr: ""
Apr 22 20:02:16.351: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:16.351
Apr 22 20:02:16.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 20:02:16.518: INFO: stderr: ""
Apr 22 20:02:16.518: INFO: stdout: "update-demo-nautilus-lzcrs update-demo-nautilus-phcs6 "
Apr 22 20:02:16.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:16.662: INFO: stderr: ""
Apr 22 20:02:16.662: INFO: stdout: ""
Apr 22 20:02:16.662: INFO: update-demo-nautilus-lzcrs is created but not running
Apr 22 20:02:21.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 22 20:02:21.852: INFO: stderr: ""
Apr 22 20:02:21.852: INFO: stdout: "update-demo-nautilus-lzcrs update-demo-nautilus-phcs6 "
Apr 22 20:02:21.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:21.976: INFO: stderr: ""
Apr 22 20:02:21.976: INFO: stdout: "true"
Apr 22 20:02:21.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 20:02:22.075: INFO: stderr: ""
Apr 22 20:02:22.075: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 20:02:22.075: INFO: validating pod update-demo-nautilus-lzcrs
Apr 22 20:02:22.099: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 20:02:22.099: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 20:02:22.099: INFO: update-demo-nautilus-lzcrs is verified up and running
Apr 22 20:02:22.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 22 20:02:22.216: INFO: stderr: ""
Apr 22 20:02:22.216: INFO: stdout: "true"
Apr 22 20:02:22.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 22 20:02:22.359: INFO: stderr: ""
Apr 22 20:02:22.359: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 22 20:02:22.359: INFO: validating pod update-demo-nautilus-phcs6
Apr 22 20:02:22.373: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 22 20:02:22.373: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 22 20:02:22.373: INFO: update-demo-nautilus-phcs6 is verified up and running
STEP: using delete to clean up resources 04/22/23 20:02:22.373
Apr 22 20:02:22.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 delete --grace-period=0 --force -f -'
Apr 22 20:02:22.538: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 22 20:02:22.538: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 22 20:02:22.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get rc,svc -l name=update-demo --no-headers'
Apr 22 20:02:22.727: INFO: stderr: "No resources found in kubectl-2067 namespace.\n"
Apr 22 20:02:22.727: INFO: stdout: ""
Apr 22 20:02:22.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 22 20:02:22.829: INFO: stderr: ""
Apr 22 20:02:22.829: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:02:22.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2067" for this suite. 04/22/23 20:02:22.84
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":244,"skipped":4430,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.525 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:06.332
    Apr 22 20:02:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:02:06.335
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:06.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:06.379
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 04/22/23 20:02:06.391
    Apr 22 20:02:06.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 create -f -'
    Apr 22 20:02:07.681: INFO: stderr: ""
    Apr 22 20:02:07.681: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:07.681
    Apr 22 20:02:07.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 20:02:07.758: INFO: stderr: ""
    Apr 22 20:02:07.758: INFO: stdout: "update-demo-nautilus-pfl7q update-demo-nautilus-phcs6 "
    Apr 22 20:02:07.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:07.840: INFO: stderr: ""
    Apr 22 20:02:07.840: INFO: stdout: ""
    Apr 22 20:02:07.840: INFO: update-demo-nautilus-pfl7q is created but not running
    Apr 22 20:02:12.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 20:02:13.026: INFO: stderr: ""
    Apr 22 20:02:13.026: INFO: stdout: "update-demo-nautilus-pfl7q update-demo-nautilus-phcs6 "
    Apr 22 20:02:13.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:13.170: INFO: stderr: ""
    Apr 22 20:02:13.170: INFO: stdout: "true"
    Apr 22 20:02:13.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-pfl7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 20:02:13.292: INFO: stderr: ""
    Apr 22 20:02:13.292: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 20:02:13.292: INFO: validating pod update-demo-nautilus-pfl7q
    Apr 22 20:02:13.307: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 20:02:13.307: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 20:02:13.308: INFO: update-demo-nautilus-pfl7q is verified up and running
    Apr 22 20:02:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:13.418: INFO: stderr: ""
    Apr 22 20:02:13.418: INFO: stdout: "true"
    Apr 22 20:02:13.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 20:02:13.529: INFO: stderr: ""
    Apr 22 20:02:13.530: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 20:02:13.530: INFO: validating pod update-demo-nautilus-phcs6
    Apr 22 20:02:13.545: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 20:02:13.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 20:02:13.545: INFO: update-demo-nautilus-phcs6 is verified up and running
    STEP: scaling down the replication controller 04/22/23 20:02:13.545
    Apr 22 20:02:13.551: INFO: scanned /root for discovery docs: <nil>
    Apr 22 20:02:13.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 22 20:02:14.707: INFO: stderr: ""
    Apr 22 20:02:14.707: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:14.707
    Apr 22 20:02:14.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 20:02:14.883: INFO: stderr: ""
    Apr 22 20:02:14.884: INFO: stdout: "update-demo-nautilus-phcs6 "
    Apr 22 20:02:14.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:15.022: INFO: stderr: ""
    Apr 22 20:02:15.022: INFO: stdout: "true"
    Apr 22 20:02:15.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 20:02:15.165: INFO: stderr: ""
    Apr 22 20:02:15.165: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 20:02:15.165: INFO: validating pod update-demo-nautilus-phcs6
    Apr 22 20:02:15.175: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 20:02:15.175: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 20:02:15.175: INFO: update-demo-nautilus-phcs6 is verified up and running
    STEP: scaling up the replication controller 04/22/23 20:02:15.175
    Apr 22 20:02:15.178: INFO: scanned /root for discovery docs: <nil>
    Apr 22 20:02:15.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 22 20:02:16.351: INFO: stderr: ""
    Apr 22 20:02:16.351: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/22/23 20:02:16.351
    Apr 22 20:02:16.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 20:02:16.518: INFO: stderr: ""
    Apr 22 20:02:16.518: INFO: stdout: "update-demo-nautilus-lzcrs update-demo-nautilus-phcs6 "
    Apr 22 20:02:16.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:16.662: INFO: stderr: ""
    Apr 22 20:02:16.662: INFO: stdout: ""
    Apr 22 20:02:16.662: INFO: update-demo-nautilus-lzcrs is created but not running
    Apr 22 20:02:21.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 22 20:02:21.852: INFO: stderr: ""
    Apr 22 20:02:21.852: INFO: stdout: "update-demo-nautilus-lzcrs update-demo-nautilus-phcs6 "
    Apr 22 20:02:21.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:21.976: INFO: stderr: ""
    Apr 22 20:02:21.976: INFO: stdout: "true"
    Apr 22 20:02:21.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-lzcrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 20:02:22.075: INFO: stderr: ""
    Apr 22 20:02:22.075: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 20:02:22.075: INFO: validating pod update-demo-nautilus-lzcrs
    Apr 22 20:02:22.099: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 20:02:22.099: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 20:02:22.099: INFO: update-demo-nautilus-lzcrs is verified up and running
    Apr 22 20:02:22.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 22 20:02:22.216: INFO: stderr: ""
    Apr 22 20:02:22.216: INFO: stdout: "true"
    Apr 22 20:02:22.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods update-demo-nautilus-phcs6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 22 20:02:22.359: INFO: stderr: ""
    Apr 22 20:02:22.359: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 22 20:02:22.359: INFO: validating pod update-demo-nautilus-phcs6
    Apr 22 20:02:22.373: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 22 20:02:22.373: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 22 20:02:22.373: INFO: update-demo-nautilus-phcs6 is verified up and running
    STEP: using delete to clean up resources 04/22/23 20:02:22.373
    Apr 22 20:02:22.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 delete --grace-period=0 --force -f -'
    Apr 22 20:02:22.538: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 22 20:02:22.538: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 22 20:02:22.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get rc,svc -l name=update-demo --no-headers'
    Apr 22 20:02:22.727: INFO: stderr: "No resources found in kubectl-2067 namespace.\n"
    Apr 22 20:02:22.727: INFO: stdout: ""
    Apr 22 20:02:22.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2067 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 22 20:02:22.829: INFO: stderr: ""
    Apr 22 20:02:22.829: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:02:22.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2067" for this suite. 04/22/23 20:02:22.84
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:22.863
Apr 22 20:02:22.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-pred 04/22/23 20:02:22.865
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:22.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:22.911
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 22 20:02:22.915: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 22 20:02:22.929: INFO: Waiting for terminating namespaces to be deleted...
Apr 22 20:02:22.933: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
Apr 22 20:02:22.949: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.949: INFO: 	Container cloud-controller-manager ready: true, restart count 0
Apr 22 20:02:22.949: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.949: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 20:02:22.949: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
Apr 22 20:02:22.950: INFO: 	Container weave ready: true, restart count 0
Apr 22 20:02:22.950: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 20:02:22.950: INFO: update-demo-nautilus-phcs6 from kubectl-2067 started at 2023-04-22 20:02:07 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.950: INFO: 	Container update-demo ready: true, restart count 0
Apr 22 20:02:22.950: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.950: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 22 20:02:22.950: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.951: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 22 20:02:22.951: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.951: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 22 20:02:22.951: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 20:02:22.951: INFO: 	Container e2e ready: true, restart count 0
Apr 22 20:02:22.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 20:02:22.951: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 20:02:22.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 20:02:22.952: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 22 20:02:22.952: INFO: 
Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
Apr 22 20:02:22.966: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.966: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 22 20:02:22.966: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
Apr 22 20:02:22.966: INFO: 	Container weave ready: true, restart count 0
Apr 22 20:02:22.966: INFO: 	Container weave-npc ready: true, restart count 0
Apr 22 20:02:22.966: INFO: update-demo-nautilus-lzcrs from kubectl-2067 started at 2023-04-22 20:02:15 +0000 UTC (1 container statuses recorded)
Apr 22 20:02:22.966: INFO: 	Container update-demo ready: true, restart count 0
Apr 22 20:02:22.966: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
Apr 22 20:02:22.966: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 22 20:02:22.966: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 20:02:22.966
Apr 22 20:02:22.979: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5853" to be "running"
Apr 22 20:02:22.987: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.638485ms
Apr 22 20:02:24.996: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017171916s
Apr 22 20:02:24.997: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 20:02:25.003
STEP: Trying to apply a random label on the found node. 04/22/23 20:02:25.039
STEP: verifying the node has the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 42 04/22/23 20:02:25.085
STEP: Trying to relaunch the pod, now with labels. 04/22/23 20:02:25.091
Apr 22 20:02:25.116: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5853" to be "not pending"
Apr 22 20:02:25.122: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007854ms
Apr 22 20:02:27.133: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.016269377s
Apr 22 20:02:27.133: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 off the node cncf25-2-node-187aa4c0d96 04/22/23 20:02:27.141
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 04/22/23 20:02:27.172
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 22 20:02:27.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5853" for this suite. 04/22/23 20:02:27.201
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":245,"skipped":4448,"failed":0}
------------------------------
â€¢ [4.354 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:22.863
    Apr 22 20:02:22.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-pred 04/22/23 20:02:22.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:22.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:22.911
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 22 20:02:22.915: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 22 20:02:22.929: INFO: Waiting for terminating namespaces to be deleted...
    Apr 22 20:02:22.933: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4bdec5 before test
    Apr 22 20:02:22.949: INFO: cloud-controller-manager-7c49d45757-jx65l from kube-system started at 2023-04-22 18:51:18 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.949: INFO: 	Container cloud-controller-manager ready: true, restart count 0
    Apr 22 20:02:22.949: INFO: kube-proxy-28gqf from kube-system started at 2023-04-22 18:50:37 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.949: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 20:02:22.949: INFO: weave-net-7dpcc from kube-system started at 2023-04-22 18:50:37 +0000 UTC (2 container statuses recorded)
    Apr 22 20:02:22.950: INFO: 	Container weave ready: true, restart count 0
    Apr 22 20:02:22.950: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 20:02:22.950: INFO: update-demo-nautilus-phcs6 from kubectl-2067 started at 2023-04-22 20:02:07 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.950: INFO: 	Container update-demo ready: true, restart count 0
    Apr 22 20:02:22.950: INFO: dashboard-metrics-scraper-64bcc67c9c-b4w74 from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.950: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 22 20:02:22.950: INFO: kubernetes-dashboard-5c8bd6b59-tmblk from kubernetes-dashboard started at 2023-04-22 19:07:12 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.951: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 22 20:02:22.951: INFO: sonobuoy from sonobuoy started at 2023-04-22 18:52:30 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.951: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 22 20:02:22.951: INFO: sonobuoy-e2e-job-ac22730371274d86 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 20:02:22.951: INFO: 	Container e2e ready: true, restart count 0
    Apr 22 20:02:22.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 20:02:22.951: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-lh6l9 from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 20:02:22.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 20:02:22.952: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 22 20:02:22.952: INFO: 
    Logging pods the apiserver thinks is on node cncf25-2-node-187aa4c0d96 before test
    Apr 22 20:02:22.966: INFO: kube-proxy-rcfsq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.966: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 22 20:02:22.966: INFO: weave-net-np8wq from kube-system started at 2023-04-22 18:50:33 +0000 UTC (2 container statuses recorded)
    Apr 22 20:02:22.966: INFO: 	Container weave ready: true, restart count 0
    Apr 22 20:02:22.966: INFO: 	Container weave-npc ready: true, restart count 0
    Apr 22 20:02:22.966: INFO: update-demo-nautilus-lzcrs from kubectl-2067 started at 2023-04-22 20:02:15 +0000 UTC (1 container statuses recorded)
    Apr 22 20:02:22.966: INFO: 	Container update-demo ready: true, restart count 0
    Apr 22 20:02:22.966: INFO: sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-px2pm from sonobuoy started at 2023-04-22 18:52:34 +0000 UTC (2 container statuses recorded)
    Apr 22 20:02:22.966: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 22 20:02:22.966: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/22/23 20:02:22.966
    Apr 22 20:02:22.979: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5853" to be "running"
    Apr 22 20:02:22.987: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.638485ms
    Apr 22 20:02:24.996: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017171916s
    Apr 22 20:02:24.997: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/22/23 20:02:25.003
    STEP: Trying to apply a random label on the found node. 04/22/23 20:02:25.039
    STEP: verifying the node has the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 42 04/22/23 20:02:25.085
    STEP: Trying to relaunch the pod, now with labels. 04/22/23 20:02:25.091
    Apr 22 20:02:25.116: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5853" to be "not pending"
    Apr 22 20:02:25.122: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007854ms
    Apr 22 20:02:27.133: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.016269377s
    Apr 22 20:02:27.133: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 off the node cncf25-2-node-187aa4c0d96 04/22/23 20:02:27.141
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c8d9c3d-e4ba-430b-b10e-99c252143a21 04/22/23 20:02:27.172
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 20:02:27.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5853" for this suite. 04/22/23 20:02:27.201
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:27.224
Apr 22 20:02:27.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename proxy 04/22/23 20:02:27.229
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:27.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:27.283
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 22 20:02:27.291: INFO: Creating pod...
Apr 22 20:02:27.313: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9564" to be "running"
Apr 22 20:02:27.329: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 15.872177ms
Apr 22 20:02:29.347: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.034061499s
Apr 22 20:02:29.347: INFO: Pod "agnhost" satisfied condition "running"
Apr 22 20:02:29.348: INFO: Creating service...
Apr 22 20:02:29.392: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=DELETE
Apr 22 20:02:29.416: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 22 20:02:29.416: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=OPTIONS
Apr 22 20:02:29.433: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 22 20:02:29.434: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=PATCH
Apr 22 20:02:29.440: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 22 20:02:29.440: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=POST
Apr 22 20:02:29.448: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 22 20:02:29.448: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=PUT
Apr 22 20:02:29.454: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 22 20:02:29.455: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 22 20:02:29.462: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 22 20:02:29.463: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 22 20:02:29.469: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 22 20:02:29.469: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 22 20:02:29.478: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 22 20:02:29.478: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=POST
Apr 22 20:02:29.486: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 22 20:02:29.486: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=PUT
Apr 22 20:02:29.494: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 22 20:02:29.494: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=GET
Apr 22 20:02:29.501: INFO: http.Client request:GET StatusCode:301
Apr 22 20:02:29.501: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=GET
Apr 22 20:02:29.505: INFO: http.Client request:GET StatusCode:301
Apr 22 20:02:29.506: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=HEAD
Apr 22 20:02:29.513: INFO: http.Client request:HEAD StatusCode:301
Apr 22 20:02:29.514: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 22 20:02:29.519: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 22 20:02:29.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9564" for this suite. 04/22/23 20:02:29.526
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":246,"skipped":4456,"failed":0}
------------------------------
â€¢ [2.310 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:27.224
    Apr 22 20:02:27.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename proxy 04/22/23 20:02:27.229
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:27.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:27.283
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 22 20:02:27.291: INFO: Creating pod...
    Apr 22 20:02:27.313: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9564" to be "running"
    Apr 22 20:02:27.329: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 15.872177ms
    Apr 22 20:02:29.347: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.034061499s
    Apr 22 20:02:29.347: INFO: Pod "agnhost" satisfied condition "running"
    Apr 22 20:02:29.348: INFO: Creating service...
    Apr 22 20:02:29.392: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=DELETE
    Apr 22 20:02:29.416: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 22 20:02:29.416: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=OPTIONS
    Apr 22 20:02:29.433: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 22 20:02:29.434: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=PATCH
    Apr 22 20:02:29.440: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 22 20:02:29.440: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=POST
    Apr 22 20:02:29.448: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 22 20:02:29.448: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=PUT
    Apr 22 20:02:29.454: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 22 20:02:29.455: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 22 20:02:29.462: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 22 20:02:29.463: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 22 20:02:29.469: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 22 20:02:29.469: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 22 20:02:29.478: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 22 20:02:29.478: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=POST
    Apr 22 20:02:29.486: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 22 20:02:29.486: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 22 20:02:29.494: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 22 20:02:29.494: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=GET
    Apr 22 20:02:29.501: INFO: http.Client request:GET StatusCode:301
    Apr 22 20:02:29.501: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=GET
    Apr 22 20:02:29.505: INFO: http.Client request:GET StatusCode:301
    Apr 22 20:02:29.506: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/pods/agnhost/proxy?method=HEAD
    Apr 22 20:02:29.513: INFO: http.Client request:HEAD StatusCode:301
    Apr 22 20:02:29.514: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9564/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 22 20:02:29.519: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 22 20:02:29.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9564" for this suite. 04/22/23 20:02:29.526
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:29.544
Apr 22 20:02:29.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 20:02:29.547
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:29.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:29.572
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-a592ae81-6747-4b2d-971c-4dab90642c65 04/22/23 20:02:29.582
STEP: Creating the pod 04/22/23 20:02:29.587
Apr 22 20:02:29.595: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c" in namespace "configmap-8921" to be "running and ready"
Apr 22 20:02:29.600: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.323462ms
Apr 22 20:02:29.601: INFO: The phase of Pod pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:02:31.610: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014984664s
Apr 22 20:02:31.610: INFO: The phase of Pod pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c is Running (Ready = true)
Apr 22 20:02:31.610: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-a592ae81-6747-4b2d-971c-4dab90642c65 04/22/23 20:02:31.636
STEP: waiting to observe update in volume 04/22/23 20:02:31.646
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 20:02:33.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8921" for this suite. 04/22/23 20:02:33.675
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":247,"skipped":4467,"failed":0}
------------------------------
â€¢ [4.142 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:29.544
    Apr 22 20:02:29.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 20:02:29.547
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:29.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:29.572
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-a592ae81-6747-4b2d-971c-4dab90642c65 04/22/23 20:02:29.582
    STEP: Creating the pod 04/22/23 20:02:29.587
    Apr 22 20:02:29.595: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c" in namespace "configmap-8921" to be "running and ready"
    Apr 22 20:02:29.600: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.323462ms
    Apr 22 20:02:29.601: INFO: The phase of Pod pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:02:31.610: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014984664s
    Apr 22 20:02:31.610: INFO: The phase of Pod pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c is Running (Ready = true)
    Apr 22 20:02:31.610: INFO: Pod "pod-configmaps-ba42538c-caa2-427c-8450-0b485100034c" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-a592ae81-6747-4b2d-971c-4dab90642c65 04/22/23 20:02:31.636
    STEP: waiting to observe update in volume 04/22/23 20:02:31.646
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 20:02:33.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8921" for this suite. 04/22/23 20:02:33.675
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:33.7
Apr 22 20:02:33.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:02:33.703
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:33.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:33.729
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 04/22/23 20:02:33.746
Apr 22 20:02:33.746: INFO: namespace kubectl-4474
Apr 22 20:02:33.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 create -f -'
Apr 22 20:02:34.069: INFO: stderr: ""
Apr 22 20:02:34.069: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/22/23 20:02:34.069
Apr 22 20:02:35.080: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:02:35.080: INFO: Found 0 / 1
Apr 22 20:02:36.081: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:02:36.081: INFO: Found 1 / 1
Apr 22 20:02:36.081: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 22 20:02:36.090: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:02:36.090: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 22 20:02:36.090: INFO: wait on agnhost-primary startup in kubectl-4474 
Apr 22 20:02:36.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 logs agnhost-primary-wlm7r agnhost-primary'
Apr 22 20:02:36.269: INFO: stderr: ""
Apr 22 20:02:36.270: INFO: stdout: "Paused\n"
STEP: exposing RC 04/22/23 20:02:36.27
Apr 22 20:02:36.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 22 20:02:36.466: INFO: stderr: ""
Apr 22 20:02:36.466: INFO: stdout: "service/rm2 exposed\n"
Apr 22 20:02:36.480: INFO: Service rm2 in namespace kubectl-4474 found.
STEP: exposing service 04/22/23 20:02:38.516
Apr 22 20:02:38.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 22 20:02:38.746: INFO: stderr: ""
Apr 22 20:02:38.746: INFO: stdout: "service/rm3 exposed\n"
Apr 22 20:02:38.762: INFO: Service rm3 in namespace kubectl-4474 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:02:40.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4474" for this suite. 04/22/23 20:02:40.791
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":248,"skipped":4470,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.106 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:33.7
    Apr 22 20:02:33.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:02:33.703
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:33.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:33.729
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 04/22/23 20:02:33.746
    Apr 22 20:02:33.746: INFO: namespace kubectl-4474
    Apr 22 20:02:33.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 create -f -'
    Apr 22 20:02:34.069: INFO: stderr: ""
    Apr 22 20:02:34.069: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/22/23 20:02:34.069
    Apr 22 20:02:35.080: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:02:35.080: INFO: Found 0 / 1
    Apr 22 20:02:36.081: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:02:36.081: INFO: Found 1 / 1
    Apr 22 20:02:36.081: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 22 20:02:36.090: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:02:36.090: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 22 20:02:36.090: INFO: wait on agnhost-primary startup in kubectl-4474 
    Apr 22 20:02:36.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 logs agnhost-primary-wlm7r agnhost-primary'
    Apr 22 20:02:36.269: INFO: stderr: ""
    Apr 22 20:02:36.270: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/22/23 20:02:36.27
    Apr 22 20:02:36.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 22 20:02:36.466: INFO: stderr: ""
    Apr 22 20:02:36.466: INFO: stdout: "service/rm2 exposed\n"
    Apr 22 20:02:36.480: INFO: Service rm2 in namespace kubectl-4474 found.
    STEP: exposing service 04/22/23 20:02:38.516
    Apr 22 20:02:38.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-4474 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 22 20:02:38.746: INFO: stderr: ""
    Apr 22 20:02:38.746: INFO: stdout: "service/rm3 exposed\n"
    Apr 22 20:02:38.762: INFO: Service rm3 in namespace kubectl-4474 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:02:40.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4474" for this suite. 04/22/23 20:02:40.791
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:40.809
Apr 22 20:02:40.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename events 04/22/23 20:02:40.816
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:40.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:40.863
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/22/23 20:02:40.876
STEP: listing all events in all namespaces 04/22/23 20:02:40.886
STEP: patching the test event 04/22/23 20:02:40.894
STEP: fetching the test event 04/22/23 20:02:40.918
STEP: updating the test event 04/22/23 20:02:40.924
STEP: getting the test event 04/22/23 20:02:40.943
STEP: deleting the test event 04/22/23 20:02:40.95
STEP: listing all events in all namespaces 04/22/23 20:02:40.963
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 22 20:02:40.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1934" for this suite. 04/22/23 20:02:40.979
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":249,"skipped":4471,"failed":0}
------------------------------
â€¢ [0.180 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:40.809
    Apr 22 20:02:40.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename events 04/22/23 20:02:40.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:40.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:40.863
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/22/23 20:02:40.876
    STEP: listing all events in all namespaces 04/22/23 20:02:40.886
    STEP: patching the test event 04/22/23 20:02:40.894
    STEP: fetching the test event 04/22/23 20:02:40.918
    STEP: updating the test event 04/22/23 20:02:40.924
    STEP: getting the test event 04/22/23 20:02:40.943
    STEP: deleting the test event 04/22/23 20:02:40.95
    STEP: listing all events in all namespaces 04/22/23 20:02:40.963
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 22 20:02:40.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1934" for this suite. 04/22/23 20:02:40.979
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:41.003
Apr 22 20:02:41.004: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename daemonsets 04/22/23 20:02:41.006
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:41.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:41.04
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Apr 22 20:02:41.077: INFO: Create a RollingUpdate DaemonSet
Apr 22 20:02:41.084: INFO: Check that daemon pods launch on every node of the cluster
Apr 22 20:02:41.091: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:41.092: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:41.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 20:02:41.097: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 20:02:42.110: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:42.110: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:42.120: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 20:02:42.120: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
Apr 22 20:02:43.108: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:43.109: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:43.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 22 20:02:43.121: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Apr 22 20:02:43.121: INFO: Update the DaemonSet to trigger a rollout
Apr 22 20:02:43.146: INFO: Updating DaemonSet daemon-set
Apr 22 20:02:46.203: INFO: Roll back the DaemonSet before rollout is complete
Apr 22 20:02:46.219: INFO: Updating DaemonSet daemon-set
Apr 22 20:02:46.219: INFO: Make sure DaemonSet rollback is complete
Apr 22 20:02:46.231: INFO: Wrong image for pod: daemon-set-59wl8. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr 22 20:02:46.231: INFO: Pod daemon-set-59wl8 is not available
Apr 22 20:02:46.242: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:46.242: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:47.267: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:47.271: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:48.275: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:48.276: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:49.297: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 22 20:02:49.298: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/22/23 20:02:49.312
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4618, will wait for the garbage collector to delete the pods 04/22/23 20:02:49.313
Apr 22 20:02:49.381: INFO: Deleting DaemonSet.extensions daemon-set took: 11.570554ms
Apr 22 20:02:49.482: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.430596ms
Apr 22 20:02:52.391: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 22 20:02:52.392: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 22 20:02:52.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27777"},"items":null}

Apr 22 20:02:52.405: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27777"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 22 20:02:52.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4618" for this suite. 04/22/23 20:02:52.44
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":250,"skipped":4482,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.450 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:41.003
    Apr 22 20:02:41.004: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename daemonsets 04/22/23 20:02:41.006
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:41.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:41.04
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Apr 22 20:02:41.077: INFO: Create a RollingUpdate DaemonSet
    Apr 22 20:02:41.084: INFO: Check that daemon pods launch on every node of the cluster
    Apr 22 20:02:41.091: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:41.092: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:41.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 20:02:41.097: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 20:02:42.110: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:42.110: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:42.120: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 20:02:42.120: INFO: Node cncf25-2-node-187aa4bdec5 is running 0 daemon pod, expected 1
    Apr 22 20:02:43.108: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:43.109: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:43.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 22 20:02:43.121: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    Apr 22 20:02:43.121: INFO: Update the DaemonSet to trigger a rollout
    Apr 22 20:02:43.146: INFO: Updating DaemonSet daemon-set
    Apr 22 20:02:46.203: INFO: Roll back the DaemonSet before rollout is complete
    Apr 22 20:02:46.219: INFO: Updating DaemonSet daemon-set
    Apr 22 20:02:46.219: INFO: Make sure DaemonSet rollback is complete
    Apr 22 20:02:46.231: INFO: Wrong image for pod: daemon-set-59wl8. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Apr 22 20:02:46.231: INFO: Pod daemon-set-59wl8 is not available
    Apr 22 20:02:46.242: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:46.242: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:47.267: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:47.271: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:48.275: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:48.276: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:49.297: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4b8379 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Apr 22 20:02:49.298: INFO: DaemonSet pods can't tolerate node cncf25-2-control-187aa4bae97 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/22/23 20:02:49.312
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4618, will wait for the garbage collector to delete the pods 04/22/23 20:02:49.313
    Apr 22 20:02:49.381: INFO: Deleting DaemonSet.extensions daemon-set took: 11.570554ms
    Apr 22 20:02:49.482: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.430596ms
    Apr 22 20:02:52.391: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 22 20:02:52.392: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 22 20:02:52.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27777"},"items":null}

    Apr 22 20:02:52.405: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27777"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 20:02:52.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4618" for this suite. 04/22/23 20:02:52.44
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:52.468
Apr 22 20:02:52.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-runtime 04/22/23 20:02:52.471
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:52.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:52.512
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 04/22/23 20:02:52.521
STEP: wait for the container to reach Failed 04/22/23 20:02:52.537
STEP: get the container status 04/22/23 20:02:56.577
STEP: the container should be terminated 04/22/23 20:02:56.585
STEP: the termination message should be set 04/22/23 20:02:56.585
Apr 22 20:02:56.586: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/22/23 20:02:56.586
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 22 20:02:56.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1953" for this suite. 04/22/23 20:02:56.641
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":251,"skipped":4491,"failed":0}
------------------------------
â€¢ [4.188 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:52.468
    Apr 22 20:02:52.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-runtime 04/22/23 20:02:52.471
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:52.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:52.512
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 04/22/23 20:02:52.521
    STEP: wait for the container to reach Failed 04/22/23 20:02:52.537
    STEP: get the container status 04/22/23 20:02:56.577
    STEP: the container should be terminated 04/22/23 20:02:56.585
    STEP: the termination message should be set 04/22/23 20:02:56.585
    Apr 22 20:02:56.586: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/22/23 20:02:56.586
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 22 20:02:56.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1953" for this suite. 04/22/23 20:02:56.641
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:02:56.662
Apr 22 20:02:56.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pod-network-test 04/22/23 20:02:56.666
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:56.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:56.711
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-1082 04/22/23 20:02:56.72
STEP: creating a selector 04/22/23 20:02:56.721
STEP: Creating the service pods in kubernetes 04/22/23 20:02:56.721
Apr 22 20:02:56.721: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 22 20:02:56.767: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1082" to be "running and ready"
Apr 22 20:02:56.775: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054867ms
Apr 22 20:02:56.776: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:02:58.794: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.026765975s
Apr 22 20:02:58.794: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:03:00.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017798217s
Apr 22 20:03:00.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:03:02.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017181466s
Apr 22 20:03:02.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:03:04.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018302855s
Apr 22 20:03:04.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:03:06.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017270226s
Apr 22 20:03:06.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:03:08.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.021154023s
Apr 22 20:03:08.789: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 22 20:03:08.789: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 22 20:03:08.795: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1082" to be "running and ready"
Apr 22 20:03:08.803: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 8.273579ms
Apr 22 20:03:08.804: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 22 20:03:08.804: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 04/22/23 20:03:08.812
Apr 22 20:03:08.850: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1082" to be "running"
Apr 22 20:03:08.864: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.14176ms
Apr 22 20:03:10.883: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.032912782s
Apr 22 20:03:10.884: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 22 20:03:10.895: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1082" to be "running"
Apr 22 20:03:10.902: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.498209ms
Apr 22 20:03:10.902: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 22 20:03:10.910: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr 22 20:03:10.911: INFO: Going to poll 10.44.0.6 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Apr 22 20:03:10.919: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.44.0.6:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1082 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 20:03:10.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:03:10.923: INFO: ExecWithOptions: Clientset creation
Apr 22 20:03:10.924: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1082/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.44.0.6%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 22 20:03:11.127: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 22 20:03:11.127: INFO: Going to poll 10.36.0.1 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Apr 22 20:03:11.135: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.36.0.1:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1082 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 20:03:11.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:03:11.137: INFO: ExecWithOptions: Clientset creation
Apr 22 20:03:11.137: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1082/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.36.0.1%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 22 20:03:11.319: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 22 20:03:11.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1082" for this suite. 04/22/23 20:03:11.33
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":252,"skipped":4496,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.690 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:02:56.662
    Apr 22 20:02:56.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pod-network-test 04/22/23 20:02:56.666
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:02:56.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:02:56.711
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-1082 04/22/23 20:02:56.72
    STEP: creating a selector 04/22/23 20:02:56.721
    STEP: Creating the service pods in kubernetes 04/22/23 20:02:56.721
    Apr 22 20:02:56.721: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 22 20:02:56.767: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1082" to be "running and ready"
    Apr 22 20:02:56.775: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054867ms
    Apr 22 20:02:56.776: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:02:58.794: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.026765975s
    Apr 22 20:02:58.794: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:03:00.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017798217s
    Apr 22 20:03:00.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:03:02.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017181466s
    Apr 22 20:03:02.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:03:04.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018302855s
    Apr 22 20:03:04.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:03:06.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017270226s
    Apr 22 20:03:06.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:03:08.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.021154023s
    Apr 22 20:03:08.789: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 22 20:03:08.789: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 22 20:03:08.795: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1082" to be "running and ready"
    Apr 22 20:03:08.803: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 8.273579ms
    Apr 22 20:03:08.804: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 22 20:03:08.804: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 04/22/23 20:03:08.812
    Apr 22 20:03:08.850: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1082" to be "running"
    Apr 22 20:03:08.864: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.14176ms
    Apr 22 20:03:10.883: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.032912782s
    Apr 22 20:03:10.884: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 22 20:03:10.895: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1082" to be "running"
    Apr 22 20:03:10.902: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.498209ms
    Apr 22 20:03:10.902: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 22 20:03:10.910: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Apr 22 20:03:10.911: INFO: Going to poll 10.44.0.6 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Apr 22 20:03:10.919: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.44.0.6:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1082 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 20:03:10.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:03:10.923: INFO: ExecWithOptions: Clientset creation
    Apr 22 20:03:10.924: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1082/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.44.0.6%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 22 20:03:11.127: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 22 20:03:11.127: INFO: Going to poll 10.36.0.1 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Apr 22 20:03:11.135: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.36.0.1:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1082 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 20:03:11.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:03:11.137: INFO: ExecWithOptions: Clientset creation
    Apr 22 20:03:11.137: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1082/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.36.0.1%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 22 20:03:11.319: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 22 20:03:11.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1082" for this suite. 04/22/23 20:03:11.33
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:03:11.36
Apr 22 20:03:11.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-webhook 04/22/23 20:03:11.362
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:11.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:11.418
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/22/23 20:03:11.426
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/22/23 20:03:11.916
STEP: Deploying the custom resource conversion webhook pod 04/22/23 20:03:11.937
STEP: Wait for the deployment to be ready 04/22/23 20:03:11.959
Apr 22 20:03:11.989: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:03:14.012
STEP: Verifying the service has paired with the endpoint 04/22/23 20:03:14.063
Apr 22 20:03:15.065: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 22 20:03:15.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Creating a v1 custom resource 04/22/23 20:03:17.787
STEP: v2 custom resource should be converted 04/22/23 20:03:17.803
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:03:18.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6083" for this suite. 04/22/23 20:03:18.382
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":253,"skipped":4509,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.144 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:03:11.36
    Apr 22 20:03:11.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-webhook 04/22/23 20:03:11.362
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:11.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:11.418
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/22/23 20:03:11.426
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/22/23 20:03:11.916
    STEP: Deploying the custom resource conversion webhook pod 04/22/23 20:03:11.937
    STEP: Wait for the deployment to be ready 04/22/23 20:03:11.959
    Apr 22 20:03:11.989: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:03:14.012
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:03:14.063
    Apr 22 20:03:15.065: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 22 20:03:15.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Creating a v1 custom resource 04/22/23 20:03:17.787
    STEP: v2 custom resource should be converted 04/22/23 20:03:17.803
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:03:18.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6083" for this suite. 04/22/23 20:03:18.382
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:03:18.521
Apr 22 20:03:18.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename watch 04/22/23 20:03:18.523
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:18.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:18.552
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/22/23 20:03:18.565
STEP: creating a new configmap 04/22/23 20:03:18.566
STEP: modifying the configmap once 04/22/23 20:03:18.571
STEP: closing the watch once it receives two notifications 04/22/23 20:03:18.579
Apr 22 20:03:18.579: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28029 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 20:03:18.579: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28030 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/22/23 20:03:18.58
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/22/23 20:03:18.587
STEP: deleting the configmap 04/22/23 20:03:18.589
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/22/23 20:03:18.596
Apr 22 20:03:18.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28031 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 22 20:03:18.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28032 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 22 20:03:18.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-220" for this suite. 04/22/23 20:03:18.602
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":254,"skipped":4553,"failed":0}
------------------------------
â€¢ [0.089 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:03:18.521
    Apr 22 20:03:18.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename watch 04/22/23 20:03:18.523
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:18.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:18.552
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/22/23 20:03:18.565
    STEP: creating a new configmap 04/22/23 20:03:18.566
    STEP: modifying the configmap once 04/22/23 20:03:18.571
    STEP: closing the watch once it receives two notifications 04/22/23 20:03:18.579
    Apr 22 20:03:18.579: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28029 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 20:03:18.579: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28030 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/22/23 20:03:18.58
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/22/23 20:03:18.587
    STEP: deleting the configmap 04/22/23 20:03:18.589
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/22/23 20:03:18.596
    Apr 22 20:03:18.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28031 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 22 20:03:18.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-220  7c169abb-f8fe-4f56-9ffa-2c7db4c8110a 28032 0 2023-04-22 20:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-22 20:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 22 20:03:18.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-220" for this suite. 04/22/23 20:03:18.602
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:03:18.628
Apr 22 20:03:18.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename cronjob 04/22/23 20:03:18.629
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:18.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:18.658
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/22/23 20:03:18.661
STEP: Ensuring a job is scheduled 04/22/23 20:03:18.668
STEP: Ensuring exactly one is scheduled 04/22/23 20:04:00.678
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/22/23 20:04:00.685
STEP: Ensuring the job is replaced with a new one 04/22/23 20:04:00.694
STEP: Removing cronjob 04/22/23 20:05:00.708
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 22 20:05:00.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3058" for this suite. 04/22/23 20:05:00.75
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":255,"skipped":4587,"failed":0}
------------------------------
â€¢ [SLOW TEST] [102.145 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:03:18.628
    Apr 22 20:03:18.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename cronjob 04/22/23 20:03:18.629
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:03:18.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:03:18.658
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/22/23 20:03:18.661
    STEP: Ensuring a job is scheduled 04/22/23 20:03:18.668
    STEP: Ensuring exactly one is scheduled 04/22/23 20:04:00.678
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/22/23 20:04:00.685
    STEP: Ensuring the job is replaced with a new one 04/22/23 20:04:00.694
    STEP: Removing cronjob 04/22/23 20:05:00.708
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 22 20:05:00.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3058" for this suite. 04/22/23 20:05:00.75
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:05:00.786
Apr 22 20:05:00.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 20:05:00.792
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:00.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:00.844
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 22 20:05:00.851: INFO: Creating ReplicaSet my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2
Apr 22 20:05:00.879: INFO: Pod name my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2: Found 1 pods out of 1
Apr 22 20:05:00.879: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2" is running
Apr 22 20:05:00.879: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" in namespace "replicaset-9752" to be "running"
Apr 22 20:05:00.887: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.857145ms
Apr 22 20:05:02.896: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp": Phase="Running", Reason="", readiness=true. Elapsed: 2.016608129s
Apr 22 20:05:02.897: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" satisfied condition "running"
Apr 22 20:05:02.897: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" is running (conditions: [])
Apr 22 20:05:02.898: INFO: Trying to dial the pod
Apr 22 20:05:07.928: INFO: Controller my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2: Got expected result from replica 1 [my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp]: "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 20:05:07.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9752" for this suite. 04/22/23 20:05:07.939
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":256,"skipped":4598,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.167 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:05:00.786
    Apr 22 20:05:00.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 20:05:00.792
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:00.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:00.844
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 22 20:05:00.851: INFO: Creating ReplicaSet my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2
    Apr 22 20:05:00.879: INFO: Pod name my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2: Found 1 pods out of 1
    Apr 22 20:05:00.879: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2" is running
    Apr 22 20:05:00.879: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" in namespace "replicaset-9752" to be "running"
    Apr 22 20:05:00.887: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.857145ms
    Apr 22 20:05:02.896: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp": Phase="Running", Reason="", readiness=true. Elapsed: 2.016608129s
    Apr 22 20:05:02.897: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" satisfied condition "running"
    Apr 22 20:05:02.897: INFO: Pod "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp" is running (conditions: [])
    Apr 22 20:05:02.898: INFO: Trying to dial the pod
    Apr 22 20:05:07.928: INFO: Controller my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2: Got expected result from replica 1 [my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp]: "my-hostname-basic-2bf074e2-74df-4365-85af-1853cd1079e2-bjtpp", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 20:05:07.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9752" for this suite. 04/22/23 20:05:07.939
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:05:07.958
Apr 22 20:05:07.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:05:07.961
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:08.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:08.015
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:05:08.026
Apr 22 20:05:08.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 22 20:05:08.196: INFO: stderr: ""
Apr 22 20:05:08.196: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/22/23 20:05:08.196
Apr 22 20:05:08.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr 22 20:05:09.383: INFO: stderr: ""
Apr 22 20:05:09.383: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:05:09.383
Apr 22 20:05:09.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 delete pods e2e-test-httpd-pod'
Apr 22 20:05:10.881: INFO: stderr: ""
Apr 22 20:05:10.881: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:05:10.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-234" for this suite. 04/22/23 20:05:10.895
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":257,"skipped":4605,"failed":0}
------------------------------
â€¢ [2.952 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:05:07.958
    Apr 22 20:05:07.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:05:07.961
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:08.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:08.015
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:05:08.026
    Apr 22 20:05:08.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 22 20:05:08.196: INFO: stderr: ""
    Apr 22 20:05:08.196: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/22/23 20:05:08.196
    Apr 22 20:05:08.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Apr 22 20:05:09.383: INFO: stderr: ""
    Apr 22 20:05:09.383: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:05:09.383
    Apr 22 20:05:09.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-234 delete pods e2e-test-httpd-pod'
    Apr 22 20:05:10.881: INFO: stderr: ""
    Apr 22 20:05:10.881: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:05:10.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-234" for this suite. 04/22/23 20:05:10.895
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:05:10.914
Apr 22 20:05:10.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:05:10.92
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:10.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:10.969
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:05:10.995
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:05:11.951
STEP: Deploying the webhook pod 04/22/23 20:05:11.966
STEP: Wait for the deployment to be ready 04/22/23 20:05:11.992
Apr 22 20:05:12.028: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:05:14.056
STEP: Verifying the service has paired with the endpoint 04/22/23 20:05:14.091
Apr 22 20:05:15.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Apr 22 20:05:15.099: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5495-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 20:05:15.627
STEP: Creating a custom resource while v1 is storage version 04/22/23 20:05:15.672
STEP: Patching Custom Resource Definition to set v2 as storage 04/22/23 20:05:17.793
STEP: Patching the custom resource while v2 is storage version 04/22/23 20:05:17.846
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:05:18.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7016" for this suite. 04/22/23 20:05:18.471
STEP: Destroying namespace "webhook-7016-markers" for this suite. 04/22/23 20:05:18.479
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":258,"skipped":4606,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.744 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:05:10.914
    Apr 22 20:05:10.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:05:10.92
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:10.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:10.969
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:05:10.995
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:05:11.951
    STEP: Deploying the webhook pod 04/22/23 20:05:11.966
    STEP: Wait for the deployment to be ready 04/22/23 20:05:11.992
    Apr 22 20:05:12.028: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:05:14.056
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:05:14.091
    Apr 22 20:05:15.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Apr 22 20:05:15.099: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5495-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 20:05:15.627
    STEP: Creating a custom resource while v1 is storage version 04/22/23 20:05:15.672
    STEP: Patching Custom Resource Definition to set v2 as storage 04/22/23 20:05:17.793
    STEP: Patching the custom resource while v2 is storage version 04/22/23 20:05:17.846
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:05:18.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7016" for this suite. 04/22/23 20:05:18.471
    STEP: Destroying namespace "webhook-7016-markers" for this suite. 04/22/23 20:05:18.479
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:05:18.675
Apr 22 20:05:18.676: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 20:05:18.678
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:18.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:18.706
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 04/22/23 20:05:18.717
STEP: Creating a ResourceQuota 04/22/23 20:05:23.723
STEP: Ensuring resource quota status is calculated 04/22/23 20:05:23.731
STEP: Creating a ReplicaSet 04/22/23 20:05:25.74
STEP: Ensuring resource quota status captures replicaset creation 04/22/23 20:05:25.766
STEP: Deleting a ReplicaSet 04/22/23 20:05:27.775
STEP: Ensuring resource quota status released usage 04/22/23 20:05:27.789
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 20:05:29.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9757" for this suite. 04/22/23 20:05:29.808
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":259,"skipped":4617,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.153 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:05:18.675
    Apr 22 20:05:18.676: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 20:05:18.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:18.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:18.706
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 04/22/23 20:05:18.717
    STEP: Creating a ResourceQuota 04/22/23 20:05:23.723
    STEP: Ensuring resource quota status is calculated 04/22/23 20:05:23.731
    STEP: Creating a ReplicaSet 04/22/23 20:05:25.74
    STEP: Ensuring resource quota status captures replicaset creation 04/22/23 20:05:25.766
    STEP: Deleting a ReplicaSet 04/22/23 20:05:27.775
    STEP: Ensuring resource quota status released usage 04/22/23 20:05:27.789
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 20:05:29.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9757" for this suite. 04/22/23 20:05:29.808
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:05:29.831
Apr 22 20:05:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 20:05:29.833
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:29.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:29.894
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 04/22/23 20:05:29.903
STEP: Ensuring active pods == parallelism 04/22/23 20:05:29.913
STEP: delete a job 04/22/23 20:05:31.925
STEP: deleting Job.batch foo in namespace job-1266, will wait for the garbage collector to delete the pods 04/22/23 20:05:31.925
Apr 22 20:05:32.000: INFO: Deleting Job.batch foo took: 15.783851ms
Apr 22 20:05:32.102: INFO: Terminating Job.batch foo pods took: 101.354388ms
STEP: Ensuring job was deleted 04/22/23 20:06:04.202
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 20:06:04.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1266" for this suite. 04/22/23 20:06:04.226
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":260,"skipped":4631,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.412 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:05:29.831
    Apr 22 20:05:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 20:05:29.833
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:05:29.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:05:29.894
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 04/22/23 20:05:29.903
    STEP: Ensuring active pods == parallelism 04/22/23 20:05:29.913
    STEP: delete a job 04/22/23 20:05:31.925
    STEP: deleting Job.batch foo in namespace job-1266, will wait for the garbage collector to delete the pods 04/22/23 20:05:31.925
    Apr 22 20:05:32.000: INFO: Deleting Job.batch foo took: 15.783851ms
    Apr 22 20:05:32.102: INFO: Terminating Job.batch foo pods took: 101.354388ms
    STEP: Ensuring job was deleted 04/22/23 20:06:04.202
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 20:06:04.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1266" for this suite. 04/22/23 20:06:04.226
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:06:04.286
Apr 22 20:06:04.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 20:06:04.288
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:04.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:04.345
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 04/22/23 20:06:04.353
STEP: watching for the ServiceAccount to be added 04/22/23 20:06:04.375
STEP: patching the ServiceAccount 04/22/23 20:06:04.379
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/22/23 20:06:04.397
STEP: deleting the ServiceAccount 04/22/23 20:06:04.404
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 20:06:04.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2616" for this suite. 04/22/23 20:06:04.44
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":261,"skipped":4675,"failed":0}
------------------------------
â€¢ [0.163 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:06:04.286
    Apr 22 20:06:04.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 20:06:04.288
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:04.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:04.345
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 04/22/23 20:06:04.353
    STEP: watching for the ServiceAccount to be added 04/22/23 20:06:04.375
    STEP: patching the ServiceAccount 04/22/23 20:06:04.379
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/22/23 20:06:04.397
    STEP: deleting the ServiceAccount 04/22/23 20:06:04.404
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 20:06:04.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2616" for this suite. 04/22/23 20:06:04.44
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:06:04.458
Apr 22 20:06:04.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pod-network-test 04/22/23 20:06:04.462
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:04.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:04.506
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3792 04/22/23 20:06:04.515
STEP: creating a selector 04/22/23 20:06:04.516
STEP: Creating the service pods in kubernetes 04/22/23 20:06:04.517
Apr 22 20:06:04.517: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 22 20:06:04.566: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3792" to be "running and ready"
Apr 22 20:06:04.576: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.444376ms
Apr 22 20:06:04.577: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:06:06.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.020475303s
Apr 22 20:06:06.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:08.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.020060049s
Apr 22 20:06:08.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:10.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020128422s
Apr 22 20:06:10.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:12.585: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018375562s
Apr 22 20:06:12.585: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:14.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02029801s
Apr 22 20:06:14.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:16.586: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018964487s
Apr 22 20:06:16.586: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:18.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021742943s
Apr 22 20:06:18.589: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:20.590: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022966163s
Apr 22 20:06:20.590: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:22.586: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.01967558s
Apr 22 20:06:22.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:24.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.02026827s
Apr 22 20:06:24.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 22 20:06:26.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.01987364s
Apr 22 20:06:26.587: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 22 20:06:26.587: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 22 20:06:26.594: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3792" to be "running and ready"
Apr 22 20:06:26.601: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 7.211596ms
Apr 22 20:06:26.602: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 22 20:06:26.602: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 04/22/23 20:06:26.608
Apr 22 20:06:26.627: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3792" to be "running"
Apr 22 20:06:26.639: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.033841ms
Apr 22 20:06:28.648: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.020303228s
Apr 22 20:06:28.648: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 22 20:06:28.658: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr 22 20:06:28.658: INFO: Breadth first check of 10.44.0.6 on host 10.1.1.165...
Apr 22 20:06:28.668: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.2:9080/dial?request=hostname&protocol=udp&host=10.44.0.6&port=8081&tries=1'] Namespace:pod-network-test-3792 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 20:06:28.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:06:28.671: INFO: ExecWithOptions: Clientset creation
Apr 22 20:06:28.671: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3792/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.2%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.44.0.6%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 22 20:06:28.869: INFO: Waiting for responses: map[]
Apr 22 20:06:28.869: INFO: reached 10.44.0.6 after 0/1 tries
Apr 22 20:06:28.869: INFO: Breadth first check of 10.36.0.1 on host 10.1.1.128...
Apr 22 20:06:28.874: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.2:9080/dial?request=hostname&protocol=udp&host=10.36.0.1&port=8081&tries=1'] Namespace:pod-network-test-3792 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 20:06:28.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:06:28.878: INFO: ExecWithOptions: Clientset creation
Apr 22 20:06:28.878: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3792/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.2%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.36.0.1%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 22 20:06:29.057: INFO: Waiting for responses: map[]
Apr 22 20:06:29.057: INFO: reached 10.36.0.1 after 0/1 tries
Apr 22 20:06:29.057: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 22 20:06:29.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3792" for this suite. 04/22/23 20:06:29.071
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":262,"skipped":4680,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.632 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:06:04.458
    Apr 22 20:06:04.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pod-network-test 04/22/23 20:06:04.462
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:04.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:04.506
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3792 04/22/23 20:06:04.515
    STEP: creating a selector 04/22/23 20:06:04.516
    STEP: Creating the service pods in kubernetes 04/22/23 20:06:04.517
    Apr 22 20:06:04.517: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 22 20:06:04.566: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3792" to be "running and ready"
    Apr 22 20:06:04.576: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.444376ms
    Apr 22 20:06:04.577: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:06:06.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.020475303s
    Apr 22 20:06:06.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:08.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.020060049s
    Apr 22 20:06:08.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:10.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020128422s
    Apr 22 20:06:10.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:12.585: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018375562s
    Apr 22 20:06:12.585: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:14.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02029801s
    Apr 22 20:06:14.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:16.586: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018964487s
    Apr 22 20:06:16.586: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:18.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021742943s
    Apr 22 20:06:18.589: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:20.590: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022966163s
    Apr 22 20:06:20.590: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:22.586: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.01967558s
    Apr 22 20:06:22.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:24.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.02026827s
    Apr 22 20:06:24.587: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 22 20:06:26.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.01987364s
    Apr 22 20:06:26.587: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 22 20:06:26.587: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 22 20:06:26.594: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3792" to be "running and ready"
    Apr 22 20:06:26.601: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 7.211596ms
    Apr 22 20:06:26.602: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 22 20:06:26.602: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 04/22/23 20:06:26.608
    Apr 22 20:06:26.627: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3792" to be "running"
    Apr 22 20:06:26.639: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.033841ms
    Apr 22 20:06:28.648: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.020303228s
    Apr 22 20:06:28.648: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 22 20:06:28.658: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Apr 22 20:06:28.658: INFO: Breadth first check of 10.44.0.6 on host 10.1.1.165...
    Apr 22 20:06:28.668: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.2:9080/dial?request=hostname&protocol=udp&host=10.44.0.6&port=8081&tries=1'] Namespace:pod-network-test-3792 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 20:06:28.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:06:28.671: INFO: ExecWithOptions: Clientset creation
    Apr 22 20:06:28.671: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3792/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.2%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.44.0.6%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 22 20:06:28.869: INFO: Waiting for responses: map[]
    Apr 22 20:06:28.869: INFO: reached 10.44.0.6 after 0/1 tries
    Apr 22 20:06:28.869: INFO: Breadth first check of 10.36.0.1 on host 10.1.1.128...
    Apr 22 20:06:28.874: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.36.0.2:9080/dial?request=hostname&protocol=udp&host=10.36.0.1&port=8081&tries=1'] Namespace:pod-network-test-3792 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 20:06:28.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:06:28.878: INFO: ExecWithOptions: Clientset creation
    Apr 22 20:06:28.878: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3792/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.36.0.2%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.36.0.1%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 22 20:06:29.057: INFO: Waiting for responses: map[]
    Apr 22 20:06:29.057: INFO: reached 10.36.0.1 after 0/1 tries
    Apr 22 20:06:29.057: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 22 20:06:29.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3792" for this suite. 04/22/23 20:06:29.071
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:06:29.103
Apr 22 20:06:29.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename endpointslicemirroring 04/22/23 20:06:29.106
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:29.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:29.159
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/22/23 20:06:29.195
Apr 22 20:06:29.214: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/22/23 20:06:31.226
STEP: mirroring deletion of a custom Endpoint 04/22/23 20:06:31.253
Apr 22 20:06:31.284: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Apr 22 20:06:33.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-2205" for this suite. 04/22/23 20:06:33.303
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":263,"skipped":4716,"failed":0}
------------------------------
â€¢ [4.217 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:06:29.103
    Apr 22 20:06:29.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename endpointslicemirroring 04/22/23 20:06:29.106
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:29.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:29.159
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/22/23 20:06:29.195
    Apr 22 20:06:29.214: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/22/23 20:06:31.226
    STEP: mirroring deletion of a custom Endpoint 04/22/23 20:06:31.253
    Apr 22 20:06:31.284: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Apr 22 20:06:33.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-2205" for this suite. 04/22/23 20:06:33.303
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:06:33.336
Apr 22 20:06:33.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:06:33.339
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:33.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:33.39
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:06:33.4
Apr 22 20:06:33.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719" in namespace "projected-9872" to be "Succeeded or Failed"
Apr 22 20:06:33.431: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Pending", Reason="", readiness=false. Elapsed: 13.299498ms
Apr 22 20:06:35.438: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Running", Reason="", readiness=false. Elapsed: 2.020342688s
Apr 22 20:06:37.441: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023307596s
STEP: Saw pod success 04/22/23 20:06:37.442
Apr 22 20:06:37.443: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719" satisfied condition "Succeeded or Failed"
Apr 22 20:06:37.453: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 container client-container: <nil>
STEP: delete the pod 04/22/23 20:06:37.496
Apr 22 20:06:37.534: INFO: Waiting for pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 to disappear
Apr 22 20:06:37.542: INFO: Pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:06:37.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9872" for this suite. 04/22/23 20:06:37.554
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":264,"skipped":4726,"failed":0}
------------------------------
â€¢ [4.235 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:06:33.336
    Apr 22 20:06:33.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:06:33.339
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:33.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:33.39
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:06:33.4
    Apr 22 20:06:33.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719" in namespace "projected-9872" to be "Succeeded or Failed"
    Apr 22 20:06:33.431: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Pending", Reason="", readiness=false. Elapsed: 13.299498ms
    Apr 22 20:06:35.438: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Running", Reason="", readiness=false. Elapsed: 2.020342688s
    Apr 22 20:06:37.441: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023307596s
    STEP: Saw pod success 04/22/23 20:06:37.442
    Apr 22 20:06:37.443: INFO: Pod "downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719" satisfied condition "Succeeded or Failed"
    Apr 22 20:06:37.453: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:06:37.496
    Apr 22 20:06:37.534: INFO: Waiting for pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 to disappear
    Apr 22 20:06:37.542: INFO: Pod downwardapi-volume-a19f3f62-131d-48cc-8ced-94373e8ef719 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:06:37.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9872" for this suite. 04/22/23 20:06:37.554
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:06:37.592
Apr 22 20:06:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption 04/22/23 20:06:37.595
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:37.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:37.638
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 22 20:06:37.675: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 20:07:37.766: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 04/22/23 20:07:37.775
Apr 22 20:07:37.832: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 22 20:07:37.843: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 22 20:07:37.884: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 22 20:07:37.898: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/22/23 20:07:37.898
Apr 22 20:07:37.899: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7504" to be "running"
Apr 22 20:07:37.906: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.748664ms
Apr 22 20:07:39.915: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014914078s
Apr 22 20:07:41.916: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.016658925s
Apr 22 20:07:41.917: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 22 20:07:41.918: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
Apr 22 20:07:41.925: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.815412ms
Apr 22 20:07:41.925: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 22 20:07:41.925: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
Apr 22 20:07:41.931: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.711243ms
Apr 22 20:07:43.950: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025055126s
Apr 22 20:07:45.941: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.015894031s
Apr 22 20:07:45.941: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 22 20:07:45.941: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
Apr 22 20:07:45.949: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.883533ms
Apr 22 20:07:45.949: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/22/23 20:07:45.949
Apr 22 20:07:45.964: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7504" to be "running"
Apr 22 20:07:45.975: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.396679ms
Apr 22 20:07:47.983: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01866368s
Apr 22 20:07:49.983: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.018942562s
Apr 22 20:07:49.983: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 22 20:07:50.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7504" for this suite. 04/22/23 20:07:50.032
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":265,"skipped":4751,"failed":0}
------------------------------
â€¢ [SLOW TEST] [72.555 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:06:37.592
    Apr 22 20:06:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption 04/22/23 20:06:37.595
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:06:37.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:06:37.638
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 22 20:06:37.675: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 20:07:37.766: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 04/22/23 20:07:37.775
    Apr 22 20:07:37.832: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 22 20:07:37.843: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 22 20:07:37.884: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 22 20:07:37.898: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/22/23 20:07:37.898
    Apr 22 20:07:37.899: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7504" to be "running"
    Apr 22 20:07:37.906: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.748664ms
    Apr 22 20:07:39.915: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014914078s
    Apr 22 20:07:41.916: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.016658925s
    Apr 22 20:07:41.917: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 22 20:07:41.918: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
    Apr 22 20:07:41.925: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.815412ms
    Apr 22 20:07:41.925: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 22 20:07:41.925: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
    Apr 22 20:07:41.931: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.711243ms
    Apr 22 20:07:43.950: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025055126s
    Apr 22 20:07:45.941: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.015894031s
    Apr 22 20:07:45.941: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 22 20:07:45.941: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7504" to be "running"
    Apr 22 20:07:45.949: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.883533ms
    Apr 22 20:07:45.949: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/22/23 20:07:45.949
    Apr 22 20:07:45.964: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7504" to be "running"
    Apr 22 20:07:45.975: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.396679ms
    Apr 22 20:07:47.983: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01866368s
    Apr 22 20:07:49.983: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.018942562s
    Apr 22 20:07:49.983: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 20:07:50.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7504" for this suite. 04/22/23 20:07:50.032
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:07:50.173
Apr 22 20:07:50.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 20:07:50.176
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:07:50.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:07:50.212
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 04/22/23 20:07:50.22
STEP: Ensuring job reaches completions 04/22/23 20:07:50.233
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 20:08:02.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4682" for this suite. 04/22/23 20:08:02.253
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":266,"skipped":4767,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.095 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:07:50.173
    Apr 22 20:07:50.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 20:07:50.176
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:07:50.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:07:50.212
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 04/22/23 20:07:50.22
    STEP: Ensuring job reaches completions 04/22/23 20:07:50.233
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 20:08:02.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4682" for this suite. 04/22/23 20:08:02.253
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:02.307
Apr 22 20:08:02.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:08:02.31
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:02.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:02.363
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 04/22/23 20:08:02.37
Apr 22 20:08:02.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-7160 create -f -'
Apr 22 20:08:03.728: INFO: stderr: ""
Apr 22 20:08:03.728: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/22/23 20:08:03.728
Apr 22 20:08:04.739: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:08:04.740: INFO: Found 1 / 1
Apr 22 20:08:04.740: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/22/23 20:08:04.74
Apr 22 20:08:04.748: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:08:04.748: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 22 20:08:04.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-7160 patch pod agnhost-primary-72s5t -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 22 20:08:04.914: INFO: stderr: ""
Apr 22 20:08:04.914: INFO: stdout: "pod/agnhost-primary-72s5t patched\n"
STEP: checking annotations 04/22/23 20:08:04.914
Apr 22 20:08:04.925: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:08:04.925: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:08:04.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7160" for this suite. 04/22/23 20:08:04.94
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":267,"skipped":4832,"failed":0}
------------------------------
â€¢ [2.644 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:02.307
    Apr 22 20:08:02.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:08:02.31
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:02.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:02.363
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 04/22/23 20:08:02.37
    Apr 22 20:08:02.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-7160 create -f -'
    Apr 22 20:08:03.728: INFO: stderr: ""
    Apr 22 20:08:03.728: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/22/23 20:08:03.728
    Apr 22 20:08:04.739: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:08:04.740: INFO: Found 1 / 1
    Apr 22 20:08:04.740: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/22/23 20:08:04.74
    Apr 22 20:08:04.748: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:08:04.748: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 22 20:08:04.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-7160 patch pod agnhost-primary-72s5t -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 22 20:08:04.914: INFO: stderr: ""
    Apr 22 20:08:04.914: INFO: stdout: "pod/agnhost-primary-72s5t patched\n"
    STEP: checking annotations 04/22/23 20:08:04.914
    Apr 22 20:08:04.925: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:08:04.925: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:08:04.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7160" for this suite. 04/22/23 20:08:04.94
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:04.964
Apr 22 20:08:04.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:04.966
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:04.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:05.004
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 04/22/23 20:08:05.01
Apr 22 20:08:05.026: INFO: Waiting up to 5m0s for pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde" in namespace "emptydir-986" to be "Succeeded or Failed"
Apr 22 20:08:05.035: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Pending", Reason="", readiness=false. Elapsed: 9.172367ms
Apr 22 20:08:07.044: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018365568s
Apr 22 20:08:09.043: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017677452s
STEP: Saw pod success 04/22/23 20:08:09.044
Apr 22 20:08:09.044: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde" satisfied condition "Succeeded or Failed"
Apr 22 20:08:09.051: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde container test-container: <nil>
STEP: delete the pod 04/22/23 20:08:09.087
Apr 22 20:08:09.112: INFO: Waiting for pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde to disappear
Apr 22 20:08:09.122: INFO: Pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:08:09.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-986" for this suite. 04/22/23 20:08:09.132
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":268,"skipped":4843,"failed":0}
------------------------------
â€¢ [4.187 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:04.964
    Apr 22 20:08:04.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:04.966
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:04.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:05.004
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/22/23 20:08:05.01
    Apr 22 20:08:05.026: INFO: Waiting up to 5m0s for pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde" in namespace "emptydir-986" to be "Succeeded or Failed"
    Apr 22 20:08:05.035: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Pending", Reason="", readiness=false. Elapsed: 9.172367ms
    Apr 22 20:08:07.044: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018365568s
    Apr 22 20:08:09.043: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017677452s
    STEP: Saw pod success 04/22/23 20:08:09.044
    Apr 22 20:08:09.044: INFO: Pod "pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde" satisfied condition "Succeeded or Failed"
    Apr 22 20:08:09.051: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde container test-container: <nil>
    STEP: delete the pod 04/22/23 20:08:09.087
    Apr 22 20:08:09.112: INFO: Waiting for pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde to disappear
    Apr 22 20:08:09.122: INFO: Pod pod-c4d5a438-69e4-4c1e-8a93-2c6b61b53dde no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:08:09.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-986" for this suite. 04/22/23 20:08:09.132
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:09.17
Apr 22 20:08:09.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 20:08:09.178
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:09.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:09.221
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-8197362e-161e-4cea-b10f-66bc2f17b9e3 04/22/23 20:08:09.226
STEP: Creating a pod to test consume configMaps 04/22/23 20:08:09.238
Apr 22 20:08:09.252: INFO: Waiting up to 5m0s for pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b" in namespace "configmap-4736" to be "Succeeded or Failed"
Apr 22 20:08:09.261: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807361ms
Apr 22 20:08:11.270: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018004429s
Apr 22 20:08:13.271: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018501622s
STEP: Saw pod success 04/22/23 20:08:13.271
Apr 22 20:08:13.271: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b" satisfied condition "Succeeded or Failed"
Apr 22 20:08:13.279: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:08:13.294
Apr 22 20:08:13.329: INFO: Waiting for pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b to disappear
Apr 22 20:08:13.339: INFO: Pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 20:08:13.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4736" for this suite. 04/22/23 20:08:13.356
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":269,"skipped":4865,"failed":0}
------------------------------
â€¢ [4.206 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:09.17
    Apr 22 20:08:09.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 20:08:09.178
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:09.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:09.221
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-8197362e-161e-4cea-b10f-66bc2f17b9e3 04/22/23 20:08:09.226
    STEP: Creating a pod to test consume configMaps 04/22/23 20:08:09.238
    Apr 22 20:08:09.252: INFO: Waiting up to 5m0s for pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b" in namespace "configmap-4736" to be "Succeeded or Failed"
    Apr 22 20:08:09.261: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807361ms
    Apr 22 20:08:11.270: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018004429s
    Apr 22 20:08:13.271: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018501622s
    STEP: Saw pod success 04/22/23 20:08:13.271
    Apr 22 20:08:13.271: INFO: Pod "pod-configmaps-db79a26e-431d-4795-b248-941b98df847b" satisfied condition "Succeeded or Failed"
    Apr 22 20:08:13.279: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:08:13.294
    Apr 22 20:08:13.329: INFO: Waiting for pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b to disappear
    Apr 22 20:08:13.339: INFO: Pod pod-configmaps-db79a26e-431d-4795-b248-941b98df847b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 20:08:13.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4736" for this suite. 04/22/23 20:08:13.356
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:13.406
Apr 22 20:08:13.406: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:13.409
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:13.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:13.458
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/22/23 20:08:13.465
Apr 22 20:08:13.479: INFO: Waiting up to 5m0s for pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0" in namespace "emptydir-1684" to be "Succeeded or Failed"
Apr 22 20:08:13.489: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.457712ms
Apr 22 20:08:15.498: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018072201s
Apr 22 20:08:17.499: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019024469s
STEP: Saw pod success 04/22/23 20:08:17.499
Apr 22 20:08:17.500: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0" satisfied condition "Succeeded or Failed"
Apr 22 20:08:17.511: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 container test-container: <nil>
STEP: delete the pod 04/22/23 20:08:17.529
Apr 22 20:08:17.570: INFO: Waiting for pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 to disappear
Apr 22 20:08:17.577: INFO: Pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:08:17.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1684" for this suite. 04/22/23 20:08:17.587
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":270,"skipped":4888,"failed":0}
------------------------------
â€¢ [4.196 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:13.406
    Apr 22 20:08:13.406: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:13.409
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:13.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:13.458
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/22/23 20:08:13.465
    Apr 22 20:08:13.479: INFO: Waiting up to 5m0s for pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0" in namespace "emptydir-1684" to be "Succeeded or Failed"
    Apr 22 20:08:13.489: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.457712ms
    Apr 22 20:08:15.498: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018072201s
    Apr 22 20:08:17.499: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019024469s
    STEP: Saw pod success 04/22/23 20:08:17.499
    Apr 22 20:08:17.500: INFO: Pod "pod-712e8dcb-7c88-48b6-b280-8794f04667c0" satisfied condition "Succeeded or Failed"
    Apr 22 20:08:17.511: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 container test-container: <nil>
    STEP: delete the pod 04/22/23 20:08:17.529
    Apr 22 20:08:17.570: INFO: Waiting for pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 to disappear
    Apr 22 20:08:17.577: INFO: Pod pod-712e8dcb-7c88-48b6-b280-8794f04667c0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:08:17.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1684" for this suite. 04/22/23 20:08:17.587
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:17.602
Apr 22 20:08:17.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:08:17.606
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:17.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:17.668
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-3768 04/22/23 20:08:17.678
STEP: creating service affinity-clusterip-transition in namespace services-3768 04/22/23 20:08:17.679
STEP: creating replication controller affinity-clusterip-transition in namespace services-3768 04/22/23 20:08:17.701
I0422 20:08:17.718956      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3768, replica count: 3
I0422 20:08:20.770165      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 20:08:20.791: INFO: Creating new exec pod
Apr 22 20:08:20.806: INFO: Waiting up to 5m0s for pod "execpod-affinitywrcgc" in namespace "services-3768" to be "running"
Apr 22 20:08:20.813: INFO: Pod "execpod-affinitywrcgc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.630078ms
Apr 22 20:08:22.823: INFO: Pod "execpod-affinitywrcgc": Phase="Running", Reason="", readiness=true. Elapsed: 2.017665517s
Apr 22 20:08:22.824: INFO: Pod "execpod-affinitywrcgc" satisfied condition "running"
Apr 22 20:08:23.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 22 20:08:24.175: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 22 20:08:24.175: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:08:24.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.219.165 80'
Apr 22 20:08:24.545: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.219.165 80\nConnection to 10.108.219.165 80 port [tcp/http] succeeded!\n"
Apr 22 20:08:24.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:08:24.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.219.165:80/ ; done'
Apr 22 20:08:25.064: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n"
Apr 22 20:08:25.064: INFO: stdout: "\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-lhv5k\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-lhv5k\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5"
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-lhv5k
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-lhv5k
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.219.165:80/ ; done'
Apr 22 20:08:25.511: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n"
Apr 22 20:08:25.511: INFO: stdout: "\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5"
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
Apr 22 20:08:25.511: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3768, will wait for the garbage collector to delete the pods 04/22/23 20:08:25.545
Apr 22 20:08:25.621: INFO: Deleting ReplicationController affinity-clusterip-transition took: 14.236721ms
Apr 22 20:08:25.726: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 104.66319ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:08:27.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3768" for this suite. 04/22/23 20:08:27.958
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":271,"skipped":4888,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.365 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:17.602
    Apr 22 20:08:17.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:08:17.606
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:17.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:17.668
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-3768 04/22/23 20:08:17.678
    STEP: creating service affinity-clusterip-transition in namespace services-3768 04/22/23 20:08:17.679
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3768 04/22/23 20:08:17.701
    I0422 20:08:17.718956      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3768, replica count: 3
    I0422 20:08:20.770165      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 20:08:20.791: INFO: Creating new exec pod
    Apr 22 20:08:20.806: INFO: Waiting up to 5m0s for pod "execpod-affinitywrcgc" in namespace "services-3768" to be "running"
    Apr 22 20:08:20.813: INFO: Pod "execpod-affinitywrcgc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.630078ms
    Apr 22 20:08:22.823: INFO: Pod "execpod-affinitywrcgc": Phase="Running", Reason="", readiness=true. Elapsed: 2.017665517s
    Apr 22 20:08:22.824: INFO: Pod "execpod-affinitywrcgc" satisfied condition "running"
    Apr 22 20:08:23.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Apr 22 20:08:24.175: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 22 20:08:24.175: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:08:24.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.219.165 80'
    Apr 22 20:08:24.545: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.219.165 80\nConnection to 10.108.219.165 80 port [tcp/http] succeeded!\n"
    Apr 22 20:08:24.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:08:24.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.219.165:80/ ; done'
    Apr 22 20:08:25.064: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n"
    Apr 22 20:08:25.064: INFO: stdout: "\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-lhv5k\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-lhv5k\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-f7cqw\naffinity-clusterip-transition-4sgz5"
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-lhv5k
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-lhv5k
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-f7cqw
    Apr 22 20:08:25.064: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3768 exec execpod-affinitywrcgc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.219.165:80/ ; done'
    Apr 22 20:08:25.511: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.219.165:80/\n"
    Apr 22 20:08:25.511: INFO: stdout: "\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5\naffinity-clusterip-transition-4sgz5"
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Received response from host: affinity-clusterip-transition-4sgz5
    Apr 22 20:08:25.511: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3768, will wait for the garbage collector to delete the pods 04/22/23 20:08:25.545
    Apr 22 20:08:25.621: INFO: Deleting ReplicationController affinity-clusterip-transition took: 14.236721ms
    Apr 22 20:08:25.726: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 104.66319ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:08:27.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3768" for this suite. 04/22/23 20:08:27.958
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:27.978
Apr 22 20:08:27.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 20:08:27.983
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:28.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:28.009
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:08:28.016
Apr 22 20:08:28.025: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539" in namespace "downward-api-2413" to be "Succeeded or Failed"
Apr 22 20:08:28.029: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933192ms
Apr 22 20:08:30.039: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013862507s
Apr 22 20:08:32.036: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011347096s
STEP: Saw pod success 04/22/23 20:08:32.036
Apr 22 20:08:32.037: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539" satisfied condition "Succeeded or Failed"
Apr 22 20:08:32.045: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 container client-container: <nil>
STEP: delete the pod 04/22/23 20:08:32.062
Apr 22 20:08:32.095: INFO: Waiting for pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 to disappear
Apr 22 20:08:32.102: INFO: Pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 20:08:32.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2413" for this suite. 04/22/23 20:08:32.115
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":272,"skipped":4902,"failed":0}
------------------------------
â€¢ [4.155 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:27.978
    Apr 22 20:08:27.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 20:08:27.983
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:28.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:28.009
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:08:28.016
    Apr 22 20:08:28.025: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539" in namespace "downward-api-2413" to be "Succeeded or Failed"
    Apr 22 20:08:28.029: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933192ms
    Apr 22 20:08:30.039: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013862507s
    Apr 22 20:08:32.036: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011347096s
    STEP: Saw pod success 04/22/23 20:08:32.036
    Apr 22 20:08:32.037: INFO: Pod "downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539" satisfied condition "Succeeded or Failed"
    Apr 22 20:08:32.045: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:08:32.062
    Apr 22 20:08:32.095: INFO: Waiting for pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 to disappear
    Apr 22 20:08:32.102: INFO: Pod downwardapi-volume-44c8fd78-f6d5-4c3f-b40d-9114456e2539 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 20:08:32.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2413" for this suite. 04/22/23 20:08:32.115
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:32.163
Apr 22 20:08:32.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:08:32.166
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:32.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:32.218
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 22 20:08:32.243: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b" in namespace "kubelet-test-6696" to be "running and ready"
Apr 22 20:08:32.252: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.578642ms
Apr 22 20:08:32.252: INFO: The phase of Pod busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:08:34.260: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.015584537s
Apr 22 20:08:34.260: INFO: The phase of Pod busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b is Running (Ready = true)
Apr 22 20:08:34.260: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 22 20:08:34.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6696" for this suite. 04/22/23 20:08:34.296
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":273,"skipped":4933,"failed":0}
------------------------------
â€¢ [2.147 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:32.163
    Apr 22 20:08:32.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:08:32.166
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:32.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:32.218
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 22 20:08:32.243: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b" in namespace "kubelet-test-6696" to be "running and ready"
    Apr 22 20:08:32.252: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.578642ms
    Apr 22 20:08:32.252: INFO: The phase of Pod busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:08:34.260: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.015584537s
    Apr 22 20:08:34.260: INFO: The phase of Pod busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b is Running (Ready = true)
    Apr 22 20:08:34.260: INFO: Pod "busybox-readonly-fsdf78b41a-e15e-4a5b-b6ae-da208fd98f6b" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 22 20:08:34.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6696" for this suite. 04/22/23 20:08:34.296
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:34.335
Apr 22 20:08:34.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename runtimeclass 04/22/23 20:08:34.343
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:34.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:34.393
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 22 20:08:34.429: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7537 to be scheduled
Apr 22 20:08:34.434: INFO: 1 pods are not scheduled: [runtimeclass-7537/test-runtimeclass-runtimeclass-7537-preconfigured-handler-m47hh(a794547b-101e-404b-889a-1f453b04c26b)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 22 20:08:36.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7537" for this suite. 04/22/23 20:08:36.471
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":274,"skipped":4963,"failed":0}
------------------------------
â€¢ [2.149 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:34.335
    Apr 22 20:08:34.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename runtimeclass 04/22/23 20:08:34.343
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:34.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:34.393
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 22 20:08:34.429: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7537 to be scheduled
    Apr 22 20:08:34.434: INFO: 1 pods are not scheduled: [runtimeclass-7537/test-runtimeclass-runtimeclass-7537-preconfigured-handler-m47hh(a794547b-101e-404b-889a-1f453b04c26b)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 22 20:08:36.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7537" for this suite. 04/22/23 20:08:36.471
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:36.485
Apr 22 20:08:36.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:36.49
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:36.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:36.544
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 04/22/23 20:08:36.556
Apr 22 20:08:36.573: INFO: Waiting up to 5m0s for pod "pod-00487d19-39bf-412a-b8f4-8500de154967" in namespace "emptydir-1170" to be "Succeeded or Failed"
Apr 22 20:08:36.580: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Pending", Reason="", readiness=false. Elapsed: 6.812935ms
Apr 22 20:08:38.590: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016819815s
Apr 22 20:08:40.591: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01710646s
STEP: Saw pod success 04/22/23 20:08:40.591
Apr 22 20:08:40.591: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967" satisfied condition "Succeeded or Failed"
Apr 22 20:08:40.598: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-00487d19-39bf-412a-b8f4-8500de154967 container test-container: <nil>
STEP: delete the pod 04/22/23 20:08:40.612
Apr 22 20:08:40.643: INFO: Waiting for pod pod-00487d19-39bf-412a-b8f4-8500de154967 to disappear
Apr 22 20:08:40.650: INFO: Pod pod-00487d19-39bf-412a-b8f4-8500de154967 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:08:40.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1170" for this suite. 04/22/23 20:08:40.666
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":275,"skipped":4964,"failed":0}
------------------------------
â€¢ [4.197 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:36.485
    Apr 22 20:08:36.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:08:36.49
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:36.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:36.544
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/22/23 20:08:36.556
    Apr 22 20:08:36.573: INFO: Waiting up to 5m0s for pod "pod-00487d19-39bf-412a-b8f4-8500de154967" in namespace "emptydir-1170" to be "Succeeded or Failed"
    Apr 22 20:08:36.580: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Pending", Reason="", readiness=false. Elapsed: 6.812935ms
    Apr 22 20:08:38.590: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016819815s
    Apr 22 20:08:40.591: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01710646s
    STEP: Saw pod success 04/22/23 20:08:40.591
    Apr 22 20:08:40.591: INFO: Pod "pod-00487d19-39bf-412a-b8f4-8500de154967" satisfied condition "Succeeded or Failed"
    Apr 22 20:08:40.598: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-00487d19-39bf-412a-b8f4-8500de154967 container test-container: <nil>
    STEP: delete the pod 04/22/23 20:08:40.612
    Apr 22 20:08:40.643: INFO: Waiting for pod pod-00487d19-39bf-412a-b8f4-8500de154967 to disappear
    Apr 22 20:08:40.650: INFO: Pod pod-00487d19-39bf-412a-b8f4-8500de154967 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:08:40.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1170" for this suite. 04/22/23 20:08:40.666
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:40.696
Apr 22 20:08:40.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 20:08:40.7
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:40.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:40.763
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/22/23 20:08:40.783
STEP: create the rc2 04/22/23 20:08:40.791
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/22/23 20:08:45.812
STEP: delete the rc simpletest-rc-to-be-deleted 04/22/23 20:08:46.282
STEP: wait for the rc to be deleted 04/22/23 20:08:46.291
Apr 22 20:08:51.312: INFO: 71 pods remaining
Apr 22 20:08:51.321: INFO: 71 pods has nil DeletionTimestamp
Apr 22 20:08:51.321: INFO: 
STEP: Gathering metrics 04/22/23 20:08:56.32
Apr 22 20:08:56.382: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 20:08:56.390: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 7.395388ms
Apr 22 20:08:56.390: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 20:08:56.390: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 20:08:56.546: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 22 20:08:56.546: INFO: Deleting pod "simpletest-rc-to-be-deleted-26vrt" in namespace "gc-7890"
Apr 22 20:08:56.568: INFO: Deleting pod "simpletest-rc-to-be-deleted-28lm2" in namespace "gc-7890"
Apr 22 20:08:56.584: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jfnr" in namespace "gc-7890"
Apr 22 20:08:56.605: INFO: Deleting pod "simpletest-rc-to-be-deleted-2m8d4" in namespace "gc-7890"
Apr 22 20:08:56.628: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q2qz" in namespace "gc-7890"
Apr 22 20:08:56.640: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sm99" in namespace "gc-7890"
Apr 22 20:08:56.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-2wwh7" in namespace "gc-7890"
Apr 22 20:08:56.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-44nt8" in namespace "gc-7890"
Apr 22 20:08:56.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-47xcj" in namespace "gc-7890"
Apr 22 20:08:56.691: INFO: Deleting pod "simpletest-rc-to-be-deleted-4dbdf" in namespace "gc-7890"
Apr 22 20:08:56.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gn8d" in namespace "gc-7890"
Apr 22 20:08:56.715: INFO: Deleting pod "simpletest-rc-to-be-deleted-4krrb" in namespace "gc-7890"
Apr 22 20:08:56.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vgsx" in namespace "gc-7890"
Apr 22 20:08:56.734: INFO: Deleting pod "simpletest-rc-to-be-deleted-54clv" in namespace "gc-7890"
Apr 22 20:08:56.745: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fdkz" in namespace "gc-7890"
Apr 22 20:08:56.755: INFO: Deleting pod "simpletest-rc-to-be-deleted-5h5bg" in namespace "gc-7890"
Apr 22 20:08:56.785: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jrh9" in namespace "gc-7890"
Apr 22 20:08:56.824: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rp6z" in namespace "gc-7890"
Apr 22 20:08:56.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-69fss" in namespace "gc-7890"
Apr 22 20:08:56.910: INFO: Deleting pod "simpletest-rc-to-be-deleted-6grrk" in namespace "gc-7890"
Apr 22 20:08:56.945: INFO: Deleting pod "simpletest-rc-to-be-deleted-6klvh" in namespace "gc-7890"
Apr 22 20:08:56.976: INFO: Deleting pod "simpletest-rc-to-be-deleted-6wr4t" in namespace "gc-7890"
Apr 22 20:08:57.025: INFO: Deleting pod "simpletest-rc-to-be-deleted-77wzt" in namespace "gc-7890"
Apr 22 20:08:57.060: INFO: Deleting pod "simpletest-rc-to-be-deleted-7vk5j" in namespace "gc-7890"
Apr 22 20:08:57.098: INFO: Deleting pod "simpletest-rc-to-be-deleted-8c8qm" in namespace "gc-7890"
Apr 22 20:08:57.148: INFO: Deleting pod "simpletest-rc-to-be-deleted-8n7tg" in namespace "gc-7890"
Apr 22 20:08:57.188: INFO: Deleting pod "simpletest-rc-to-be-deleted-9gtgc" in namespace "gc-7890"
Apr 22 20:08:57.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-9kkqk" in namespace "gc-7890"
Apr 22 20:08:57.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-9pqcz" in namespace "gc-7890"
Apr 22 20:08:57.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-9z85n" in namespace "gc-7890"
Apr 22 20:08:57.320: INFO: Deleting pod "simpletest-rc-to-be-deleted-b74sg" in namespace "gc-7890"
Apr 22 20:08:57.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7br9" in namespace "gc-7890"
Apr 22 20:08:57.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjbmq" in namespace "gc-7890"
Apr 22 20:08:57.424: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl688" in namespace "gc-7890"
Apr 22 20:08:57.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-bskr6" in namespace "gc-7890"
Apr 22 20:08:57.465: INFO: Deleting pod "simpletest-rc-to-be-deleted-c6t6d" in namespace "gc-7890"
Apr 22 20:08:57.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-chsxz" in namespace "gc-7890"
Apr 22 20:08:57.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmm5m" in namespace "gc-7890"
Apr 22 20:08:57.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-cs44k" in namespace "gc-7890"
Apr 22 20:08:57.566: INFO: Deleting pod "simpletest-rc-to-be-deleted-csf56" in namespace "gc-7890"
Apr 22 20:08:57.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6j4n" in namespace "gc-7890"
Apr 22 20:08:57.612: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7k8x" in namespace "gc-7890"
Apr 22 20:08:57.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5g2l" in namespace "gc-7890"
Apr 22 20:08:57.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7fqv" in namespace "gc-7890"
Apr 22 20:08:57.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7pzr" in namespace "gc-7890"
Apr 22 20:08:57.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-ff6zm" in namespace "gc-7890"
Apr 22 20:08:57.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftmrp" in namespace "gc-7890"
Apr 22 20:08:57.728: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz5dn" in namespace "gc-7890"
Apr 22 20:08:57.746: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4wjm" in namespace "gc-7890"
Apr 22 20:08:57.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsqj4" in namespace "gc-7890"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 20:08:57.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7890" for this suite. 04/22/23 20:08:57.779
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":276,"skipped":4975,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.092 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:40.696
    Apr 22 20:08:40.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 20:08:40.7
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:40.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:40.763
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/22/23 20:08:40.783
    STEP: create the rc2 04/22/23 20:08:40.791
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/22/23 20:08:45.812
    STEP: delete the rc simpletest-rc-to-be-deleted 04/22/23 20:08:46.282
    STEP: wait for the rc to be deleted 04/22/23 20:08:46.291
    Apr 22 20:08:51.312: INFO: 71 pods remaining
    Apr 22 20:08:51.321: INFO: 71 pods has nil DeletionTimestamp
    Apr 22 20:08:51.321: INFO: 
    STEP: Gathering metrics 04/22/23 20:08:56.32
    Apr 22 20:08:56.382: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 20:08:56.390: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 7.395388ms
    Apr 22 20:08:56.390: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 20:08:56.390: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 20:08:56.546: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 22 20:08:56.546: INFO: Deleting pod "simpletest-rc-to-be-deleted-26vrt" in namespace "gc-7890"
    Apr 22 20:08:56.568: INFO: Deleting pod "simpletest-rc-to-be-deleted-28lm2" in namespace "gc-7890"
    Apr 22 20:08:56.584: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jfnr" in namespace "gc-7890"
    Apr 22 20:08:56.605: INFO: Deleting pod "simpletest-rc-to-be-deleted-2m8d4" in namespace "gc-7890"
    Apr 22 20:08:56.628: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q2qz" in namespace "gc-7890"
    Apr 22 20:08:56.640: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sm99" in namespace "gc-7890"
    Apr 22 20:08:56.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-2wwh7" in namespace "gc-7890"
    Apr 22 20:08:56.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-44nt8" in namespace "gc-7890"
    Apr 22 20:08:56.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-47xcj" in namespace "gc-7890"
    Apr 22 20:08:56.691: INFO: Deleting pod "simpletest-rc-to-be-deleted-4dbdf" in namespace "gc-7890"
    Apr 22 20:08:56.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gn8d" in namespace "gc-7890"
    Apr 22 20:08:56.715: INFO: Deleting pod "simpletest-rc-to-be-deleted-4krrb" in namespace "gc-7890"
    Apr 22 20:08:56.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vgsx" in namespace "gc-7890"
    Apr 22 20:08:56.734: INFO: Deleting pod "simpletest-rc-to-be-deleted-54clv" in namespace "gc-7890"
    Apr 22 20:08:56.745: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fdkz" in namespace "gc-7890"
    Apr 22 20:08:56.755: INFO: Deleting pod "simpletest-rc-to-be-deleted-5h5bg" in namespace "gc-7890"
    Apr 22 20:08:56.785: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jrh9" in namespace "gc-7890"
    Apr 22 20:08:56.824: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rp6z" in namespace "gc-7890"
    Apr 22 20:08:56.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-69fss" in namespace "gc-7890"
    Apr 22 20:08:56.910: INFO: Deleting pod "simpletest-rc-to-be-deleted-6grrk" in namespace "gc-7890"
    Apr 22 20:08:56.945: INFO: Deleting pod "simpletest-rc-to-be-deleted-6klvh" in namespace "gc-7890"
    Apr 22 20:08:56.976: INFO: Deleting pod "simpletest-rc-to-be-deleted-6wr4t" in namespace "gc-7890"
    Apr 22 20:08:57.025: INFO: Deleting pod "simpletest-rc-to-be-deleted-77wzt" in namespace "gc-7890"
    Apr 22 20:08:57.060: INFO: Deleting pod "simpletest-rc-to-be-deleted-7vk5j" in namespace "gc-7890"
    Apr 22 20:08:57.098: INFO: Deleting pod "simpletest-rc-to-be-deleted-8c8qm" in namespace "gc-7890"
    Apr 22 20:08:57.148: INFO: Deleting pod "simpletest-rc-to-be-deleted-8n7tg" in namespace "gc-7890"
    Apr 22 20:08:57.188: INFO: Deleting pod "simpletest-rc-to-be-deleted-9gtgc" in namespace "gc-7890"
    Apr 22 20:08:57.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-9kkqk" in namespace "gc-7890"
    Apr 22 20:08:57.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-9pqcz" in namespace "gc-7890"
    Apr 22 20:08:57.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-9z85n" in namespace "gc-7890"
    Apr 22 20:08:57.320: INFO: Deleting pod "simpletest-rc-to-be-deleted-b74sg" in namespace "gc-7890"
    Apr 22 20:08:57.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7br9" in namespace "gc-7890"
    Apr 22 20:08:57.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjbmq" in namespace "gc-7890"
    Apr 22 20:08:57.424: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl688" in namespace "gc-7890"
    Apr 22 20:08:57.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-bskr6" in namespace "gc-7890"
    Apr 22 20:08:57.465: INFO: Deleting pod "simpletest-rc-to-be-deleted-c6t6d" in namespace "gc-7890"
    Apr 22 20:08:57.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-chsxz" in namespace "gc-7890"
    Apr 22 20:08:57.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmm5m" in namespace "gc-7890"
    Apr 22 20:08:57.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-cs44k" in namespace "gc-7890"
    Apr 22 20:08:57.566: INFO: Deleting pod "simpletest-rc-to-be-deleted-csf56" in namespace "gc-7890"
    Apr 22 20:08:57.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6j4n" in namespace "gc-7890"
    Apr 22 20:08:57.612: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7k8x" in namespace "gc-7890"
    Apr 22 20:08:57.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5g2l" in namespace "gc-7890"
    Apr 22 20:08:57.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7fqv" in namespace "gc-7890"
    Apr 22 20:08:57.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7pzr" in namespace "gc-7890"
    Apr 22 20:08:57.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-ff6zm" in namespace "gc-7890"
    Apr 22 20:08:57.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftmrp" in namespace "gc-7890"
    Apr 22 20:08:57.728: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz5dn" in namespace "gc-7890"
    Apr 22 20:08:57.746: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4wjm" in namespace "gc-7890"
    Apr 22 20:08:57.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsqj4" in namespace "gc-7890"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 20:08:57.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7890" for this suite. 04/22/23 20:08:57.779
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:08:57.795
Apr 22 20:08:57.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:08:57.797
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:57.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:57.822
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/22/23 20:08:57.826
Apr 22 20:08:57.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:09:01.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:09:14.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6650" for this suite. 04/22/23 20:09:14.266
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":277,"skipped":4985,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.484 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:08:57.795
    Apr 22 20:08:57.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:08:57.797
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:08:57.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:08:57.822
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/22/23 20:08:57.826
    Apr 22 20:08:57.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:09:01.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:09:14.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6650" for this suite. 04/22/23 20:09:14.266
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:14.291
Apr 22 20:09:14.292: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 20:09:14.293
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:14.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:14.333
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-8a254af9-8fdc-498c-97e4-57aa2f18ed05 04/22/23 20:09:14.34
STEP: Creating a pod to test consume secrets 04/22/23 20:09:14.35
Apr 22 20:09:14.367: INFO: Waiting up to 5m0s for pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d" in namespace "secrets-6195" to be "Succeeded or Failed"
Apr 22 20:09:14.384: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.223016ms
Apr 22 20:09:16.393: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025259955s
Apr 22 20:09:18.395: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027792272s
STEP: Saw pod success 04/22/23 20:09:18.395
Apr 22 20:09:18.396: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d" satisfied condition "Succeeded or Failed"
Apr 22 20:09:18.404: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d container secret-volume-test: <nil>
STEP: delete the pod 04/22/23 20:09:18.452
Apr 22 20:09:18.480: INFO: Waiting for pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d to disappear
Apr 22 20:09:18.492: INFO: Pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 20:09:18.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6195" for this suite. 04/22/23 20:09:18.503
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":278,"skipped":5015,"failed":0}
------------------------------
â€¢ [4.243 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:14.291
    Apr 22 20:09:14.292: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 20:09:14.293
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:14.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:14.333
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-8a254af9-8fdc-498c-97e4-57aa2f18ed05 04/22/23 20:09:14.34
    STEP: Creating a pod to test consume secrets 04/22/23 20:09:14.35
    Apr 22 20:09:14.367: INFO: Waiting up to 5m0s for pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d" in namespace "secrets-6195" to be "Succeeded or Failed"
    Apr 22 20:09:14.384: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.223016ms
    Apr 22 20:09:16.393: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025259955s
    Apr 22 20:09:18.395: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027792272s
    STEP: Saw pod success 04/22/23 20:09:18.395
    Apr 22 20:09:18.396: INFO: Pod "pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d" satisfied condition "Succeeded or Failed"
    Apr 22 20:09:18.404: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d container secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 20:09:18.452
    Apr 22 20:09:18.480: INFO: Waiting for pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d to disappear
    Apr 22 20:09:18.492: INFO: Pod pod-secrets-08813368-1983-4c90-81dc-329a4be72c6d no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 20:09:18.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6195" for this suite. 04/22/23 20:09:18.503
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:18.545
Apr 22 20:09:18.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:09:18.548
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:18.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:18.584
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 04/22/23 20:09:18.59
Apr 22 20:09:18.591: INFO: Creating e2e-svc-a-jqb4h
Apr 22 20:09:18.613: INFO: Creating e2e-svc-b-h4fk2
Apr 22 20:09:18.631: INFO: Creating e2e-svc-c-m7tmw
STEP: deleting service collection 04/22/23 20:09:18.657
Apr 22 20:09:18.714: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:09:18.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3395" for this suite. 04/22/23 20:09:18.722
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":279,"skipped":5024,"failed":0}
------------------------------
â€¢ [0.186 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:18.545
    Apr 22 20:09:18.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:09:18.548
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:18.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:18.584
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 04/22/23 20:09:18.59
    Apr 22 20:09:18.591: INFO: Creating e2e-svc-a-jqb4h
    Apr 22 20:09:18.613: INFO: Creating e2e-svc-b-h4fk2
    Apr 22 20:09:18.631: INFO: Creating e2e-svc-c-m7tmw
    STEP: deleting service collection 04/22/23 20:09:18.657
    Apr 22 20:09:18.714: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:09:18.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3395" for this suite. 04/22/23 20:09:18.722
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:18.735
Apr 22 20:09:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:09:18.736
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:18.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:18.76
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 04/22/23 20:09:18.765
Apr 22 20:09:18.790: INFO: Waiting up to 5m0s for pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2" in namespace "emptydir-9162" to be "Succeeded or Failed"
Apr 22 20:09:18.809: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.526944ms
Apr 22 20:09:20.820: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02962174s
Apr 22 20:09:22.819: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028938299s
STEP: Saw pod success 04/22/23 20:09:22.82
Apr 22 20:09:22.821: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2" satisfied condition "Succeeded or Failed"
Apr 22 20:09:22.830: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 container test-container: <nil>
STEP: delete the pod 04/22/23 20:09:22.846
Apr 22 20:09:22.882: INFO: Waiting for pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 to disappear
Apr 22 20:09:22.888: INFO: Pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:09:22.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9162" for this suite. 04/22/23 20:09:22.897
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":280,"skipped":5031,"failed":0}
------------------------------
â€¢ [4.181 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:18.735
    Apr 22 20:09:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:09:18.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:18.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:18.76
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/22/23 20:09:18.765
    Apr 22 20:09:18.790: INFO: Waiting up to 5m0s for pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2" in namespace "emptydir-9162" to be "Succeeded or Failed"
    Apr 22 20:09:18.809: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.526944ms
    Apr 22 20:09:20.820: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02962174s
    Apr 22 20:09:22.819: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028938299s
    STEP: Saw pod success 04/22/23 20:09:22.82
    Apr 22 20:09:22.821: INFO: Pod "pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2" satisfied condition "Succeeded or Failed"
    Apr 22 20:09:22.830: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 container test-container: <nil>
    STEP: delete the pod 04/22/23 20:09:22.846
    Apr 22 20:09:22.882: INFO: Waiting for pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 to disappear
    Apr 22 20:09:22.888: INFO: Pod pod-44dad473-b5cc-4c64-b6a7-e431bf9d36b2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:09:22.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9162" for this suite. 04/22/23 20:09:22.897
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:22.931
Apr 22 20:09:22.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:09:22.934
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:22.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:22.995
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-5779 04/22/23 20:09:23.005
STEP: creating service affinity-clusterip in namespace services-5779 04/22/23 20:09:23.005
STEP: creating replication controller affinity-clusterip in namespace services-5779 04/22/23 20:09:23.043
I0422 20:09:23.062425      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-5779, replica count: 3
I0422 20:09:26.118683      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 20:09:26.143: INFO: Creating new exec pod
Apr 22 20:09:26.173: INFO: Waiting up to 5m0s for pod "execpod-affinityv2jtn" in namespace "services-5779" to be "running"
Apr 22 20:09:26.183: INFO: Pod "execpod-affinityv2jtn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.005405ms
Apr 22 20:09:28.190: INFO: Pod "execpod-affinityv2jtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.017466303s
Apr 22 20:09:28.190: INFO: Pod "execpod-affinityv2jtn" satisfied condition "running"
Apr 22 20:09:29.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 22 20:09:29.515: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 22 20:09:29.515: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:09:29.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.19.93 80'
Apr 22 20:09:29.795: INFO: stderr: "+ nc -v -t -w 2 10.102.19.93 80\n+ echo hostName\nConnection to 10.102.19.93 80 port [tcp/http] succeeded!\n"
Apr 22 20:09:29.795: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:09:29.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.102.19.93:80/ ; done'
Apr 22 20:09:30.238: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n"
Apr 22 20:09:30.238: INFO: stdout: "\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq"
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
Apr 22 20:09:30.238: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-5779, will wait for the garbage collector to delete the pods 04/22/23 20:09:30.274
Apr 22 20:09:30.351: INFO: Deleting ReplicationController affinity-clusterip took: 9.877306ms
Apr 22 20:09:30.452: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.538301ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:09:32.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5779" for this suite. 04/22/23 20:09:32.407
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":281,"skipped":5042,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.487 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:22.931
    Apr 22 20:09:22.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:09:22.934
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:22.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:22.995
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-5779 04/22/23 20:09:23.005
    STEP: creating service affinity-clusterip in namespace services-5779 04/22/23 20:09:23.005
    STEP: creating replication controller affinity-clusterip in namespace services-5779 04/22/23 20:09:23.043
    I0422 20:09:23.062425      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-5779, replica count: 3
    I0422 20:09:26.118683      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 20:09:26.143: INFO: Creating new exec pod
    Apr 22 20:09:26.173: INFO: Waiting up to 5m0s for pod "execpod-affinityv2jtn" in namespace "services-5779" to be "running"
    Apr 22 20:09:26.183: INFO: Pod "execpod-affinityv2jtn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.005405ms
    Apr 22 20:09:28.190: INFO: Pod "execpod-affinityv2jtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.017466303s
    Apr 22 20:09:28.190: INFO: Pod "execpod-affinityv2jtn" satisfied condition "running"
    Apr 22 20:09:29.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Apr 22 20:09:29.515: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 22 20:09:29.515: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:09:29.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.19.93 80'
    Apr 22 20:09:29.795: INFO: stderr: "+ nc -v -t -w 2 10.102.19.93 80\n+ echo hostName\nConnection to 10.102.19.93 80 port [tcp/http] succeeded!\n"
    Apr 22 20:09:29.795: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:09:29.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-5779 exec execpod-affinityv2jtn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.102.19.93:80/ ; done'
    Apr 22 20:09:30.238: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.102.19.93:80/\n"
    Apr 22 20:09:30.238: INFO: stdout: "\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq\naffinity-clusterip-594wq"
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Received response from host: affinity-clusterip-594wq
    Apr 22 20:09:30.238: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-5779, will wait for the garbage collector to delete the pods 04/22/23 20:09:30.274
    Apr 22 20:09:30.351: INFO: Deleting ReplicationController affinity-clusterip took: 9.877306ms
    Apr 22 20:09:30.452: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.538301ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:09:32.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5779" for this suite. 04/22/23 20:09:32.407
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:32.455
Apr 22 20:09:32.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename emptydir 04/22/23 20:09:32.459
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:32.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:32.489
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/22/23 20:09:32.493
Apr 22 20:09:32.510: INFO: Waiting up to 5m0s for pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3" in namespace "emptydir-3249" to be "Succeeded or Failed"
Apr 22 20:09:32.515: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513734ms
Apr 22 20:09:34.526: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015902031s
Apr 22 20:09:36.525: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014934996s
STEP: Saw pod success 04/22/23 20:09:36.526
Apr 22 20:09:36.526: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3" satisfied condition "Succeeded or Failed"
Apr 22 20:09:36.535: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 container test-container: <nil>
STEP: delete the pod 04/22/23 20:09:36.554
Apr 22 20:09:36.592: INFO: Waiting for pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 to disappear
Apr 22 20:09:36.602: INFO: Pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 22 20:09:36.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3249" for this suite. 04/22/23 20:09:36.617
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":282,"skipped":5064,"failed":0}
------------------------------
â€¢ [4.180 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:32.455
    Apr 22 20:09:32.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename emptydir 04/22/23 20:09:32.459
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:32.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:32.489
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/22/23 20:09:32.493
    Apr 22 20:09:32.510: INFO: Waiting up to 5m0s for pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3" in namespace "emptydir-3249" to be "Succeeded or Failed"
    Apr 22 20:09:32.515: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513734ms
    Apr 22 20:09:34.526: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015902031s
    Apr 22 20:09:36.525: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014934996s
    STEP: Saw pod success 04/22/23 20:09:36.526
    Apr 22 20:09:36.526: INFO: Pod "pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3" satisfied condition "Succeeded or Failed"
    Apr 22 20:09:36.535: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 container test-container: <nil>
    STEP: delete the pod 04/22/23 20:09:36.554
    Apr 22 20:09:36.592: INFO: Waiting for pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 to disappear
    Apr 22 20:09:36.602: INFO: Pod pod-cb77c9f0-931d-4a80-a007-2cabbf8e6ba3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 22 20:09:36.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3249" for this suite. 04/22/23 20:09:36.617
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:09:36.65
Apr 22 20:09:36.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:09:36.654
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:36.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:36.71
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-3763 04/22/23 20:09:36.719
Apr 22 20:09:36.737: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3763" to be "running and ready"
Apr 22 20:09:36.749: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.837119ms
Apr 22 20:09:36.749: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:09:38.758: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.020533509s
Apr 22 20:09:38.759: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 22 20:09:38.759: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 22 20:09:38.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 22 20:09:39.142: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 22 20:09:39.142: INFO: stdout: "iptables"
Apr 22 20:09:39.142: INFO: proxyMode: iptables
Apr 22 20:09:39.186: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 22 20:09:39.198: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-3763 04/22/23 20:09:39.198
STEP: creating replication controller affinity-clusterip-timeout in namespace services-3763 04/22/23 20:09:39.24
I0422 20:09:39.261646      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3763, replica count: 3
I0422 20:09:42.316674      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 22 20:09:42.332: INFO: Creating new exec pod
Apr 22 20:09:42.345: INFO: Waiting up to 5m0s for pod "execpod-affinity48wc5" in namespace "services-3763" to be "running"
Apr 22 20:09:42.356: INFO: Pod "execpod-affinity48wc5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.945658ms
Apr 22 20:09:44.379: INFO: Pod "execpod-affinity48wc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.033660099s
Apr 22 20:09:44.379: INFO: Pod "execpod-affinity48wc5" satisfied condition "running"
Apr 22 20:09:45.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Apr 22 20:09:45.728: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Apr 22 20:09:45.728: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:09:45.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.81.123 80'
Apr 22 20:09:46.054: INFO: stderr: "+ nc -v -t -w 2 10.107.81.123 80\n+ echo hostName\nConnection to 10.107.81.123 80 port [tcp/http] succeeded!\n"
Apr 22 20:09:46.054: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:09:46.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.107.81.123:80/ ; done'
Apr 22 20:09:46.478: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
Apr 22 20:09:46.478: INFO: stdout: "\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2"
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
Apr 22 20:09:46.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.107.81.123:80/'
Apr 22 20:09:46.797: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
Apr 22 20:09:46.797: INFO: stdout: "affinity-clusterip-timeout-v76f2"
Apr 22 20:10:06.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.107.81.123:80/'
Apr 22 20:10:07.154: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
Apr 22 20:10:07.154: INFO: stdout: "affinity-clusterip-timeout-q5f9l"
Apr 22 20:10:07.154: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3763, will wait for the garbage collector to delete the pods 04/22/23 20:10:07.188
Apr 22 20:10:07.273: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 20.20483ms
Apr 22 20:10:07.373: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.651627ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:10:09.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3763" for this suite. 04/22/23 20:10:09.526
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":283,"skipped":5072,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.884 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:09:36.65
    Apr 22 20:09:36.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:09:36.654
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:09:36.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:09:36.71
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-3763 04/22/23 20:09:36.719
    Apr 22 20:09:36.737: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3763" to be "running and ready"
    Apr 22 20:09:36.749: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.837119ms
    Apr 22 20:09:36.749: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:09:38.758: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.020533509s
    Apr 22 20:09:38.759: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 22 20:09:38.759: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 22 20:09:38.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 22 20:09:39.142: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 22 20:09:39.142: INFO: stdout: "iptables"
    Apr 22 20:09:39.142: INFO: proxyMode: iptables
    Apr 22 20:09:39.186: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 22 20:09:39.198: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-3763 04/22/23 20:09:39.198
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-3763 04/22/23 20:09:39.24
    I0422 20:09:39.261646      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3763, replica count: 3
    I0422 20:09:42.316674      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 22 20:09:42.332: INFO: Creating new exec pod
    Apr 22 20:09:42.345: INFO: Waiting up to 5m0s for pod "execpod-affinity48wc5" in namespace "services-3763" to be "running"
    Apr 22 20:09:42.356: INFO: Pod "execpod-affinity48wc5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.945658ms
    Apr 22 20:09:44.379: INFO: Pod "execpod-affinity48wc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.033660099s
    Apr 22 20:09:44.379: INFO: Pod "execpod-affinity48wc5" satisfied condition "running"
    Apr 22 20:09:45.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Apr 22 20:09:45.728: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Apr 22 20:09:45.728: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:09:45.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.81.123 80'
    Apr 22 20:09:46.054: INFO: stderr: "+ nc -v -t -w 2 10.107.81.123 80\n+ echo hostName\nConnection to 10.107.81.123 80 port [tcp/http] succeeded!\n"
    Apr 22 20:09:46.054: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:09:46.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.107.81.123:80/ ; done'
    Apr 22 20:09:46.478: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
    Apr 22 20:09:46.478: INFO: stdout: "\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2\naffinity-clusterip-timeout-v76f2"
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Received response from host: affinity-clusterip-timeout-v76f2
    Apr 22 20:09:46.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.107.81.123:80/'
    Apr 22 20:09:46.797: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
    Apr 22 20:09:46.797: INFO: stdout: "affinity-clusterip-timeout-v76f2"
    Apr 22 20:10:06.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-3763 exec execpod-affinity48wc5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.107.81.123:80/'
    Apr 22 20:10:07.154: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.107.81.123:80/\n"
    Apr 22 20:10:07.154: INFO: stdout: "affinity-clusterip-timeout-q5f9l"
    Apr 22 20:10:07.154: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3763, will wait for the garbage collector to delete the pods 04/22/23 20:10:07.188
    Apr 22 20:10:07.273: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 20.20483ms
    Apr 22 20:10:07.373: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.651627ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:10:09.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3763" for this suite. 04/22/23 20:10:09.526
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:09.562
Apr 22 20:10:09.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 20:10:09.565
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:09.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:09.592
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/22/23 20:10:09.595
STEP: delete the rc 04/22/23 20:10:14.617
STEP: wait for all pods to be garbage collected 04/22/23 20:10:14.64
STEP: Gathering metrics 04/22/23 20:10:19.659
Apr 22 20:10:19.735: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 20:10:19.758: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 22.530454ms
Apr 22 20:10:19.758: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 20:10:19.759: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 20:10:19.844: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 20:10:19.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2717" for this suite. 04/22/23 20:10:19.851
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":284,"skipped":5102,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.301 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:09.562
    Apr 22 20:10:09.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 20:10:09.565
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:09.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:09.592
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/22/23 20:10:09.595
    STEP: delete the rc 04/22/23 20:10:14.617
    STEP: wait for all pods to be garbage collected 04/22/23 20:10:14.64
    STEP: Gathering metrics 04/22/23 20:10:19.659
    Apr 22 20:10:19.735: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 20:10:19.758: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 22.530454ms
    Apr 22 20:10:19.758: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 20:10:19.759: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 20:10:19.844: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 20:10:19.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2717" for this suite. 04/22/23 20:10:19.851
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:19.872
Apr 22 20:10:19.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename runtimeclass 04/22/23 20:10:19.875
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:19.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:19.914
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 22 20:10:19.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2841" for this suite. 04/22/23 20:10:19.94
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":285,"skipped":5104,"failed":0}
------------------------------
â€¢ [0.081 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:19.872
    Apr 22 20:10:19.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename runtimeclass 04/22/23 20:10:19.875
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:19.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:19.914
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 22 20:10:19.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2841" for this suite. 04/22/23 20:10:19.94
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:19.978
Apr 22 20:10:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename job 04/22/23 20:10:19.98
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:20.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:20.022
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 04/22/23 20:10:20.033
STEP: Patching the Job 04/22/23 20:10:20.045
STEP: Watching for Job to be patched 04/22/23 20:10:20.075
Apr 22 20:10:20.081: INFO: Event ADDED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 22 20:10:20.081: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 22 20:10:20.082: INFO: Event MODIFIED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/22/23 20:10:20.084
STEP: Watching for Job to be updated 04/22/23 20:10:20.101
Apr 22 20:10:20.104: INFO: Event MODIFIED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:20.105: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/22/23 20:10:20.106
Apr 22 20:10:20.118: INFO: Job: e2e-zj6fj as labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched]
STEP: Waiting for job to complete 04/22/23 20:10:20.118
STEP: Delete a job collection with a labelselector 04/22/23 20:10:30.129
STEP: Watching for Job to be deleted 04/22/23 20:10:30.149
Apr 22 20:10:30.153: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:30.153: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 22 20:10:30.154: INFO: Event DELETED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/22/23 20:10:30.154
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 22 20:10:30.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3457" for this suite. 04/22/23 20:10:30.192
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":286,"skipped":5120,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.254 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:19.978
    Apr 22 20:10:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename job 04/22/23 20:10:19.98
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:20.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:20.022
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 04/22/23 20:10:20.033
    STEP: Patching the Job 04/22/23 20:10:20.045
    STEP: Watching for Job to be patched 04/22/23 20:10:20.075
    Apr 22 20:10:20.081: INFO: Event ADDED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 22 20:10:20.081: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 22 20:10:20.082: INFO: Event MODIFIED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/22/23 20:10:20.084
    STEP: Watching for Job to be updated 04/22/23 20:10:20.101
    Apr 22 20:10:20.104: INFO: Event MODIFIED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:20.105: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/22/23 20:10:20.106
    Apr 22 20:10:20.118: INFO: Job: e2e-zj6fj as labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched]
    STEP: Waiting for job to complete 04/22/23 20:10:20.118
    STEP: Delete a job collection with a labelselector 04/22/23 20:10:30.129
    STEP: Watching for Job to be deleted 04/22/23 20:10:30.149
    Apr 22 20:10:30.153: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:30.153: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:30.154: INFO: Event MODIFIED observed for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 22 20:10:30.154: INFO: Event DELETED found for Job e2e-zj6fj in namespace job-3457 with labels: map[e2e-job-label:e2e-zj6fj e2e-zj6fj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/22/23 20:10:30.154
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 22 20:10:30.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3457" for this suite. 04/22/23 20:10:30.192
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:30.247
Apr 22 20:10:30.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 20:10:30.249
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:30.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:30.306
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 04/22/23 20:10:30.314
STEP: Ensuring ResourceQuota status is calculated 04/22/23 20:10:30.326
STEP: Creating a ResourceQuota with not terminating scope 04/22/23 20:10:32.337
STEP: Ensuring ResourceQuota status is calculated 04/22/23 20:10:32.352
STEP: Creating a long running pod 04/22/23 20:10:34.375
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/22/23 20:10:34.41
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/22/23 20:10:36.423
STEP: Deleting the pod 04/22/23 20:10:38.432
STEP: Ensuring resource quota status released the pod usage 04/22/23 20:10:38.511
STEP: Creating a terminating pod 04/22/23 20:10:40.523
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/22/23 20:10:40.554
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/22/23 20:10:42.564
STEP: Deleting the pod 04/22/23 20:10:44.575
STEP: Ensuring resource quota status released the pod usage 04/22/23 20:10:44.617
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 20:10:46.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3170" for this suite. 04/22/23 20:10:46.638
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":287,"skipped":5149,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.407 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:30.247
    Apr 22 20:10:30.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 20:10:30.249
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:30.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:30.306
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 04/22/23 20:10:30.314
    STEP: Ensuring ResourceQuota status is calculated 04/22/23 20:10:30.326
    STEP: Creating a ResourceQuota with not terminating scope 04/22/23 20:10:32.337
    STEP: Ensuring ResourceQuota status is calculated 04/22/23 20:10:32.352
    STEP: Creating a long running pod 04/22/23 20:10:34.375
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/22/23 20:10:34.41
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/22/23 20:10:36.423
    STEP: Deleting the pod 04/22/23 20:10:38.432
    STEP: Ensuring resource quota status released the pod usage 04/22/23 20:10:38.511
    STEP: Creating a terminating pod 04/22/23 20:10:40.523
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/22/23 20:10:40.554
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/22/23 20:10:42.564
    STEP: Deleting the pod 04/22/23 20:10:44.575
    STEP: Ensuring resource quota status released the pod usage 04/22/23 20:10:44.617
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 20:10:46.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3170" for this suite. 04/22/23 20:10:46.638
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:46.664
Apr 22 20:10:46.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 20:10:46.668
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:46.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:46.723
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/22/23 20:10:46.746
Apr 22 20:10:46.746: INFO: Creating simple deployment test-deployment-n2pj2
Apr 22 20:10:46.795: INFO: deployment "test-deployment-n2pj2" doesn't have the required revision set
STEP: Getting /status 04/22/23 20:10:48.829
Apr 22 20:10:48.845: INFO: Deployment test-deployment-n2pj2 has Conditions: [{Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 04/22/23 20:10:48.846
Apr 22 20:10:48.872: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 10, 46, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-n2pj2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/22/23 20:10:48.872
Apr 22 20:10:48.877: INFO: Observed &Deployment event: ADDED
Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-n2pj2-777898ffcc" is progressing.}
Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
Apr 22 20:10:48.878: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
Apr 22 20:10:48.878: INFO: Found Deployment test-deployment-n2pj2 in namespace deployment-2470 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 22 20:10:48.878: INFO: Deployment test-deployment-n2pj2 has an updated status
STEP: patching the Statefulset Status 04/22/23 20:10:48.878
Apr 22 20:10:48.878: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 22 20:10:48.897: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/22/23 20:10:48.897
Apr 22 20:10:48.900: INFO: Observed &Deployment event: ADDED
Apr 22 20:10:48.901: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
Apr 22 20:10:48.901: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.901: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 22 20:10:48.902: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-n2pj2-777898ffcc" is progressing.}
Apr 22 20:10:48.903: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.903: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 22 20:10:48.903: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
Apr 22 20:10:48.904: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 22 20:10:48.904: INFO: Observed &Deployment event: MODIFIED
Apr 22 20:10:48.905: INFO: Found deployment test-deployment-n2pj2 in namespace deployment-2470 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 22 20:10:48.905: INFO: Deployment test-deployment-n2pj2 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 20:10:48.922: INFO: Deployment "test-deployment-n2pj2":
&Deployment{ObjectMeta:{test-deployment-n2pj2  deployment-2470  5f2fe0a5-3bd4-4755-99d9-66075f5ff4de 31923 1 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a2a8a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-n2pj2-777898ffcc",LastUpdateTime:2023-04-22 20:10:48 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 22 20:10:48.930: INFO: New ReplicaSet "test-deployment-n2pj2-777898ffcc" of Deployment "test-deployment-n2pj2":
&ReplicaSet{ObjectMeta:{test-deployment-n2pj2-777898ffcc  deployment-2470  10524bf7-0ff9-4091-8055-5b6161a72b2c 31919 1 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-n2pj2 5f2fe0a5-3bd4-4755-99d9-66075f5ff4de 0xc003a2acb0 0xc003a2acb1}] [] [{kube-controller-manager Update apps/v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f2fe0a5-3bd4-4755-99d9-66075f5ff4de\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a2ad58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 22 20:10:48.943: INFO: Pod "test-deployment-n2pj2-777898ffcc-gg85n" is available:
&Pod{ObjectMeta:{test-deployment-n2pj2-777898ffcc-gg85n test-deployment-n2pj2-777898ffcc- deployment-2470  b6da859e-47dc-40b2-b23a-824f5d92ccfa 31917 0 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-n2pj2-777898ffcc 10524bf7-0ff9-4091-8055-5b6161a72b2c 0xc00460efe7 0xc00460efe8}] [] [{kube-controller-manager Update v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"10524bf7-0ff9-4091-8055-5b6161a72b2c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s4fdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s4fdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 20:10:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 20:10:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ea9892f722a7e2d55e906d1e9f6e37a99bb088dee9466aaf88d0c054545f53a7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 20:10:48.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2470" for this suite. 04/22/23 20:10:48.962
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":288,"skipped":5167,"failed":0}
------------------------------
â€¢ [2.322 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:46.664
    Apr 22 20:10:46.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 20:10:46.668
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:46.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:46.723
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/22/23 20:10:46.746
    Apr 22 20:10:46.746: INFO: Creating simple deployment test-deployment-n2pj2
    Apr 22 20:10:46.795: INFO: deployment "test-deployment-n2pj2" doesn't have the required revision set
    STEP: Getting /status 04/22/23 20:10:48.829
    Apr 22 20:10:48.845: INFO: Deployment test-deployment-n2pj2 has Conditions: [{Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 04/22/23 20:10:48.846
    Apr 22 20:10:48.872: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 10, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 10, 46, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-n2pj2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/22/23 20:10:48.872
    Apr 22 20:10:48.877: INFO: Observed &Deployment event: ADDED
    Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
    Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
    Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 22 20:10:48.877: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-n2pj2-777898ffcc" is progressing.}
    Apr 22 20:10:48.877: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
    Apr 22 20:10:48.878: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 22 20:10:48.878: INFO: Observed Deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
    Apr 22 20:10:48.878: INFO: Found Deployment test-deployment-n2pj2 in namespace deployment-2470 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 22 20:10:48.878: INFO: Deployment test-deployment-n2pj2 has an updated status
    STEP: patching the Statefulset Status 04/22/23 20:10:48.878
    Apr 22 20:10:48.878: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 22 20:10:48.897: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/22/23 20:10:48.897
    Apr 22 20:10:48.900: INFO: Observed &Deployment event: ADDED
    Apr 22 20:10:48.901: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
    Apr 22 20:10:48.901: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.901: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-n2pj2-777898ffcc"}
    Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 22 20:10:48.902: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 22 20:10:48.902: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:46 +0000 UTC 2023-04-22 20:10:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-n2pj2-777898ffcc" is progressing.}
    Apr 22 20:10:48.903: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.903: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 22 20:10:48.903: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
    Apr 22 20:10:48.904: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-22 20:10:48 +0000 UTC 2023-04-22 20:10:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-n2pj2-777898ffcc" has successfully progressed.}
    Apr 22 20:10:48.904: INFO: Observed deployment test-deployment-n2pj2 in namespace deployment-2470 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 22 20:10:48.904: INFO: Observed &Deployment event: MODIFIED
    Apr 22 20:10:48.905: INFO: Found deployment test-deployment-n2pj2 in namespace deployment-2470 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 22 20:10:48.905: INFO: Deployment test-deployment-n2pj2 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 20:10:48.922: INFO: Deployment "test-deployment-n2pj2":
    &Deployment{ObjectMeta:{test-deployment-n2pj2  deployment-2470  5f2fe0a5-3bd4-4755-99d9-66075f5ff4de 31923 1 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a2a8a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-n2pj2-777898ffcc",LastUpdateTime:2023-04-22 20:10:48 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 22 20:10:48.930: INFO: New ReplicaSet "test-deployment-n2pj2-777898ffcc" of Deployment "test-deployment-n2pj2":
    &ReplicaSet{ObjectMeta:{test-deployment-n2pj2-777898ffcc  deployment-2470  10524bf7-0ff9-4091-8055-5b6161a72b2c 31919 1 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-n2pj2 5f2fe0a5-3bd4-4755-99d9-66075f5ff4de 0xc003a2acb0 0xc003a2acb1}] [] [{kube-controller-manager Update apps/v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f2fe0a5-3bd4-4755-99d9-66075f5ff4de\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a2ad58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 20:10:48.943: INFO: Pod "test-deployment-n2pj2-777898ffcc-gg85n" is available:
    &Pod{ObjectMeta:{test-deployment-n2pj2-777898ffcc-gg85n test-deployment-n2pj2-777898ffcc- deployment-2470  b6da859e-47dc-40b2-b23a-824f5d92ccfa 31917 0 2023-04-22 20:10:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-n2pj2-777898ffcc 10524bf7-0ff9-4091-8055-5b6161a72b2c 0xc00460efe7 0xc00460efe8}] [] [{kube-controller-manager Update v1 2023-04-22 20:10:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"10524bf7-0ff9-4091-8055-5b6161a72b2c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 20:10:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s4fdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s4fdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:10:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 20:10:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 20:10:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ea9892f722a7e2d55e906d1e9f6e37a99bb088dee9466aaf88d0c054545f53a7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 20:10:48.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2470" for this suite. 04/22/23 20:10:48.962
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:48.989
Apr 22 20:10:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 20:10:48.993
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:49.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:49.048
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/22/23 20:10:49.061
STEP: Verify that the required pods have come up. 04/22/23 20:10:49.071
Apr 22 20:10:49.076: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 22 20:10:54.090: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 20:10:54.091
STEP: Getting /status 04/22/23 20:10:54.092
Apr 22 20:10:54.104: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/22/23 20:10:54.104
Apr 22 20:10:54.125: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/22/23 20:10:54.125
Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: ADDED
Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.130: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.130: INFO: Found replicaset test-rs in namespace replicaset-9432 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 22 20:10:54.130: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/22/23 20:10:54.13
Apr 22 20:10:54.130: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 22 20:10:54.143: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/22/23 20:10:54.143
Apr 22 20:10:54.146: INFO: Observed &ReplicaSet event: ADDED
Apr 22 20:10:54.147: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.148: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.149: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.149: INFO: Observed replicaset test-rs in namespace replicaset-9432 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 22 20:10:54.150: INFO: Observed &ReplicaSet event: MODIFIED
Apr 22 20:10:54.151: INFO: Found replicaset test-rs in namespace replicaset-9432 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 22 20:10:54.152: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 20:10:54.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9432" for this suite. 04/22/23 20:10:54.163
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":289,"skipped":5169,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.186 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:48.989
    Apr 22 20:10:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 20:10:48.993
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:49.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:49.048
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/22/23 20:10:49.061
    STEP: Verify that the required pods have come up. 04/22/23 20:10:49.071
    Apr 22 20:10:49.076: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 22 20:10:54.090: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 20:10:54.091
    STEP: Getting /status 04/22/23 20:10:54.092
    Apr 22 20:10:54.104: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/22/23 20:10:54.104
    Apr 22 20:10:54.125: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/22/23 20:10:54.125
    Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: ADDED
    Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.129: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.130: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.130: INFO: Found replicaset test-rs in namespace replicaset-9432 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 22 20:10:54.130: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/22/23 20:10:54.13
    Apr 22 20:10:54.130: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 22 20:10:54.143: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/22/23 20:10:54.143
    Apr 22 20:10:54.146: INFO: Observed &ReplicaSet event: ADDED
    Apr 22 20:10:54.147: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.148: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.149: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.149: INFO: Observed replicaset test-rs in namespace replicaset-9432 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 22 20:10:54.150: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 22 20:10:54.151: INFO: Found replicaset test-rs in namespace replicaset-9432 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 22 20:10:54.152: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 20:10:54.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9432" for this suite. 04/22/23 20:10:54.163
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:54.224
Apr 22 20:10:54.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:10:54.226
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:54.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:54.253
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-d8a1fea1-d87e-4d85-9214-c309550c8c89 04/22/23 20:10:54.258
STEP: Creating a pod to test consume secrets 04/22/23 20:10:54.264
Apr 22 20:10:54.274: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a" in namespace "projected-3605" to be "Succeeded or Failed"
Apr 22 20:10:54.283: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.028832ms
Apr 22 20:10:56.296: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021730615s
Apr 22 20:10:58.293: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019084806s
STEP: Saw pod success 04/22/23 20:10:58.293
Apr 22 20:10:58.294: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a" satisfied condition "Succeeded or Failed"
Apr 22 20:10:58.302: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a container projected-secret-volume-test: <nil>
STEP: delete the pod 04/22/23 20:10:58.32
Apr 22 20:10:58.356: INFO: Waiting for pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a to disappear
Apr 22 20:10:58.369: INFO: Pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 22 20:10:58.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3605" for this suite. 04/22/23 20:10:58.384
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":290,"skipped":5207,"failed":0}
------------------------------
â€¢ [4.181 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:54.224
    Apr 22 20:10:54.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:10:54.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:54.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:54.253
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-d8a1fea1-d87e-4d85-9214-c309550c8c89 04/22/23 20:10:54.258
    STEP: Creating a pod to test consume secrets 04/22/23 20:10:54.264
    Apr 22 20:10:54.274: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a" in namespace "projected-3605" to be "Succeeded or Failed"
    Apr 22 20:10:54.283: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.028832ms
    Apr 22 20:10:56.296: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021730615s
    Apr 22 20:10:58.293: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019084806s
    STEP: Saw pod success 04/22/23 20:10:58.293
    Apr 22 20:10:58.294: INFO: Pod "pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a" satisfied condition "Succeeded or Failed"
    Apr 22 20:10:58.302: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/22/23 20:10:58.32
    Apr 22 20:10:58.356: INFO: Waiting for pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a to disappear
    Apr 22 20:10:58.369: INFO: Pod pod-projected-secrets-780ba6c4-628f-4b26-a246-d8e87187361a no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 22 20:10:58.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3605" for this suite. 04/22/23 20:10:58.384
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:10:58.425
Apr 22 20:10:58.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 20:10:58.429
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:58.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:58.486
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 04/22/23 20:10:58.491
Apr 22 20:10:58.525: INFO: Waiting up to 5m0s for pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228" in namespace "var-expansion-6842" to be "Succeeded or Failed"
Apr 22 20:10:58.534: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Pending", Reason="", readiness=false. Elapsed: 8.403888ms
Apr 22 20:11:00.544: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01882777s
Apr 22 20:11:02.545: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01980414s
STEP: Saw pod success 04/22/23 20:11:02.546
Apr 22 20:11:02.546: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228" satisfied condition "Succeeded or Failed"
Apr 22 20:11:02.555: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 container dapi-container: <nil>
STEP: delete the pod 04/22/23 20:11:02.577
Apr 22 20:11:02.610: INFO: Waiting for pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 to disappear
Apr 22 20:11:02.625: INFO: Pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 20:11:02.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6842" for this suite. 04/22/23 20:11:02.638
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":291,"skipped":5244,"failed":0}
------------------------------
â€¢ [4.229 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:10:58.425
    Apr 22 20:10:58.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 20:10:58.429
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:10:58.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:10:58.486
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 04/22/23 20:10:58.491
    Apr 22 20:10:58.525: INFO: Waiting up to 5m0s for pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228" in namespace "var-expansion-6842" to be "Succeeded or Failed"
    Apr 22 20:10:58.534: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Pending", Reason="", readiness=false. Elapsed: 8.403888ms
    Apr 22 20:11:00.544: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01882777s
    Apr 22 20:11:02.545: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01980414s
    STEP: Saw pod success 04/22/23 20:11:02.546
    Apr 22 20:11:02.546: INFO: Pod "var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228" satisfied condition "Succeeded or Failed"
    Apr 22 20:11:02.555: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 20:11:02.577
    Apr 22 20:11:02.610: INFO: Waiting for pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 to disappear
    Apr 22 20:11:02.625: INFO: Pod var-expansion-0a0f93bf-a970-4c84-8a8d-69c21b028228 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 20:11:02.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6842" for this suite. 04/22/23 20:11:02.638
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:02.657
Apr 22 20:11:02.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:11:02.66
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:02.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:02.717
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 04/22/23 20:11:02.726
Apr 22 20:11:02.746: INFO: Waiting up to 5m0s for pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233" in namespace "projected-2803" to be "running and ready"
Apr 22 20:11:02.757: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233": Phase="Pending", Reason="", readiness=false. Elapsed: 10.329876ms
Apr 22 20:11:02.757: INFO: The phase of Pod annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:11:04.768: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233": Phase="Running", Reason="", readiness=true. Elapsed: 2.021531293s
Apr 22 20:11:04.768: INFO: The phase of Pod annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233 is Running (Ready = true)
Apr 22 20:11:04.768: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233" satisfied condition "running and ready"
Apr 22 20:11:05.320: INFO: Successfully updated pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:11:09.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2803" for this suite. 04/22/23 20:11:09.391
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":292,"skipped":5245,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.751 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:02.657
    Apr 22 20:11:02.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:11:02.66
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:02.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:02.717
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 04/22/23 20:11:02.726
    Apr 22 20:11:02.746: INFO: Waiting up to 5m0s for pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233" in namespace "projected-2803" to be "running and ready"
    Apr 22 20:11:02.757: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233": Phase="Pending", Reason="", readiness=false. Elapsed: 10.329876ms
    Apr 22 20:11:02.757: INFO: The phase of Pod annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:11:04.768: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233": Phase="Running", Reason="", readiness=true. Elapsed: 2.021531293s
    Apr 22 20:11:04.768: INFO: The phase of Pod annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233 is Running (Ready = true)
    Apr 22 20:11:04.768: INFO: Pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233" satisfied condition "running and ready"
    Apr 22 20:11:05.320: INFO: Successfully updated pod "annotationupdatee6849bf2-a822-4d80-ab10-4e1959123233"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:11:09.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2803" for this suite. 04/22/23 20:11:09.391
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:09.416
Apr 22 20:11:09.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:11:09.419
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:09.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:09.475
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Apr 22 20:11:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 20:11:12.494
Apr 22 20:11:12.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 create -f -'
Apr 22 20:11:13.475: INFO: stderr: ""
Apr 22 20:11:13.475: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 22 20:11:13.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 delete e2e-test-crd-publish-openapi-8038-crds test-cr'
Apr 22 20:11:13.671: INFO: stderr: ""
Apr 22 20:11:13.671: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 22 20:11:13.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 apply -f -'
Apr 22 20:11:14.536: INFO: stderr: ""
Apr 22 20:11:14.536: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 22 20:11:14.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 delete e2e-test-crd-publish-openapi-8038-crds test-cr'
Apr 22 20:11:14.664: INFO: stderr: ""
Apr 22 20:11:14.664: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/22/23 20:11:14.664
Apr 22 20:11:14.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 explain e2e-test-crd-publish-openapi-8038-crds'
Apr 22 20:11:14.969: INFO: stderr: ""
Apr 22 20:11:14.969: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8038-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:11:17.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-139" for this suite. 04/22/23 20:11:17.833
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":293,"skipped":5260,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.437 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:09.416
    Apr 22 20:11:09.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:11:09.419
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:09.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:09.475
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Apr 22 20:11:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/22/23 20:11:12.494
    Apr 22 20:11:12.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 create -f -'
    Apr 22 20:11:13.475: INFO: stderr: ""
    Apr 22 20:11:13.475: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 22 20:11:13.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 delete e2e-test-crd-publish-openapi-8038-crds test-cr'
    Apr 22 20:11:13.671: INFO: stderr: ""
    Apr 22 20:11:13.671: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 22 20:11:13.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 apply -f -'
    Apr 22 20:11:14.536: INFO: stderr: ""
    Apr 22 20:11:14.536: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 22 20:11:14.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 --namespace=crd-publish-openapi-139 delete e2e-test-crd-publish-openapi-8038-crds test-cr'
    Apr 22 20:11:14.664: INFO: stderr: ""
    Apr 22 20:11:14.664: INFO: stdout: "e2e-test-crd-publish-openapi-8038-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/22/23 20:11:14.664
    Apr 22 20:11:14.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-139 explain e2e-test-crd-publish-openapi-8038-crds'
    Apr 22 20:11:14.969: INFO: stderr: ""
    Apr 22 20:11:14.969: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8038-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:11:17.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-139" for this suite. 04/22/23 20:11:17.833
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:17.859
Apr 22 20:11:17.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 20:11:17.862
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:17.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:17.953
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 04/22/23 20:11:17.963
STEP: Creating a ResourceQuota 04/22/23 20:11:22.972
STEP: Ensuring resource quota status is calculated 04/22/23 20:11:22.981
STEP: Creating a Service 04/22/23 20:11:25.001
STEP: Creating a NodePort Service 04/22/23 20:11:25.069
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/22/23 20:11:25.125
STEP: Ensuring resource quota status captures service creation 04/22/23 20:11:25.182
STEP: Deleting Services 04/22/23 20:11:27.191
STEP: Ensuring resource quota status released usage 04/22/23 20:11:27.32
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 20:11:29.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2604" for this suite. 04/22/23 20:11:29.342
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":294,"skipped":5267,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.502 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:17.859
    Apr 22 20:11:17.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 20:11:17.862
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:17.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:17.953
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 04/22/23 20:11:17.963
    STEP: Creating a ResourceQuota 04/22/23 20:11:22.972
    STEP: Ensuring resource quota status is calculated 04/22/23 20:11:22.981
    STEP: Creating a Service 04/22/23 20:11:25.001
    STEP: Creating a NodePort Service 04/22/23 20:11:25.069
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/22/23 20:11:25.125
    STEP: Ensuring resource quota status captures service creation 04/22/23 20:11:25.182
    STEP: Deleting Services 04/22/23 20:11:27.191
    STEP: Ensuring resource quota status released usage 04/22/23 20:11:27.32
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 20:11:29.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2604" for this suite. 04/22/23 20:11:29.342
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:29.39
Apr 22 20:11:29.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replication-controller 04/22/23 20:11:29.393
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:29.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:29.441
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a 04/22/23 20:11:29.453
Apr 22 20:11:29.471: INFO: Pod name my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Found 0 pods out of 1
Apr 22 20:11:34.482: INFO: Pod name my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Found 1 pods out of 1
Apr 22 20:11:34.482: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a" are running
Apr 22 20:11:34.483: INFO: Waiting up to 5m0s for pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" in namespace "replication-controller-9324" to be "running"
Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf": Phase="Running", Reason="", readiness=true. Elapsed: 6.331689ms
Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" satisfied condition "running"
Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:29 +0000 UTC Reason: Message:}])
Apr 22 20:11:34.490: INFO: Trying to dial the pod
Apr 22 20:11:39.541: INFO: Controller my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Got expected result from replica 1 [my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf]: "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 22 20:11:39.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9324" for this suite. 04/22/23 20:11:39.555
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":295,"skipped":5286,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.189 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:29.39
    Apr 22 20:11:29.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replication-controller 04/22/23 20:11:29.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:29.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:29.441
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a 04/22/23 20:11:29.453
    Apr 22 20:11:29.471: INFO: Pod name my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Found 0 pods out of 1
    Apr 22 20:11:34.482: INFO: Pod name my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Found 1 pods out of 1
    Apr 22 20:11:34.482: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a" are running
    Apr 22 20:11:34.483: INFO: Waiting up to 5m0s for pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" in namespace "replication-controller-9324" to be "running"
    Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf": Phase="Running", Reason="", readiness=true. Elapsed: 6.331689ms
    Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" satisfied condition "running"
    Apr 22 20:11:34.490: INFO: Pod "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-22 20:11:29 +0000 UTC Reason: Message:}])
    Apr 22 20:11:34.490: INFO: Trying to dial the pod
    Apr 22 20:11:39.541: INFO: Controller my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a: Got expected result from replica 1 [my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf]: "my-hostname-basic-c25c3419-1d0c-4275-b77e-565bc6927d3a-jwnpf", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 22 20:11:39.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9324" for this suite. 04/22/23 20:11:39.555
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:39.606
Apr 22 20:11:39.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename limitrange 04/22/23 20:11:39.611
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:39.668
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:39.677
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 04/22/23 20:11:39.685
STEP: Setting up watch 04/22/23 20:11:39.691
STEP: Submitting a LimitRange 04/22/23 20:11:39.798
STEP: Verifying LimitRange creation was observed 04/22/23 20:11:39.815
STEP: Fetching the LimitRange to ensure it has proper values 04/22/23 20:11:39.821
Apr 22 20:11:39.829: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 22 20:11:39.829: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/22/23 20:11:39.829
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/22/23 20:11:39.843
Apr 22 20:11:39.854: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 22 20:11:39.855: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/22/23 20:11:39.856
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/22/23 20:11:39.872
Apr 22 20:11:39.886: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 22 20:11:39.886: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/22/23 20:11:39.886
STEP: Failing to create a Pod with more than max resources 04/22/23 20:11:39.89
STEP: Updating a LimitRange 04/22/23 20:11:39.896
STEP: Verifying LimitRange updating is effective 04/22/23 20:11:39.91
STEP: Creating a Pod with less than former min resources 04/22/23 20:11:41.921
STEP: Failing to create a Pod with more than max resources 04/22/23 20:11:41.94
STEP: Deleting a LimitRange 04/22/23 20:11:41.947
STEP: Verifying the LimitRange was deleted 04/22/23 20:11:41.973
Apr 22 20:11:46.982: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/22/23 20:11:46.983
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Apr 22 20:11:47.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-7027" for this suite. 04/22/23 20:11:47.063
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":296,"skipped":5316,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.493 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:39.606
    Apr 22 20:11:39.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename limitrange 04/22/23 20:11:39.611
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:39.668
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:39.677
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 04/22/23 20:11:39.685
    STEP: Setting up watch 04/22/23 20:11:39.691
    STEP: Submitting a LimitRange 04/22/23 20:11:39.798
    STEP: Verifying LimitRange creation was observed 04/22/23 20:11:39.815
    STEP: Fetching the LimitRange to ensure it has proper values 04/22/23 20:11:39.821
    Apr 22 20:11:39.829: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 22 20:11:39.829: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/22/23 20:11:39.829
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/22/23 20:11:39.843
    Apr 22 20:11:39.854: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 22 20:11:39.855: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/22/23 20:11:39.856
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/22/23 20:11:39.872
    Apr 22 20:11:39.886: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 22 20:11:39.886: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/22/23 20:11:39.886
    STEP: Failing to create a Pod with more than max resources 04/22/23 20:11:39.89
    STEP: Updating a LimitRange 04/22/23 20:11:39.896
    STEP: Verifying LimitRange updating is effective 04/22/23 20:11:39.91
    STEP: Creating a Pod with less than former min resources 04/22/23 20:11:41.921
    STEP: Failing to create a Pod with more than max resources 04/22/23 20:11:41.94
    STEP: Deleting a LimitRange 04/22/23 20:11:41.947
    STEP: Verifying the LimitRange was deleted 04/22/23 20:11:41.973
    Apr 22 20:11:46.982: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/22/23 20:11:46.983
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Apr 22 20:11:47.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-7027" for this suite. 04/22/23 20:11:47.063
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:11:47.111
Apr 22 20:11:47.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:11:47.114
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:47.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:47.182
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 04/22/23 20:11:47.187
Apr 22 20:11:47.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: mark a version not serverd 04/22/23 20:11:55.177
STEP: check the unserved version gets removed 04/22/23 20:11:55.227
STEP: check the other version is not changed 04/22/23 20:11:57.37
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:12:03.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2766" for this suite. 04/22/23 20:12:03.504
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":297,"skipped":5321,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.412 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:11:47.111
    Apr 22 20:11:47.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:11:47.114
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:11:47.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:11:47.182
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 04/22/23 20:11:47.187
    Apr 22 20:11:47.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: mark a version not serverd 04/22/23 20:11:55.177
    STEP: check the unserved version gets removed 04/22/23 20:11:55.227
    STEP: check the other version is not changed 04/22/23 20:11:57.37
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:12:03.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2766" for this suite. 04/22/23 20:12:03.504
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:12:03.526
Apr 22 20:12:03.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:12:03.529
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:03.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:03.585
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:12:03.592
Apr 22 20:12:03.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 22 20:12:03.757: INFO: stderr: ""
Apr 22 20:12:03.757: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/22/23 20:12:03.757
STEP: verifying the pod e2e-test-httpd-pod was created 04/22/23 20:12:08.809
Apr 22 20:12:08.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 get pod e2e-test-httpd-pod -o json'
Apr 22 20:12:08.963: INFO: stderr: ""
Apr 22 20:12:08.963: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-22T20:12:03Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-857\",\n        \"resourceVersion\": \"32409\",\n        \"uid\": \"e554c18c-9557-446e-9795-e620a96068eb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-xkc4s\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"cncf25-2-node-187aa4c0d96\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-xkc4s\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:03Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9e0103ef8645ab2e8bf5ef36edf697207e28c1cebc3fddac7b2e428e79615955\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-22T20:12:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.1.128\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.36.0.1\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.36.0.1\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-22T20:12:03Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/22/23 20:12:08.964
Apr 22 20:12:08.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 replace -f -'
Apr 22 20:12:09.993: INFO: stderr: ""
Apr 22 20:12:09.993: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/22/23 20:12:09.993
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Apr 22 20:12:09.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 delete pods e2e-test-httpd-pod'
Apr 22 20:12:11.947: INFO: stderr: ""
Apr 22 20:12:11.947: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:12:11.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-857" for this suite. 04/22/23 20:12:11.959
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":298,"skipped":5323,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.448 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:12:03.526
    Apr 22 20:12:03.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:12:03.529
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:03.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:03.585
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:12:03.592
    Apr 22 20:12:03.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 22 20:12:03.757: INFO: stderr: ""
    Apr 22 20:12:03.757: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/22/23 20:12:03.757
    STEP: verifying the pod e2e-test-httpd-pod was created 04/22/23 20:12:08.809
    Apr 22 20:12:08.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 get pod e2e-test-httpd-pod -o json'
    Apr 22 20:12:08.963: INFO: stderr: ""
    Apr 22 20:12:08.963: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-22T20:12:03Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-857\",\n        \"resourceVersion\": \"32409\",\n        \"uid\": \"e554c18c-9557-446e-9795-e620a96068eb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-xkc4s\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"cncf25-2-node-187aa4c0d96\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-xkc4s\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-22T20:12:03Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9e0103ef8645ab2e8bf5ef36edf697207e28c1cebc3fddac7b2e428e79615955\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-22T20:12:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.1.128\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.36.0.1\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.36.0.1\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-22T20:12:03Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/22/23 20:12:08.964
    Apr 22 20:12:08.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 replace -f -'
    Apr 22 20:12:09.993: INFO: stderr: ""
    Apr 22 20:12:09.993: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/22/23 20:12:09.993
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Apr 22 20:12:09.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-857 delete pods e2e-test-httpd-pod'
    Apr 22 20:12:11.947: INFO: stderr: ""
    Apr 22 20:12:11.947: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:12:11.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-857" for this suite. 04/22/23 20:12:11.959
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:12:12.002
Apr 22 20:12:12.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename resourcequota 04/22/23 20:12:12.006
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:12.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:12.063
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 04/22/23 20:12:12.072
STEP: Getting a ResourceQuota 04/22/23 20:12:12.086
STEP: Listing all ResourceQuotas with LabelSelector 04/22/23 20:12:12.095
STEP: Patching the ResourceQuota 04/22/23 20:12:12.103
STEP: Deleting a Collection of ResourceQuotas 04/22/23 20:12:12.119
STEP: Verifying the deleted ResourceQuota 04/22/23 20:12:12.142
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 22 20:12:12.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-161" for this suite. 04/22/23 20:12:12.16
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":299,"skipped":5362,"failed":0}
------------------------------
â€¢ [0.169 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:12:12.002
    Apr 22 20:12:12.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename resourcequota 04/22/23 20:12:12.006
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:12.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:12.063
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 04/22/23 20:12:12.072
    STEP: Getting a ResourceQuota 04/22/23 20:12:12.086
    STEP: Listing all ResourceQuotas with LabelSelector 04/22/23 20:12:12.095
    STEP: Patching the ResourceQuota 04/22/23 20:12:12.103
    STEP: Deleting a Collection of ResourceQuotas 04/22/23 20:12:12.119
    STEP: Verifying the deleted ResourceQuota 04/22/23 20:12:12.142
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 22 20:12:12.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-161" for this suite. 04/22/23 20:12:12.16
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:12:12.196
Apr 22 20:12:12.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 20:12:12.199
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:12.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:12.243
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 04/22/23 20:12:12.258
Apr 22 20:12:12.282: INFO: Waiting up to 5m0s for pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00" in namespace "downward-api-3937" to be "Succeeded or Failed"
Apr 22 20:12:12.296: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Pending", Reason="", readiness=false. Elapsed: 13.155356ms
Apr 22 20:12:14.304: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021742272s
Apr 22 20:12:16.304: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021735446s
STEP: Saw pod success 04/22/23 20:12:16.304
Apr 22 20:12:16.305: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00" satisfied condition "Succeeded or Failed"
Apr 22 20:12:16.309: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 container dapi-container: <nil>
STEP: delete the pod 04/22/23 20:12:16.333
Apr 22 20:12:16.370: INFO: Waiting for pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 to disappear
Apr 22 20:12:16.383: INFO: Pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 22 20:12:16.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3937" for this suite. 04/22/23 20:12:16.403
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":300,"skipped":5370,"failed":0}
------------------------------
â€¢ [4.229 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:12:12.196
    Apr 22 20:12:12.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 20:12:12.199
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:12.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:12.243
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 04/22/23 20:12:12.258
    Apr 22 20:12:12.282: INFO: Waiting up to 5m0s for pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00" in namespace "downward-api-3937" to be "Succeeded or Failed"
    Apr 22 20:12:12.296: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Pending", Reason="", readiness=false. Elapsed: 13.155356ms
    Apr 22 20:12:14.304: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021742272s
    Apr 22 20:12:16.304: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021735446s
    STEP: Saw pod success 04/22/23 20:12:16.304
    Apr 22 20:12:16.305: INFO: Pod "downward-api-c73f9057-10a4-4071-ab55-9de231688f00" satisfied condition "Succeeded or Failed"
    Apr 22 20:12:16.309: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 20:12:16.333
    Apr 22 20:12:16.370: INFO: Waiting for pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 to disappear
    Apr 22 20:12:16.383: INFO: Pod downward-api-c73f9057-10a4-4071-ab55-9de231688f00 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 22 20:12:16.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3937" for this suite. 04/22/23 20:12:16.403
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:12:16.456
Apr 22 20:12:16.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption 04/22/23 20:12:16.459
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:16.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:16.528
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 22 20:12:16.559: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 22 20:13:16.646: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:13:16.655
Apr 22 20:13:16.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename sched-preemption-path 04/22/23 20:13:16.658
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:16.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:16.718
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Apr 22 20:13:16.755: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 22 20:13:16.775: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Apr 22 20:13:16.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-167" for this suite. 04/22/23 20:13:16.822
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 22 20:13:16.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6409" for this suite. 04/22/23 20:13:16.875
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":301,"skipped":5489,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.523 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:12:16.456
    Apr 22 20:12:16.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption 04/22/23 20:12:16.459
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:12:16.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:12:16.528
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 22 20:12:16.559: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 22 20:13:16.646: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:13:16.655
    Apr 22 20:13:16.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename sched-preemption-path 04/22/23 20:13:16.658
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:16.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:16.718
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Apr 22 20:13:16.755: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 22 20:13:16.775: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Apr 22 20:13:16.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-167" for this suite. 04/22/23 20:13:16.822
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 22 20:13:16.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-6409" for this suite. 04/22/23 20:13:16.875
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:13:16.984
Apr 22 20:13:16.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption 04/22/23 20:13:16.988
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:17.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:17.036
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 04/22/23 20:13:17.064
STEP: Waiting for all pods to be running 04/22/23 20:13:19.17
Apr 22 20:13:19.187: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 22 20:13:21.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4658" for this suite. 04/22/23 20:13:21.222
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":302,"skipped":5499,"failed":0}
------------------------------
â€¢ [4.256 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:13:16.984
    Apr 22 20:13:16.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption 04/22/23 20:13:16.988
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:17.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:17.036
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 04/22/23 20:13:17.064
    STEP: Waiting for all pods to be running 04/22/23 20:13:19.17
    Apr 22 20:13:19.187: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 22 20:13:21.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4658" for this suite. 04/22/23 20:13:21.222
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:13:21.28
Apr 22 20:13:21.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename cronjob 04/22/23 20:13:21.282
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:21.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:21.343
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/22/23 20:13:21.351
STEP: creating 04/22/23 20:13:21.352
STEP: getting 04/22/23 20:13:21.373
STEP: listing 04/22/23 20:13:21.382
STEP: watching 04/22/23 20:13:21.399
Apr 22 20:13:21.399: INFO: starting watch
STEP: cluster-wide listing 04/22/23 20:13:21.402
STEP: cluster-wide watching 04/22/23 20:13:21.409
Apr 22 20:13:21.410: INFO: starting watch
STEP: patching 04/22/23 20:13:21.413
STEP: updating 04/22/23 20:13:21.429
Apr 22 20:13:21.452: INFO: waiting for watch events with expected annotations
Apr 22 20:13:21.452: INFO: saw patched and updated annotations
STEP: patching /status 04/22/23 20:13:21.453
STEP: updating /status 04/22/23 20:13:21.473
STEP: get /status 04/22/23 20:13:21.498
STEP: deleting 04/22/23 20:13:21.505
STEP: deleting a collection 04/22/23 20:13:21.535
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 22 20:13:21.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8043" for this suite. 04/22/23 20:13:21.571
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":303,"skipped":5525,"failed":0}
------------------------------
â€¢ [0.308 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:13:21.28
    Apr 22 20:13:21.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename cronjob 04/22/23 20:13:21.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:21.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:21.343
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/22/23 20:13:21.351
    STEP: creating 04/22/23 20:13:21.352
    STEP: getting 04/22/23 20:13:21.373
    STEP: listing 04/22/23 20:13:21.382
    STEP: watching 04/22/23 20:13:21.399
    Apr 22 20:13:21.399: INFO: starting watch
    STEP: cluster-wide listing 04/22/23 20:13:21.402
    STEP: cluster-wide watching 04/22/23 20:13:21.409
    Apr 22 20:13:21.410: INFO: starting watch
    STEP: patching 04/22/23 20:13:21.413
    STEP: updating 04/22/23 20:13:21.429
    Apr 22 20:13:21.452: INFO: waiting for watch events with expected annotations
    Apr 22 20:13:21.452: INFO: saw patched and updated annotations
    STEP: patching /status 04/22/23 20:13:21.453
    STEP: updating /status 04/22/23 20:13:21.473
    STEP: get /status 04/22/23 20:13:21.498
    STEP: deleting 04/22/23 20:13:21.505
    STEP: deleting a collection 04/22/23 20:13:21.535
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 22 20:13:21.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8043" for this suite. 04/22/23 20:13:21.571
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:13:21.63
Apr 22 20:13:21.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:13:21.633
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:21.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:21.695
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/22/23 20:13:21.721
Apr 22 20:13:21.721: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f" in namespace "kubelet-test-8782" to be "completed"
Apr 22 20:13:21.730: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.253153ms
Apr 22 20:13:23.741: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019342426s
Apr 22 20:13:25.739: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017494192s
Apr 22 20:13:25.739: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 22 20:13:25.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8782" for this suite. 04/22/23 20:13:25.769
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":304,"skipped":5562,"failed":0}
------------------------------
â€¢ [4.156 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:13:21.63
    Apr 22 20:13:21.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:13:21.633
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:21.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:21.695
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/22/23 20:13:21.721
    Apr 22 20:13:21.721: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f" in namespace "kubelet-test-8782" to be "completed"
    Apr 22 20:13:21.730: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.253153ms
    Apr 22 20:13:23.741: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019342426s
    Apr 22 20:13:25.739: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017494192s
    Apr 22 20:13:25.739: INFO: Pod "agnhost-host-aliasesc5ec531e-760e-40f7-8543-54a86f36a16f" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 22 20:13:25.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8782" for this suite. 04/22/23 20:13:25.769
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:13:25.808
Apr 22 20:13:25.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 20:13:25.811
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:25.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:25.882
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-69 04/22/23 20:13:25.889
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-69 04/22/23 20:13:25.908
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-69 04/22/23 20:13:25.924
Apr 22 20:13:25.933: INFO: Found 0 stateful pods, waiting for 1
Apr 22 20:13:35.944: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/22/23 20:13:35.945
Apr 22 20:13:35.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 20:13:36.308: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 20:13:36.308: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 20:13:36.308: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 20:13:36.315: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 22 20:13:46.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 20:13:46.327: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:13:46.385: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Apr 22 20:13:46.385: INFO: ss-0  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  }]
Apr 22 20:13:46.386: INFO: 
Apr 22 20:13:46.386: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 22 20:13:47.402: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979147975s
Apr 22 20:13:48.414: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.964857474s
Apr 22 20:13:49.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.953217834s
Apr 22 20:13:50.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.943011702s
Apr 22 20:13:51.450: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.931094678s
Apr 22 20:13:52.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.917379346s
Apr 22 20:13:53.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.905085083s
Apr 22 20:13:54.486: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.89217749s
Apr 22 20:13:55.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 881.22594ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-69 04/22/23 20:13:56.498
Apr 22 20:13:56.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 20:13:56.858: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 22 20:13:56.858: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 20:13:56.858: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 20:13:56.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 20:13:57.216: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 22 20:13:57.216: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 20:13:57.216: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 20:13:57.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 22 20:13:57.541: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 22 20:13:57.541: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 22 20:13:57.541: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 22 20:13:57.551: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:13:57.551: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:13:57.551: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/22/23 20:13:57.551
Apr 22 20:13:57.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 20:13:57.895: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 20:13:57.895: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 20:13:57.895: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 20:13:57.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 20:13:58.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 20:13:58.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 20:13:58.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 20:13:58.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 22 20:13:58.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 22 20:13:58.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 22 20:13:58.498: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 22 20:13:58.498: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:13:58.514: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 22 20:14:08.539: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 20:14:08.539: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 20:14:08.539: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 22 20:14:08.579: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Apr 22 20:14:08.579: INFO: ss-0  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  }]
Apr 22 20:14:08.579: INFO: ss-1  cncf25-2-node-187aa4bdec5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  }]
Apr 22 20:14:08.579: INFO: ss-2  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  }]
Apr 22 20:14:08.579: INFO: 
Apr 22 20:14:08.579: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 22 20:14:09.585: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.990328091s
Apr 22 20:14:10.595: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984758275s
Apr 22 20:14:11.604: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.974156638s
Apr 22 20:14:12.615: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.965726158s
Apr 22 20:14:13.626: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.953841731s
Apr 22 20:14:14.635: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.943104953s
Apr 22 20:14:15.644: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.934731588s
Apr 22 20:14:16.653: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.926188234s
Apr 22 20:14:17.663: INFO: Verifying statefulset ss doesn't scale past 0 for another 916.418448ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-69 04/22/23 20:14:18.663
Apr 22 20:14:18.672: INFO: Scaling statefulset ss to 0
Apr 22 20:14:18.703: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 20:14:18.712: INFO: Deleting all statefulset in ns statefulset-69
Apr 22 20:14:18.720: INFO: Scaling statefulset ss to 0
Apr 22 20:14:18.750: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:14:18.761: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 20:14:18.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-69" for this suite. 04/22/23 20:14:18.811
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":305,"skipped":5571,"failed":0}
------------------------------
â€¢ [SLOW TEST] [53.022 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:13:25.808
    Apr 22 20:13:25.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 20:13:25.811
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:13:25.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:13:25.882
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-69 04/22/23 20:13:25.889
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-69 04/22/23 20:13:25.908
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-69 04/22/23 20:13:25.924
    Apr 22 20:13:25.933: INFO: Found 0 stateful pods, waiting for 1
    Apr 22 20:13:35.944: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/22/23 20:13:35.945
    Apr 22 20:13:35.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 20:13:36.308: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 20:13:36.308: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 20:13:36.308: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 20:13:36.315: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 22 20:13:46.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 20:13:46.327: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:13:46.385: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
    Apr 22 20:13:46.385: INFO: ss-0  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  }]
    Apr 22 20:13:46.386: INFO: 
    Apr 22 20:13:46.386: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 22 20:13:47.402: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979147975s
    Apr 22 20:13:48.414: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.964857474s
    Apr 22 20:13:49.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.953217834s
    Apr 22 20:13:50.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.943011702s
    Apr 22 20:13:51.450: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.931094678s
    Apr 22 20:13:52.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.917379346s
    Apr 22 20:13:53.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.905085083s
    Apr 22 20:13:54.486: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.89217749s
    Apr 22 20:13:55.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 881.22594ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-69 04/22/23 20:13:56.498
    Apr 22 20:13:56.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 20:13:56.858: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 22 20:13:56.858: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 20:13:56.858: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 20:13:56.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 20:13:57.216: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 22 20:13:57.216: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 20:13:57.216: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 20:13:57.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 22 20:13:57.541: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 22 20:13:57.541: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 22 20:13:57.541: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 22 20:13:57.551: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:13:57.551: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:13:57.551: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/22/23 20:13:57.551
    Apr 22 20:13:57.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 20:13:57.895: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 20:13:57.895: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 20:13:57.895: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 20:13:57.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 20:13:58.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 20:13:58.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 20:13:58.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 20:13:58.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=statefulset-69 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 22 20:13:58.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 22 20:13:58.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 22 20:13:58.498: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 22 20:13:58.498: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:13:58.514: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 22 20:14:08.539: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 20:14:08.539: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 20:14:08.539: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 22 20:14:08.579: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
    Apr 22 20:14:08.579: INFO: ss-0  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:25 +0000 UTC  }]
    Apr 22 20:14:08.579: INFO: ss-1  cncf25-2-node-187aa4bdec5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  }]
    Apr 22 20:14:08.579: INFO: ss-2  cncf25-2-node-187aa4c0d96  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-22 20:13:46 +0000 UTC  }]
    Apr 22 20:14:08.579: INFO: 
    Apr 22 20:14:08.579: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 22 20:14:09.585: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.990328091s
    Apr 22 20:14:10.595: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984758275s
    Apr 22 20:14:11.604: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.974156638s
    Apr 22 20:14:12.615: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.965726158s
    Apr 22 20:14:13.626: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.953841731s
    Apr 22 20:14:14.635: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.943104953s
    Apr 22 20:14:15.644: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.934731588s
    Apr 22 20:14:16.653: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.926188234s
    Apr 22 20:14:17.663: INFO: Verifying statefulset ss doesn't scale past 0 for another 916.418448ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-69 04/22/23 20:14:18.663
    Apr 22 20:14:18.672: INFO: Scaling statefulset ss to 0
    Apr 22 20:14:18.703: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 20:14:18.712: INFO: Deleting all statefulset in ns statefulset-69
    Apr 22 20:14:18.720: INFO: Scaling statefulset ss to 0
    Apr 22 20:14:18.750: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:14:18.761: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 20:14:18.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-69" for this suite. 04/22/23 20:14:18.811
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:18.871
Apr 22 20:14:18.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename deployment 04/22/23 20:14:18.874
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:18.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:18.917
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 22 20:14:18.942: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 22 20:14:23.954: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 20:14:23.954
Apr 22 20:14:23.955: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/22/23 20:14:23.999
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 22 20:14:24.034: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1354  a127497e-baad-4548-8024-302c314c0165 33149 1 2023-04-22 20:14:23 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-22 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003555cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr 22 20:14:24.043: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-1354  40366a5c-8ca0-4c4c-97c4-b16b0597e88c 33154 1 2023-04-22 20:14:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment a127497e-baad-4548-8024-302c314c0165 0xc0035fa167 0xc0035fa168}] [] [{kube-controller-manager Update apps/v1 2023-04-22 20:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a127497e-baad-4548-8024-302c314c0165\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 22 20:14:24.043: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 22 20:14:24.044: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1354  8439876e-99fc-47f6-8394-8e95d2a6a670 33152 1 2023-04-22 20:14:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a127497e-baad-4548-8024-302c314c0165 0xc0035fa037 0xc0035fa038}] [] [{e2e.test Update apps/v1 2023-04-22 20:14:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 20:14:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-22 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a127497e-baad-4548-8024-302c314c0165\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0035fa0f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 22 20:14:24.054: INFO: Pod "test-cleanup-controller-28f6k" is available:
&Pod{ObjectMeta:{test-cleanup-controller-28f6k test-cleanup-controller- deployment-1354  c816b455-5313-42e1-a890-358578c7ee17 33133 0 2023-04-22 20:14:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 8439876e-99fc-47f6-8394-8e95d2a6a670 0xc0035fa647 0xc0035fa648}] [] [{kube-controller-manager Update v1 2023-04-22 20:14:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8439876e-99fc-47f6-8394-8e95d2a6a670\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 20:14:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2p7ms,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2p7ms,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 20:14:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 20:14:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c1bac203fdf7d2a9453900f8af277ee470e227e4d79cca6cd1ad3c064cdacda,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 22 20:14:24.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1354" for this suite. 04/22/23 20:14:24.069
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":306,"skipped":5593,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.216 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:18.871
    Apr 22 20:14:18.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename deployment 04/22/23 20:14:18.874
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:18.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:18.917
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 22 20:14:18.942: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Apr 22 20:14:23.954: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 20:14:23.954
    Apr 22 20:14:23.955: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/22/23 20:14:23.999
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 22 20:14:24.034: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1354  a127497e-baad-4548-8024-302c314c0165 33149 1 2023-04-22 20:14:23 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-22 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003555cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 22 20:14:24.043: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-1354  40366a5c-8ca0-4c4c-97c4-b16b0597e88c 33154 1 2023-04-22 20:14:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment a127497e-baad-4548-8024-302c314c0165 0xc0035fa167 0xc0035fa168}] [] [{kube-controller-manager Update apps/v1 2023-04-22 20:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a127497e-baad-4548-8024-302c314c0165\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035fa1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 20:14:24.043: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Apr 22 20:14:24.044: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1354  8439876e-99fc-47f6-8394-8e95d2a6a670 33152 1 2023-04-22 20:14:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a127497e-baad-4548-8024-302c314c0165 0xc0035fa037 0xc0035fa038}] [] [{e2e.test Update apps/v1 2023-04-22 20:14:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-22 20:14:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-22 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a127497e-baad-4548-8024-302c314c0165\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0035fa0f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 22 20:14:24.054: INFO: Pod "test-cleanup-controller-28f6k" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-28f6k test-cleanup-controller- deployment-1354  c816b455-5313-42e1-a890-358578c7ee17 33133 0 2023-04-22 20:14:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 8439876e-99fc-47f6-8394-8e95d2a6a670 0xc0035fa647 0xc0035fa648}] [] [{kube-controller-manager Update v1 2023-04-22 20:14:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8439876e-99fc-47f6-8394-8e95d2a6a670\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-22 20:14:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.36.0.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2p7ms,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2p7ms,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf25-2-node-187aa4c0d96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-22 20:14:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.1.1.128,PodIP:10.36.0.1,StartTime:2023-04-22 20:14:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-22 20:14:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c1bac203fdf7d2a9453900f8af277ee470e227e4d79cca6cd1ad3c064cdacda,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.36.0.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 22 20:14:24.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1354" for this suite. 04/22/23 20:14:24.069
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:24.122
Apr 22 20:14:24.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 20:14:24.125
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:24.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:24.156
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 04/22/23 20:14:24.162
Apr 22 20:14:24.174: INFO: Waiting up to 5m0s for pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788" in namespace "downward-api-4318" to be "Succeeded or Failed"
Apr 22 20:14:24.180: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Pending", Reason="", readiness=false. Elapsed: 5.535733ms
Apr 22 20:14:26.190: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016019361s
Apr 22 20:14:28.188: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014179948s
STEP: Saw pod success 04/22/23 20:14:28.189
Apr 22 20:14:28.190: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788" satisfied condition "Succeeded or Failed"
Apr 22 20:14:28.198: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 container dapi-container: <nil>
STEP: delete the pod 04/22/23 20:14:28.218
Apr 22 20:14:28.256: INFO: Waiting for pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 to disappear
Apr 22 20:14:28.265: INFO: Pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 22 20:14:28.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4318" for this suite. 04/22/23 20:14:28.279
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":307,"skipped":5631,"failed":0}
------------------------------
â€¢ [4.175 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:24.122
    Apr 22 20:14:24.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 20:14:24.125
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:24.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:24.156
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 04/22/23 20:14:24.162
    Apr 22 20:14:24.174: INFO: Waiting up to 5m0s for pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788" in namespace "downward-api-4318" to be "Succeeded or Failed"
    Apr 22 20:14:24.180: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Pending", Reason="", readiness=false. Elapsed: 5.535733ms
    Apr 22 20:14:26.190: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016019361s
    Apr 22 20:14:28.188: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014179948s
    STEP: Saw pod success 04/22/23 20:14:28.189
    Apr 22 20:14:28.190: INFO: Pod "downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788" satisfied condition "Succeeded or Failed"
    Apr 22 20:14:28.198: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 20:14:28.218
    Apr 22 20:14:28.256: INFO: Waiting for pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 to disappear
    Apr 22 20:14:28.265: INFO: Pod downward-api-08052e9d-a62d-4f5f-8b9f-8995d6714788 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 22 20:14:28.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4318" for this suite. 04/22/23 20:14:28.279
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:28.311
Apr 22 20:14:28.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename pods 04/22/23 20:14:28.314
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:28.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:28.385
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Apr 22 20:14:28.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: creating the pod 04/22/23 20:14:28.402
STEP: submitting the pod to kubernetes 04/22/23 20:14:28.403
Apr 22 20:14:28.420: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a" in namespace "pods-7115" to be "running and ready"
Apr 22 20:14:28.432: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.639024ms
Apr 22 20:14:28.432: INFO: The phase of Pod pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:14:30.450: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a": Phase="Running", Reason="", readiness=true. Elapsed: 2.029446285s
Apr 22 20:14:30.450: INFO: The phase of Pod pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a is Running (Ready = true)
Apr 22 20:14:30.450: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 22 20:14:30.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7115" for this suite. 04/22/23 20:14:30.68
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":308,"skipped":5632,"failed":0}
------------------------------
â€¢ [2.390 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:28.311
    Apr 22 20:14:28.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename pods 04/22/23 20:14:28.314
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:28.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:28.385
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Apr 22 20:14:28.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: creating the pod 04/22/23 20:14:28.402
    STEP: submitting the pod to kubernetes 04/22/23 20:14:28.403
    Apr 22 20:14:28.420: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a" in namespace "pods-7115" to be "running and ready"
    Apr 22 20:14:28.432: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.639024ms
    Apr 22 20:14:28.432: INFO: The phase of Pod pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:14:30.450: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a": Phase="Running", Reason="", readiness=true. Elapsed: 2.029446285s
    Apr 22 20:14:30.450: INFO: The phase of Pod pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a is Running (Ready = true)
    Apr 22 20:14:30.450: INFO: Pod "pod-exec-websocket-88eaa9c3-fe23-4366-9f38-c6d7506fff6a" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 22 20:14:30.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7115" for this suite. 04/22/23 20:14:30.68
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:30.742
Apr 22 20:14:30.742: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 20:14:30.745
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:30.797
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:30.802
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/22/23 20:14:30.819
Apr 22 20:14:30.835: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1399" to be "running and ready"
Apr 22 20:14:30.845: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.903506ms
Apr 22 20:14:30.845: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:14:32.856: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020704789s
Apr 22 20:14:32.856: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 22 20:14:32.857: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 04/22/23 20:14:32.869
Apr 22 20:14:32.904: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-1399" to be "running and ready"
Apr 22 20:14:32.918: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.129295ms
Apr 22 20:14:32.919: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:14:34.931: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02712748s
Apr 22 20:14:34.932: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 22 20:14:34.932: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/22/23 20:14:34.941
Apr 22 20:14:34.962: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 22 20:14:34.973: INFO: Pod pod-with-prestop-http-hook still exists
Apr 22 20:14:36.974: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 22 20:14:36.986: INFO: Pod pod-with-prestop-http-hook still exists
Apr 22 20:14:38.974: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 22 20:14:38.983: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/22/23 20:14:38.983
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 22 20:14:39.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1399" for this suite. 04/22/23 20:14:39.038
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":309,"skipped":5684,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.314 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:30.742
    Apr 22 20:14:30.742: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/22/23 20:14:30.745
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:30.797
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:30.802
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/22/23 20:14:30.819
    Apr 22 20:14:30.835: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1399" to be "running and ready"
    Apr 22 20:14:30.845: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.903506ms
    Apr 22 20:14:30.845: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:14:32.856: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020704789s
    Apr 22 20:14:32.856: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 22 20:14:32.857: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 04/22/23 20:14:32.869
    Apr 22 20:14:32.904: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-1399" to be "running and ready"
    Apr 22 20:14:32.918: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.129295ms
    Apr 22 20:14:32.919: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:14:34.931: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02712748s
    Apr 22 20:14:34.932: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 22 20:14:34.932: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/22/23 20:14:34.941
    Apr 22 20:14:34.962: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 22 20:14:34.973: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 22 20:14:36.974: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 22 20:14:36.986: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 22 20:14:38.974: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 22 20:14:38.983: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/22/23 20:14:38.983
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 22 20:14:39.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1399" for this suite. 04/22/23 20:14:39.038
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:39.062
Apr 22 20:14:39.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 20:14:39.071
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:39.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:39.131
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 22 20:14:39.163: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 22 20:14:44.174: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/22/23 20:14:44.174
STEP: Scaling up "test-rs" replicaset  04/22/23 20:14:44.175
Apr 22 20:14:44.220: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/22/23 20:14:44.22
W0422 20:14:44.251691      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 22 20:14:44.254: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
Apr 22 20:14:44.273: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
Apr 22 20:14:44.323: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
Apr 22 20:14:44.341: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
Apr 22 20:14:45.461: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 2, AvailableReplicas 2
Apr 22 20:14:45.519: INFO: observed Replicaset test-rs in namespace replicaset-4177 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 20:14:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4177" for this suite. 04/22/23 20:14:45.529
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":310,"skipped":5720,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.476 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:39.062
    Apr 22 20:14:39.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 20:14:39.071
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:39.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:39.131
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 22 20:14:39.163: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 22 20:14:44.174: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/22/23 20:14:44.174
    STEP: Scaling up "test-rs" replicaset  04/22/23 20:14:44.175
    Apr 22 20:14:44.220: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/22/23 20:14:44.22
    W0422 20:14:44.251691      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 22 20:14:44.254: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
    Apr 22 20:14:44.273: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
    Apr 22 20:14:44.323: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
    Apr 22 20:14:44.341: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 1, AvailableReplicas 1
    Apr 22 20:14:45.461: INFO: observed ReplicaSet test-rs in namespace replicaset-4177 with ReadyReplicas 2, AvailableReplicas 2
    Apr 22 20:14:45.519: INFO: observed Replicaset test-rs in namespace replicaset-4177 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 20:14:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4177" for this suite. 04/22/23 20:14:45.529
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:45.543
Apr 22 20:14:45.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 20:14:45.545
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:45.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:45.589
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:14:45.598
Apr 22 20:14:45.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7" in namespace "downward-api-2207" to be "Succeeded or Failed"
Apr 22 20:14:45.621: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.985833ms
Apr 22 20:14:47.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016424746s
Apr 22 20:14:49.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016106695s
STEP: Saw pod success 04/22/23 20:14:49.63
Apr 22 20:14:49.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7" satisfied condition "Succeeded or Failed"
Apr 22 20:14:49.642: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 container client-container: <nil>
STEP: delete the pod 04/22/23 20:14:49.675
Apr 22 20:14:49.715: INFO: Waiting for pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 to disappear
Apr 22 20:14:49.727: INFO: Pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 20:14:49.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2207" for this suite. 04/22/23 20:14:49.736
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":311,"skipped":5734,"failed":0}
------------------------------
â€¢ [4.207 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:45.543
    Apr 22 20:14:45.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 20:14:45.545
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:45.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:45.589
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:14:45.598
    Apr 22 20:14:45.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7" in namespace "downward-api-2207" to be "Succeeded or Failed"
    Apr 22 20:14:45.621: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.985833ms
    Apr 22 20:14:47.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016424746s
    Apr 22 20:14:49.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016106695s
    STEP: Saw pod success 04/22/23 20:14:49.63
    Apr 22 20:14:49.630: INFO: Pod "downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7" satisfied condition "Succeeded or Failed"
    Apr 22 20:14:49.642: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:14:49.675
    Apr 22 20:14:49.715: INFO: Waiting for pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 to disappear
    Apr 22 20:14:49.727: INFO: Pod downwardapi-volume-08f7659f-6ce1-4b15-bb05-62dc36d4bbe7 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 20:14:49.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2207" for this suite. 04/22/23 20:14:49.736
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:49.752
Apr 22 20:14:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:14:49.755
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:49.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:49.859
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7909 04/22/23 20:14:49.868
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/22/23 20:14:49.932
STEP: creating service externalsvc in namespace services-7909 04/22/23 20:14:49.933
STEP: creating replication controller externalsvc in namespace services-7909 04/22/23 20:14:49.972
I0422 20:14:49.986075      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7909, replica count: 2
I0422 20:14:53.037118      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/22/23 20:14:53.045
Apr 22 20:14:53.111: INFO: Creating new exec pod
Apr 22 20:14:53.140: INFO: Waiting up to 5m0s for pod "execpodwfbtn" in namespace "services-7909" to be "running"
Apr 22 20:14:53.150: INFO: Pod "execpodwfbtn": Phase="Pending", Reason="", readiness=false. Elapsed: 9.792402ms
Apr 22 20:14:55.156: INFO: Pod "execpodwfbtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016621516s
Apr 22 20:14:55.157: INFO: Pod "execpodwfbtn" satisfied condition "running"
Apr 22 20:14:55.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7909 exec execpodwfbtn -- /bin/sh -x -c nslookup nodeport-service.services-7909.svc.cluster.local'
Apr 22 20:14:55.571: INFO: stderr: "+ nslookup nodeport-service.services-7909.svc.cluster.local\n"
Apr 22 20:14:55.571: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-7909.svc.cluster.local\tcanonical name = externalsvc.services-7909.svc.cluster.local.\nName:\texternalsvc.services-7909.svc.cluster.local\nAddress: 10.107.94.72\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7909, will wait for the garbage collector to delete the pods 04/22/23 20:14:55.571
Apr 22 20:14:55.648: INFO: Deleting ReplicationController externalsvc took: 14.460195ms
Apr 22 20:14:55.749: INFO: Terminating ReplicationController externalsvc pods took: 100.760737ms
Apr 22 20:14:57.677: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:14:57.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7909" for this suite. 04/22/23 20:14:57.701
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":312,"skipped":5741,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.957 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:49.752
    Apr 22 20:14:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:14:49.755
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:49.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:49.859
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-7909 04/22/23 20:14:49.868
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/22/23 20:14:49.932
    STEP: creating service externalsvc in namespace services-7909 04/22/23 20:14:49.933
    STEP: creating replication controller externalsvc in namespace services-7909 04/22/23 20:14:49.972
    I0422 20:14:49.986075      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7909, replica count: 2
    I0422 20:14:53.037118      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/22/23 20:14:53.045
    Apr 22 20:14:53.111: INFO: Creating new exec pod
    Apr 22 20:14:53.140: INFO: Waiting up to 5m0s for pod "execpodwfbtn" in namespace "services-7909" to be "running"
    Apr 22 20:14:53.150: INFO: Pod "execpodwfbtn": Phase="Pending", Reason="", readiness=false. Elapsed: 9.792402ms
    Apr 22 20:14:55.156: INFO: Pod "execpodwfbtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016621516s
    Apr 22 20:14:55.157: INFO: Pod "execpodwfbtn" satisfied condition "running"
    Apr 22 20:14:55.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-7909 exec execpodwfbtn -- /bin/sh -x -c nslookup nodeport-service.services-7909.svc.cluster.local'
    Apr 22 20:14:55.571: INFO: stderr: "+ nslookup nodeport-service.services-7909.svc.cluster.local\n"
    Apr 22 20:14:55.571: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-7909.svc.cluster.local\tcanonical name = externalsvc.services-7909.svc.cluster.local.\nName:\texternalsvc.services-7909.svc.cluster.local\nAddress: 10.107.94.72\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7909, will wait for the garbage collector to delete the pods 04/22/23 20:14:55.571
    Apr 22 20:14:55.648: INFO: Deleting ReplicationController externalsvc took: 14.460195ms
    Apr 22 20:14:55.749: INFO: Terminating ReplicationController externalsvc pods took: 100.760737ms
    Apr 22 20:14:57.677: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:14:57.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7909" for this suite. 04/22/23 20:14:57.701
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:14:57.722
Apr 22 20:14:57.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename cronjob 04/22/23 20:14:57.725
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:57.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:57.758
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/22/23 20:14:57.762
STEP: Ensuring more than one job is running at a time 04/22/23 20:14:57.768
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/22/23 20:16:01.781
STEP: Removing cronjob 04/22/23 20:16:01.791
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 22 20:16:01.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4883" for this suite. 04/22/23 20:16:01.848
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":313,"skipped":5772,"failed":0}
------------------------------
â€¢ [SLOW TEST] [64.146 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:14:57.722
    Apr 22 20:14:57.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename cronjob 04/22/23 20:14:57.725
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:14:57.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:14:57.758
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/22/23 20:14:57.762
    STEP: Ensuring more than one job is running at a time 04/22/23 20:14:57.768
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/22/23 20:16:01.781
    STEP: Removing cronjob 04/22/23 20:16:01.791
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 22 20:16:01.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4883" for this suite. 04/22/23 20:16:01.848
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:01.883
Apr 22 20:16:01.884: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 20:16:01.892
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:01.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:01.962
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-3983/configmap-test-85dac328-f243-4959-a91a-924e2c025305 04/22/23 20:16:01.97
STEP: Creating a pod to test consume configMaps 04/22/23 20:16:01.986
Apr 22 20:16:02.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510" in namespace "configmap-3983" to be "Succeeded or Failed"
Apr 22 20:16:02.038: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Pending", Reason="", readiness=false. Elapsed: 10.638313ms
Apr 22 20:16:04.051: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02345229s
Apr 22 20:16:06.049: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022181409s
STEP: Saw pod success 04/22/23 20:16:06.05
Apr 22 20:16:06.050: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510" satisfied condition "Succeeded or Failed"
Apr 22 20:16:06.059: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 container env-test: <nil>
STEP: delete the pod 04/22/23 20:16:06.085
Apr 22 20:16:06.132: INFO: Waiting for pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 to disappear
Apr 22 20:16:06.145: INFO: Pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 20:16:06.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3983" for this suite. 04/22/23 20:16:06.158
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":314,"skipped":5772,"failed":0}
------------------------------
â€¢ [4.295 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:01.883
    Apr 22 20:16:01.884: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 20:16:01.892
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:01.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:01.962
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-3983/configmap-test-85dac328-f243-4959-a91a-924e2c025305 04/22/23 20:16:01.97
    STEP: Creating a pod to test consume configMaps 04/22/23 20:16:01.986
    Apr 22 20:16:02.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510" in namespace "configmap-3983" to be "Succeeded or Failed"
    Apr 22 20:16:02.038: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Pending", Reason="", readiness=false. Elapsed: 10.638313ms
    Apr 22 20:16:04.051: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02345229s
    Apr 22 20:16:06.049: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022181409s
    STEP: Saw pod success 04/22/23 20:16:06.05
    Apr 22 20:16:06.050: INFO: Pod "pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510" satisfied condition "Succeeded or Failed"
    Apr 22 20:16:06.059: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 container env-test: <nil>
    STEP: delete the pod 04/22/23 20:16:06.085
    Apr 22 20:16:06.132: INFO: Waiting for pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 to disappear
    Apr 22 20:16:06.145: INFO: Pod pod-configmaps-adcc7d6d-125a-4582-b368-3234cd6ce510 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 20:16:06.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3983" for this suite. 04/22/23 20:16:06.158
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:06.211
Apr 22 20:16:06.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:16:06.214
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:06.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:06.282
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:16:06.327
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:07.066
STEP: Deploying the webhook pod 04/22/23 20:16:07.091
STEP: Wait for the deployment to be ready 04/22/23 20:16:07.122
Apr 22 20:16:07.136: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/22/23 20:16:09.166
STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:09.21
Apr 22 20:16:10.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/22/23 20:16:10.22
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/22/23 20:16:10.27
STEP: Creating a dummy validating-webhook-configuration object 04/22/23 20:16:10.311
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/22/23 20:16:10.33
STEP: Creating a dummy mutating-webhook-configuration object 04/22/23 20:16:10.338
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/22/23 20:16:10.363
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:16:10.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8091" for this suite. 04/22/23 20:16:10.399
STEP: Destroying namespace "webhook-8091-markers" for this suite. 04/22/23 20:16:10.41
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":315,"skipped":5796,"failed":0}
------------------------------
â€¢ [4.280 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:06.211
    Apr 22 20:16:06.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:16:06.214
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:06.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:06.282
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:16:06.327
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:07.066
    STEP: Deploying the webhook pod 04/22/23 20:16:07.091
    STEP: Wait for the deployment to be ready 04/22/23 20:16:07.122
    Apr 22 20:16:07.136: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/22/23 20:16:09.166
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:09.21
    Apr 22 20:16:10.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/22/23 20:16:10.22
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/22/23 20:16:10.27
    STEP: Creating a dummy validating-webhook-configuration object 04/22/23 20:16:10.311
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/22/23 20:16:10.33
    STEP: Creating a dummy mutating-webhook-configuration object 04/22/23 20:16:10.338
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/22/23 20:16:10.363
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:10.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8091" for this suite. 04/22/23 20:16:10.399
    STEP: Destroying namespace "webhook-8091-markers" for this suite. 04/22/23 20:16:10.41
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:10.501
Apr 22 20:16:10.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename security-context-test 04/22/23 20:16:10.504
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:10.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:10.542
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Apr 22 20:16:10.560: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa" in namespace "security-context-test-5742" to be "Succeeded or Failed"
Apr 22 20:16:10.566: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095116ms
Apr 22 20:16:12.580: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019207123s
Apr 22 20:16:14.579: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018830439s
Apr 22 20:16:14.580: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 22 20:16:14.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5742" for this suite. 04/22/23 20:16:14.596
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":316,"skipped":5815,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:10.501
    Apr 22 20:16:10.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename security-context-test 04/22/23 20:16:10.504
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:10.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:10.542
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Apr 22 20:16:10.560: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa" in namespace "security-context-test-5742" to be "Succeeded or Failed"
    Apr 22 20:16:10.566: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095116ms
    Apr 22 20:16:12.580: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019207123s
    Apr 22 20:16:14.579: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018830439s
    Apr 22 20:16:14.580: INFO: Pod "busybox-readonly-false-97cfef3a-1a30-43c6-95ab-2c1951f911aa" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 22 20:16:14.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-5742" for this suite. 04/22/23 20:16:14.596
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:14.642
Apr 22 20:16:14.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:16:14.645
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:14.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:14.711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 04/22/23 20:16:14.722
Apr 22 20:16:14.724: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2378 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/22/23 20:16:14.846
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:16:14.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2378" for this suite. 04/22/23 20:16:14.89
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":317,"skipped":5831,"failed":0}
------------------------------
â€¢ [0.269 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:14.642
    Apr 22 20:16:14.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:16:14.645
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:14.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:14.711
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 04/22/23 20:16:14.722
    Apr 22 20:16:14.724: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-2378 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/22/23 20:16:14.846
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:16:14.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2378" for this suite. 04/22/23 20:16:14.89
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:14.912
Apr 22 20:16:14.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename containers 04/22/23 20:16:14.916
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:14.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:14.982
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 04/22/23 20:16:14.991
Apr 22 20:16:15.016: INFO: Waiting up to 5m0s for pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae" in namespace "containers-8744" to be "Succeeded or Failed"
Apr 22 20:16:15.030: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Pending", Reason="", readiness=false. Elapsed: 13.819199ms
Apr 22 20:16:17.042: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025995494s
Apr 22 20:16:19.041: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025180794s
STEP: Saw pod success 04/22/23 20:16:19.042
Apr 22 20:16:19.042: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae" satisfied condition "Succeeded or Failed"
Apr 22 20:16:19.051: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-containers-8b6566bf-bded-44af-94bd-507919decfae container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:16:19.067
Apr 22 20:16:19.101: INFO: Waiting for pod client-containers-8b6566bf-bded-44af-94bd-507919decfae to disappear
Apr 22 20:16:19.111: INFO: Pod client-containers-8b6566bf-bded-44af-94bd-507919decfae no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 22 20:16:19.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8744" for this suite. 04/22/23 20:16:19.124
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":318,"skipped":5834,"failed":0}
------------------------------
â€¢ [4.228 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:14.912
    Apr 22 20:16:14.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename containers 04/22/23 20:16:14.916
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:14.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:14.982
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 04/22/23 20:16:14.991
    Apr 22 20:16:15.016: INFO: Waiting up to 5m0s for pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae" in namespace "containers-8744" to be "Succeeded or Failed"
    Apr 22 20:16:15.030: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Pending", Reason="", readiness=false. Elapsed: 13.819199ms
    Apr 22 20:16:17.042: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025995494s
    Apr 22 20:16:19.041: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025180794s
    STEP: Saw pod success 04/22/23 20:16:19.042
    Apr 22 20:16:19.042: INFO: Pod "client-containers-8b6566bf-bded-44af-94bd-507919decfae" satisfied condition "Succeeded or Failed"
    Apr 22 20:16:19.051: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-containers-8b6566bf-bded-44af-94bd-507919decfae container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:16:19.067
    Apr 22 20:16:19.101: INFO: Waiting for pod client-containers-8b6566bf-bded-44af-94bd-507919decfae to disappear
    Apr 22 20:16:19.111: INFO: Pod client-containers-8b6566bf-bded-44af-94bd-507919decfae no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 22 20:16:19.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8744" for this suite. 04/22/23 20:16:19.124
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:19.153
Apr 22 20:16:19.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:16:19.154
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:19.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:19.201
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:16:19.239
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:20.004
STEP: Deploying the webhook pod 04/22/23 20:16:20.011
STEP: Wait for the deployment to be ready 04/22/23 20:16:20.025
Apr 22 20:16:20.046: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 22 20:16:22.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/22/23 20:16:24.089
STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:24.133
Apr 22 20:16:25.134: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/22/23 20:16:25.156
STEP: create a pod that should be updated by the webhook 04/22/23 20:16:25.2
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:16:25.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-988" for this suite. 04/22/23 20:16:25.285
STEP: Destroying namespace "webhook-988-markers" for this suite. 04/22/23 20:16:25.31
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":319,"skipped":5844,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.354 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:19.153
    Apr 22 20:16:19.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:16:19.154
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:19.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:19.201
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:16:19.239
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:20.004
    STEP: Deploying the webhook pod 04/22/23 20:16:20.011
    STEP: Wait for the deployment to be ready 04/22/23 20:16:20.025
    Apr 22 20:16:20.046: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 22 20:16:22.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/22/23 20:16:24.089
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:24.133
    Apr 22 20:16:25.134: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/22/23 20:16:25.156
    STEP: create a pod that should be updated by the webhook 04/22/23 20:16:25.2
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:25.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-988" for this suite. 04/22/23 20:16:25.285
    STEP: Destroying namespace "webhook-988-markers" for this suite. 04/22/23 20:16:25.31
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:25.526
Apr 22 20:16:25.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:16:25.53
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:25.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:25.568
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:16:25.591
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:25.995
STEP: Deploying the webhook pod 04/22/23 20:16:26.008
STEP: Wait for the deployment to be ready 04/22/23 20:16:26.037
Apr 22 20:16:26.059: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:16:28.087
STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:28.13
Apr 22 20:16:29.131: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 04/22/23 20:16:29.139
STEP: create a pod 04/22/23 20:16:29.178
Apr 22 20:16:29.195: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-82" to be "running"
Apr 22 20:16:29.202: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.344801ms
Apr 22 20:16:31.209: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014232138s
Apr 22 20:16:31.209: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/22/23 20:16:31.209
Apr 22 20:16:31.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=webhook-82 attach --namespace=webhook-82 to-be-attached-pod -i -c=container1'
Apr 22 20:16:31.398: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:16:31.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-82" for this suite. 04/22/23 20:16:31.433
STEP: Destroying namespace "webhook-82-markers" for this suite. 04/22/23 20:16:31.45
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":320,"skipped":5876,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.037 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:25.526
    Apr 22 20:16:25.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:16:25.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:25.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:25.568
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:16:25.591
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:25.995
    STEP: Deploying the webhook pod 04/22/23 20:16:26.008
    STEP: Wait for the deployment to be ready 04/22/23 20:16:26.037
    Apr 22 20:16:26.059: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:16:28.087
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:28.13
    Apr 22 20:16:29.131: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 04/22/23 20:16:29.139
    STEP: create a pod 04/22/23 20:16:29.178
    Apr 22 20:16:29.195: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-82" to be "running"
    Apr 22 20:16:29.202: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.344801ms
    Apr 22 20:16:31.209: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014232138s
    Apr 22 20:16:31.209: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/22/23 20:16:31.209
    Apr 22 20:16:31.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=webhook-82 attach --namespace=webhook-82 to-be-attached-pod -i -c=container1'
    Apr 22 20:16:31.398: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:31.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-82" for this suite. 04/22/23 20:16:31.433
    STEP: Destroying namespace "webhook-82-markers" for this suite. 04/22/23 20:16:31.45
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:31.572
Apr 22 20:16:31.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:16:31.579
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:31.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:31.612
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 04/22/23 20:16:31.618
Apr 22 20:16:31.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8346 cluster-info'
Apr 22 20:16:31.724: INFO: stderr: ""
Apr 22 20:16:31.724: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:16:31.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8346" for this suite. 04/22/23 20:16:31.734
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":321,"skipped":5882,"failed":0}
------------------------------
â€¢ [0.174 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:31.572
    Apr 22 20:16:31.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:16:31.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:31.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:31.612
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 04/22/23 20:16:31.618
    Apr 22 20:16:31.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-8346 cluster-info'
    Apr 22 20:16:31.724: INFO: stderr: ""
    Apr 22 20:16:31.724: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:16:31.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8346" for this suite. 04/22/23 20:16:31.734
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:31.75
Apr 22 20:16:31.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename init-container 04/22/23 20:16:31.752
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:31.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:31.789
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 04/22/23 20:16:31.793
Apr 22 20:16:31.793: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 20:16:36.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5427" for this suite. 04/22/23 20:16:36.087
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":322,"skipped":5896,"failed":0}
------------------------------
â€¢ [4.348 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:31.75
    Apr 22 20:16:31.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename init-container 04/22/23 20:16:31.752
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:31.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:31.789
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 04/22/23 20:16:31.793
    Apr 22 20:16:31.793: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:36.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5427" for this suite. 04/22/23 20:16:36.087
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:36.106
Apr 22 20:16:36.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:16:36.109
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:36.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:36.146
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:16:36.176
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:36.608
STEP: Deploying the webhook pod 04/22/23 20:16:36.618
STEP: Wait for the deployment to be ready 04/22/23 20:16:36.632
Apr 22 20:16:36.641: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:16:38.656
STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:38.684
Apr 22 20:16:39.684: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 04/22/23 20:16:39.699
STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.747
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/22/23 20:16:39.769
STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.805
STEP: Patching a validating webhook configuration's rules to include the create operation 04/22/23 20:16:39.837
STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.86
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:16:39.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4804" for this suite. 04/22/23 20:16:39.899
STEP: Destroying namespace "webhook-4804-markers" for this suite. 04/22/23 20:16:39.916
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":323,"skipped":5905,"failed":0}
------------------------------
â€¢ [3.930 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:36.106
    Apr 22 20:16:36.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:16:36.109
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:36.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:36.146
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:16:36.176
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:36.608
    STEP: Deploying the webhook pod 04/22/23 20:16:36.618
    STEP: Wait for the deployment to be ready 04/22/23 20:16:36.632
    Apr 22 20:16:36.641: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:16:38.656
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:38.684
    Apr 22 20:16:39.684: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 04/22/23 20:16:39.699
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.747
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/22/23 20:16:39.769
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.805
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/22/23 20:16:39.837
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/22/23 20:16:39.86
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:39.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4804" for this suite. 04/22/23 20:16:39.899
    STEP: Destroying namespace "webhook-4804-markers" for this suite. 04/22/23 20:16:39.916
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:40.053
Apr 22 20:16:40.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:16:40.056
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:40.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:40.088
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:16:40.108
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:40.741
STEP: Deploying the webhook pod 04/22/23 20:16:40.764
STEP: Wait for the deployment to be ready 04/22/23 20:16:40.792
Apr 22 20:16:40.811: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:16:42.846
STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:42.902
Apr 22 20:16:43.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 04/22/23 20:16:44.058
STEP: Creating a configMap that should be mutated 04/22/23 20:16:44.104
STEP: Deleting the collection of validation webhooks 04/22/23 20:16:44.201
STEP: Creating a configMap that should not be mutated 04/22/23 20:16:44.343
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:16:44.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9424" for this suite. 04/22/23 20:16:44.363
STEP: Destroying namespace "webhook-9424-markers" for this suite. 04/22/23 20:16:44.371
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":324,"skipped":5932,"failed":0}
------------------------------
â€¢ [4.387 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:40.053
    Apr 22 20:16:40.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:16:40.056
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:40.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:40.088
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:16:40.108
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:16:40.741
    STEP: Deploying the webhook pod 04/22/23 20:16:40.764
    STEP: Wait for the deployment to be ready 04/22/23 20:16:40.792
    Apr 22 20:16:40.811: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:16:42.846
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:16:42.902
    Apr 22 20:16:43.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 04/22/23 20:16:44.058
    STEP: Creating a configMap that should be mutated 04/22/23 20:16:44.104
    STEP: Deleting the collection of validation webhooks 04/22/23 20:16:44.201
    STEP: Creating a configMap that should not be mutated 04/22/23 20:16:44.343
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:16:44.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9424" for this suite. 04/22/23 20:16:44.363
    STEP: Destroying namespace "webhook-9424-markers" for this suite. 04/22/23 20:16:44.371
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:44.457
Apr 22 20:16:44.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 20:16:44.46
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:44.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:44.493
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-c56607a8-9e0c-4fe6-9ebf-711b90b3a116 04/22/23 20:16:44.5
STEP: Creating a pod to test consume configMaps 04/22/23 20:16:44.507
Apr 22 20:16:44.517: INFO: Waiting up to 5m0s for pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e" in namespace "configmap-916" to be "Succeeded or Failed"
Apr 22 20:16:44.523: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.375431ms
Apr 22 20:16:46.532: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015087368s
Apr 22 20:16:48.534: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01618531s
STEP: Saw pod success 04/22/23 20:16:48.534
Apr 22 20:16:48.535: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e" satisfied condition "Succeeded or Failed"
Apr 22 20:16:48.544: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:16:48.573
Apr 22 20:16:48.616: INFO: Waiting for pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e to disappear
Apr 22 20:16:48.624: INFO: Pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 20:16:48.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-916" for this suite. 04/22/23 20:16:48.636
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":325,"skipped":5959,"failed":0}
------------------------------
â€¢ [4.194 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:44.457
    Apr 22 20:16:44.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 20:16:44.46
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:44.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:44.493
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-c56607a8-9e0c-4fe6-9ebf-711b90b3a116 04/22/23 20:16:44.5
    STEP: Creating a pod to test consume configMaps 04/22/23 20:16:44.507
    Apr 22 20:16:44.517: INFO: Waiting up to 5m0s for pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e" in namespace "configmap-916" to be "Succeeded or Failed"
    Apr 22 20:16:44.523: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.375431ms
    Apr 22 20:16:46.532: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015087368s
    Apr 22 20:16:48.534: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01618531s
    STEP: Saw pod success 04/22/23 20:16:48.534
    Apr 22 20:16:48.535: INFO: Pod "pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e" satisfied condition "Succeeded or Failed"
    Apr 22 20:16:48.544: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:16:48.573
    Apr 22 20:16:48.616: INFO: Waiting for pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e to disappear
    Apr 22 20:16:48.624: INFO: Pod pod-configmaps-3898a2d8-063a-4c76-b72c-74d9e432fa0e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 20:16:48.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-916" for this suite. 04/22/23 20:16:48.636
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:48.663
Apr 22 20:16:48.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 20:16:48.666
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:48.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:48.722
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 04/22/23 20:16:48.73
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/22/23 20:16:48.744
STEP: patching the secret 04/22/23 20:16:48.754
STEP: deleting the secret using a LabelSelector 04/22/23 20:16:48.774
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/22/23 20:16:48.786
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 22 20:16:48.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5010" for this suite. 04/22/23 20:16:48.799
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":326,"skipped":5968,"failed":0}
------------------------------
â€¢ [0.143 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:48.663
    Apr 22 20:16:48.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 20:16:48.666
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:48.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:48.722
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 04/22/23 20:16:48.73
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/22/23 20:16:48.744
    STEP: patching the secret 04/22/23 20:16:48.754
    STEP: deleting the secret using a LabelSelector 04/22/23 20:16:48.774
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/22/23 20:16:48.786
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 20:16:48.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5010" for this suite. 04/22/23 20:16:48.799
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:48.862
Apr 22 20:16:48.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename disruption 04/22/23 20:16:48.865
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:48.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:48.907
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 04/22/23 20:16:48.911
STEP: Waiting for the pdb to be processed 04/22/23 20:16:48.918
STEP: First trying to evict a pod which shouldn't be evictable 04/22/23 20:16:50.948
STEP: Waiting for all pods to be running 04/22/23 20:16:50.948
Apr 22 20:16:50.965: INFO: pods: 0 < 3
STEP: locating a running pod 04/22/23 20:16:52.979
STEP: Updating the pdb to allow a pod to be evicted 04/22/23 20:16:53.019
STEP: Waiting for the pdb to be processed 04/22/23 20:16:53.051
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/22/23 20:16:53.074
STEP: Waiting for all pods to be running 04/22/23 20:16:53.074
STEP: Waiting for the pdb to observed all healthy pods 04/22/23 20:16:53.085
STEP: Patching the pdb to disallow a pod to be evicted 04/22/23 20:16:53.137
STEP: Waiting for the pdb to be processed 04/22/23 20:16:53.167
STEP: Waiting for all pods to be running 04/22/23 20:16:55.185
STEP: locating a running pod 04/22/23 20:16:55.197
STEP: Deleting the pdb to allow a pod to be evicted 04/22/23 20:16:55.232
STEP: Waiting for the pdb to be deleted 04/22/23 20:16:55.251
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/22/23 20:16:55.258
STEP: Waiting for all pods to be running 04/22/23 20:16:55.258
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 22 20:16:55.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8725" for this suite. 04/22/23 20:16:55.311
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":327,"skipped":6023,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.467 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:48.862
    Apr 22 20:16:48.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename disruption 04/22/23 20:16:48.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:48.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:48.907
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 04/22/23 20:16:48.911
    STEP: Waiting for the pdb to be processed 04/22/23 20:16:48.918
    STEP: First trying to evict a pod which shouldn't be evictable 04/22/23 20:16:50.948
    STEP: Waiting for all pods to be running 04/22/23 20:16:50.948
    Apr 22 20:16:50.965: INFO: pods: 0 < 3
    STEP: locating a running pod 04/22/23 20:16:52.979
    STEP: Updating the pdb to allow a pod to be evicted 04/22/23 20:16:53.019
    STEP: Waiting for the pdb to be processed 04/22/23 20:16:53.051
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/22/23 20:16:53.074
    STEP: Waiting for all pods to be running 04/22/23 20:16:53.074
    STEP: Waiting for the pdb to observed all healthy pods 04/22/23 20:16:53.085
    STEP: Patching the pdb to disallow a pod to be evicted 04/22/23 20:16:53.137
    STEP: Waiting for the pdb to be processed 04/22/23 20:16:53.167
    STEP: Waiting for all pods to be running 04/22/23 20:16:55.185
    STEP: locating a running pod 04/22/23 20:16:55.197
    STEP: Deleting the pdb to allow a pod to be evicted 04/22/23 20:16:55.232
    STEP: Waiting for the pdb to be deleted 04/22/23 20:16:55.251
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/22/23 20:16:55.258
    STEP: Waiting for all pods to be running 04/22/23 20:16:55.258
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 22 20:16:55.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8725" for this suite. 04/22/23 20:16:55.311
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:16:55.334
Apr 22 20:16:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename aggregator 04/22/23 20:16:55.344
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:55.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:55.381
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 22 20:16:55.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/22/23 20:16:55.399
Apr 22 20:16:56.879: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 22 20:16:58.998: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:01.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:03.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:05.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:07.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:09.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:11.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:13.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:15.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:17.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:19.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 22 20:17:21.182: INFO: Waited 146.659976ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/22/23 20:17:21.309
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/22/23 20:17:21.318
STEP: List APIServices 04/22/23 20:17:21.34
Apr 22 20:17:21.359: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Apr 22 20:17:21.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9570" for this suite. 04/22/23 20:17:21.608
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":328,"skipped":6024,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.282 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:16:55.334
    Apr 22 20:16:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename aggregator 04/22/23 20:16:55.344
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:16:55.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:16:55.381
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 22 20:16:55.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/22/23 20:16:55.399
    Apr 22 20:16:56.879: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 22 20:16:58.998: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:01.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:03.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:05.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:07.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:09.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:11.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:13.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:15.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:17.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:19.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 22, 20, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 22 20:17:21.182: INFO: Waited 146.659976ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/22/23 20:17:21.309
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/22/23 20:17:21.318
    STEP: List APIServices 04/22/23 20:17:21.34
    Apr 22 20:17:21.359: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Apr 22 20:17:21.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-9570" for this suite. 04/22/23 20:17:21.608
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:21.616
Apr 22 20:17:21.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename ephemeral-containers-test 04/22/23 20:17:21.62
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:21.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:21.655
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/22/23 20:17:21.659
Apr 22 20:17:21.671: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-580" to be "running and ready"
Apr 22 20:17:21.675: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.867844ms
Apr 22 20:17:21.676: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:17:23.687: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016659223s
Apr 22 20:17:23.687: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 22 20:17:23.687: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/22/23 20:17:23.696
Apr 22 20:17:23.732: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-580" to be "container debugger running"
Apr 22 20:17:23.743: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.940942ms
Apr 22 20:17:25.753: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021694455s
Apr 22 20:17:27.748: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016580474s
Apr 22 20:17:27.749: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/22/23 20:17:27.749
Apr 22 20:17:27.750: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-580 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 22 20:17:27.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:17:27.752: INFO: ExecWithOptions: Clientset creation
Apr 22 20:17:27.753: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-580/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 22 20:17:27.892: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 20:17:27.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-580" for this suite. 04/22/23 20:17:27.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":329,"skipped":6029,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.308 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:21.616
    Apr 22 20:17:21.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/22/23 20:17:21.62
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:21.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:21.655
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/22/23 20:17:21.659
    Apr 22 20:17:21.671: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-580" to be "running and ready"
    Apr 22 20:17:21.675: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.867844ms
    Apr 22 20:17:21.676: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:17:23.687: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016659223s
    Apr 22 20:17:23.687: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 22 20:17:23.687: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/22/23 20:17:23.696
    Apr 22 20:17:23.732: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-580" to be "container debugger running"
    Apr 22 20:17:23.743: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.940942ms
    Apr 22 20:17:25.753: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021694455s
    Apr 22 20:17:27.748: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016580474s
    Apr 22 20:17:27.749: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/22/23 20:17:27.749
    Apr 22 20:17:27.750: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-580 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 22 20:17:27.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:17:27.752: INFO: ExecWithOptions: Clientset creation
    Apr 22 20:17:27.753: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-580/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 22 20:17:27.892: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 20:17:27.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-580" for this suite. 04/22/23 20:17:27.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:27.932
Apr 22 20:17:27.932: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:17:27.934
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:27.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:27.965
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-4675976e-9e58-45a4-9c16-1eb75c7fc7f6 04/22/23 20:17:27.973
STEP: Creating a pod to test consume configMaps 04/22/23 20:17:27.981
Apr 22 20:17:27.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934" in namespace "projected-6054" to be "Succeeded or Failed"
Apr 22 20:17:28.000: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505858ms
Apr 22 20:17:30.014: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020872078s
Apr 22 20:17:32.008: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014826107s
STEP: Saw pod success 04/22/23 20:17:32.009
Apr 22 20:17:32.010: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934" satisfied condition "Succeeded or Failed"
Apr 22 20:17:32.034: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:17:32.066
Apr 22 20:17:32.121: INFO: Waiting for pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 to disappear
Apr 22 20:17:32.131: INFO: Pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 22 20:17:32.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6054" for this suite. 04/22/23 20:17:32.14
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":330,"skipped":6033,"failed":0}
------------------------------
â€¢ [4.219 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:27.932
    Apr 22 20:17:27.932: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:17:27.934
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:27.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:27.965
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-4675976e-9e58-45a4-9c16-1eb75c7fc7f6 04/22/23 20:17:27.973
    STEP: Creating a pod to test consume configMaps 04/22/23 20:17:27.981
    Apr 22 20:17:27.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934" in namespace "projected-6054" to be "Succeeded or Failed"
    Apr 22 20:17:28.000: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505858ms
    Apr 22 20:17:30.014: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020872078s
    Apr 22 20:17:32.008: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014826107s
    STEP: Saw pod success 04/22/23 20:17:32.009
    Apr 22 20:17:32.010: INFO: Pod "pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934" satisfied condition "Succeeded or Failed"
    Apr 22 20:17:32.034: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:17:32.066
    Apr 22 20:17:32.121: INFO: Waiting for pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 to disappear
    Apr 22 20:17:32.131: INFO: Pod pod-projected-configmaps-d24fce7f-c624-46e5-aa43-2d19c510c934 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 22 20:17:32.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6054" for this suite. 04/22/23 20:17:32.14
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:32.172
Apr 22 20:17:32.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename downward-api 04/22/23 20:17:32.174
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:32.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:32.209
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:17:32.219
Apr 22 20:17:32.235: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9" in namespace "downward-api-909" to be "Succeeded or Failed"
Apr 22 20:17:32.242: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.364539ms
Apr 22 20:17:34.253: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018826174s
Apr 22 20:17:36.253: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018751904s
STEP: Saw pod success 04/22/23 20:17:36.254
Apr 22 20:17:36.255: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9" satisfied condition "Succeeded or Failed"
Apr 22 20:17:36.264: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 container client-container: <nil>
STEP: delete the pod 04/22/23 20:17:36.285
Apr 22 20:17:36.328: INFO: Waiting for pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 to disappear
Apr 22 20:17:36.342: INFO: Pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 22 20:17:36.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-909" for this suite. 04/22/23 20:17:36.358
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":331,"skipped":6038,"failed":0}
------------------------------
â€¢ [4.208 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:32.172
    Apr 22 20:17:32.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename downward-api 04/22/23 20:17:32.174
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:32.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:32.209
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:17:32.219
    Apr 22 20:17:32.235: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9" in namespace "downward-api-909" to be "Succeeded or Failed"
    Apr 22 20:17:32.242: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.364539ms
    Apr 22 20:17:34.253: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018826174s
    Apr 22 20:17:36.253: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018751904s
    STEP: Saw pod success 04/22/23 20:17:36.254
    Apr 22 20:17:36.255: INFO: Pod "downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9" satisfied condition "Succeeded or Failed"
    Apr 22 20:17:36.264: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:17:36.285
    Apr 22 20:17:36.328: INFO: Waiting for pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 to disappear
    Apr 22 20:17:36.342: INFO: Pod downwardapi-volume-dd97a61a-8314-4978-99f4-c3fca6142da9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 22 20:17:36.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-909" for this suite. 04/22/23 20:17:36.358
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:36.399
Apr 22 20:17:36.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:17:36.402
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:36.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:36.461
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Apr 22 20:17:36.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/22/23 20:17:39.531
Apr 22 20:17:39.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
Apr 22 20:17:40.582: INFO: stderr: ""
Apr 22 20:17:40.582: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 22 20:17:40.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 delete e2e-test-crd-publish-openapi-1767-crds test-foo'
Apr 22 20:17:40.731: INFO: stderr: ""
Apr 22 20:17:40.731: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 22 20:17:40.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
Apr 22 20:17:41.592: INFO: stderr: ""
Apr 22 20:17:41.592: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 22 20:17:41.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 delete e2e-test-crd-publish-openapi-1767-crds test-foo'
Apr 22 20:17:41.705: INFO: stderr: ""
Apr 22 20:17:41.705: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/22/23 20:17:41.705
Apr 22 20:17:41.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
Apr 22 20:17:41.968: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/22/23 20:17:41.968
Apr 22 20:17:41.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
Apr 22 20:17:42.168: INFO: rc: 1
Apr 22 20:17:42.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
Apr 22 20:17:42.392: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/22/23 20:17:42.393
Apr 22 20:17:42.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
Apr 22 20:17:42.637: INFO: rc: 1
Apr 22 20:17:42.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
Apr 22 20:17:42.860: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/22/23 20:17:42.86
Apr 22 20:17:42.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds'
Apr 22 20:17:43.069: INFO: stderr: ""
Apr 22 20:17:43.069: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/22/23 20:17:43.07
Apr 22 20:17:43.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.metadata'
Apr 22 20:17:43.302: INFO: stderr: ""
Apr 22 20:17:43.302: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 22 20:17:43.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec'
Apr 22 20:17:43.503: INFO: stderr: ""
Apr 22 20:17:43.503: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 22 20:17:43.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec.bars'
Apr 22 20:17:43.703: INFO: stderr: ""
Apr 22 20:17:43.703: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/22/23 20:17:43.703
Apr 22 20:17:43.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec.bars2'
Apr 22 20:17:43.901: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:17:46.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5607" for this suite. 04/22/23 20:17:46.917
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":332,"skipped":6052,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.539 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:36.399
    Apr 22 20:17:36.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:17:36.402
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:36.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:36.461
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Apr 22 20:17:36.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/22/23 20:17:39.531
    Apr 22 20:17:39.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
    Apr 22 20:17:40.582: INFO: stderr: ""
    Apr 22 20:17:40.582: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 22 20:17:40.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 delete e2e-test-crd-publish-openapi-1767-crds test-foo'
    Apr 22 20:17:40.731: INFO: stderr: ""
    Apr 22 20:17:40.731: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 22 20:17:40.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
    Apr 22 20:17:41.592: INFO: stderr: ""
    Apr 22 20:17:41.592: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 22 20:17:41.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 delete e2e-test-crd-publish-openapi-1767-crds test-foo'
    Apr 22 20:17:41.705: INFO: stderr: ""
    Apr 22 20:17:41.705: INFO: stdout: "e2e-test-crd-publish-openapi-1767-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/22/23 20:17:41.705
    Apr 22 20:17:41.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
    Apr 22 20:17:41.968: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/22/23 20:17:41.968
    Apr 22 20:17:41.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
    Apr 22 20:17:42.168: INFO: rc: 1
    Apr 22 20:17:42.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
    Apr 22 20:17:42.392: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/22/23 20:17:42.393
    Apr 22 20:17:42.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 create -f -'
    Apr 22 20:17:42.637: INFO: rc: 1
    Apr 22 20:17:42.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 --namespace=crd-publish-openapi-5607 apply -f -'
    Apr 22 20:17:42.860: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/22/23 20:17:42.86
    Apr 22 20:17:42.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds'
    Apr 22 20:17:43.069: INFO: stderr: ""
    Apr 22 20:17:43.069: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/22/23 20:17:43.07
    Apr 22 20:17:43.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.metadata'
    Apr 22 20:17:43.302: INFO: stderr: ""
    Apr 22 20:17:43.302: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 22 20:17:43.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec'
    Apr 22 20:17:43.503: INFO: stderr: ""
    Apr 22 20:17:43.503: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 22 20:17:43.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec.bars'
    Apr 22 20:17:43.703: INFO: stderr: ""
    Apr 22 20:17:43.703: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1767-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/22/23 20:17:43.703
    Apr 22 20:17:43.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=crd-publish-openapi-5607 explain e2e-test-crd-publish-openapi-1767-crds.spec.bars2'
    Apr 22 20:17:43.901: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:17:46.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5607" for this suite. 04/22/23 20:17:46.917
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:46.972
Apr 22 20:17:46.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename podtemplate 04/22/23 20:17:46.974
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:47.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:47.043
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/22/23 20:17:47.054
STEP: Replace a pod template 04/22/23 20:17:47.073
Apr 22 20:17:47.113: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 22 20:17:47.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9905" for this suite. 04/22/23 20:17:47.122
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":333,"skipped":6111,"failed":0}
------------------------------
â€¢ [0.164 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:46.972
    Apr 22 20:17:46.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename podtemplate 04/22/23 20:17:46.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:47.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:47.043
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/22/23 20:17:47.054
    STEP: Replace a pod template 04/22/23 20:17:47.073
    Apr 22 20:17:47.113: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 22 20:17:47.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9905" for this suite. 04/22/23 20:17:47.122
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:47.143
Apr 22 20:17:47.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:17:47.146
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:47.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:47.179
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:17:47.188
Apr 22 20:17:47.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6" in namespace "projected-9167" to be "Succeeded or Failed"
Apr 22 20:17:47.219: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.005891ms
Apr 22 20:17:49.230: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020529239s
Apr 22 20:17:51.231: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021861852s
STEP: Saw pod success 04/22/23 20:17:51.231
Apr 22 20:17:51.232: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6" satisfied condition "Succeeded or Failed"
Apr 22 20:17:51.241: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 container client-container: <nil>
STEP: delete the pod 04/22/23 20:17:51.262
Apr 22 20:17:51.298: INFO: Waiting for pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 to disappear
Apr 22 20:17:51.308: INFO: Pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:17:51.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9167" for this suite. 04/22/23 20:17:51.318
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":334,"skipped":6115,"failed":0}
------------------------------
â€¢ [4.193 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:47.143
    Apr 22 20:17:47.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:17:47.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:47.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:47.179
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:17:47.188
    Apr 22 20:17:47.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6" in namespace "projected-9167" to be "Succeeded or Failed"
    Apr 22 20:17:47.219: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.005891ms
    Apr 22 20:17:49.230: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020529239s
    Apr 22 20:17:51.231: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021861852s
    STEP: Saw pod success 04/22/23 20:17:51.231
    Apr 22 20:17:51.232: INFO: Pod "downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6" satisfied condition "Succeeded or Failed"
    Apr 22 20:17:51.241: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:17:51.262
    Apr 22 20:17:51.298: INFO: Waiting for pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 to disappear
    Apr 22 20:17:51.308: INFO: Pod downwardapi-volume-70b05ce2-d7b8-4877-a36d-ceb2da250bf6 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:17:51.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9167" for this suite. 04/22/23 20:17:51.318
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:51.351
Apr 22 20:17:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 20:17:51.354
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:51.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:51.451
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 22 20:17:51.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:17:52.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3620" for this suite. 04/22/23 20:17:52.521
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":335,"skipped":6142,"failed":0}
------------------------------
â€¢ [1.180 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:51.351
    Apr 22 20:17:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename custom-resource-definition 04/22/23 20:17:51.354
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:51.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:51.451
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 22 20:17:51.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:17:52.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3620" for this suite. 04/22/23 20:17:52.521
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:17:52.551
Apr 22 20:17:52.552: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 20:17:52.555
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:52.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:52.587
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9709 04/22/23 20:17:52.592
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 04/22/23 20:17:52.599
Apr 22 20:17:52.612: INFO: Found 0 stateful pods, waiting for 3
Apr 22 20:18:02.624: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:18:02.624: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:18:02.624: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/22/23 20:18:02.651
Apr 22 20:18:02.690: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/22/23 20:18:02.69
STEP: Not applying an update when the partition is greater than the number of replicas 04/22/23 20:18:12.733
STEP: Performing a canary update 04/22/23 20:18:12.734
Apr 22 20:18:12.775: INFO: Updating stateful set ss2
Apr 22 20:18:12.800: INFO: Waiting for Pod statefulset-9709/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 04/22/23 20:18:22.824
Apr 22 20:18:22.930: INFO: Found 1 stateful pods, waiting for 3
Apr 22 20:18:32.944: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:18:32.945: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 22 20:18:32.945: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/22/23 20:18:32.965
Apr 22 20:18:33.002: INFO: Updating stateful set ss2
Apr 22 20:18:33.023: INFO: Waiting for Pod statefulset-9709/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Apr 22 20:18:43.084: INFO: Updating stateful set ss2
Apr 22 20:18:43.131: INFO: Waiting for StatefulSet statefulset-9709/ss2 to complete update
Apr 22 20:18:43.132: INFO: Waiting for Pod statefulset-9709/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 20:18:53.145: INFO: Deleting all statefulset in ns statefulset-9709
Apr 22 20:18:53.152: INFO: Scaling statefulset ss2 to 0
Apr 22 20:19:03.185: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:19:03.195: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 20:19:03.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9709" for this suite. 04/22/23 20:19:03.254
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":336,"skipped":6151,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.723 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:17:52.551
    Apr 22 20:17:52.552: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 20:17:52.555
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:17:52.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:17:52.587
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9709 04/22/23 20:17:52.592
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 04/22/23 20:17:52.599
    Apr 22 20:17:52.612: INFO: Found 0 stateful pods, waiting for 3
    Apr 22 20:18:02.624: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:18:02.624: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:18:02.624: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/22/23 20:18:02.651
    Apr 22 20:18:02.690: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/22/23 20:18:02.69
    STEP: Not applying an update when the partition is greater than the number of replicas 04/22/23 20:18:12.733
    STEP: Performing a canary update 04/22/23 20:18:12.734
    Apr 22 20:18:12.775: INFO: Updating stateful set ss2
    Apr 22 20:18:12.800: INFO: Waiting for Pod statefulset-9709/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 04/22/23 20:18:22.824
    Apr 22 20:18:22.930: INFO: Found 1 stateful pods, waiting for 3
    Apr 22 20:18:32.944: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:18:32.945: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 22 20:18:32.945: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/22/23 20:18:32.965
    Apr 22 20:18:33.002: INFO: Updating stateful set ss2
    Apr 22 20:18:33.023: INFO: Waiting for Pod statefulset-9709/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Apr 22 20:18:43.084: INFO: Updating stateful set ss2
    Apr 22 20:18:43.131: INFO: Waiting for StatefulSet statefulset-9709/ss2 to complete update
    Apr 22 20:18:43.132: INFO: Waiting for Pod statefulset-9709/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 20:18:53.145: INFO: Deleting all statefulset in ns statefulset-9709
    Apr 22 20:18:53.152: INFO: Scaling statefulset ss2 to 0
    Apr 22 20:19:03.185: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:19:03.195: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 20:19:03.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9709" for this suite. 04/22/23 20:19:03.254
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:03.275
Apr 22 20:19:03.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:19:03.281
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:03.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:03.344
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 04/22/23 20:19:03.353
Apr 22 20:19:03.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949" in namespace "projected-41" to be "Succeeded or Failed"
Apr 22 20:19:03.397: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Pending", Reason="", readiness=false. Elapsed: 10.063826ms
Apr 22 20:19:05.406: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018335005s
Apr 22 20:19:07.407: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019731291s
STEP: Saw pod success 04/22/23 20:19:07.407
Apr 22 20:19:07.407: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949" satisfied condition "Succeeded or Failed"
Apr 22 20:19:07.419: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 container client-container: <nil>
STEP: delete the pod 04/22/23 20:19:07.437
Apr 22 20:19:07.475: INFO: Waiting for pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 to disappear
Apr 22 20:19:07.485: INFO: Pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:19:07.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-41" for this suite. 04/22/23 20:19:07.5
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":337,"skipped":6152,"failed":0}
------------------------------
â€¢ [4.246 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:03.275
    Apr 22 20:19:03.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:19:03.281
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:03.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:03.344
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 04/22/23 20:19:03.353
    Apr 22 20:19:03.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949" in namespace "projected-41" to be "Succeeded or Failed"
    Apr 22 20:19:03.397: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Pending", Reason="", readiness=false. Elapsed: 10.063826ms
    Apr 22 20:19:05.406: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018335005s
    Apr 22 20:19:07.407: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019731291s
    STEP: Saw pod success 04/22/23 20:19:07.407
    Apr 22 20:19:07.407: INFO: Pod "downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949" satisfied condition "Succeeded or Failed"
    Apr 22 20:19:07.419: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 container client-container: <nil>
    STEP: delete the pod 04/22/23 20:19:07.437
    Apr 22 20:19:07.475: INFO: Waiting for pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 to disappear
    Apr 22 20:19:07.485: INFO: Pod downwardapi-volume-4fa99326-1327-4191-9818-2b9bfda91949 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:19:07.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-41" for this suite. 04/22/23 20:19:07.5
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:07.535
Apr 22 20:19:07.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename events 04/22/23 20:19:07.538
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:07.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:07.588
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/22/23 20:19:07.601
STEP: listing events in all namespaces 04/22/23 20:19:07.623
STEP: listing events in test namespace 04/22/23 20:19:07.638
STEP: listing events with field selection filtering on source 04/22/23 20:19:07.648
STEP: listing events with field selection filtering on reportingController 04/22/23 20:19:07.659
STEP: getting the test event 04/22/23 20:19:07.669
STEP: patching the test event 04/22/23 20:19:07.676
STEP: getting the test event 04/22/23 20:19:07.715
STEP: updating the test event 04/22/23 20:19:07.722
STEP: getting the test event 04/22/23 20:19:07.743
STEP: deleting the test event 04/22/23 20:19:07.754
STEP: listing events in all namespaces 04/22/23 20:19:07.795
STEP: listing events in test namespace 04/22/23 20:19:07.804
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 22 20:19:07.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-155" for this suite. 04/22/23 20:19:07.823
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":338,"skipped":6174,"failed":0}
------------------------------
â€¢ [0.306 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:07.535
    Apr 22 20:19:07.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename events 04/22/23 20:19:07.538
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:07.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:07.588
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/22/23 20:19:07.601
    STEP: listing events in all namespaces 04/22/23 20:19:07.623
    STEP: listing events in test namespace 04/22/23 20:19:07.638
    STEP: listing events with field selection filtering on source 04/22/23 20:19:07.648
    STEP: listing events with field selection filtering on reportingController 04/22/23 20:19:07.659
    STEP: getting the test event 04/22/23 20:19:07.669
    STEP: patching the test event 04/22/23 20:19:07.676
    STEP: getting the test event 04/22/23 20:19:07.715
    STEP: updating the test event 04/22/23 20:19:07.722
    STEP: getting the test event 04/22/23 20:19:07.743
    STEP: deleting the test event 04/22/23 20:19:07.754
    STEP: listing events in all namespaces 04/22/23 20:19:07.795
    STEP: listing events in test namespace 04/22/23 20:19:07.804
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 22 20:19:07.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-155" for this suite. 04/22/23 20:19:07.823
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:07.88
Apr 22 20:19:07.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename var-expansion 04/22/23 20:19:07.883
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:07.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:07.932
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 04/22/23 20:19:07.939
Apr 22 20:19:07.956: INFO: Waiting up to 5m0s for pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62" in namespace "var-expansion-3228" to be "Succeeded or Failed"
Apr 22 20:19:07.963: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Pending", Reason="", readiness=false. Elapsed: 7.535768ms
Apr 22 20:19:09.974: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017731982s
Apr 22 20:19:11.974: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017742874s
STEP: Saw pod success 04/22/23 20:19:11.974
Apr 22 20:19:11.975: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62" satisfied condition "Succeeded or Failed"
Apr 22 20:19:11.985: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 container dapi-container: <nil>
STEP: delete the pod 04/22/23 20:19:12.004
Apr 22 20:19:12.044: INFO: Waiting for pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 to disappear
Apr 22 20:19:12.052: INFO: Pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 22 20:19:12.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3228" for this suite. 04/22/23 20:19:12.07
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":339,"skipped":6243,"failed":0}
------------------------------
â€¢ [4.211 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:07.88
    Apr 22 20:19:07.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename var-expansion 04/22/23 20:19:07.883
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:07.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:07.932
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 04/22/23 20:19:07.939
    Apr 22 20:19:07.956: INFO: Waiting up to 5m0s for pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62" in namespace "var-expansion-3228" to be "Succeeded or Failed"
    Apr 22 20:19:07.963: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Pending", Reason="", readiness=false. Elapsed: 7.535768ms
    Apr 22 20:19:09.974: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017731982s
    Apr 22 20:19:11.974: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017742874s
    STEP: Saw pod success 04/22/23 20:19:11.974
    Apr 22 20:19:11.975: INFO: Pod "var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62" satisfied condition "Succeeded or Failed"
    Apr 22 20:19:11.985: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 container dapi-container: <nil>
    STEP: delete the pod 04/22/23 20:19:12.004
    Apr 22 20:19:12.044: INFO: Waiting for pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 to disappear
    Apr 22 20:19:12.052: INFO: Pod var-expansion-d12e928b-2531-4ea0-9510-1117395e5b62 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 22 20:19:12.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3228" for this suite. 04/22/23 20:19:12.07
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:12.104
Apr 22 20:19:12.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:19:12.108
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:12.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:12.167
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:19:12.177
Apr 22 20:19:12.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-1039 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Apr 22 20:19:12.295: INFO: stderr: ""
Apr 22 20:19:12.295: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/22/23 20:19:12.295
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Apr 22 20:19:12.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-1039 delete pods e2e-test-httpd-pod'
Apr 22 20:19:14.904: INFO: stderr: ""
Apr 22 20:19:14.904: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:19:14.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1039" for this suite. 04/22/23 20:19:14.917
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":340,"skipped":6245,"failed":0}
------------------------------
â€¢ [2.830 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:12.104
    Apr 22 20:19:12.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:19:12.108
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:12.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:12.167
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/22/23 20:19:12.177
    Apr 22 20:19:12.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-1039 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Apr 22 20:19:12.295: INFO: stderr: ""
    Apr 22 20:19:12.295: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/22/23 20:19:12.295
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Apr 22 20:19:12.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-1039 delete pods e2e-test-httpd-pod'
    Apr 22 20:19:14.904: INFO: stderr: ""
    Apr 22 20:19:14.904: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:19:14.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1039" for this suite. 04/22/23 20:19:14.917
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:14.939
Apr 22 20:19:14.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:19:14.942
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:14.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:15.002
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:19:15.024
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:19:16.147
STEP: Deploying the webhook pod 04/22/23 20:19:16.166
STEP: Wait for the deployment to be ready 04/22/23 20:19:16.195
Apr 22 20:19:16.218: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:19:18.254
STEP: Verifying the service has paired with the endpoint 04/22/23 20:19:18.315
Apr 22 20:19:19.317: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Apr 22 20:19:19.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7949-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 20:19:19.869
Apr 22 20:19:19.912: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 04/22/23 20:19:20.039
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:19:22.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9255" for this suite. 04/22/23 20:19:22.751
STEP: Destroying namespace "webhook-9255-markers" for this suite. 04/22/23 20:19:22.777
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":341,"skipped":6254,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.963 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:14.939
    Apr 22 20:19:14.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:19:14.942
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:14.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:15.002
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:19:15.024
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:19:16.147
    STEP: Deploying the webhook pod 04/22/23 20:19:16.166
    STEP: Wait for the deployment to be ready 04/22/23 20:19:16.195
    Apr 22 20:19:16.218: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:19:18.254
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:19:18.315
    Apr 22 20:19:19.317: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Apr 22 20:19:19.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7949-crds.webhook.example.com via the AdmissionRegistration API 04/22/23 20:19:19.869
    Apr 22 20:19:19.912: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 04/22/23 20:19:20.039
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:19:22.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9255" for this suite. 04/22/23 20:19:22.751
    STEP: Destroying namespace "webhook-9255-markers" for this suite. 04/22/23 20:19:22.777
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:22.943
Apr 22 20:19:22.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubectl 04/22/23 20:19:22.946
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:22.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:22.976
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Apr 22 20:19:22.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 create -f -'
Apr 22 20:19:24.018: INFO: stderr: ""
Apr 22 20:19:24.018: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 22 20:19:24.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 create -f -'
Apr 22 20:19:25.155: INFO: stderr: ""
Apr 22 20:19:25.155: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/22/23 20:19:25.155
Apr 22 20:19:26.165: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:19:26.165: INFO: Found 1 / 1
Apr 22 20:19:26.165: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 22 20:19:26.174: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 22 20:19:26.174: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 22 20:19:26.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe pod agnhost-primary-59r76'
Apr 22 20:19:26.365: INFO: stderr: ""
Apr 22 20:19:26.365: INFO: stdout: "Name:             agnhost-primary-59r76\nNamespace:        kubectl-9811\nPriority:         0\nService Account:  default\nNode:             cncf25-2-node-187aa4c0d96/10.1.1.128\nStart Time:       Sat, 22 Apr 2023 20:19:24 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.36.0.1\nIPs:\n  IP:           10.36.0.1\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://c3b5febe53b0dadc195c375367be810ffca7b6bbb11e68f72f80c9c16a113ee3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 22 Apr 2023 20:19:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nkfms (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-nkfms:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9811/agnhost-primary-59r76 to cncf25-2-node-187aa4c0d96\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Apr 22 20:19:26.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe rc agnhost-primary'
Apr 22 20:19:26.565: INFO: stderr: ""
Apr 22 20:19:26.565: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9811\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-59r76\n"
Apr 22 20:19:26.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe service agnhost-primary'
Apr 22 20:19:26.713: INFO: stderr: ""
Apr 22 20:19:26.713: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9811\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.109.133.31\nIPs:               10.109.133.31\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.36.0.1:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 22 20:19:26.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe node cncf25-2-control-187aa4b8379'
Apr 22 20:19:26.928: INFO: stderr: ""
Apr 22 20:19:26.928: INFO: stdout: "Name:               cncf25-2-control-187aa4b8379\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=cncf25-2-control-187aa4b8379\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        cluster-autoscaler.kubernetes.io/scale-down-disabled: true\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 22 Apr 2023 18:50:07 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  cncf25-2-control-187aa4b8379\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 22 Apr 2023 20:19:26 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 22 Apr 2023 18:50:22 +0000   Sat, 22 Apr 2023 18:50:22 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.1.1.29\n  Hostname:    cncf25-2-control-187aa4b8379\nCapacity:\n  cpu:                2\n  ephemeral-storage:  102551812Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2030224Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  94511749783\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1927824Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 923c987be4c547618829c8741f2ad13c\n  System UUID:                964fd75a-e958-4be7-9a8f-2f1f0b7db65c\n  Boot ID:                    64cc76e4-b3c2-4ac7-afc4-70c10855cffe\n  Kernel Version:             5.10.0-13-amd64\n  OS Image:                   Debian GNU/Linux 11 (bullseye)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.11\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-565d847f94-xwp87                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     89m\n  kube-system                 coredns-565d847f94-z2wlm                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     89m\n  kube-system                 etcd-cncf25-2-control-187aa4b8379                          100m (5%)     0 (0%)      100Mi (5%)       0 (0%)         89m\n  kube-system                 kube-apiserver-cncf25-2-control-187aa4b8379                250m (12%)    0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-controller-manager-cncf25-2-control-187aa4b8379       200m (10%)    0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-proxy-nlvpr                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-scheduler-cncf25-2-control-187aa4b8379                100m (5%)     0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 weave-net-r94nd                                            100m (5%)     0 (0%)      0 (0%)           0 (0%)         89m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-r2256    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                950m (47%)   0 (0%)\n  memory             240Mi (12%)  340Mi (18%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n"
Apr 22 20:19:26.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe namespace kubectl-9811'
Apr 22 20:19:27.104: INFO: stderr: ""
Apr 22 20:19:27.104: INFO: stdout: "Name:         kubectl-9811\nLabels:       e2e-framework=kubectl\n              e2e-run=7305ce57-647e-4d5d-807f-a37572b6ebbc\n              kubernetes.io/metadata.name=kubectl-9811\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 22 20:19:27.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9811" for this suite. 04/22/23 20:19:27.118
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":342,"skipped":6316,"failed":0}
------------------------------
â€¢ [4.200 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:22.943
    Apr 22 20:19:22.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubectl 04/22/23 20:19:22.946
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:22.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:22.976
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Apr 22 20:19:22.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 create -f -'
    Apr 22 20:19:24.018: INFO: stderr: ""
    Apr 22 20:19:24.018: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 22 20:19:24.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 create -f -'
    Apr 22 20:19:25.155: INFO: stderr: ""
    Apr 22 20:19:25.155: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/22/23 20:19:25.155
    Apr 22 20:19:26.165: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:19:26.165: INFO: Found 1 / 1
    Apr 22 20:19:26.165: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 22 20:19:26.174: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 22 20:19:26.174: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 22 20:19:26.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe pod agnhost-primary-59r76'
    Apr 22 20:19:26.365: INFO: stderr: ""
    Apr 22 20:19:26.365: INFO: stdout: "Name:             agnhost-primary-59r76\nNamespace:        kubectl-9811\nPriority:         0\nService Account:  default\nNode:             cncf25-2-node-187aa4c0d96/10.1.1.128\nStart Time:       Sat, 22 Apr 2023 20:19:24 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.36.0.1\nIPs:\n  IP:           10.36.0.1\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://c3b5febe53b0dadc195c375367be810ffca7b6bbb11e68f72f80c9c16a113ee3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 22 Apr 2023 20:19:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nkfms (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-nkfms:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9811/agnhost-primary-59r76 to cncf25-2-node-187aa4c0d96\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    Apr 22 20:19:26.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe rc agnhost-primary'
    Apr 22 20:19:26.565: INFO: stderr: ""
    Apr 22 20:19:26.565: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9811\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-59r76\n"
    Apr 22 20:19:26.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe service agnhost-primary'
    Apr 22 20:19:26.713: INFO: stderr: ""
    Apr 22 20:19:26.713: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9811\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.109.133.31\nIPs:               10.109.133.31\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.36.0.1:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 22 20:19:26.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe node cncf25-2-control-187aa4b8379'
    Apr 22 20:19:26.928: INFO: stderr: ""
    Apr 22 20:19:26.928: INFO: stdout: "Name:               cncf25-2-control-187aa4b8379\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=cncf25-2-control-187aa4b8379\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        cluster-autoscaler.kubernetes.io/scale-down-disabled: true\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 22 Apr 2023 18:50:07 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  cncf25-2-control-187aa4b8379\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 22 Apr 2023 20:19:26 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 22 Apr 2023 18:50:22 +0000   Sat, 22 Apr 2023 18:50:22 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 22 Apr 2023 20:15:00 +0000   Sat, 22 Apr 2023 18:50:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.1.1.29\n  Hostname:    cncf25-2-control-187aa4b8379\nCapacity:\n  cpu:                2\n  ephemeral-storage:  102551812Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2030224Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  94511749783\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1927824Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 923c987be4c547618829c8741f2ad13c\n  System UUID:                964fd75a-e958-4be7-9a8f-2f1f0b7db65c\n  Boot ID:                    64cc76e4-b3c2-4ac7-afc4-70c10855cffe\n  Kernel Version:             5.10.0-13-amd64\n  OS Image:                   Debian GNU/Linux 11 (bullseye)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.11\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-565d847f94-xwp87                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     89m\n  kube-system                 coredns-565d847f94-z2wlm                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     89m\n  kube-system                 etcd-cncf25-2-control-187aa4b8379                          100m (5%)     0 (0%)      100Mi (5%)       0 (0%)         89m\n  kube-system                 kube-apiserver-cncf25-2-control-187aa4b8379                250m (12%)    0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-controller-manager-cncf25-2-control-187aa4b8379       200m (10%)    0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-proxy-nlvpr                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 kube-scheduler-cncf25-2-control-187aa4b8379                100m (5%)     0 (0%)      0 (0%)           0 (0%)         89m\n  kube-system                 weave-net-r94nd                                            100m (5%)     0 (0%)      0 (0%)           0 (0%)         89m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-de8ee56d738b4b70-r2256    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                950m (47%)   0 (0%)\n  memory             240Mi (12%)  340Mi (18%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n"
    Apr 22 20:19:26.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=kubectl-9811 describe namespace kubectl-9811'
    Apr 22 20:19:27.104: INFO: stderr: ""
    Apr 22 20:19:27.104: INFO: stdout: "Name:         kubectl-9811\nLabels:       e2e-framework=kubectl\n              e2e-run=7305ce57-647e-4d5d-807f-a37572b6ebbc\n              kubernetes.io/metadata.name=kubectl-9811\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 22 20:19:27.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9811" for this suite. 04/22/23 20:19:27.118
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:27.158
Apr 22 20:19:27.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:19:27.162
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:27.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:27.221
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-202 04/22/23 20:19:27.228
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[] 04/22/23 20:19:27.277
Apr 22 20:19:27.297: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Apr 22 20:19:28.312: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-202 04/22/23 20:19:28.313
Apr 22 20:19:28.326: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-202" to be "running and ready"
Apr 22 20:19:28.332: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.280581ms
Apr 22 20:19:28.332: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:19:30.342: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014962174s
Apr 22 20:19:30.342: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 22 20:19:30.342: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod1:[80]] 04/22/23 20:19:30.35
Apr 22 20:19:30.391: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/22/23 20:19:30.391
Apr 22 20:19:30.391: INFO: Creating new exec pod
Apr 22 20:19:30.406: INFO: Waiting up to 5m0s for pod "execpod9bm9f" in namespace "services-202" to be "running"
Apr 22 20:19:30.421: INFO: Pod "execpod9bm9f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.268654ms
Apr 22 20:19:32.427: INFO: Pod "execpod9bm9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.021127871s
Apr 22 20:19:32.428: INFO: Pod "execpod9bm9f" satisfied condition "running"
Apr 22 20:19:33.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 22 20:19:33.783: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 22 20:19:33.783: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:19:33.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
Apr 22 20:19:34.087: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Apr 22 20:19:34.087: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-202 04/22/23 20:19:34.087
Apr 22 20:19:34.108: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-202" to be "running and ready"
Apr 22 20:19:34.119: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.509644ms
Apr 22 20:19:34.119: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:19:36.130: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.021548145s
Apr 22 20:19:36.130: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 22 20:19:36.131: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod1:[80] pod2:[80]] 04/22/23 20:19:36.139
Apr 22 20:19:36.177: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/22/23 20:19:36.177
Apr 22 20:19:37.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 22 20:19:37.520: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 22 20:19:37.520: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:19:37.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
Apr 22 20:19:37.830: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Apr 22 20:19:37.830: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-202 04/22/23 20:19:37.83
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod2:[80]] 04/22/23 20:19:37.852
Apr 22 20:19:37.886: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/22/23 20:19:37.886
Apr 22 20:19:38.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 22 20:19:39.212: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 22 20:19:39.212: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 22 20:19:39.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
Apr 22 20:19:39.492: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\n+ echo hostName\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n"
Apr 22 20:19:39.492: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-202 04/22/23 20:19:39.492
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[] 04/22/23 20:19:39.55
Apr 22 20:19:39.572: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:19:39.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-202" for this suite. 04/22/23 20:19:39.623
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":343,"skipped":6352,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.477 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:27.158
    Apr 22 20:19:27.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:19:27.162
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:27.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:27.221
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-202 04/22/23 20:19:27.228
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[] 04/22/23 20:19:27.277
    Apr 22 20:19:27.297: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Apr 22 20:19:28.312: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-202 04/22/23 20:19:28.313
    Apr 22 20:19:28.326: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-202" to be "running and ready"
    Apr 22 20:19:28.332: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.280581ms
    Apr 22 20:19:28.332: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:19:30.342: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014962174s
    Apr 22 20:19:30.342: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 22 20:19:30.342: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod1:[80]] 04/22/23 20:19:30.35
    Apr 22 20:19:30.391: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/22/23 20:19:30.391
    Apr 22 20:19:30.391: INFO: Creating new exec pod
    Apr 22 20:19:30.406: INFO: Waiting up to 5m0s for pod "execpod9bm9f" in namespace "services-202" to be "running"
    Apr 22 20:19:30.421: INFO: Pod "execpod9bm9f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.268654ms
    Apr 22 20:19:32.427: INFO: Pod "execpod9bm9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.021127871s
    Apr 22 20:19:32.428: INFO: Pod "execpod9bm9f" satisfied condition "running"
    Apr 22 20:19:33.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 22 20:19:33.783: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 22 20:19:33.783: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:19:33.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
    Apr 22 20:19:34.087: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Apr 22 20:19:34.087: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-202 04/22/23 20:19:34.087
    Apr 22 20:19:34.108: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-202" to be "running and ready"
    Apr 22 20:19:34.119: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.509644ms
    Apr 22 20:19:34.119: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:19:36.130: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.021548145s
    Apr 22 20:19:36.130: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 22 20:19:36.131: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod1:[80] pod2:[80]] 04/22/23 20:19:36.139
    Apr 22 20:19:36.177: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/22/23 20:19:36.177
    Apr 22 20:19:37.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 22 20:19:37.520: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 22 20:19:37.520: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:19:37.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
    Apr 22 20:19:37.830: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Apr 22 20:19:37.830: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-202 04/22/23 20:19:37.83
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[pod2:[80]] 04/22/23 20:19:37.852
    Apr 22 20:19:37.886: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/22/23 20:19:37.886
    Apr 22 20:19:38.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 22 20:19:39.212: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 22 20:19:39.212: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 22 20:19:39.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2498517891 --namespace=services-202 exec execpod9bm9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.194.12 80'
    Apr 22 20:19:39.492: INFO: stderr: "+ nc -v -t -w 2 10.100.194.12 80\n+ echo hostName\nConnection to 10.100.194.12 80 port [tcp/http] succeeded!\n"
    Apr 22 20:19:39.492: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-202 04/22/23 20:19:39.492
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-202 to expose endpoints map[] 04/22/23 20:19:39.55
    Apr 22 20:19:39.572: INFO: successfully validated that service endpoint-test2 in namespace services-202 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:19:39.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-202" for this suite. 04/22/23 20:19:39.623
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:19:39.639
Apr 22 20:19:39.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 20:19:39.647
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:39.677
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:39.682
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 in namespace container-probe-5362 04/22/23 20:19:39.685
Apr 22 20:19:39.701: INFO: Waiting up to 5m0s for pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6" in namespace "container-probe-5362" to be "not pending"
Apr 22 20:19:39.704: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.161998ms
Apr 22 20:19:41.714: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.013605472s
Apr 22 20:19:41.715: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6" satisfied condition "not pending"
Apr 22 20:19:41.715: INFO: Started pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 in namespace container-probe-5362
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 20:19:41.715
Apr 22 20:19:41.724: INFO: Initial restart count of pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 is 0
STEP: deleting the pod 04/22/23 20:23:43.072
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 20:23:43.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5362" for this suite. 04/22/23 20:23:43.139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":344,"skipped":6374,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.518 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:19:39.639
    Apr 22 20:19:39.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 20:19:39.647
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:19:39.677
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:19:39.682
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 in namespace container-probe-5362 04/22/23 20:19:39.685
    Apr 22 20:19:39.701: INFO: Waiting up to 5m0s for pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6" in namespace "container-probe-5362" to be "not pending"
    Apr 22 20:19:39.704: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.161998ms
    Apr 22 20:19:41.714: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.013605472s
    Apr 22 20:19:41.715: INFO: Pod "test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6" satisfied condition "not pending"
    Apr 22 20:19:41.715: INFO: Started pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 in namespace container-probe-5362
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 20:19:41.715
    Apr 22 20:19:41.724: INFO: Initial restart count of pod test-webserver-f9f314b9-bdd9-42c3-8831-6949686a34b6 is 0
    STEP: deleting the pod 04/22/23 20:23:43.072
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 20:23:43.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5362" for this suite. 04/22/23 20:23:43.139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:23:43.194
Apr 22 20:23:43.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename svcaccounts 04/22/23 20:23:43.198
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:43.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:43.271
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  04/22/23 20:23:43.277
Apr 22 20:23:43.300: INFO: Waiting up to 5m0s for pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22" in namespace "svcaccounts-2786" to be "Succeeded or Failed"
Apr 22 20:23:43.310: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Pending", Reason="", readiness=false. Elapsed: 10.323049ms
Apr 22 20:23:45.321: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021090759s
Apr 22 20:23:47.325: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024954947s
STEP: Saw pod success 04/22/23 20:23:47.325
Apr 22 20:23:47.326: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22" satisfied condition "Succeeded or Failed"
Apr 22 20:23:47.334: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:23:47.374
Apr 22 20:23:47.414: INFO: Waiting for pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 to disappear
Apr 22 20:23:47.422: INFO: Pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 22 20:23:47.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2786" for this suite. 04/22/23 20:23:47.437
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":345,"skipped":6392,"failed":0}
------------------------------
â€¢ [4.258 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:23:43.194
    Apr 22 20:23:43.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename svcaccounts 04/22/23 20:23:43.198
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:43.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:43.271
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  04/22/23 20:23:43.277
    Apr 22 20:23:43.300: INFO: Waiting up to 5m0s for pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22" in namespace "svcaccounts-2786" to be "Succeeded or Failed"
    Apr 22 20:23:43.310: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Pending", Reason="", readiness=false. Elapsed: 10.323049ms
    Apr 22 20:23:45.321: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021090759s
    Apr 22 20:23:47.325: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024954947s
    STEP: Saw pod success 04/22/23 20:23:47.325
    Apr 22 20:23:47.326: INFO: Pod "test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22" satisfied condition "Succeeded or Failed"
    Apr 22 20:23:47.334: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:23:47.374
    Apr 22 20:23:47.414: INFO: Waiting for pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 to disappear
    Apr 22 20:23:47.422: INFO: Pod test-pod-145b984f-00f7-4f4c-a1a8-ff81b0d06a22 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 22 20:23:47.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2786" for this suite. 04/22/23 20:23:47.437
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:23:47.455
Apr 22 20:23:47.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:23:47.46
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:47.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:47.515
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 22 20:23:51.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4212" for this suite. 04/22/23 20:23:51.576
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":346,"skipped":6399,"failed":0}
------------------------------
â€¢ [4.145 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:23:47.455
    Apr 22 20:23:47.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename kubelet-test 04/22/23 20:23:47.46
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:47.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:47.515
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 22 20:23:51.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4212" for this suite. 04/22/23 20:23:51.576
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:23:51.651
Apr 22 20:23:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename init-container 04/22/23 20:23:51.655
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:51.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:51.722
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 04/22/23 20:23:51.737
Apr 22 20:23:51.738: INFO: PodSpec: initContainers in spec.initContainers
Apr 22 20:24:37.908: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0bd4e18d-a00f-4f81-8c22-f5ce7eba644a", GenerateName:"", Namespace:"init-container-2781", SelfLink:"", UID:"e6e7ae54-1e02-444c-9bf3-4b53098fcd1b", ResourceVersion:"36705", Generation:0, CreationTimestamp:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"737974485"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039b0cd8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 22, 20, 24, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039b0d08), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-2whr5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003e5f120), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004025210), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cncf25-2-node-187aa4c0d96", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003bad030), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004025290)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0040252b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0040252b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0040252bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003de3140), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.1.128", PodIP:"10.36.0.1", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.36.0.1"}}, StartTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003bad110)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003bad180)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://8b2bfd1e1c72770d4c4add613a87260048c3f18857d16763487b88cd5ea22b13", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e5f1a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e5f180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00402535f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 22 20:24:37.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2781" for this suite. 04/22/23 20:24:37.929
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":347,"skipped":6437,"failed":0}
------------------------------
â€¢ [SLOW TEST] [46.299 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:23:51.651
    Apr 22 20:23:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename init-container 04/22/23 20:23:51.655
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:23:51.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:23:51.722
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 04/22/23 20:23:51.737
    Apr 22 20:23:51.738: INFO: PodSpec: initContainers in spec.initContainers
    Apr 22 20:24:37.908: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0bd4e18d-a00f-4f81-8c22-f5ce7eba644a", GenerateName:"", Namespace:"init-container-2781", SelfLink:"", UID:"e6e7ae54-1e02-444c-9bf3-4b53098fcd1b", ResourceVersion:"36705", Generation:0, CreationTimestamp:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"737974485"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039b0cd8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 22, 20, 24, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039b0d08), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-2whr5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003e5f120), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2whr5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004025210), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cncf25-2-node-187aa4c0d96", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003bad030), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004025290)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0040252b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0040252b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0040252bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003de3140), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.1.128", PodIP:"10.36.0.1", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.36.0.1"}}, StartTime:time.Date(2023, time.April, 22, 20, 23, 51, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003bad110)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003bad180)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://8b2bfd1e1c72770d4c4add613a87260048c3f18857d16763487b88cd5ea22b13", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e5f1a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e5f180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00402535f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 22 20:24:37.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2781" for this suite. 04/22/23 20:24:37.929
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:37.977
Apr 22 20:24:37.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename secrets 04/22/23 20:24:37.982
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:38.044
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:38.054
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 22 20:24:38.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3721" for this suite. 04/22/23 20:24:38.157
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":348,"skipped":6453,"failed":0}
------------------------------
â€¢ [0.197 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:37.977
    Apr 22 20:24:37.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename secrets 04/22/23 20:24:37.982
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:38.044
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:38.054
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 22 20:24:38.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3721" for this suite. 04/22/23 20:24:38.157
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:38.204
Apr 22 20:24:38.205: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename gc 04/22/23 20:24:38.208
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:38.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:38.278
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/22/23 20:24:38.288
STEP: Wait for the Deployment to create new ReplicaSet 04/22/23 20:24:38.304
STEP: delete the deployment 04/22/23 20:24:38.832
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/22/23 20:24:38.85
STEP: Gathering metrics 04/22/23 20:24:39.4
Apr 22 20:24:39.461: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
Apr 22 20:24:39.469: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 7.55892ms
Apr 22 20:24:39.469: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
Apr 22 20:24:39.469: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
Apr 22 20:24:39.635: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 22 20:24:39.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1716" for this suite. 04/22/23 20:24:39.646
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":349,"skipped":6482,"failed":0}
------------------------------
â€¢ [1.454 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:38.204
    Apr 22 20:24:38.205: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename gc 04/22/23 20:24:38.208
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:38.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:38.278
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/22/23 20:24:38.288
    STEP: Wait for the Deployment to create new ReplicaSet 04/22/23 20:24:38.304
    STEP: delete the deployment 04/22/23 20:24:38.832
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/22/23 20:24:38.85
    STEP: Gathering metrics 04/22/23 20:24:39.4
    Apr 22 20:24:39.461: INFO: Waiting up to 5m0s for pod "kube-controller-manager-cncf25-2-control-187aa4bae97" in namespace "kube-system" to be "running and ready"
    Apr 22 20:24:39.469: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97": Phase="Running", Reason="", readiness=true. Elapsed: 7.55892ms
    Apr 22 20:24:39.469: INFO: The phase of Pod kube-controller-manager-cncf25-2-control-187aa4bae97 is Running (Ready = true)
    Apr 22 20:24:39.469: INFO: Pod "kube-controller-manager-cncf25-2-control-187aa4bae97" satisfied condition "running and ready"
    Apr 22 20:24:39.635: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 22 20:24:39.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1716" for this suite. 04/22/23 20:24:39.646
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:39.69
Apr 22 20:24:39.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename conformance-tests 04/22/23 20:24:39.692
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:39.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:39.744
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/22/23 20:24:39.75
Apr 22 20:24:39.755: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Apr 22 20:24:39.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-2314" for this suite. 04/22/23 20:24:39.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":350,"skipped":6500,"failed":0}
------------------------------
â€¢ [0.118 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:39.69
    Apr 22 20:24:39.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename conformance-tests 04/22/23 20:24:39.692
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:39.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:39.744
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/22/23 20:24:39.75
    Apr 22 20:24:39.755: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Apr 22 20:24:39.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-2314" for this suite. 04/22/23 20:24:39.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:39.841
Apr 22 20:24:39.841: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:24:39.843
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:39.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:39.892
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:24:39.926
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:24:40.496
STEP: Deploying the webhook pod 04/22/23 20:24:40.519
STEP: Wait for the deployment to be ready 04/22/23 20:24:40.559
Apr 22 20:24:40.592: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:24:42.628
STEP: Verifying the service has paired with the endpoint 04/22/23 20:24:42.682
Apr 22 20:24:43.683: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/22/23 20:24:43.692
STEP: create a namespace for the webhook 04/22/23 20:24:43.735
STEP: create a configmap should be unconditionally rejected by the webhook 04/22/23 20:24:43.753
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:24:43.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8892" for this suite. 04/22/23 20:24:43.824
STEP: Destroying namespace "webhook-8892-markers" for this suite. 04/22/23 20:24:43.84
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":351,"skipped":6521,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:39.841
    Apr 22 20:24:39.841: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:24:39.843
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:39.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:39.892
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:24:39.926
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:24:40.496
    STEP: Deploying the webhook pod 04/22/23 20:24:40.519
    STEP: Wait for the deployment to be ready 04/22/23 20:24:40.559
    Apr 22 20:24:40.592: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:24:42.628
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:24:42.682
    Apr 22 20:24:43.683: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/22/23 20:24:43.692
    STEP: create a namespace for the webhook 04/22/23 20:24:43.735
    STEP: create a configmap should be unconditionally rejected by the webhook 04/22/23 20:24:43.753
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:24:43.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8892" for this suite. 04/22/23 20:24:43.824
    STEP: Destroying namespace "webhook-8892-markers" for this suite. 04/22/23 20:24:43.84
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:43.967
Apr 22 20:24:43.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename containers 04/22/23 20:24:43.969
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:44.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:44.014
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 04/22/23 20:24:44.026
Apr 22 20:24:44.046: INFO: Waiting up to 5m0s for pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e" in namespace "containers-231" to be "Succeeded or Failed"
Apr 22 20:24:44.052: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060934ms
Apr 22 20:24:46.063: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017061392s
Apr 22 20:24:48.065: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019216092s
STEP: Saw pod success 04/22/23 20:24:48.065
Apr 22 20:24:48.066: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e" satisfied condition "Succeeded or Failed"
Apr 22 20:24:48.075: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:24:48.093
Apr 22 20:24:48.127: INFO: Waiting for pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e to disappear
Apr 22 20:24:48.137: INFO: Pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 22 20:24:48.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-231" for this suite. 04/22/23 20:24:48.15
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":352,"skipped":6525,"failed":0}
------------------------------
â€¢ [4.205 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:43.967
    Apr 22 20:24:43.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename containers 04/22/23 20:24:43.969
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:44.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:44.014
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 04/22/23 20:24:44.026
    Apr 22 20:24:44.046: INFO: Waiting up to 5m0s for pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e" in namespace "containers-231" to be "Succeeded or Failed"
    Apr 22 20:24:44.052: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060934ms
    Apr 22 20:24:46.063: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017061392s
    Apr 22 20:24:48.065: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019216092s
    STEP: Saw pod success 04/22/23 20:24:48.065
    Apr 22 20:24:48.066: INFO: Pod "client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e" satisfied condition "Succeeded or Failed"
    Apr 22 20:24:48.075: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:24:48.093
    Apr 22 20:24:48.127: INFO: Waiting for pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e to disappear
    Apr 22 20:24:48.137: INFO: Pod client-containers-aa47f104-3a35-47f5-a463-6e51b7bcc55e no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 22 20:24:48.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-231" for this suite. 04/22/23 20:24:48.15
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:48.194
Apr 22 20:24:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename replicaset 04/22/23 20:24:48.197
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:48.251
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:48.261
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/22/23 20:24:48.271
Apr 22 20:24:48.295: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2552" to be "running and ready"
Apr 22 20:24:48.305: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.753758ms
Apr 22 20:24:48.305: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:24:50.315: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.018640852s
Apr 22 20:24:50.315: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 22 20:24:50.316: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/22/23 20:24:50.326
STEP: Then the orphan pod is adopted 04/22/23 20:24:50.349
STEP: When the matched label of one of its pods change 04/22/23 20:24:50.383
Apr 22 20:24:50.390: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/22/23 20:24:50.416
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 22 20:24:51.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2552" for this suite. 04/22/23 20:24:51.463
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":353,"skipped":6534,"failed":0}
------------------------------
â€¢ [3.290 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:48.194
    Apr 22 20:24:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename replicaset 04/22/23 20:24:48.197
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:48.251
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:48.261
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/22/23 20:24:48.271
    Apr 22 20:24:48.295: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2552" to be "running and ready"
    Apr 22 20:24:48.305: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.753758ms
    Apr 22 20:24:48.305: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:24:50.315: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.018640852s
    Apr 22 20:24:50.315: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 22 20:24:50.316: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/22/23 20:24:50.326
    STEP: Then the orphan pod is adopted 04/22/23 20:24:50.349
    STEP: When the matched label of one of its pods change 04/22/23 20:24:50.383
    Apr 22 20:24:50.390: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/22/23 20:24:50.416
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 22 20:24:51.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2552" for this suite. 04/22/23 20:24:51.463
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:51.495
Apr 22 20:24:51.496: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename configmap 04/22/23 20:24:51.498
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:51.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:51.567
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-2f7902e6-3f66-4c4e-a326-602b784def33 04/22/23 20:24:51.578
STEP: Creating a pod to test consume configMaps 04/22/23 20:24:51.588
Apr 22 20:24:51.605: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac" in namespace "configmap-9825" to be "Succeeded or Failed"
Apr 22 20:24:51.615: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.888429ms
Apr 22 20:24:53.624: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017676664s
Apr 22 20:24:55.629: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023399236s
STEP: Saw pod success 04/22/23 20:24:55.629
Apr 22 20:24:55.631: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac" satisfied condition "Succeeded or Failed"
Apr 22 20:24:55.641: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac container agnhost-container: <nil>
STEP: delete the pod 04/22/23 20:24:55.659
Apr 22 20:24:55.693: INFO: Waiting for pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac to disappear
Apr 22 20:24:55.705: INFO: Pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 22 20:24:55.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9825" for this suite. 04/22/23 20:24:55.72
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":354,"skipped":6549,"failed":0}
------------------------------
â€¢ [4.242 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:51.495
    Apr 22 20:24:51.496: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename configmap 04/22/23 20:24:51.498
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:51.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:51.567
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-2f7902e6-3f66-4c4e-a326-602b784def33 04/22/23 20:24:51.578
    STEP: Creating a pod to test consume configMaps 04/22/23 20:24:51.588
    Apr 22 20:24:51.605: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac" in namespace "configmap-9825" to be "Succeeded or Failed"
    Apr 22 20:24:51.615: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.888429ms
    Apr 22 20:24:53.624: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017676664s
    Apr 22 20:24:55.629: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023399236s
    STEP: Saw pod success 04/22/23 20:24:55.629
    Apr 22 20:24:55.631: INFO: Pod "pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac" satisfied condition "Succeeded or Failed"
    Apr 22 20:24:55.641: INFO: Trying to get logs from node cncf25-2-node-187aa4c0d96 pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac container agnhost-container: <nil>
    STEP: delete the pod 04/22/23 20:24:55.659
    Apr 22 20:24:55.693: INFO: Waiting for pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac to disappear
    Apr 22 20:24:55.705: INFO: Pod pod-configmaps-4a879579-7bcc-41ae-8cb3-55cdefcb1bac no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 22 20:24:55.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9825" for this suite. 04/22/23 20:24:55.72
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:24:55.758
Apr 22 20:24:55.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename statefulset 04/22/23 20:24:55.76
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:55.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:55.835
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1117 04/22/23 20:24:55.845
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1117 04/22/23 20:24:55.86
Apr 22 20:24:55.892: INFO: Found 0 stateful pods, waiting for 1
Apr 22 20:25:05.902: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/22/23 20:25:05.928
STEP: updating a scale subresource 04/22/23 20:25:05.938
STEP: verifying the statefulset Spec.Replicas was modified 04/22/23 20:25:05.957
STEP: Patch a scale subresource 04/22/23 20:25:05.968
STEP: verifying the statefulset Spec.Replicas was modified 04/22/23 20:25:05.991
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 22 20:25:06.005: INFO: Deleting all statefulset in ns statefulset-1117
Apr 22 20:25:06.014: INFO: Scaling statefulset ss to 0
Apr 22 20:25:16.091: INFO: Waiting for statefulset status.replicas updated to 0
Apr 22 20:25:16.101: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 22 20:25:16.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1117" for this suite. 04/22/23 20:25:16.179
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":355,"skipped":6582,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.440 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:24:55.758
    Apr 22 20:24:55.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename statefulset 04/22/23 20:24:55.76
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:24:55.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:24:55.835
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1117 04/22/23 20:24:55.845
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1117 04/22/23 20:24:55.86
    Apr 22 20:24:55.892: INFO: Found 0 stateful pods, waiting for 1
    Apr 22 20:25:05.902: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/22/23 20:25:05.928
    STEP: updating a scale subresource 04/22/23 20:25:05.938
    STEP: verifying the statefulset Spec.Replicas was modified 04/22/23 20:25:05.957
    STEP: Patch a scale subresource 04/22/23 20:25:05.968
    STEP: verifying the statefulset Spec.Replicas was modified 04/22/23 20:25:05.991
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 22 20:25:06.005: INFO: Deleting all statefulset in ns statefulset-1117
    Apr 22 20:25:06.014: INFO: Scaling statefulset ss to 0
    Apr 22 20:25:16.091: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 22 20:25:16.101: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 22 20:25:16.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1117" for this suite. 04/22/23 20:25:16.179
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:25:16.21
Apr 22 20:25:16.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename container-probe 04/22/23 20:25:16.213
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:25:16.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:25:16.271
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-7917f089-039f-4705-8a48-c22da191f202 in namespace container-probe-9358 04/22/23 20:25:16.28
Apr 22 20:25:16.300: INFO: Waiting up to 5m0s for pod "busybox-7917f089-039f-4705-8a48-c22da191f202" in namespace "container-probe-9358" to be "not pending"
Apr 22 20:25:16.310: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.370994ms
Apr 22 20:25:18.320: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202": Phase="Running", Reason="", readiness=true. Elapsed: 2.019933867s
Apr 22 20:25:18.320: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202" satisfied condition "not pending"
Apr 22 20:25:18.320: INFO: Started pod busybox-7917f089-039f-4705-8a48-c22da191f202 in namespace container-probe-9358
STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 20:25:18.32
Apr 22 20:25:18.331: INFO: Initial restart count of pod busybox-7917f089-039f-4705-8a48-c22da191f202 is 0
Apr 22 20:26:08.626: INFO: Restart count of pod container-probe-9358/busybox-7917f089-039f-4705-8a48-c22da191f202 is now 1 (50.294592759s elapsed)
STEP: deleting the pod 04/22/23 20:26:08.626
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 22 20:26:08.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9358" for this suite. 04/22/23 20:26:08.676
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":356,"skipped":6590,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.486 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:25:16.21
    Apr 22 20:25:16.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename container-probe 04/22/23 20:25:16.213
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:25:16.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:25:16.271
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-7917f089-039f-4705-8a48-c22da191f202 in namespace container-probe-9358 04/22/23 20:25:16.28
    Apr 22 20:25:16.300: INFO: Waiting up to 5m0s for pod "busybox-7917f089-039f-4705-8a48-c22da191f202" in namespace "container-probe-9358" to be "not pending"
    Apr 22 20:25:16.310: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.370994ms
    Apr 22 20:25:18.320: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202": Phase="Running", Reason="", readiness=true. Elapsed: 2.019933867s
    Apr 22 20:25:18.320: INFO: Pod "busybox-7917f089-039f-4705-8a48-c22da191f202" satisfied condition "not pending"
    Apr 22 20:25:18.320: INFO: Started pod busybox-7917f089-039f-4705-8a48-c22da191f202 in namespace container-probe-9358
    STEP: checking the pod's current state and verifying that restartCount is present 04/22/23 20:25:18.32
    Apr 22 20:25:18.331: INFO: Initial restart count of pod busybox-7917f089-039f-4705-8a48-c22da191f202 is 0
    Apr 22 20:26:08.626: INFO: Restart count of pod container-probe-9358/busybox-7917f089-039f-4705-8a48-c22da191f202 is now 1 (50.294592759s elapsed)
    STEP: deleting the pod 04/22/23 20:26:08.626
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 22 20:26:08.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9358" for this suite. 04/22/23 20:26:08.676
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:08.709
Apr 22 20:26:08.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename services 04/22/23 20:26:08.712
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:08.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:08.756
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 04/22/23 20:26:08.77
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 22 20:26:08.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1" for this suite. 04/22/23 20:26:08.799
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":357,"skipped":6592,"failed":0}
------------------------------
â€¢ [0.112 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:08.709
    Apr 22 20:26:08.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename services 04/22/23 20:26:08.712
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:08.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:08.756
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 04/22/23 20:26:08.77
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 22 20:26:08.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1" for this suite. 04/22/23 20:26:08.799
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:08.822
Apr 22 20:26:08.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename events 04/22/23 20:26:08.825
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:08.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:08.889
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/22/23 20:26:08.904
STEP: get a list of Events with a label in the current namespace 04/22/23 20:26:08.948
STEP: delete a list of events 04/22/23 20:26:08.957
Apr 22 20:26:08.957: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/22/23 20:26:09.01
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 22 20:26:09.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8431" for this suite. 04/22/23 20:26:09.035
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":358,"skipped":6594,"failed":0}
------------------------------
â€¢ [0.230 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:08.822
    Apr 22 20:26:08.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename events 04/22/23 20:26:08.825
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:08.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:08.889
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/22/23 20:26:08.904
    STEP: get a list of Events with a label in the current namespace 04/22/23 20:26:08.948
    STEP: delete a list of events 04/22/23 20:26:08.957
    Apr 22 20:26:08.957: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/22/23 20:26:09.01
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 22 20:26:09.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8431" for this suite. 04/22/23 20:26:09.035
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:09.076
Apr 22 20:26:09.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename webhook 04/22/23 20:26:09.078
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:09.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:09.129
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/22/23 20:26:09.167
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:26:09.686
STEP: Deploying the webhook pod 04/22/23 20:26:09.706
STEP: Wait for the deployment to be ready 04/22/23 20:26:09.743
Apr 22 20:26:09.764: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/22/23 20:26:11.792
STEP: Verifying the service has paired with the endpoint 04/22/23 20:26:11.845
Apr 22 20:26:12.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/22/23 20:26:12.856
STEP: create a configmap that should be updated by the webhook 04/22/23 20:26:12.905
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:26:12.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9069" for this suite. 04/22/23 20:26:12.988
STEP: Destroying namespace "webhook-9069-markers" for this suite. 04/22/23 20:26:13.007
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":359,"skipped":6611,"failed":0}
------------------------------
â€¢ [4.064 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:09.076
    Apr 22 20:26:09.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename webhook 04/22/23 20:26:09.078
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:09.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:09.129
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/22/23 20:26:09.167
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/22/23 20:26:09.686
    STEP: Deploying the webhook pod 04/22/23 20:26:09.706
    STEP: Wait for the deployment to be ready 04/22/23 20:26:09.743
    Apr 22 20:26:09.764: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/22/23 20:26:11.792
    STEP: Verifying the service has paired with the endpoint 04/22/23 20:26:11.845
    Apr 22 20:26:12.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/22/23 20:26:12.856
    STEP: create a configmap that should be updated by the webhook 04/22/23 20:26:12.905
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:26:12.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9069" for this suite. 04/22/23 20:26:12.988
    STEP: Destroying namespace "webhook-9069-markers" for this suite. 04/22/23 20:26:13.007
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:13.144
Apr 22 20:26:13.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename podtemplate 04/22/23 20:26:13.148
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:13.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:13.182
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/22/23 20:26:13.187
Apr 22 20:26:13.195: INFO: created test-podtemplate-1
Apr 22 20:26:13.201: INFO: created test-podtemplate-2
Apr 22 20:26:13.208: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/22/23 20:26:13.208
STEP: delete collection of pod templates 04/22/23 20:26:13.219
Apr 22 20:26:13.219: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/22/23 20:26:13.247
Apr 22 20:26:13.252: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 22 20:26:13.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9865" for this suite. 04/22/23 20:26:13.272
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":360,"skipped":6616,"failed":0}
------------------------------
â€¢ [0.139 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:13.144
    Apr 22 20:26:13.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename podtemplate 04/22/23 20:26:13.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:13.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:13.182
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/22/23 20:26:13.187
    Apr 22 20:26:13.195: INFO: created test-podtemplate-1
    Apr 22 20:26:13.201: INFO: created test-podtemplate-2
    Apr 22 20:26:13.208: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/22/23 20:26:13.208
    STEP: delete collection of pod templates 04/22/23 20:26:13.219
    Apr 22 20:26:13.219: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/22/23 20:26:13.247
    Apr 22 20:26:13.252: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 22 20:26:13.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9865" for this suite. 04/22/23 20:26:13.272
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:13.29
Apr 22 20:26:13.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename projected 04/22/23 20:26:13.293
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:13.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:13.333
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 04/22/23 20:26:13.341
Apr 22 20:26:13.355: INFO: Waiting up to 5m0s for pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1" in namespace "projected-5112" to be "running and ready"
Apr 22 20:26:13.365: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.073916ms
Apr 22 20:26:13.366: INFO: The phase of Pod labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1 is Pending, waiting for it to be Running (with Ready = true)
Apr 22 20:26:15.382: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1": Phase="Running", Reason="", readiness=true. Elapsed: 2.026842985s
Apr 22 20:26:15.382: INFO: The phase of Pod labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1 is Running (Ready = true)
Apr 22 20:26:15.382: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1" satisfied condition "running and ready"
Apr 22 20:26:15.940: INFO: Successfully updated pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 22 20:26:20.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5112" for this suite. 04/22/23 20:26:20.013
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":361,"skipped":6623,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.742 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:13.29
    Apr 22 20:26:13.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename projected 04/22/23 20:26:13.293
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:13.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:13.333
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 04/22/23 20:26:13.341
    Apr 22 20:26:13.355: INFO: Waiting up to 5m0s for pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1" in namespace "projected-5112" to be "running and ready"
    Apr 22 20:26:13.365: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.073916ms
    Apr 22 20:26:13.366: INFO: The phase of Pod labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 22 20:26:15.382: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1": Phase="Running", Reason="", readiness=true. Elapsed: 2.026842985s
    Apr 22 20:26:15.382: INFO: The phase of Pod labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1 is Running (Ready = true)
    Apr 22 20:26:15.382: INFO: Pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1" satisfied condition "running and ready"
    Apr 22 20:26:15.940: INFO: Successfully updated pod "labelsupdate439feebe-a17a-40f5-b454-8c23a07ebfc1"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 22 20:26:20.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5112" for this suite. 04/22/23 20:26:20.013
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/22/23 20:26:20.089
Apr 22 20:26:20.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:26:20.091
STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:20.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:20.162
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/22/23 20:26:20.169
Apr 22 20:26:20.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
Apr 22 20:26:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 22 20:26:36.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4024" for this suite. 04/22/23 20:26:36.365
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":362,"skipped":6703,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.291 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/22/23 20:26:20.089
    Apr 22 20:26:20.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    STEP: Building a namespace api object, basename crd-publish-openapi 04/22/23 20:26:20.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/22/23 20:26:20.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/22/23 20:26:20.162
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/22/23 20:26:20.169
    Apr 22 20:26:20.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    Apr 22 20:26:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2498517891
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 22 20:26:36.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4024" for this suite. 04/22/23 20:26:36.365
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Apr 22 20:26:36.395: INFO: Running AfterSuite actions on all nodes
Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 22 20:26:36.398: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 22 20:26:36.398: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Apr 22 20:26:36.398: INFO: Running AfterSuite actions on node 1
Apr 22 20:26:36.398: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.013 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 22 20:26:36.395: INFO: Running AfterSuite actions on all nodes
    Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Apr 22 20:26:36.397: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Apr 22 20:26:36.398: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Apr 22 20:26:36.398: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 22 20:26:36.398: INFO: Running AfterSuite actions on node 1
    Apr 22 20:26:36.398: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.115 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5625.134 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h33m45.55534357s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.4[0m

